{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hermittt/-/blob/main/FLGo2023%E5%B9%B410%E6%9C%888%E6%97%A5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "95yiQNJoquKe"
      },
      "source": [
        "# 安装"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hvs1mo8zqyYd"
      },
      "source": [
        "方式1：从github（我的版本）"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rIFQ8PMxeE1U",
        "outputId": "1dd3a9f0-78d3-4a72-8318-fe529478e3f7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchsampler\n",
            "  Downloading torchsampler-0.1.2-py3-none-any.whl (5.6 kB)\n",
            "Requirement already satisfied: torch>=1.3 in /usr/local/lib/python3.10/dist-packages (from torchsampler) (2.0.1+cu118)\n",
            "Requirement already satisfied: torchvision>=0.5 in /usr/local/lib/python3.10/dist-packages (from torchsampler) (0.15.2+cu118)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from torchsampler) (1.5.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->torchsampler) (3.12.4)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->torchsampler) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->torchsampler) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->torchsampler) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->torchsampler) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->torchsampler) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.3->torchsampler) (3.27.6)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.3->torchsampler) (17.0.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision>=0.5->torchsampler) (1.23.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision>=0.5->torchsampler) (2.31.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision>=0.5->torchsampler) (9.4.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->torchsampler) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->torchsampler) (2023.3.post1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->torchsampler) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.3->torchsampler) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision>=0.5->torchsampler) (3.3.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision>=0.5->torchsampler) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision>=0.5->torchsampler) (2.0.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision>=0.5->torchsampler) (2023.7.22)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.3->torchsampler) (1.3.0)\n",
            "Installing collected packages: torchsampler\n",
            "Successfully installed torchsampler-0.1.2\n",
            "Collecting wandb\n",
            "  Downloading wandb-0.15.12-py3-none-any.whl (2.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: Click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb) (8.1.7)\n",
            "Collecting GitPython!=3.1.29,>=1.0.0 (from wandb)\n",
            "  Downloading GitPython-3.1.37-py3-none-any.whl (190 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.0/190.0 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.31.0)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (5.9.5)\n",
            "Collecting sentry-sdk>=1.0.0 (from wandb)\n",
            "  Downloading sentry_sdk-1.31.0-py2.py3-none-any.whl (224 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.8/224.8 kB\u001b[0m \u001b[31m20.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting docker-pycreds>=0.4.0 (from wandb)\n",
            "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from wandb) (6.0.1)\n",
            "Collecting pathtools (from wandb)\n",
            "  Downloading pathtools-0.1.2.tar.gz (11 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting setproctitle (from wandb)\n",
            "  Downloading setproctitle-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb) (67.7.2)\n",
            "Requirement already satisfied: appdirs>=1.4.3 in /usr/local/lib/python3.10/dist-packages (from wandb) (1.4.4)\n",
            "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.20.3)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
            "Collecting gitdb<5,>=4.0.1 (from GitPython!=3.1.29,>=1.0.0->wandb)\n",
            "  Downloading gitdb-4.0.10-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.3.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2.0.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2023.7.22)\n",
            "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb)\n",
            "  Downloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
            "Building wheels for collected packages: pathtools\n",
            "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8791 sha256=cb09a5b5df803c4fafba61e6fbd349cc32dfedee0a3e2994261427cd0c8a90ff\n",
            "  Stored in directory: /root/.cache/pip/wheels/e7/f3/22/152153d6eb222ee7a56ff8617d80ee5207207a8c00a7aab794\n",
            "Successfully built pathtools\n",
            "Installing collected packages: pathtools, smmap, setproctitle, sentry-sdk, docker-pycreds, gitdb, GitPython, wandb\n",
            "Successfully installed GitPython-3.1.37 docker-pycreds-0.4.0 gitdb-4.0.10 pathtools-0.1.2 sentry-sdk-1.31.0 setproctitle-1.3.3 smmap-5.0.1 wandb-0.15.12\n",
            "Cloning into 'FLGo'...\n",
            "remote: Enumerating objects: 5352, done.\u001b[K\n",
            "remote: Counting objects: 100% (1449/1449), done.\u001b[K\n",
            "remote: Compressing objects: 100% (551/551), done.\u001b[K\n",
            "remote: Total 5352 (delta 884), reused 1331 (delta 839), pack-reused 3903\u001b[K\n",
            "Receiving objects: 100% (5352/5352), 9.43 MiB | 6.02 MiB/s, done.\n",
            "Resolving deltas: 100% (3131/3131), done.\n",
            "Cloning into '/content/GAN'...\n",
            "remote: Enumerating objects: 621, done.\u001b[K\n",
            "remote: Counting objects: 100% (15/15), done.\u001b[K\n",
            "remote: Compressing objects: 100% (10/10), done.\u001b[K\n",
            "remote: Total 621 (delta 6), reused 10 (delta 5), pack-reused 606\u001b[K\n",
            "Receiving objects: 100% (621/621), 127.05 MiB | 28.49 MiB/s, done.\n",
            "Resolving deltas: 100% (202/202), done.\n",
            "Cloning into '/content/VQVAE'...\n",
            "remote: Enumerating objects: 233, done.\u001b[K\n",
            "remote: Counting objects: 100% (51/51), done.\u001b[K\n",
            "remote: Compressing objects: 100% (11/11), done.\u001b[K\n",
            "remote: Total 233 (delta 44), reused 40 (delta 40), pack-reused 182\u001b[K\n",
            "Receiving objects: 100% (233/233), 5.22 MiB | 10.49 MiB/s, done.\n",
            "Resolving deltas: 100% (122/122), done.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import sys\n",
        "!pip install torchsampler\n",
        "!pip install wandb\n",
        "!git clone https://github.com/hermittt/FLGo.git\n",
        "\n",
        "sys.path.append('./FLGo')\n",
        "BASEPATH=\"/content/FLGo\"\n",
        "os.chdir(BASEPATH)\n",
        "!git clone https://github.com/hermittt/pytorch-generative-model-collections.git /content/GAN\n",
        "sys.path.append('./GAN')\n",
        "!git clone https://github.com/hermittt/pytorch-vqvae.git /content/VQVAE\n",
        "sys.path.append('./VQVAE')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MLER6btHwbow"
      },
      "source": [
        "方式2：用pip安装"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j5GiHXnKwaeO"
      },
      "outputs": [],
      "source": [
        "!pip install -i https://test.pypi.org/simple/ test-flgo-wwwzz"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DQZ6Kj6o15P1"
      },
      "source": [
        "# 每个客户端本地预训练VQGAN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FjuAea3V5BL9"
      },
      "source": [
        "## 产生task(划分数据集)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "elbDfrMV5ASg",
        "outputId": "27b6baa6-6748-4b1d-91e2-1147dd5ec6f5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into '/content/VQGAN'...\n",
            "remote: Enumerating objects: 34, done.\u001b[K\n",
            "remote: Counting objects: 100% (14/14), done.\u001b[K\n",
            "remote: Compressing objects: 100% (12/12), done.\u001b[K\n",
            "remote: Total 34 (delta 10), reused 2 (delta 2), pack-reused 20\u001b[K\n",
            "Receiving objects: 100% (34/34), 20.71 KiB | 2.59 MiB/s, done.\n",
            "Resolving deltas: 100% (10/10), done.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2023-10-07 17:05:43,771 fflow.py init [line:441] INFO Initializing devices: cpu will be used for this running.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://ufldl.stanford.edu/housenumbers/train_32x32.mat to /content/FLGo/flgo/benchmark/RAW_DATA/SVHN/train_32x32.mat\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 182040794/182040794 [00:03<00:00, 54887272.34it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://ufldl.stanford.edu/housenumbers/test_32x32.mat to /content/FLGo/flgo/benchmark/RAW_DATA/SVHN/test_32x32.mat\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 64275384/64275384 [00:01<00:00, 51726896.96it/s]\n",
            "2023-10-07 17:05:55,750 fflow.py init [line:479] INFO Use `<class 'flgo.simulator.default_simulator.Simulator'>` as the system simulator\n",
            "2023-10-07 17:05:55,766 fflow.py init [line:487] INFO Ready to start.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "optimizer_name:\t SGD\n",
            "[task]:    \t ./task/svhn_dir10\n",
            "num_steps:  \t 510\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import sys\n",
        "os.chdir(\"/content\")\n",
        "!git clone https://github.com/hermittt/VQGAN-pytorch.git /content/VQGAN\n",
        "sys.path.append('./VQGAN')\n",
        "VQ=\"/content/VQGAN\"\n",
        "os.chdir(VQ)\n",
        "os.chdir(BASEPATH)\n",
        "import flgo\n",
        "#task,task_imsz,task_imch,ep1,ep2,ld,cd,benchmark = './task/mnist_dir10_clients10' ,28,1,10,1,32,64 , 'flgo.benchmark.mnist_classification'\n",
        "#task,task_imsz,task_imch,ep1,ep2,ld,cd,benchmark = './task/cifar10_dir10',     32,3,50,1,64,128 ,'flgo.benchmark.cifar10_classification'\n",
        "task,task_imsz,task_imch,ep1,ep2,ld,cd,benchmark  = './task/svhn_dir10',      32,3,20,1,32,64 ,'flgo.benchmark.svhn_classification'\n",
        "#task,task_imsz,task_imch,ep1,ep2,ld,cd,benchmark = './task/fashion_dir10',     28,1,20,1,64,128 ,'flgo.benchmark.fashion_classification'\n",
        "config_dir01 = {'benchmark':{'name':benchmark},'partitioner':{'name': 'DirichletPartitioner',\\\n",
        "          'para':{'num_clients':10, 'alpha':0.1}}}\n",
        "config_dir10 = {'benchmark':{'name':benchmark},'partitioner':{'name': 'DirichletPartitioner',\\\n",
        "          'para':{'num_clients':10, 'alpha':1.0}}}\n",
        "config_dir100 = {'benchmark':{'name':benchmark},'partitioner':{'name': 'DirichletPartitioner',\\\n",
        "          'para':{'num_clients':10, 'alpha':10.0}}}\n",
        "#!rm -r $task\n",
        "if not os.path.exists(task): flgo.gen_task(config_dir10, task_path = task)\n",
        "\n",
        "import flgo.algorithm.fedavg as fedavg\n",
        "runner = flgo.init(task, fedavg) #调用client成员的工具\n",
        "client=runner.clients[0] #runner本身是surver\n",
        "print(\"optimizer_name:\\t\",client.optimizer_name)\n",
        "print(\"[task]:    \\t\",client.option['task'])\n",
        "print(\"num_steps:  \\t\",client.num_steps)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xM9xQeY8mT2r"
      },
      "outputs": [],
      "source": [
        "from dataclasses import dataclass\n",
        "@dataclass\n",
        "class Namespace:\n",
        "    latent_dim: int = 64\n",
        "    image_size: int = task_imsz\n",
        "    num_codebook_vectors: int = 128\n",
        "    beta: float = 0.25\n",
        "    image_channels: int = task_imch\n",
        "    device: str = 'cuda'\n",
        "    batch_size: int = 128\n",
        "    pre_epochs: int = ep1\n",
        "    epochs: int = ep2\n",
        "    learning_rate: float = 2e-3\n",
        "    beta1: float = 0.5\n",
        "    beta2: float = 0.9\n",
        "    disc_start: int = 10000\n",
        "    disc_factor: float = 1.0\n",
        "    rec_loss_factor: float = 1.0\n",
        "    perceptual_loss_factor: float = 1.0\n",
        "args = Namespace()\n",
        "args.client=client\n",
        "args.task=task.replace('/','').replace('.','').replace('task','')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GyeCkBNwchcb",
        "outputId": "fcdd3152-39fc-4464-8f82-59066fe8983b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "4437"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(client.train_data)#.indices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nx_SUi7B-ra2",
        "outputId": "aeda114b-33cb-45e7-9a3d-d4c5099523aa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.66.1)\n",
            "rm: cannot remove '/content/FLGo/results': No such file or directory\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to /root/.cache/torch/hub/checkpoints/vgg16-397923af.pth\n",
            "100%|██████████| 528M/528M [00:04<00:00, 123MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading vgg_lpips model from https://heibox.uni-heidelberg.de/f/607503859c864bc1b30b/?dl=1 to vgg_lpips/vgg.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "8.19kB [00:00, 106kB/s]                    \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ep0,0/50 : VQ_Loss= 1.58422 GAN_Loss 0.0\n",
            "ep0,50/50 : VQ_Loss= 0.40367 GAN_Loss 0.0\n",
            "ep1,0/50 : VQ_Loss= 0.38304 GAN_Loss 0.0\n",
            "ep1,50/50 : VQ_Loss= 0.38645 GAN_Loss 0.0\n",
            "ep2,0/50 : VQ_Loss= 0.29647 GAN_Loss 0.0\n",
            "ep2,50/50 : VQ_Loss= 0.22375 GAN_Loss 0.0\n",
            "ep3,0/50 : VQ_Loss= 0.25808 GAN_Loss 0.0\n",
            "ep3,50/50 : VQ_Loss= 0.22243 GAN_Loss 0.0\n",
            "ep4,0/50 : VQ_Loss= 0.26792 GAN_Loss 0.0\n",
            "ep4,50/50 : VQ_Loss= 0.22043 GAN_Loss 0.0\n",
            "ep5,0/50 : VQ_Loss= 0.20006 GAN_Loss 0.0\n",
            "ep5,50/50 : VQ_Loss= 0.17455 GAN_Loss 0.0\n",
            "ep6,0/50 : VQ_Loss= 0.1888 GAN_Loss 0.0\n",
            "ep6,50/50 : VQ_Loss= 0.16458 GAN_Loss 0.0\n",
            "ep7,0/50 : VQ_Loss= 0.17978 GAN_Loss 0.0\n",
            "ep7,50/50 : VQ_Loss= 0.20964 GAN_Loss 0.0\n",
            "ep8,0/50 : VQ_Loss= 0.19334 GAN_Loss 0.0\n",
            "ep8,50/50 : VQ_Loss= 0.175 GAN_Loss 0.0\n",
            "ep9,0/50 : VQ_Loss= 0.17417 GAN_Loss 0.0\n",
            "ep9,50/50 : VQ_Loss= 0.17839 GAN_Loss 0.0\n",
            "ep10,0/50 : VQ_Loss= 0.18044 GAN_Loss 0.0\n",
            "ep10,50/50 : VQ_Loss= 0.21344 GAN_Loss 0.0\n",
            "ep11,0/50 : VQ_Loss= 0.17043 GAN_Loss 0.0\n",
            "ep11,50/50 : VQ_Loss= 0.1648 GAN_Loss 0.0\n",
            "ep12,0/50 : VQ_Loss= 0.17181 GAN_Loss 0.0\n",
            "ep12,50/50 : VQ_Loss= 0.16617 GAN_Loss 0.0\n",
            "ep13,0/50 : VQ_Loss= 0.15629 GAN_Loss 0.0\n",
            "ep13,50/50 : VQ_Loss= 0.17653 GAN_Loss 0.0\n",
            "ep14,0/50 : VQ_Loss= 0.15795 GAN_Loss 0.0\n",
            "ep14,50/50 : VQ_Loss= 0.14595 GAN_Loss 0.0\n",
            "ep15,0/50 : VQ_Loss= 0.16174 GAN_Loss 0.0\n",
            "ep15,50/50 : VQ_Loss= 0.146 GAN_Loss 0.0\n",
            "ep16,0/50 : VQ_Loss= 0.143 GAN_Loss 0.0\n",
            "ep16,50/50 : VQ_Loss= 0.1497 GAN_Loss 0.0\n",
            "ep17,0/50 : VQ_Loss= 0.17774 GAN_Loss 0.0\n",
            "ep17,50/50 : VQ_Loss= 0.16269 GAN_Loss 0.0\n",
            "ep18,0/50 : VQ_Loss= 0.15461 GAN_Loss 0.0\n",
            "ep18,50/50 : VQ_Loss= 0.15399 GAN_Loss 0.0\n",
            "ep19,0/50 : VQ_Loss= 0.16239 GAN_Loss 0.0\n",
            "ep19,50/50 : VQ_Loss= 0.13775 GAN_Loss 0.0\n",
            "ep0,0/50 : VQ_Loss= 0.1478 GAN_Loss 0.0\n",
            "ep0,50/50 : VQ_Loss= 0.15836 GAN_Loss 0.0\n"
          ]
        }
      ],
      "source": [
        "from dataclasses import dataclass\n",
        "@dataclass\n",
        "class Namespace:\n",
        "    latent_dim: int = ld\n",
        "    image_size: int = task_imsz\n",
        "    num_codebook_vectors: int = cd\n",
        "    beta: float = 0.25\n",
        "    image_channels: int = task_imch\n",
        "    device: str = 'cuda'\n",
        "    batch_size: int = 128\n",
        "    pre_epochs: int = ep1\n",
        "    epochs: int = ep2\n",
        "    learning_rate: float = 5e-3\n",
        "    beta1: float = 0.5\n",
        "    beta2: float = 0.9\n",
        "    disc_start: int = 10000\n",
        "    disc_factor: float = 1.0\n",
        "    rec_loss_factor: float = 1.0\n",
        "    perceptual_loss_factor: float = 1.0\n",
        "args = Namespace()\n",
        "args.client=client\n",
        "args.task=task.replace('/','').replace('.','').replace('task','')\n",
        "\n",
        "os.chdir(VQ)\n",
        "!pip install tqdm\n",
        "from tqdm import tqdm\n",
        "from training_vqgan import TrainVQGAN\n",
        "from discriminator import Discriminator\n",
        "import numpy as np\n",
        "from lpips import LPIPS\n",
        "from vqgan import VQGAN\n",
        "from utils import load_data, weights_init\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.utils.data as data\n",
        "from torchvision import utils as vutils\n",
        "from codebook import Codebook\n",
        "from IPython.display import display, clear_output\n",
        "\n",
        "import cv2 as cv\n",
        "os.chdir('/content')\n",
        "from GAN.utils import merge\n",
        "os.chdir(BASEPATH)\n",
        "gpu_mode=1\n",
        "from torchvision import datasets, transforms\n",
        "def get_Normalize_mean_std(transform):\n",
        "  for t in transform.transforms:\n",
        "    if isinstance(t, transforms.Normalize):\n",
        "        return t.std,t.mean\n",
        "def get_transform(dataset):\n",
        "  if hasattr(dataset, 'transform'):\n",
        "    return dataset.transform\n",
        "  else: #针对嵌套很多层的情况，递归调用来寻找dataset中的transform\n",
        "    return get_transform(dataset.dataset)\n",
        "def show_img(samples,image_frame_dim,path,transform=None):\n",
        "    samples = samples.cpu().data.numpy().transpose(0, 2, 3, 1)\n",
        "    if transform!=None:\n",
        "      std,mean=get_Normalize_mean_std(transform)\n",
        "      samples = samples*std+mean #反归一化\n",
        "    img_float = np.squeeze(merge(samples[:image_frame_dim * image_frame_dim, :, :, :], [image_frame_dim, image_frame_dim]  ))\n",
        "    image = np.clip((img_float * 255),0, 255).astype(np.uint8)\n",
        "    # 将 RGB 图像数据转换为 BGR 顺序, 因为OpenCV 中，默认的颜色通道顺序是 BGR（蓝绿红），而不是常见的 RGB（红绿蓝）\n",
        "    image = cv.cvtColor(image, cv.COLOR_RGB2BGR)\n",
        "    cv.imwrite(path, image)\n",
        "    return image\n",
        "def visualize_results(client,step,args,vqgan): #transform是归一化参数\n",
        "    rslt_path0=BASEPATH+\"/recon/\"\n",
        "    #std,mean=get_Normalize_mean_std(transform)\n",
        "    if not os.path.exists(rslt_path0):\n",
        "        os.makedirs(rslt_path0)\n",
        "    rslt_path=rslt_path0+step\n",
        "    image_frame_dim = 5\n",
        "    imgs, y_ = client.get_batch_data()\n",
        "    imgs = imgs.to(device=args.device)\n",
        "\n",
        "    decoded_images, _, q_loss = vqgan(imgs)\n",
        "    batch_data = client.get_batch_data()\n",
        "\n",
        "    show_img(imgs[:image_frame_dim*image_frame_dim],image_frame_dim,\\\n",
        "        rslt_path +'-0.png')\n",
        "\n",
        "    show_img(decoded_images[:image_frame_dim*image_frame_dim],image_frame_dim,\\\n",
        "        rslt_path +'-1.png')\n",
        "\n",
        "class ResBlock(nn.Module):\n",
        "    def __init__(self, dim):\n",
        "        super().__init__()\n",
        "        self.block = nn.Sequential(\n",
        "            nn.ReLU(True),\n",
        "            nn.Conv2d(dim, dim, 3, 1, 1),\n",
        "            nn.BatchNorm2d(dim),\n",
        "            nn.ReLU(True),\n",
        "            nn.Conv2d(dim, dim, 1),\n",
        "            nn.BatchNorm2d(dim)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return x + self.block(x)\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self, args):\n",
        "        super().__init__()\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Conv2d(args.image_channels, args.latent_dim, 4, 2, 1),\n",
        "            nn.BatchNorm2d(args.latent_dim),\n",
        "            nn.ReLU(True),\n",
        "            nn.Conv2d(args.latent_dim, args.latent_dim, 4, 2, 1),\n",
        "            ResBlock(args.latent_dim),\n",
        "            ResBlock(args.latent_dim),\n",
        "            ).to(device=args.device)\n",
        "    def forward(self, x):\n",
        "        return self.model(x)\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, args):\n",
        "        super().__init__()\n",
        "        self.model = nn.Sequential(\n",
        "            ResBlock(args.latent_dim),\n",
        "            ResBlock(args.latent_dim),\n",
        "            nn.ReLU(True),\n",
        "            nn.ConvTranspose2d(args.latent_dim, args.latent_dim, 4, 2, 1),\n",
        "            nn.BatchNorm2d(args.latent_dim),\n",
        "            nn.ReLU(True),\n",
        "            nn.ConvTranspose2d(args.latent_dim, args.latent_dim, 4, 2, 1),\n",
        "            nn.BatchNorm2d(args.latent_dim),\n",
        "            nn.ReLU(True),\n",
        "            nn.Conv2d(args.latent_dim, args.image_channels, 3, 1, 1),\n",
        "            ).to(device=args.device)\n",
        "    def forward(self, x):\n",
        "        return F.tanh(self.model(x))\n",
        "\n",
        "class VQGAN_my(VQGAN):\n",
        "  # encoder和decoder参考：https://github.com/ritheshkumar95/pytorch-vqvae/blob/master/modules.py\n",
        "  def __init__(self, args):\n",
        "    super(VQGAN, self).__init__()\n",
        "    self.std,self.mean=get_Normalize_mean_std(get_transform(args.client.train_data))\n",
        "    if type(self.std)==tuple:\n",
        "        self.std,self.mean=self.std[0],self.mean[0]\n",
        "    self.args = args\n",
        "    self.encoder = Encoder(args).to(device=args.device)\n",
        "    self.decoder = Decoder(args).to(device=args.device)\n",
        "    self.codebook = Codebook(args).to(device=args.device)\n",
        "    self.quant_conv = nn.Conv2d(args.latent_dim, args.latent_dim, 1).to(device=args.device) #1x1 的卷积核，提高表征能力\n",
        "    self.post_quant_conv = nn.Conv2d(args.latent_dim, args.latent_dim, 1).to(device=args.device)\n",
        "  def forward(self, imgs):\n",
        "    decoded_images, codebook_indices, q_loss = VQGAN.forward(self,imgs)\n",
        "    return self.change(decoded_images), codebook_indices, q_loss\n",
        "  def change(self,x): #[-1, 1]将范围内的值转换为[0, 1]范围内的值的过程\n",
        "    x = x*0.5+0.5\n",
        "    return (x-self.mean)/np.clip(self.std,1e-5,None)\n",
        "\n",
        "class TrainVQGAN_my(TrainVQGAN):\n",
        "  def __init__(self, args):\n",
        "    self.pre_vqgan = VQGAN_my(args).to(device=args.device)\n",
        "    self.vqgan = VQGAN_my(args).to(device=args.device)\n",
        "    self.discriminator = Discriminator(args).to(device=args.device)\n",
        "    self.discriminator.apply(weights_init)\n",
        "    self.perceptual_loss = LPIPS().eval().to(device=args.device)\n",
        "    self.opt_vq, self.opt_disc = self.configure_optimizers(args)\n",
        "    self.prepare_training()\n",
        "    self.train(args)\n",
        "\n",
        "  def train(self,args):\n",
        "    self.train_vqgan(args,args.pre_epochs,self.vqgan)\n",
        "    self.pre_vqgan.load_state_dict(self.vqgan.state_dict())  # 复制参数\n",
        "    for param in self.pre_vqgan.parameters(): # 冻结vqgan的参数\n",
        "      param.requires_grad = False\n",
        "    self.train_vqgan(args,args.epochs,self.vqgan,pre_vqgan=self.pre_vqgan)\n",
        "\n",
        "  def train_vqgan(self,args,epochs,vqgan,pre_vqgan=None):\n",
        "    client = args.client\n",
        "    steps_per_epoch = len(client.train_data)//args.batch_size\n",
        "    train_loader = data.DataLoader(client.train_data, batch_size=args.batch_size, shuffle=True)\n",
        "    #data_iter = iter(train_loader)\n",
        "    for epoch in range(epochs):\n",
        "      for i, batch in enumerate(train_loader):\n",
        "        imgs, y_ = batch\n",
        "        #imgs, y_ = next(data_iter) #client.get_batch_data()\n",
        "        imgs = imgs.to(device=args.device)\n",
        "\n",
        "        if pre_vqgan==None:\n",
        "          decoded_images, _, q_loss = vqgan(imgs)\n",
        "        else:\n",
        "          decoded_images, _, q_loss = vqgan(pre_vqgan(imgs)[0].detach())\n",
        "\n",
        "        disc_real = self.discriminator(imgs)\n",
        "        disc_fake = self.discriminator(decoded_images)\n",
        "\n",
        "        disc_factor = vqgan.adopt_weight(args.disc_factor, epoch*steps_per_epoch+i, threshold=args.disc_start)\n",
        "\n",
        "        perceptual_loss = self.perceptual_loss(imgs, decoded_images)\n",
        "        rec_loss = torch.abs(imgs - decoded_images)\n",
        "        perceptual_rec_loss = args.perceptual_loss_factor * perceptual_loss + args.rec_loss_factor * rec_loss\n",
        "        perceptual_rec_loss = perceptual_rec_loss.mean()\n",
        "        g_loss = -torch.mean(disc_fake)\n",
        "\n",
        "        λ = vqgan.calculate_lambda(perceptual_rec_loss, g_loss)\n",
        "        vq_loss = perceptual_rec_loss + q_loss + disc_factor * λ * g_loss\n",
        "\n",
        "        d_loss_real = torch.mean(F.relu(1. - disc_real))\n",
        "        d_loss_fake = torch.mean(F.relu(1. + disc_fake))\n",
        "        gan_loss = disc_factor * 0.5*(d_loss_real + d_loss_fake)\n",
        "\n",
        "        self.opt_vq.zero_grad()\n",
        "        vq_loss.backward(retain_graph=True)\n",
        "\n",
        "        self.opt_disc.zero_grad()\n",
        "        gan_loss.backward()\n",
        "\n",
        "        self.opt_vq.step()\n",
        "        self.opt_disc.step()\n",
        "\n",
        "        if i % 50 == 0:\n",
        "          with torch.no_grad():\n",
        "            print('ep%d,%d/%d'%(epoch,i,steps_per_epoch,),': VQ_Loss=',np.round(vq_loss.cpu().detach().numpy().item(), 5),'GAN_Loss',np.round(gan_loss.cpu().detach().numpy().item(), 3))\n",
        "            real_fake_images = torch.cat((imgs[:4], decoded_images[:4]))\n",
        "            vutils.save_image(real_fake_images, os.path.join(\"results\", \"%2d-%3d.jpg\"%(epoch,i)), nrow=4)\n",
        "        '''\n",
        "        if i % 50 == 0:\n",
        "          print('ep%d,%d/%d'%(epoch,i,steps_per_epoch,),': VQ_Loss=',np.round(vq_loss.cpu().detach().numpy().item(), 5),'GAN_Loss',np.round(gan_loss.cpu().detach().numpy().item(), 3))\n",
        "          visualize_results(client,'%d,%d'%(epoch,i//50,),args,vqgan)\n",
        "        '''\n",
        "    if pre_vqgan==None:\n",
        "      torch.save(vqgan.state_dict(), os.path.join(\"checkpoints\", f\"{args.task}.vqgan_epoch.pt\"))\n",
        "    else:\n",
        "      torch.save(vqgan.state_dict(), os.path.join(\"checkpoints\", f\"{args.task}.vqgan_epoch_pre.pt\"))\n",
        "\n",
        "!rm -r /content/FLGo/results\n",
        "train_vqgan = TrainVQGAN_my(args)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DHZy0_Z6OvJS"
      },
      "source": [
        "- 随机采样mnist"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rn0SIMMrF6Yn",
        "outputId": "2814c174-4f12-4baa-f6e0-d58ccec542fe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([16, 3, 28, 28])\n",
            "tensor(-1.8762, device='cuda:0', grad_fn=<MinBackward1>) tensor(2.2489, device='cuda:0', grad_fn=<MaxBackward1>)\n"
          ]
        }
      ],
      "source": [
        "import torch.utils.data as data\n",
        "train_loader = data.DataLoader(client.train_data, batch_size=16, shuffle=False)\n",
        "transform = get_transform(client.train_data)\n",
        "n=4\n",
        "z = torch.randn(n*n,ld,7,7).to(device=args.device)\n",
        "z, _, _ = train_vqgan.vqgan.codebook(z)\n",
        "img2=train_vqgan.vqgan.decode(z)\n",
        "img2=train_vqgan.vqgan.change(img2)\n",
        "show=show_img(img2,n,'0.png',transform=transform)\n",
        "print(img2.shape)\n",
        "print(img2.min(),img2.max())\n",
        "img3=train_vqgan.pre_vqgan.decode(z)\n",
        "img3=train_vqgan.vqgan.change(img3)\n",
        "show=show_img(img3,n,'2.png',transform=transform)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K-adTbGzF7Zz"
      },
      "source": [
        "- 真实数据"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 259
        },
        "id": "sZIWPMAnDazc",
        "outputId": "e1bdd801-e917-4119-e257-bc2470ba08a3"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-af87e2fd2698>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# 访问前两个元素\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0;32mbreak\u001b[0m   \u001b[0;31m# 只打印第一个batch的数据\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mshow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshow_img\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'1.png'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'train_loader' is not defined"
          ]
        }
      ],
      "source": [
        "# 访问前两个元素\n",
        "for img, label in train_loader:\n",
        "  print(img.shape, label.shape)\n",
        "  break   # 只打印第一个batch的数据\n",
        "show=show_img(img,n,'1.png',transform=transform)\n",
        "print(img.min(),img.max())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3CLsiRuyGaGH",
        "outputId": "aca66b40-0c56-4a2b-be9a-a3bb14f3c4d9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Compose(\n",
              "    ToTensor()\n",
              "    Normalize(mean=(0.1307,), std=(0.3081,))\n",
              ")"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "get_transform(client.train_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cYVJjRmnacQL",
        "outputId": "68017e14-11a1-4c53-fa44-c42e56b5be7e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'sample': 'md',\n",
              " 'aggregate': 'uniform',\n",
              " 'num_rounds': 20,\n",
              " 'proportion': 0.2,\n",
              " 'learning_rate_decay': 0.998,\n",
              " 'lr_scheduler': -1,\n",
              " 'early_stop': -1,\n",
              " 'num_epochs': 5,\n",
              " 'num_steps': -1,\n",
              " 'learning_rate': 0.1,\n",
              " 'batch_size': 64.0,\n",
              " 'optimizer': 'SGD',\n",
              " 'clip_grad': 0.0,\n",
              " 'momentum': 0.0,\n",
              " 'weight_decay': 0.0,\n",
              " 'algo_para': [],\n",
              " 'train_holdout': 0.1,\n",
              " 'test_holdout': 0.0,\n",
              " 'local_test': False,\n",
              " 'seed': 0,\n",
              " 'gpu': [],\n",
              " 'server_with_cpu': False,\n",
              " 'num_parallels': 1,\n",
              " 'num_workers': 0,\n",
              " 'pin_memory': False,\n",
              " 'test_batch_size': 512,\n",
              " 'availability': 'IDL',\n",
              " 'connectivity': 'IDL',\n",
              " 'completeness': 'IDL',\n",
              " 'responsiveness': 'IDL',\n",
              " 'log_level': 'INFO',\n",
              " 'log_file': False,\n",
              " 'no_log_console': False,\n",
              " 'no_overwrite': False,\n",
              " 'eval_interval': 1,\n",
              " 'task': './task/mnist_dir10_clients10',\n",
              " 'algorithm': 'fedavg',\n",
              " 'model': 'cnn'}"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "client.option"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BL4sZROmJ8xr"
      },
      "source": [
        "# 联邦训练阶段(test)\n",
        "- 1.client载入预训练模型"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x8Knnsxr406Q",
        "outputId": "fec256b6-a8de-41ce-b481-5b561c41505a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Compose(\n",
              "    ToTensor()\n",
              "    Normalize(mean=(0.1307,), std=(0.3081,))\n",
              ")"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "get_transform(client.train_data)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from flgo.algorithm.fedbase import BasicServer, BasicClient\n",
        "import flgo.algorithm.fedavg as fedavg\n",
        "os.chdir('/content/VQVAE')\n",
        "from modules import GatedMaskedConv2d\n",
        "os.chdir(BASEPATH)\n",
        "import copy\n",
        "from flgo.utils import fmodule\n",
        "import flgo\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "import json\n",
        "import importlib\n",
        "!pip install pytorch-msssim\n",
        "from pytorch_msssim import ssim\n",
        "!export CUDA_LAUNCH_BLOCKING=1\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "def weights_init(net):\n",
        "  for m in net.modules():\n",
        "    if isinstance(m, nn.Conv2d):\n",
        "      #nn.init.xavier_uniform_(m.weight.data)\n",
        "      m.weight.data.normal_(0, 0.02)\n",
        "      m.bias.data.zero_()\n",
        "\n",
        "def masked_loss(A, B, mask, threshold = 0.5):\n",
        "  masked_A = A * mask      # 将掩码应用到特征图 A\n",
        "  masked_B = B * mask      # 将掩码应用到特征图 B\n",
        "  mask_mean = torch.mean(mask, dim=(2, 3))\n",
        "  # 将小于阈值的图像掩码置零，并计算非零元素的均值\n",
        "  loss_mask = torch.mean(torch.relu(threshold - mask_mean))\n",
        "  return F.mse_loss(masked_A, masked_B)+loss_mask\n",
        "\n",
        "def imageDiffLoss(input1, input2):\n",
        "  loss = 1 - ssim(input1, input2)\n",
        "  return loss\n",
        "\n",
        "def load_vqgan(checkpoint_path,args):\n",
        "  model = VQGAN_my(args)\n",
        "  model.load_checkpoint(checkpoint_path)\n",
        "  model = model.eval()\n",
        "  return model\n",
        "\n",
        "class discriminator(nn.Module):\n",
        "  # Network Architecture is exactly same as in infoGAN (https://arxiv.org/abs/1606.03657)\n",
        "  # Architecture : (64)4c2s-(128)4c2s_BL-FC1024_BL-FC1_S\n",
        "  def __init__(self, input_dim=1, output_dim=1, input_size=32, latent_dim=1):\n",
        "    super(discriminator, self).__init__()\n",
        "    self.input_dim = input_dim\n",
        "    self.output_dim = output_dim\n",
        "    self.input_size = input_size\n",
        "    if latent_dim==1:\n",
        "      self.fc_in_dim = 128 * (self.input_size // 4) * (self.input_size // 4)\n",
        "    else:\n",
        "      self.fc_in_dim = latent_dim * (self.input_size // 4) * (self.input_size // 4)\n",
        "    self.conv = nn.Sequential(\n",
        "        nn.Conv2d(self.input_dim, 64, 4, 2, 1),\n",
        "        nn.LeakyReLU(0.2),\n",
        "        nn.Conv2d(64, 128, 4, 2, 1),\n",
        "        nn.BatchNorm2d(128),\n",
        "        nn.LeakyReLU(0.2),\n",
        "    )\n",
        "    self.fc = nn.Sequential(\n",
        "        nn.Linear(self.fc_in_dim, 1024),\n",
        "        nn.BatchNorm1d(1024),\n",
        "        nn.LeakyReLU(0.2),\n",
        "        nn.Linear(1024, self.output_dim),\n",
        "        nn.Sigmoid(),\n",
        "    )\n",
        "\n",
        "  def forward(self, input, mod='latent'):#'all'):\n",
        "    if mod!='latent':\n",
        "      input = self.conv(input)\n",
        "    x = input.reshape(-1, self.fc_in_dim)\n",
        "    x = self.fc(x)\n",
        "\n",
        "    return x\n",
        "\n",
        "class Residual(nn.Module):\n",
        "  def __init__(self, in_channels, num_hiddens, num_residual_hiddens):\n",
        "    super(Residual, self).__init__()\n",
        "    self.num_hiddens = num_hiddens\n",
        "    self._block = nn.Sequential(\n",
        "        nn.ReLU(True),\n",
        "        nn.Conv2d(in_channels=in_channels,\n",
        "                  out_channels=num_residual_hiddens,\n",
        "                  kernel_size=3, stride=1, padding=1, bias=False),\n",
        "        nn.ReLU(True),\n",
        "        nn.Conv2d(in_channels=num_residual_hiddens,\n",
        "                  out_channels=num_hiddens,\n",
        "                  kernel_size=1, stride=1, bias=False)\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "      return x[:,:self.num_hiddens] + F.tanh(self._block(x))\n",
        "\n",
        "\n",
        "class ResidualStack(nn.Module):\n",
        "  def __init__(self, in_channels, num_hiddens, num_residual_layers, num_residual_hiddens):\n",
        "    super(ResidualStack, self).__init__()\n",
        "    self._num_residual_layers = num_residual_layers\n",
        "    self._layer0 = Residual(in_channels, num_hiddens, num_residual_hiddens)\n",
        "    self._layers = nn.ModuleList([Residual(num_hiddens, num_hiddens, num_residual_hiddens)\n",
        "                          for _ in range(self._num_residual_layers-1)])\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self._layer0(x)\n",
        "    for i in range(self._num_residual_layers-1):\n",
        "      x = self._layers[i](x)\n",
        "    return F.relu(x)\n",
        "\n",
        "class generator(nn.Module): #适用于图像大小是4的倍数的数据(mnist-28,cifa10-32)\n",
        "  def __init__(self, input_dim, input_size ,vqgan, class_num=10, latent_dim=1024):\n",
        "    super().__init__()\n",
        "    self.input_dim = input_dim\n",
        "    self.input_size = input_size\n",
        "    self.vqgan = vqgan\n",
        "    self.class_num = class_num\n",
        "    self.z_channel = self.vqgan.args.latent_dim\n",
        "    self.z_size = (self.input_size // 4)\n",
        "    self.G_z = nn.Sequential(\n",
        "            #nn.Linear(self.input_dim + self.class_num, latent_dim),\n",
        "            nn.Linear(self.input_dim, latent_dim),\n",
        "            nn.BatchNorm1d(latent_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(latent_dim, self.z_channel*self.z_size*self.z_size),\n",
        "            nn.BatchNorm1d(self.z_channel*self.z_size*self.z_size),\n",
        "            nn.ReLU(),\n",
        "        )\n",
        "\n",
        "    self.change_z= nn.Sequential(\n",
        "            nn.Conv2d(self.z_channel+class_num, self.z_channel, 5, 1, 2),\n",
        "            nn.BatchNorm2d(self.z_channel),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Conv2d(self.z_channel, self.z_channel, 5, 1, 2),\n",
        "            nn.BatchNorm2d(self.z_channel),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Conv2d(self.z_channel, self.z_channel, 5, 1, 2),\n",
        "            nn.BatchNorm2d(self.z_channel),\n",
        "            nn.LeakyReLU(0.2),\n",
        "        )\n",
        "\n",
        "    self._residual_stack= ResidualStack(in_channels=self.z_channel,\n",
        "              num_hiddens=self.z_channel,\n",
        "              num_residual_layers=self.z_channel,\n",
        "              num_residual_hiddens=2)\n",
        "\n",
        "    # 冻结vqgan的参数\n",
        "    for param in self.vqgan.parameters():\n",
        "      param.requires_grad = False\n",
        "\n",
        "\n",
        "  def forward(self, input, label, mod=\"z_in\"):\n",
        "    if mod !=\"z_in\":\n",
        "      input = self.G_z(input)#torch.cat([input, label], 1))\n",
        "      input = input.view(-1, self.z_channel, self.z_size, self.z_size)\n",
        "    label = label.unsqueeze(-1).unsqueeze(-1)  # 添加两个维度，使其与输入图像的维度相匹配\n",
        "    label = label.expand(label.size(0), label.size(1), input.size(2), input.size(3))  # 扩展为与输入图像相同的尺寸\n",
        "    z = self.change_z(torch.cat([input, label], 1))\n",
        "    #z = self._residual_stack(z)\n",
        "    x = self.z_to_image(z)\n",
        "    return x\n",
        "\n",
        "  def z_to_image(self, z):\n",
        "    z_vq, _, _ = self.vqgan.codebook(z)\n",
        "    image = self.vqgan.decode(z_vq)\n",
        "    return image,z_vq\n",
        "\n",
        "def crop_image(image, target_size):\n",
        "    # 获取原始图像的大小\n",
        "    original_size = image.shape[-1]\n",
        "\n",
        "    # 计算裁剪区域的边界\n",
        "    left = (original_size - target_size) // 2\n",
        "    top = (original_size - target_size) // 2\n",
        "    right = left + target_size\n",
        "    bottom = top + target_size\n",
        "\n",
        "    # 裁剪图像\n",
        "    cropped_image = image[:,:,top:bottom, left:right]\n",
        "\n",
        "    return cropped_image\n",
        "\n",
        "\n",
        "class GatedPixelCNN_my(nn.Module):\n",
        "  def __init__(self, embedding, input_dim=256, dim=64, n_layers=15, n_classes=10):\n",
        "    super().__init__()\n",
        "    self.dim = dim\n",
        "\n",
        "    # Building the PixelCNN layer by layer\n",
        "    self.layers = nn.ModuleList()\n",
        "\n",
        "    # Initial block with Mask-A convolution\n",
        "    # Rest with Mask-B convolutions\n",
        "    for i in range(n_layers):\n",
        "        mask_type = 'A' if i == 0 else 'B'\n",
        "        kernel = 7 if i == 0 else 3\n",
        "        residual = False if i == 0 else True\n",
        "\n",
        "        self.layers.append(\n",
        "            GatedMaskedConv2d(mask_type, dim, kernel, residual, n_classes)\n",
        "        )\n",
        "\n",
        "    # Add the output layer\n",
        "    self.output_conv = nn.Sequential(\n",
        "        nn.Conv2d(dim, dim, 1)\n",
        "    )\n",
        "\n",
        "    self.apply(weights_init)\n",
        "  def forward(self, x, label):\n",
        "    x_v, x_h = (x, x)\n",
        "    for i, layer in enumerate(self.layers):\n",
        "      x_v, x_h = layer(x_v, x_h, label) #torch.Size([32, 128, 7, 7])\n",
        "    return self.output_conv(x_h)\n",
        "\n",
        "class augmentation(nn.Module):\n",
        "  def __init__(self, vqgan, input_dim=1, input_size=32, class_num=10):\n",
        "    super(augmentation, self).__init__()\n",
        "    self.vqgan = vqgan\n",
        "    self.input_dim = input_dim\n",
        "    self.input_size = input_size\n",
        "    self.class_num = class_num\n",
        "    self.z_channel = self.vqgan.args.latent_dim\n",
        "    self.prior = GatedPixelCNN_my(self.vqgan.codebook.embedding,self.vqgan.args.num_codebook_vectors, dim=self.z_channel, n_layers=3, n_classes=self.class_num)\n",
        "    self._conv_1 = nn.Sequential(\n",
        "        nn.Conv2d(self.input_dim+class_num, 32, 4, 2, 1),\n",
        "        nn.BatchNorm2d(32),\n",
        "        nn.LeakyReLU(0.2),\n",
        "        nn.Conv2d(32, 64, 4, 2, 1),\n",
        "        nn.BatchNorm2d(64),\n",
        "        nn.LeakyReLU(0.2),\n",
        "        nn.Conv2d(64, 64, 3, 1, 1),\n",
        "        nn.BatchNorm2d(64),\n",
        "        nn.LeakyReLU(0.2),)\n",
        "    self._conv_trans_1  = nn.Sequential(\n",
        "        nn.ConvTranspose2d(64, 64, 4, 2, 1),\n",
        "        nn.BatchNorm2d(64),\n",
        "        nn.LeakyReLU(0.2),\n",
        "        nn.ConvTranspose2d(64, 32, 4, 2, 1),\n",
        "        nn.BatchNorm2d(32),\n",
        "        nn.LeakyReLU(0.2),\n",
        "        nn.ConvTranspose2d(32, self.input_dim, 3, 1, 1),\n",
        "        nn.Tanh(),\n",
        "    )\n",
        "\n",
        "    self._conv = nn.Sequential(\n",
        "        nn.Conv2d(self.z_channel+class_num, self.z_channel, 7, 1, 3),\n",
        "        ResBlock(self.z_channel),\n",
        "        ResBlock(self.z_channel),\n",
        "        nn.ReLU(),#nn.LeakyReLU(0.2),\n",
        "        nn.Conv2d(self.z_channel, self.z_channel, 3, 1, 1),\n",
        "        nn.BatchNorm2d(self.z_channel),\n",
        "        nn.ReLU(),#nn.LeakyReLU(0.2),\n",
        "        nn.Conv2d(self.z_channel, self.z_channel, 1, 1, 0),\n",
        "        nn.Tanh(),\n",
        "        )\n",
        "    self.mask = nn.Sequential(\n",
        "        nn.Conv2d(self.z_channel, 1, 1, 1, 0),\n",
        "        nn.Sigmoid(),\n",
        "        )\n",
        "\n",
        "    # 冻结vqgan的参数\n",
        "    for param in self.vqgan.parameters():\n",
        "      param.requires_grad = False\n",
        "\n",
        "    weights_init(self._conv)\n",
        "\n",
        "  def forward(self, x, label):\n",
        "    # 将类别标签转换为 one-hot 编码\n",
        "    z = self.encode(x) #torch.Size([32, 64, 7, 7])\n",
        "    label = label.unsqueeze(-1).unsqueeze(-1)  # 添加两个维度，使其与输入图像的维度相匹配\n",
        "    label = label.expand(label.size(0), label.size(1), z.size(2), z.size(3))  # 扩展为与输入图像相同的尺寸\n",
        "    z = self._conv(torch.cat([z, label], dim=1)) #+ z.detach()\n",
        "    #z_, _, _ = self.vqgan.codebook(z)\n",
        "    x = self.decode(z)\n",
        "    x = self.vqgan.change(x)\n",
        "    return x,z\n",
        "\n",
        "  def forward0(self, x, label):\n",
        "    Y=torch.max(label, 1)[1]\n",
        "    with torch.no_grad():\n",
        "      z = self.encode(x)\n",
        "      _,latents,_ = self.vqgan.codebook(z)\n",
        "      latents = latents.detach()\n",
        "      z_size = (self.input_size // 4)\n",
        "      latents = latents.reshape(Y.size(0),z_size,z_size) #torch.Size([32, 7, 7])\n",
        "    z = self.prior(z, Y) #torch.Size([32, 7, 7, 128])\n",
        "    x = self.decode(z)\n",
        "    x = self.vqgan.change(x)\n",
        "    return x,z\n",
        "\n",
        "  def encode(self, imgs):\n",
        "    encoded_images = self.vqgan.encoder(imgs)\n",
        "    quant_conv_encoded_images = self.vqgan.quant_conv(encoded_images)\n",
        "    #z, indices, _ = self.vqgan.codebook(quant_conv_encoded_images)\n",
        "    return quant_conv_encoded_images\n",
        "\n",
        "  def decode(self, z):\n",
        "    z, _, _ = self.vqgan.codebook(z)\n",
        "    post_quant_conv_mapping = self.vqgan.post_quant_conv(z)\n",
        "    decoded_images = self.vqgan.decoder(post_quant_conv_mapping)\n",
        "    return decoded_images\n",
        "\n",
        "\n",
        "\n",
        "class Server(BasicServer):\n",
        "  def initialize(self, *args, **kwargs):\n",
        "    # 指定随机种子创建随机数生成器对象\n",
        "    np.random.seed(0)\n",
        "    self.rng_sample = np.random.RandomState(42) #采样客户端专用的随机数生成器，以免在其他地方改变随机数列表\n",
        "  def pack(self, client_id, mtype=0, *args, **kwargs):\n",
        "    return {\n",
        "        \"model\": copy.deepcopy(self.model),\n",
        "        \"round\": self.current_round,\n",
        "    }\n",
        "  def sample(self):\n",
        "    all_clients = self.available_clients if 'available' in self.sample_option else [cid for cid in range(self.num_clients)]\n",
        "    # full sampling with unlimited communication resources of the server\n",
        "    if 'full' in self.sample_option:\n",
        "        return all_clients\n",
        "    # sample clients\n",
        "    elif 'uniform' in self.sample_option:\n",
        "        # original sample proposed by fedavg\n",
        "        selected_clients = list(\n",
        "            self.rng_sample.choice(all_clients, min(self.clients_per_round, len(all_clients)), replace=False)) if len(\n",
        "            all_clients) > 0 else []\n",
        "    elif 'md' in self.sample_option:\n",
        "        # the default setting that is introduced by FedProx, where the clients are sampled with the probability in proportion to their local_movielens_recommendation data sizes\n",
        "        local_data_vols = [self.clients[cid].datavol for cid in all_clients]\n",
        "        total_data_vol = sum(local_data_vols)\n",
        "        p = np.array(local_data_vols) / total_data_vol\n",
        "        selected_clients = list(self.rng_sample.choice(all_clients, self.clients_per_round, replace=True, p=p)) if len(\n",
        "            all_clients) > 0 else []\n",
        "    print('客户端选择：',selected_clients)\n",
        "    return selected_clients\n",
        "class Client(BasicClient):\n",
        "  def initialize(self, *args, **kwargs):\n",
        "    self.rng_local = np.random.RandomState(0) #专用的随机对象\n",
        "    self.z_dim = 62\n",
        "    if self.option['gpu']!='':\n",
        "      self.gpu_mode = 1\n",
        "    else:\n",
        "      self.gpu_mode = 0\n",
        "    self.gan_clip_grad = 10 #(默认为0)\n",
        "    #self.clip_grad = 10\n",
        "    self.class_num = self.option['class_num']\n",
        "    self.sample_num = self.class_num ** 2\n",
        "\n",
        "    data_shape = self.train_data[0][0].shape\n",
        "\n",
        "    vqgan = load_vqgan(os.path.join(\"/content/FLGo/checkpoints\", f\"{self.option['vqgan_args'].task}.vqgan_epoch_pre.pt\"),self.option['vqgan_args'])\n",
        "    self.vqgan2 = load_vqgan(os.path.join(\"/content/FLGo/checkpoints\", f\"{self.option['vqgan_args'].task}.vqgan_epoch.pt\"),self.option['vqgan_args'])\n",
        "    self.G = generator(self.z_dim,data_shape[1],vqgan,class_num=self.class_num)\n",
        "    self.A = augmentation(vqgan,input_dim=data_shape[0], input_size=data_shape[1],class_num=self.class_num).to(device=self.option['vqgan_args'].device)\n",
        "    self.D = discriminator(input_dim=data_shape[0], input_size=data_shape[1]).to(device=self.option['vqgan_args'].device)#, latent_dim=self.option['vqgan_args'].latent_dim).to(device=self.option['vqgan_args'].device)\n",
        "    self.G_optimizer = optim.Adam(self.G.parameters(), lr=self.option['G_lr'], betas=(self.option['vqgan_args'].beta1, self.option['vqgan_args'].beta2))\n",
        "    self.A_optimizer = optim.Adam(self.A.parameters(), lr=self.option['G_lr'], betas=(self.option['vqgan_args'].beta1, self.option['vqgan_args'].beta2))\n",
        "    self.D_optimizer = optim.Adam(self.D.parameters(), lr=self.option['D_lr'], betas=(self.option['vqgan_args'].beta1, self.option['vqgan_args'].beta2))\n",
        "    self.V_optimizer = optim.Adam(self.vqgan2.parameters(), lr=self.option['V_lr'], betas=(self.option['vqgan_args'].beta1, self.option['vqgan_args'].beta2))\n",
        "\n",
        "    #self.P_optimizer = torch.optim.Adam(self.prior.parameters(), lr=self.option['G_lr'], betas=(self.option['vqgan_args'].beta1, self.option['vqgan_args'].beta2))\n",
        "\n",
        "    sample_z_=self.generate_random_z(self.class_num,self.z_dim,self.gpu_mode)\n",
        "    self.sample_z_=sample_z_.unsqueeze(1).repeat(1,self.class_num,1).reshape(-1,self.z_dim)\n",
        "    sample_y_=self.generate_labels(self.class_num, self.class_num, self.gpu_mode, rng_local=self.rng_local)\n",
        "    self.sample_y_=sample_y_.unsqueeze(0).repeat(self.class_num,1,1).reshape(-1,self.class_num)\n",
        "    self.rslt_path = self.get_rslt_path()\n",
        "    if self.gpu_mode:\n",
        "      self.G.cuda()\n",
        "\n",
        "    # 冻结除了 decoder 之外的参数\n",
        "    for name, param in self.vqgan2.named_parameters():\n",
        "        if 'decoder' not in name:\n",
        "            param.requires_grad = False\n",
        "\n",
        "  def unpack(self, received_pkg):\n",
        "    return received_pkg['model'],received_pkg['round']\n",
        "  def get_loc_data(self):\n",
        "    date_num=len(self.train_data)#.indices)\n",
        "    data_loader = self.calculator.get_dataloader(self.train_data, batch_size=date_num)\n",
        "    y_ = data_loader.__iter__().__next__()[1]\n",
        "    y_vec_ = torch.zeros((y_.shape[0], 10)).scatter_(1, y_.type(torch.LongTensor).unsqueeze(1), 1)\n",
        "    c = y_vec_.sum(0)\n",
        "    print(\"client\",self.id,\"总样本数：\",date_num,\" 各类：\", c.int().numpy())\n",
        "    return c\n",
        "  def reply(self, svr_pkg):\n",
        "    model,self.round = self.unpack(svr_pkg) #svr_pkg (dict): the package received from the server\n",
        "    self.src_model = copy.deepcopy(model)\n",
        "    self.src_model.freeze_grad()\n",
        "    self.train(model)\n",
        "    cpkg = self.pack(model)\n",
        "    return cpkg #client_pkg (dict): the package to be send to the server\n",
        "\n",
        "  def z_loss(self, z, indices):\n",
        "    z = z.permute(0, 2, 3, 1).contiguous()\n",
        "    z_flattened = z.view(-1, self.A.vqgan.codebook.latent_dim)\n",
        "    d = torch.sum(z_flattened**2, dim=1, keepdim=True) + \\\n",
        "        torch.sum(self.A.vqgan.codebook.embedding.weight**2, dim=1) - \\\n",
        "        2*(torch.matmul(z_flattened, self.A.vqgan.codebook.embedding.weight.t()))\n",
        "    logits = F.softmin(d, dim=1)\n",
        "    loss = F.cross_entropy(logits, indices.detach().view(-1))\n",
        "    return loss\n",
        "\n",
        "\n",
        "  def train(self,global_model):\n",
        "    global_model.train()\n",
        "    self.G.train()\n",
        "    self.A.train()\n",
        "    optimizer = self.calculator.get_optimizer(global_model, lr=self.learning_rate, weight_decay=self.weight_decay,\n",
        "                                              momentum=self.momentum)\n",
        "    for epoch in range(self.num_epochs):\n",
        "      for iter in range(self.num_steps):\n",
        "        batch_data = self.get_batch_data()\n",
        "        x_,y_ = batch_data\n",
        "        y_vec_ = torch.zeros((self.batch_size, self.class_num)).scatter_(1, y_.type(torch.LongTensor).unsqueeze(1), 1)\n",
        "        x_,y_vec_ = self.to_gpu([x_,y_vec_])\n",
        "        if self.option['batch_size'] != batch_data[1].shape[0]:\n",
        "          break\n",
        "        x0,y0 = x_,y_\n",
        "        print_head = \"Epoch: [%2d] [%4d/%4d]\" % ((epoch + 1), (iter + 1), client.num_steps)\n",
        "        self.train_step(x_,y_vec_, iter, global_model, optimizer, print_head)\n",
        "      with torch.no_grad():\n",
        "        if x0.shape[0]<self.class_num:\n",
        "          print(x0.shape[0])\n",
        "          break\n",
        "        self.visualize_results(epoch+1,x0,y0)\n",
        "    return\n",
        "\n",
        "  def train_step(self, x_, y_vec_, iter, global_model, optimizer, print_head):\n",
        "    z_ = self.generate_random_z(self.batch_size, self.z_dim, self.gpu_mode)\n",
        "    y_disc_ = self.generate_labels(self.G.class_num, self.batch_size, self.gpu_mode, rng_local=self.rng_local)\n",
        "    y_disc_2 = self.generate_labels(self.G.class_num, self.batch_size, self.gpu_mode, rng_local=self.rng_local,mod='rand')\n",
        "\n",
        "    G,Z= self.A(x_,y_disc_2)\n",
        "    G_v,_,_ = self.vqgan2(G)\n",
        "\n",
        "    G2,Z2= self.A(x_,y_vec_)\n",
        "    G3,Z3= self.A(G,y_vec_)\n",
        "    G4,Z4= self.A(G.detach(),y_disc_2)\n",
        "    Z0 = self.A.encode(x_).detach()\n",
        "    _,latents,_ = self.A.vqgan.codebook(Z0)\n",
        "    G_t = G#G4\n",
        "    #G_t,_ = self.A(G_v,y_disc_2)\n",
        "    #G_t,_,_ = self.vqgan2(G_t)\n",
        "\n",
        "    C_real = global_model(x_)\n",
        "    ## 训练分类模型\n",
        "    optimizer.zero_grad()\n",
        "    batch_data=[x_,torch.max(y_vec_, 1)[1]]\n",
        "    # calculate the loss of the model on batched dataset through task-specified calculator\n",
        "    C_src = self.src_model(G_t).detach()\n",
        "    C_ = global_model(G_t.detach())\n",
        "    logic_mean=(F.softmax(C_src, dim=-1) * y_disc_2).sum(-1).detach().mean()\n",
        "    logic_mask=(logic_mean>0.5).float()\n",
        "    distill_loss = F.mse_loss(C_src, C_)\n",
        "    loss = F.cross_entropy(C_real,y_vec_)+distill_loss*logic_mask\n",
        "\n",
        "    loss.backward(retain_graph=True)\n",
        "    if self.clip_grad>0:torch.nn.utils.clip_grad_norm_(parameters=global_model.parameters(), max_norm=self.clip_grad)\n",
        "    optimizer.step()\n",
        "\n",
        "    self.A_optimizer.zero_grad()\n",
        "\n",
        "    #d_loss = -torch.mean(disc_fake)\n",
        "    recon_loss = F.mse_loss(G2, x_)+ F.mse_loss(G3, x_)#+F.mse_loss(G2_, x_)+F.mse_loss(G3_, x_)#+F.mse_loss(G2_v, x_)+F.mse_loss(G3_v, x_)\n",
        "    #z_loss = self.mse_loss_clip(Z0, Z2, 0)+self.mse_loss_clip(Z0, Z3, 0)+self.mse_loss_clip(Z0, Z, 0)\n",
        "    #z_loss = F.mse_loss(Z0, Z2)+F.mse_loss(Z0, Z3)+10*F.mse_loss(Z0, Z)\n",
        "    z_loss = F.mse_loss(Z0, Z2)+F.mse_loss(Z0, Z3)+10*self.z_loss(Z,latents)#10*F.mse_loss(Z0, Z)#+0.001*F.cross_entropy(Z0, Z3)#masked_loss(Z0, Z3, M)#masked_loss(Z0, Z, M)#F.mse_loss(Z0, Z)\n",
        "    #z_loss = F.mse_loss(Z2, Z0)+self.z_loss(Z3,latents)+10*F.mse_loss(Z, Z0)#+10*self.z_loss(Z,latents)\n",
        "    #z_loss = F.mse_loss(Z, Z0)\n",
        "    cycle_loss = F.mse_loss(G4.detach(), G)\n",
        "    c_loss = F.cross_entropy(self.src_model(G), y_disc_2)#+F.cross_entropy(self.src_model(G3), y_vec_)\n",
        "    G_loss = c_loss/c_loss.detach() + z_loss #+ recon_loss#+ cycle_loss\n",
        "    G_loss.backward()\n",
        "\n",
        "    #if self.gan_clip_grad>0:torch.nn.utils.clip_grad_norm_(parameters=self.vqgan2.parameters(), max_norm=self.gan_clip_grad)\n",
        "    #self.V_optimizer.step()\n",
        "    if self.gan_clip_grad>0:torch.nn.utils.clip_grad_norm_(parameters=self.A.parameters(), max_norm=self.gan_clip_grad)\n",
        "    self.A_optimizer.step()\n",
        "    #if self.gan_clip_grad>0:torch.nn.utils.clip_grad_norm_(parameters=self.G.parameters(), max_norm=self.gan_clip_grad)\n",
        "    #self.G_optimizer.step()\n",
        "    if iter % 100 == 0:\n",
        "      print(\"c_loss: %.2f, distill_loss%.2f, recon_loss%.2f\"\n",
        "      %(c_loss.item(),distill_loss.item(),recon_loss.item()))\n",
        "\n",
        "  @staticmethod\n",
        "  def adopt_weight(disc_factor, i, threshold, value=0.):\n",
        "    if i < threshold:\n",
        "        disc_factor = value\n",
        "    return disc_factor\n",
        "\n",
        "  @staticmethod\n",
        "  def mse_loss_clip(a,b,clip=0):\n",
        "    loss = F.mse_loss(a, b, reduce=False).mean(dim=(1,2,3))\n",
        "    loss[loss<clip] = 0\n",
        "    return loss.mean()\n",
        "\n",
        "  def to_gpu(self,data_tuple):\n",
        "    if self.gpu_mode:\n",
        "      return tuple(data_tensor.cuda() for data_tensor in data_tuple)\n",
        "    else:\n",
        "      return data_tuple\n",
        "  # Function to generate random z_ for G network:\n",
        "  @staticmethod\n",
        "  def generate_random_z(batch_size, z_dim, gpu_mode):\n",
        "    z_ = torch.rand((batch_size, z_dim))\n",
        "    if gpu_mode:\n",
        "      z_ = z_.cuda()\n",
        "    return z_\n",
        "  @staticmethod\n",
        "  def generate_labels(class_num, batch_size, gpu_mode, rng_local, mod=\"regu\"): #随机种子rng_local\n",
        "    weight = class_num * [float(1.0 / class_num)]\n",
        "    if mod == \"regu\":\n",
        "      mean_Y = torch.range(0, class_num - 1, dtype=torch.int64).repeat(batch_size // class_num)\n",
        "      mean_Y_ = torch.zeros((mean_Y.shape[0], class_num)).scatter_(1, mean_Y.type(torch.LongTensor).unsqueeze(1), 1)\n",
        "      y_disc_ = torch.from_numpy(rng_local.multinomial(1, weight, size=[batch_size % class_num])).type(torch.FloatTensor)\n",
        "      y_disc_ = torch.cat([mean_Y_, y_disc_], 0)\n",
        "    else:\n",
        "      y_disc_ = torch.from_numpy(rng_local.multinomial(1, weight, size=[batch_size])).type(torch.FloatTensor)\n",
        "    if gpu_mode:\n",
        "      y_disc_ = y_disc_.cuda()\n",
        "    return y_disc_\n",
        "  def visualize_results(self,epoch,x_=None,y_=None): #transform是归一化参数\n",
        "    self.G.eval()\n",
        "    self.A.eval()\n",
        "    self.vqgan2.eval()\n",
        "    if not os.path.exists(self.rslt_path):\n",
        "        os.makedirs(self.rslt_path)\n",
        "    image_frame_dim = int(np.floor(np.sqrt(self.sample_num)))\n",
        "\n",
        "    size=x_.shape[-1]\n",
        "    x2=x_[:image_frame_dim].reshape(1,image_frame_dim,-1,size,size).repeat(image_frame_dim,1,1,1,1).permute(1,0,2,3,4)\n",
        "    x2=x2.reshape(image_frame_dim*image_frame_dim,-1,size,size)\n",
        "    y2 = y_[:image_frame_dim].unsqueeze(0).t().repeat(1,image_frame_dim).reshape(image_frame_dim*image_frame_dim)\n",
        "    y2 = torch.zeros((image_frame_dim*image_frame_dim, self.class_num)).scatter_(1, y2.type(torch.LongTensor).unsqueeze(1), 1)\n",
        "    if gpu_mode:\n",
        "      y2 = y2.cuda()\n",
        "\n",
        "    G = self.A(x2, self.sample_y_)[0]\n",
        "    G_v,_,_ = self.vqgan2(G)\n",
        "    G3 = self.A(G_v,y2)[0]\n",
        "    G3_v,_,_ = self.vqgan2(G3)\n",
        "    G4 = self.A(G_v,self.sample_y_)[0]\n",
        "    G4,_,_ = self.vqgan2(G4)\n",
        "    '''\n",
        "    print(y2)\n",
        "    print(self.sample_y_)\n",
        "    1/0\n",
        "    '''\n",
        "    imgs=[x2,G,G_v,G4,G3,G3_v]\n",
        "\n",
        "    for i, img in enumerate(imgs):\n",
        "      image=show_img(img,image_frame_dim,\\\n",
        "        self.rslt_path + '/%2d[%d]_ep%d' % (self.round,i,epoch) + '.png',transform=get_transform(self.train_data))\n",
        "\n",
        "\n",
        "  def get_rslt_path(self):\n",
        "    task = self.option['task'].replace('/','').replace('.','').replace('task','')\n",
        "    self.C=self.get_loc_data()\n",
        "    c = self.C.topk(k=10).indices\n",
        "    name='client '+str(self.id)+str(c.tolist())\n",
        "    return 'result_G/' + task + '/' + name\n",
        "\n",
        "  '''\n",
        "  def get_loc_data(self):\n",
        "    date_num=len(self.train_data.indices)\n",
        "    data_loader = self.calculator.get_dataloader(self.train_data, batch_size=date_num)\n",
        "    y_ = data_loader.__iter__().__next__()[1]\n",
        "    y_vec_ = torch.zeros((y_.shape[0], 10)).scatter_(1, y_.type(torch.LongTensor).unsqueeze(1), 1)\n",
        "    c = y_vec_.sum(0)\n",
        "    print(\"client\",self.id,\"总样本数：\",date_num,\" 各类：\", c.int().numpy())\n",
        "    return c\n",
        "    '''\n",
        "\n",
        "class test:\n",
        "    Server=Server\n",
        "    Client=Client\n",
        "\n",
        "\n",
        "#!rm -r $task\n",
        "if not os.path.exists(task): flgo.gen_task(config_dir10, task_path = task)\n",
        "option = {'clip_grad':10,'num_rounds':50, 'num_epochs':1, 'batch_size':32, 'learning_rate':0.1, 'gpu':0 if torch.cuda.is_available() else ''}\n",
        "option['vqgan_args']=args\n",
        "option['class_num']=10\n",
        "option['G_lr'] = 1e-3\n",
        "option['D_lr'] = 1e-2\n",
        "option['V_lr'] = 1e-4\n",
        "!rm -r /content/FLGo/result_G\n",
        "\n",
        "\n",
        "\n",
        "runner = flgo.init(task, test, option=option)\n",
        "#runner = flgo.init(task, fedavg, option=option, model=model_DC)\n",
        "torch.cuda.empty_cache()\n",
        "runner.model\n",
        "runner.run()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mib3WtZ1DMk9",
        "outputId": "49706495-7cca-4afe-8fee-5cf63bb061dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pytorch-msssim in /usr/local/lib/python3.10/dist-packages (1.0.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from pytorch-msssim) (2.0.1+cu118)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->pytorch-msssim) (3.12.4)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->pytorch-msssim) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->pytorch-msssim) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->pytorch-msssim) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->pytorch-msssim) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch->pytorch-msssim) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->pytorch-msssim) (3.27.6)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->pytorch-msssim) (17.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->pytorch-msssim) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->pytorch-msssim) (1.3.0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2023-10-07 17:43:10,394 fflow.py init [line:441] INFO Initializing devices: cuda:0 will be used for this running.\n",
            "<ipython-input-8-112e297749b6>:515: UserWarning: torch.range is deprecated and will be removed in a future release because its behavior is inconsistent with Python's range builtin. Instead, use torch.arange, which produces values in [start, end).\n",
            "  mean_Y = torch.range(0, class_num - 1, dtype=torch.int64).repeat(batch_size // class_num)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "client 0 总样本数： 6471  各类： [   0 1126  473 4872    0    0    0    0    0    0]\n",
            "client 1 总样本数： 6749  各类： [   0  285   84  194 5919    0    0    0    0  267]\n",
            "client 2 总样本数： 6615  各类： [1531    1  260    0    0    0    0    4 2825 1994]\n",
            "client 3 总样本数： 6529  各类： [   0 1987  215    0  703    0   34 3590    0    0]\n",
            "client 4 总样本数： 6598  各类： [   1  362   91  954    0 5170   20    0    0    0]\n",
            "client 5 总样本数： 6681  各类： [   0    0 5487  933    0   49   82  130    0    0]\n",
            "client 6 总样本数： 6551  各类： [1786 3204    4  617    2  527    0  396    0   15]\n",
            "client 7 总样本数： 6615  各类： [1104 1913    1    0   18    3    0    0 1670 1906]\n",
            "client 8 总样本数： 6601  各类： [   0 3605 2896    1   82    0    1    0   16    0]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2023-10-07 17:43:38,423 fflow.py init [line:479] INFO Use `<class 'flgo.simulator.default_simulator.Simulator'>` as the system simulator\n",
            "2023-10-07 17:43:38,424 fflow.py init [line:487] INFO Ready to start.\n",
            "2023-10-07 17:43:38,429 fedbase.py run [line:236] INFO --------------Initial Evaluation--------------\n",
            "2023-10-07 17:43:38,430 simple_logger.py log_once [line:14] INFO Current_time:0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "client 9 总样本数： 6525  各类： [   1    3   43   35    1  443 5016  934   49    0]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2023-10-07 17:43:49,018 simple_logger.py log_once [line:28] INFO test_accuracy                 0.0740\n",
            "2023-10-07 17:43:49,024 simple_logger.py log_once [line:28] INFO test_loss                     2.3097\n",
            "2023-10-07 17:43:49,026 simple_logger.py log_once [line:28] INFO valid_accuracy                0.0770\n",
            "2023-10-07 17:43:49,028 simple_logger.py log_once [line:28] INFO mean_valid_accuracy           0.0771\n",
            "2023-10-07 17:43:49,029 simple_logger.py log_once [line:28] INFO std_valid_accuracy            0.0995\n",
            "2023-10-07 17:43:49,031 simple_logger.py log_once [line:28] INFO valid_loss                    2.3081\n",
            "2023-10-07 17:43:49,032 simple_logger.py log_once [line:28] INFO mean_valid_loss               2.3081\n",
            "2023-10-07 17:43:49,035 simple_logger.py log_once [line:28] INFO std_valid_loss                0.0309\n",
            "2023-10-07 17:43:49,038 fedbase.py run [line:239] INFO Eval Time Cost:               10.6076s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "客户端选择： [3, 9]\n",
            "c_loss: 2.31, distill_loss0.00, recon_loss2.71\n",
            "c_loss: 2.30, distill_loss7.06, recon_loss0.29\n",
            "c_loss: 2.30, distill_loss5.34, recon_loss0.23\n",
            "c_loss: 2.30, distill_loss0.00, recon_loss3.27\n",
            "c_loss: 2.30, distill_loss7.60, recon_loss0.15\n",
            "c_loss: 2.31, distill_loss10.95, recon_loss0.11\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2023-10-07 17:44:11,621 fedbase.py run [line:246] INFO --------------Round 1--------------\n",
            "2023-10-07 17:44:11,625 simple_logger.py log_once [line:14] INFO Current_time:1\n",
            "2023-10-07 17:44:21,703 simple_logger.py log_once [line:28] INFO test_accuracy                 0.0776\n",
            "2023-10-07 17:44:21,704 simple_logger.py log_once [line:28] INFO test_loss                     3.0628\n",
            "2023-10-07 17:44:21,706 simple_logger.py log_once [line:28] INFO valid_accuracy                0.0739\n",
            "2023-10-07 17:44:21,708 simple_logger.py log_once [line:28] INFO mean_valid_accuracy           0.0746\n",
            "2023-10-07 17:44:21,712 simple_logger.py log_once [line:28] INFO std_valid_accuracy            0.1641\n",
            "2023-10-07 17:44:21,714 simple_logger.py log_once [line:28] INFO valid_loss                    3.1003\n",
            "2023-10-07 17:44:21,716 simple_logger.py log_once [line:28] INFO mean_valid_loss               3.0991\n",
            "2023-10-07 17:44:21,717 simple_logger.py log_once [line:28] INFO std_valid_loss                0.8763\n",
            "2023-10-07 17:44:21,718 fedbase.py run [line:251] INFO Eval Time Cost:               10.0929s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "客户端选择： [7, 5]\n",
            "c_loss: 3.71, distill_loss0.00, recon_loss3.04\n",
            "c_loss: 3.40, distill_loss4.58, recon_loss0.19\n",
            "c_loss: 2.98, distill_loss7.70, recon_loss0.10\n",
            "c_loss: 3.74, distill_loss0.00, recon_loss3.50\n",
            "c_loss: 3.41, distill_loss8.24, recon_loss0.32\n",
            "c_loss: 2.99, distill_loss17.24, recon_loss0.12\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2023-10-07 17:44:45,292 fedbase.py run [line:246] INFO --------------Round 2--------------\n",
            "2023-10-07 17:44:45,293 simple_logger.py log_once [line:14] INFO Current_time:2\n",
            "2023-10-07 17:44:55,773 simple_logger.py log_once [line:28] INFO test_accuracy                 0.4184\n",
            "2023-10-07 17:44:55,774 simple_logger.py log_once [line:28] INFO test_loss                     1.9499\n",
            "2023-10-07 17:44:55,777 simple_logger.py log_once [line:28] INFO valid_accuracy                0.3934\n",
            "2023-10-07 17:44:55,779 simple_logger.py log_once [line:28] INFO mean_valid_accuracy           0.3930\n",
            "2023-10-07 17:44:55,781 simple_logger.py log_once [line:28] INFO std_valid_accuracy            0.2690\n",
            "2023-10-07 17:44:55,782 simple_logger.py log_once [line:28] INFO valid_loss                    1.9860\n",
            "2023-10-07 17:44:55,784 simple_logger.py log_once [line:28] INFO mean_valid_loss               1.9842\n",
            "2023-10-07 17:44:55,785 simple_logger.py log_once [line:28] INFO std_valid_loss                0.4272\n",
            "2023-10-07 17:44:55,786 fedbase.py run [line:251] INFO Eval Time Cost:               10.4925s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "客户端选择： [1, 1]\n",
            "c_loss: 2.51, distill_loss0.00, recon_loss3.00\n",
            "c_loss: 2.31, distill_loss13.13, recon_loss0.23\n",
            "c_loss: 2.42, distill_loss17.64, recon_loss0.12\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2023-10-07 17:45:06,400 fedbase.py run [line:246] INFO --------------Round 3--------------\n",
            "2023-10-07 17:45:06,405 simple_logger.py log_once [line:14] INFO Current_time:3\n",
            "2023-10-07 17:45:15,943 simple_logger.py log_once [line:28] INFO test_accuracy                 0.3096\n",
            "2023-10-07 17:45:15,944 simple_logger.py log_once [line:28] INFO test_loss                     4.4919\n",
            "2023-10-07 17:45:15,948 simple_logger.py log_once [line:28] INFO valid_accuracy                0.3285\n",
            "2023-10-07 17:45:15,953 simple_logger.py log_once [line:28] INFO mean_valid_accuracy           0.3270\n",
            "2023-10-07 17:45:15,954 simple_logger.py log_once [line:28] INFO std_valid_accuracy            0.2446\n",
            "2023-10-07 17:45:15,956 simple_logger.py log_once [line:28] INFO valid_loss                    4.0802\n",
            "2023-10-07 17:45:15,958 simple_logger.py log_once [line:28] INFO mean_valid_loss               4.0908\n",
            "2023-10-07 17:45:15,962 simple_logger.py log_once [line:28] INFO std_valid_loss                2.7282\n",
            "2023-10-07 17:45:15,963 fedbase.py run [line:251] INFO Eval Time Cost:               9.5583s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "客户端选择： [0, 8]\n",
            "c_loss: 11.46, distill_loss0.00, recon_loss3.04\n",
            "c_loss: 2.38, distill_loss5.51, recon_loss0.46\n",
            "c_loss: 4.62, distill_loss7.16, recon_loss0.19\n",
            "c_loss: 9.01, distill_loss0.00, recon_loss3.40\n",
            "c_loss: 2.12, distill_loss2.89, recon_loss0.51\n",
            "c_loss: 4.30, distill_loss4.38, recon_loss0.28\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2023-10-07 17:45:38,569 fedbase.py run [line:246] INFO --------------Round 4--------------\n",
            "2023-10-07 17:45:38,571 simple_logger.py log_once [line:14] INFO Current_time:4\n",
            "2023-10-07 17:45:48,441 simple_logger.py log_once [line:28] INFO test_accuracy                 0.4551\n",
            "2023-10-07 17:45:48,443 simple_logger.py log_once [line:28] INFO test_loss                     2.9147\n",
            "2023-10-07 17:45:48,445 simple_logger.py log_once [line:28] INFO valid_accuracy                0.4428\n",
            "2023-10-07 17:45:48,447 simple_logger.py log_once [line:28] INFO mean_valid_accuracy           0.4428\n",
            "2023-10-07 17:45:48,450 simple_logger.py log_once [line:28] INFO std_valid_accuracy            0.3210\n",
            "2023-10-07 17:45:48,451 simple_logger.py log_once [line:28] INFO valid_loss                    2.9046\n",
            "2023-10-07 17:45:48,452 simple_logger.py log_once [line:28] INFO mean_valid_loss               2.9095\n",
            "2023-10-07 17:45:48,454 simple_logger.py log_once [line:28] INFO std_valid_loss                2.0111\n",
            "2023-10-07 17:45:48,455 fedbase.py run [line:251] INFO Eval Time Cost:               9.8844s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "客户端选择： [5, 7]\n",
            "c_loss: 7.13, distill_loss0.00, recon_loss0.11\n",
            "c_loss: 6.56, distill_loss7.86, recon_loss0.11\n",
            "c_loss: 6.14, distill_loss10.10, recon_loss0.11\n",
            "c_loss: 7.05, distill_loss0.00, recon_loss0.17\n",
            "c_loss: 5.61, distill_loss20.38, recon_loss0.14\n",
            "c_loss: 5.95, distill_loss20.45, recon_loss0.18\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2023-10-07 17:46:11,038 fedbase.py run [line:246] INFO --------------Round 5--------------\n",
            "2023-10-07 17:46:11,039 simple_logger.py log_once [line:14] INFO Current_time:5\n",
            "2023-10-07 17:46:20,964 simple_logger.py log_once [line:28] INFO test_accuracy                 0.5578\n",
            "2023-10-07 17:46:20,965 simple_logger.py log_once [line:28] INFO test_loss                     1.4403\n",
            "2023-10-07 17:46:20,969 simple_logger.py log_once [line:28] INFO valid_accuracy                0.5682\n",
            "2023-10-07 17:46:20,973 simple_logger.py log_once [line:28] INFO mean_valid_accuracy           0.5677\n",
            "2023-10-07 17:46:20,975 simple_logger.py log_once [line:28] INFO std_valid_accuracy            0.2917\n",
            "2023-10-07 17:46:20,977 simple_logger.py log_once [line:28] INFO valid_loss                    1.3947\n",
            "2023-10-07 17:46:20,978 simple_logger.py log_once [line:28] INFO mean_valid_loss               1.3966\n",
            "2023-10-07 17:46:20,979 simple_logger.py log_once [line:28] INFO std_valid_loss                0.9195\n",
            "2023-10-07 17:46:20,981 fedbase.py run [line:251] INFO Eval Time Cost:               9.9418s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "客户端选择： [0, 9]\n",
            "c_loss: 3.28, distill_loss0.00, recon_loss0.18\n",
            "c_loss: 3.54, distill_loss8.21, recon_loss0.11\n",
            "c_loss: 5.01, distill_loss13.18, recon_loss0.20\n",
            "c_loss: 3.91, distill_loss0.00, recon_loss0.21\n",
            "c_loss: 3.73, distill_loss11.76, recon_loss0.14\n",
            "c_loss: 3.28, distill_loss8.35, recon_loss0.23\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2023-10-07 17:46:44,974 fedbase.py run [line:246] INFO --------------Round 6--------------\n",
            "2023-10-07 17:46:44,977 simple_logger.py log_once [line:14] INFO Current_time:6\n",
            "2023-10-07 17:46:54,026 simple_logger.py log_once [line:28] INFO test_accuracy                 0.5453\n",
            "2023-10-07 17:46:54,028 simple_logger.py log_once [line:28] INFO test_loss                     1.4837\n",
            "2023-10-07 17:46:54,034 simple_logger.py log_once [line:28] INFO valid_accuracy                0.5460\n",
            "2023-10-07 17:46:54,035 simple_logger.py log_once [line:28] INFO mean_valid_accuracy           0.5475\n",
            "2023-10-07 17:46:54,038 simple_logger.py log_once [line:28] INFO std_valid_accuracy            0.3025\n",
            "2023-10-07 17:46:54,041 simple_logger.py log_once [line:28] INFO valid_loss                    1.4486\n",
            "2023-10-07 17:46:54,045 simple_logger.py log_once [line:28] INFO mean_valid_loss               1.4441\n",
            "2023-10-07 17:46:54,046 simple_logger.py log_once [line:28] INFO std_valid_loss                0.9669\n",
            "2023-10-07 17:46:54,047 fedbase.py run [line:251] INFO Eval Time Cost:               9.0703s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "客户端选择： [8, 2]\n",
            "c_loss: 4.36, distill_loss0.00, recon_loss0.20\n",
            "c_loss: 2.84, distill_loss6.31, recon_loss0.27\n",
            "c_loss: 2.98, distill_loss6.10, recon_loss0.19\n",
            "c_loss: 4.39, distill_loss0.00, recon_loss3.18\n",
            "c_loss: 3.03, distill_loss8.44, recon_loss0.77\n",
            "c_loss: 3.12, distill_loss21.44, recon_loss0.18\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2023-10-07 17:47:17,923 fedbase.py run [line:246] INFO --------------Round 7--------------\n",
            "2023-10-07 17:47:17,924 simple_logger.py log_once [line:14] INFO Current_time:7\n",
            "2023-10-07 17:47:27,879 simple_logger.py log_once [line:28] INFO test_accuracy                 0.5272\n",
            "2023-10-07 17:47:27,880 simple_logger.py log_once [line:28] INFO test_loss                     1.8458\n",
            "2023-10-07 17:47:27,883 simple_logger.py log_once [line:28] INFO valid_accuracy                0.5180\n",
            "2023-10-07 17:47:27,885 simple_logger.py log_once [line:28] INFO mean_valid_accuracy           0.5163\n",
            "2023-10-07 17:47:27,887 simple_logger.py log_once [line:28] INFO std_valid_accuracy            0.3208\n",
            "2023-10-07 17:47:27,888 simple_logger.py log_once [line:28] INFO valid_loss                    1.8154\n",
            "2023-10-07 17:47:27,890 simple_logger.py log_once [line:28] INFO mean_valid_loss               1.8224\n",
            "2023-10-07 17:47:27,891 simple_logger.py log_once [line:28] INFO std_valid_loss                1.3133\n",
            "2023-10-07 17:47:27,892 fedbase.py run [line:251] INFO Eval Time Cost:               9.9680s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "客户端选择： [1, 1]\n",
            "c_loss: 3.85, distill_loss0.00, recon_loss0.11\n",
            "c_loss: 4.49, distill_loss10.95, recon_loss0.11\n",
            "c_loss: 4.40, distill_loss17.62, recon_loss0.10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2023-10-07 17:47:39,535 fedbase.py run [line:246] INFO --------------Round 8--------------\n",
            "2023-10-07 17:47:39,536 simple_logger.py log_once [line:14] INFO Current_time:8\n",
            "2023-10-07 17:47:48,204 simple_logger.py log_once [line:28] INFO test_accuracy                 0.4953\n",
            "2023-10-07 17:47:48,206 simple_logger.py log_once [line:28] INFO test_loss                     2.8151\n",
            "2023-10-07 17:47:48,210 simple_logger.py log_once [line:28] INFO valid_accuracy                0.4977\n",
            "2023-10-07 17:47:48,212 simple_logger.py log_once [line:28] INFO mean_valid_accuracy           0.4963\n",
            "2023-10-07 17:47:48,215 simple_logger.py log_once [line:28] INFO std_valid_accuracy            0.2775\n",
            "2023-10-07 17:47:48,217 simple_logger.py log_once [line:28] INFO valid_loss                    2.5776\n",
            "2023-10-07 17:47:48,218 simple_logger.py log_once [line:28] INFO mean_valid_loss               2.5862\n",
            "2023-10-07 17:47:48,220 simple_logger.py log_once [line:28] INFO std_valid_loss                1.9423\n",
            "2023-10-07 17:47:48,221 fedbase.py run [line:251] INFO Eval Time Cost:               8.6847s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "客户端选择： [3, 5]\n",
            "c_loss: 8.58, distill_loss0.00, recon_loss0.19\n",
            "c_loss: 9.72, distill_loss11.78, recon_loss0.13\n",
            "c_loss: 9.14, distill_loss12.60, recon_loss0.13\n",
            "c_loss: 5.62, distill_loss0.00, recon_loss0.10\n",
            "c_loss: 6.61, distill_loss16.23, recon_loss0.15\n",
            "c_loss: 7.66, distill_loss24.47, recon_loss0.12\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2023-10-07 17:48:11,015 fedbase.py run [line:246] INFO --------------Round 9--------------\n",
            "2023-10-07 17:48:11,016 simple_logger.py log_once [line:14] INFO Current_time:9\n",
            "2023-10-07 17:48:21,556 simple_logger.py log_once [line:28] INFO test_accuracy                 0.6445\n",
            "2023-10-07 17:48:21,557 simple_logger.py log_once [line:28] INFO test_loss                     1.2166\n",
            "2023-10-07 17:48:21,560 simple_logger.py log_once [line:28] INFO valid_accuracy                0.6480\n",
            "2023-10-07 17:48:21,562 simple_logger.py log_once [line:28] INFO mean_valid_accuracy           0.6482\n",
            "2023-10-07 17:48:21,565 simple_logger.py log_once [line:28] INFO std_valid_accuracy            0.2678\n",
            "2023-10-07 17:48:21,567 simple_logger.py log_once [line:28] INFO valid_loss                    1.1510\n",
            "2023-10-07 17:48:21,569 simple_logger.py log_once [line:28] INFO mean_valid_loss               1.1504\n",
            "2023-10-07 17:48:21,570 simple_logger.py log_once [line:28] INFO std_valid_loss                0.8664\n",
            "2023-10-07 17:48:21,571 fedbase.py run [line:251] INFO Eval Time Cost:               10.5554s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "客户端选择： [4, 2]\n",
            "c_loss: 3.41, distill_loss0.00, recon_loss0.15\n",
            "c_loss: 3.01, distill_loss28.15, recon_loss0.15\n",
            "c_loss: 3.56, distill_loss15.30, recon_loss0.12\n",
            "c_loss: 4.94, distill_loss0.00, recon_loss3.45\n",
            "c_loss: 1.57, distill_loss2.37, recon_loss1.48\n",
            "c_loss: 0.24, distill_loss1.81, recon_loss1.59\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2023-10-07 17:48:44,063 fedbase.py run [line:246] INFO --------------Round 10--------------\n",
            "2023-10-07 17:48:44,069 simple_logger.py log_once [line:14] INFO Current_time:10\n",
            "2023-10-07 17:48:54,093 simple_logger.py log_once [line:28] INFO test_accuracy                 0.7204\n",
            "2023-10-07 17:48:54,095 simple_logger.py log_once [line:28] INFO test_loss                     0.8857\n",
            "2023-10-07 17:48:54,097 simple_logger.py log_once [line:28] INFO valid_accuracy                0.7280\n",
            "2023-10-07 17:48:54,101 simple_logger.py log_once [line:28] INFO mean_valid_accuracy           0.7273\n",
            "2023-10-07 17:48:54,103 simple_logger.py log_once [line:28] INFO std_valid_accuracy            0.1917\n",
            "2023-10-07 17:48:54,105 simple_logger.py log_once [line:28] INFO valid_loss                    0.8323\n",
            "2023-10-07 17:48:54,106 simple_logger.py log_once [line:28] INFO mean_valid_loss               0.8335\n",
            "2023-10-07 17:48:54,107 simple_logger.py log_once [line:28] INFO std_valid_loss                0.3098\n",
            "2023-10-07 17:48:54,108 fedbase.py run [line:251] INFO Eval Time Cost:               10.0394s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "客户端选择： [6, 1]\n",
            "c_loss: 3.22, distill_loss0.00, recon_loss0.11\n",
            "c_loss: 3.39, distill_loss9.19, recon_loss0.15\n",
            "c_loss: 3.33, distill_loss11.94, recon_loss0.10\n",
            "c_loss: 2.82, distill_loss0.00, recon_loss3.27\n",
            "c_loss: 1.95, distill_loss3.40, recon_loss1.30\n",
            "c_loss: 0.23, distill_loss2.88, recon_loss1.76\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2023-10-07 17:49:17,312 fedbase.py run [line:246] INFO --------------Round 11--------------\n",
            "2023-10-07 17:49:17,314 simple_logger.py log_once [line:14] INFO Current_time:11\n",
            "2023-10-07 17:49:27,240 simple_logger.py log_once [line:28] INFO test_accuracy                 0.7347\n",
            "2023-10-07 17:49:27,243 simple_logger.py log_once [line:28] INFO test_loss                     0.8572\n",
            "2023-10-07 17:49:27,245 simple_logger.py log_once [line:28] INFO valid_accuracy                0.7390\n",
            "2023-10-07 17:49:27,251 simple_logger.py log_once [line:28] INFO mean_valid_accuracy           0.7384\n",
            "2023-10-07 17:49:27,253 simple_logger.py log_once [line:28] INFO std_valid_accuracy            0.1896\n",
            "2023-10-07 17:49:27,254 simple_logger.py log_once [line:28] INFO valid_loss                    0.8018\n",
            "2023-10-07 17:49:27,255 simple_logger.py log_once [line:28] INFO mean_valid_loss               0.8033\n",
            "2023-10-07 17:49:27,256 simple_logger.py log_once [line:28] INFO std_valid_loss                0.4936\n",
            "2023-10-07 17:49:27,257 fedbase.py run [line:251] INFO Eval Time Cost:               9.9434s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "客户端选择： [2, 3]\n",
            "c_loss: 4.27, distill_loss0.00, recon_loss0.19\n",
            "c_loss: 3.41, distill_loss11.46, recon_loss0.12\n",
            "c_loss: 4.10, distill_loss13.47, recon_loss0.13\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q_eO_DKG8cg2",
        "outputId": "1188d618-7959-4af0-a83d-2dfd78b2cc8d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Compose(\n",
              "    ToTensor()\n",
              "    Normalize(mean=(0.1307,), std=(0.3081,))\n",
              ")"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "get_transform(client.train_data.dataset)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "x = torch.tensor([[0.2, 0.3, 0.1, 0.5],[0.2, 0.3, 0.1, 0.5]])\n",
        "softmin_x = F.softmin(x, dim=-1)\n",
        "print(softmin_x.shape)\n",
        "print(softmin_x)\n"
      ],
      "metadata": {
        "id": "emRN7ZAhJlHI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "055627f2-992f-481d-a93d-9631f269f98c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 4])\n",
            "tensor([[0.2666, 0.2412, 0.2946, 0.1975],\n",
            "        [0.2666, 0.2412, 0.2946, 0.1975]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.distributions import Gumbel\n",
        "\n",
        "def gumbel_argmin(x: torch.Tensor, temperature: float = 1.0) -> torch.Tensor:\n",
        "    \"\"\"\n",
        "    使用Gumbel Softmax采样方法来近似torch.argmin函数\n",
        "    :param x: 输入张量\n",
        "    :param temperature: Gumbel Softmax 采样温度\n",
        "    :return: 最小值索引张量\n",
        "    \"\"\"\n",
        "    gumbel_dist = Gumbel(torch.tensor([0.0]), torch.tensor([1.0]))\n",
        "    noise = -torch.log(-torch.log(torch.rand_like(x)))  # 从 Gumbel 分布中采样噪声\n",
        "    y = (x - noise) / temperature  # 加入噪声并除以温度\n",
        "    softmin_y = F.softmax(y, dim=-1)  # 使用 softmax 转换为概率分布\n",
        "    return torch.sum(softmin_y * torch.arange(len(x)), dim=-1)  # 计算最小索引\n",
        "\n",
        "x = torch.tensor([0.2, 0.3, 0.1, 0.5])\n",
        "min_idx = gumbel_argmin(x, temperature=0.1)\n",
        "\n",
        "print(min_idx)  # 输出最小值的索引，即 2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2L4ZzBNCI6Sg",
        "outputId": "7a7304cb-4f12-486c-9f4a-a21004c1c6e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.0542)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "embedding = nn.Embedding(10, 3).to('cuda')\n",
        "input = torch.randint(0, 10, (2, 4)).to('cuda')  # 生成整数随机数作为输入\n",
        "print(input)\n",
        "output = embedding(input)\n",
        "print(output)\n",
        "print(output.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sm-eg5XrHLbw",
        "outputId": "de3d46ee-4e30-40c5-ffb6-14fa588a2baf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0, 7, 3, 8],\n",
            "        [3, 2, 3, 0]], device='cuda:0')\n",
            "tensor([[[-0.5129,  0.7735,  0.1710],\n",
            "         [ 0.9360,  0.5372,  0.9311],\n",
            "         [ 0.0340, -0.2477,  0.2426],\n",
            "         [-0.5103, -0.1171,  0.2446]],\n",
            "\n",
            "        [[ 0.0340, -0.2477,  0.2426],\n",
            "         [ 1.9889, -1.4424,  0.8801],\n",
            "         [ 0.0340, -0.2477,  0.2426],\n",
            "         [-0.5129,  0.7735,  0.1710]]], device='cuda:0',\n",
            "       grad_fn=<EmbeddingBackward0>)\n",
            "torch.Size([2, 4, 3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from flgo.algorithm.fedbase import BasicServer, BasicClient\n",
        "import flgo.algorithm.fedavg as fedavg\n",
        "os.chdir('/content/GAN')\n",
        "#from infoGAN import infoGAN\n",
        "os.chdir(BASEPATH)\n",
        "import copy\n",
        "from flgo.utils import fmodule\n",
        "import flgo\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "import json\n",
        "import importlib\n",
        "!pip install pytorch-msssim\n",
        "from pytorch_msssim import ssim\n",
        "\n",
        "def masked_loss(A, B, mask, threshold = 0.5):\n",
        "  masked_A = A * mask      # 将掩码应用到特征图 A\n",
        "  masked_B = B * mask      # 将掩码应用到特征图 B\n",
        "  mask_mean = torch.mean(mask, dim=(2, 3))\n",
        "  # 将小于阈值的图像掩码置零，并计算非零元素的均值\n",
        "  loss_mask = torch.mean(torch.relu(threshold - mask_mean))\n",
        "  return F.mse_loss(masked_A, masked_B)+loss_mask\n",
        "\n",
        "def imageDiffLoss(input1, input2):\n",
        "  loss = 1 - ssim(input1, input2)\n",
        "  return loss\n",
        "\n",
        "def load_vqgan(checkpoint_path,args):\n",
        "  model = VQGAN_my(args)\n",
        "  model.load_checkpoint(checkpoint_path)\n",
        "  model = model.eval()\n",
        "  return model\n",
        "\n",
        "class discriminator(nn.Module):\n",
        "  # Network Architecture is exactly same as in infoGAN (https://arxiv.org/abs/1606.03657)\n",
        "  # Architecture : (64)4c2s-(128)4c2s_BL-FC1024_BL-FC1_S\n",
        "  def __init__(self, input_dim=1, output_dim=1, input_size=32, latent_dim=1):\n",
        "    super(discriminator, self).__init__()\n",
        "    self.input_dim = input_dim\n",
        "    self.output_dim = output_dim\n",
        "    self.input_size = input_size\n",
        "    if latent_dim==1:\n",
        "      self.fc_in_dim = 128 * (self.input_size // 4) * (self.input_size // 4)\n",
        "    else:\n",
        "      self.fc_in_dim = latent_dim * (self.input_size // 4) * (self.input_size // 4)\n",
        "    self.conv = nn.Sequential(\n",
        "        nn.Conv2d(self.input_dim, 64, 4, 2, 1),\n",
        "        nn.LeakyReLU(0.2),\n",
        "        nn.Conv2d(64, 128, 4, 2, 1),\n",
        "        nn.BatchNorm2d(128),\n",
        "        nn.LeakyReLU(0.2),\n",
        "    )\n",
        "    self.fc = nn.Sequential(\n",
        "        nn.Linear(self.fc_in_dim, 1024),\n",
        "        nn.BatchNorm1d(1024),\n",
        "        nn.LeakyReLU(0.2),\n",
        "        nn.Linear(1024, self.output_dim),\n",
        "        nn.Sigmoid(),\n",
        "    )\n",
        "\n",
        "  def forward(self, input, mod='latent'):#'all'):\n",
        "    if mod!='latent':\n",
        "      input = self.conv(input)\n",
        "    x = input.reshape(-1, self.fc_in_dim)\n",
        "    x = self.fc(x)\n",
        "\n",
        "    return x\n",
        "\n",
        "class Residual(nn.Module):\n",
        "  def __init__(self, in_channels, num_hiddens, num_residual_hiddens):\n",
        "    super(Residual, self).__init__()\n",
        "    self.num_hiddens = num_hiddens\n",
        "    self._block = nn.Sequential(\n",
        "        nn.ReLU(True),\n",
        "        nn.Conv2d(in_channels=in_channels,\n",
        "                  out_channels=num_residual_hiddens,\n",
        "                  kernel_size=3, stride=1, padding=1, bias=False),\n",
        "        nn.ReLU(True),\n",
        "        nn.Conv2d(in_channels=num_residual_hiddens,\n",
        "                  out_channels=num_hiddens,\n",
        "                  kernel_size=1, stride=1, bias=False)\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "      return x[:,:self.num_hiddens] + F.tanh(self._block(x))\n",
        "\n",
        "\n",
        "class ResidualStack(nn.Module):\n",
        "  def __init__(self, in_channels, num_hiddens, num_residual_layers, num_residual_hiddens):\n",
        "    super(ResidualStack, self).__init__()\n",
        "    self._num_residual_layers = num_residual_layers\n",
        "    self._layer0 = Residual(in_channels, num_hiddens, num_residual_hiddens)\n",
        "    self._layers = nn.ModuleList([Residual(num_hiddens, num_hiddens, num_residual_hiddens)\n",
        "                          for _ in range(self._num_residual_layers-1)])\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self._layer0(x)\n",
        "    for i in range(self._num_residual_layers-1):\n",
        "      x = self._layers[i](x)\n",
        "    return F.relu(x)\n",
        "\n",
        "class generator(nn.Module): #适用于图像大小是4的倍数的数据(mnist-28,cifa10-32)\n",
        "  def __init__(self, input_dim, input_size ,vqgan, class_num=10, latent_dim=1024):\n",
        "    super().__init__()\n",
        "    self.input_dim = input_dim\n",
        "    self.input_size = input_size\n",
        "    self.vqgan = vqgan\n",
        "    self.class_num = class_num\n",
        "    self.z_channel = self.vqgan.args.latent_dim\n",
        "    self.z_size = (self.input_size // 4)\n",
        "    self.G_z = nn.Sequential(\n",
        "            nn.Linear(self.input_dim + self.class_num, latent_dim),\n",
        "            #nn.Linear(self.input_dim, latent_dim),\n",
        "            nn.BatchNorm1d(latent_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(latent_dim, self.z_channel*self.z_size*self.z_size),\n",
        "            nn.BatchNorm1d(self.z_channel*self.z_size*self.z_size),\n",
        "            nn.ReLU(),\n",
        "        )\n",
        "\n",
        "    self.change_z= nn.Sequential(\n",
        "            nn.Conv2d(self.z_channel, self.z_channel, 5, 1, 2),\n",
        "            nn.BatchNorm2d(self.z_channel),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Conv2d(self.z_channel, self.z_channel, 5, 1, 2),\n",
        "            nn.BatchNorm2d(self.z_channel),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Conv2d(self.z_channel, self.z_channel, 5, 1, 2),\n",
        "            nn.BatchNorm2d(self.z_channel),\n",
        "            nn.LeakyReLU(0.2),\n",
        "        )\n",
        "\n",
        "    self._residual_stack= ResidualStack(in_channels=self.z_channel,\n",
        "              num_hiddens=self.z_channel,\n",
        "              num_residual_layers=self.z_channel,\n",
        "              num_residual_hiddens=2)\n",
        "\n",
        "    # 冻结vqgan的参数\n",
        "    for param in self.vqgan.parameters():\n",
        "      param.requires_grad = False\n",
        "\n",
        "\n",
        "  def forward(self, input, label, mod=\"sample_in\"):\n",
        "    #label = label.unsqueeze(-1).unsqueeze(-1)  # 添加两个维度，使其与输入图像的维度相匹配\n",
        "    #label = label.expand(label.size(0), label.size(1), input.size(2), input.size(3))  # 扩展为与输入图像相同的尺寸\n",
        "    z = self.G_z(torch.cat([input, label], 1))\n",
        "    z = z.view(-1, self.z_channel, self.z_size, self.z_size)\n",
        "    x = self.z_to_image(z)\n",
        "    x = self.vqgan.change(x)\n",
        "    return x,z\n",
        "\n",
        "  def z_to_image(self, z):\n",
        "    #z_vq, _, _ = self.vqgan.codebook(z)\n",
        "    image = self.vqgan.decode(z)\n",
        "    return image\n",
        "\n",
        "def crop_image(image, target_size):\n",
        "    # 获取原始图像的大小\n",
        "    original_size = image.shape[-1]\n",
        "\n",
        "    # 计算裁剪区域的边界\n",
        "    left = (original_size - target_size) // 2\n",
        "    top = (original_size - target_size) // 2\n",
        "    right = left + target_size\n",
        "    bottom = top + target_size\n",
        "\n",
        "    # 裁剪图像\n",
        "    cropped_image = image[:,:,top:bottom, left:right]\n",
        "\n",
        "    return cropped_image\n",
        "\n",
        "class augmentation(nn.Module):\n",
        "  def __init__(self, vqgan, input_dim=1, input_size=32, class_num=10):\n",
        "    super(augmentation, self).__init__()\n",
        "    self.vqgan = vqgan\n",
        "    self.input_dim = input_dim\n",
        "    self.input_size = input_size\n",
        "    self.class_num = class_num\n",
        "    self.z_channel = self.vqgan.args.latent_dim\n",
        "    self._conv_1 = nn.Sequential(\n",
        "        nn.Conv2d(self.input_dim+class_num, 32, 4, 2, 1),\n",
        "        nn.BatchNorm2d(32),\n",
        "        nn.LeakyReLU(0.2),\n",
        "        nn.Conv2d(32, 64, 4, 2, 1),\n",
        "        nn.BatchNorm2d(64),\n",
        "        nn.LeakyReLU(0.2),\n",
        "        nn.Conv2d(64, 64, 3, 1, 1),\n",
        "        nn.BatchNorm2d(64),\n",
        "        nn.LeakyReLU(0.2),)\n",
        "    self._conv_trans_1  = nn.Sequential(\n",
        "        nn.ConvTranspose2d(64, 64, 4, 2, 1),\n",
        "        nn.BatchNorm2d(64),\n",
        "        nn.LeakyReLU(0.2),\n",
        "        nn.ConvTranspose2d(64, 32, 4, 2, 1),\n",
        "        nn.BatchNorm2d(32),\n",
        "        nn.LeakyReLU(0.2),\n",
        "        nn.ConvTranspose2d(32, self.input_dim, 3, 1, 1),\n",
        "        nn.Tanh(),\n",
        "    )\n",
        "\n",
        "    self._conv = nn.Sequential(\n",
        "        nn.Conv2d(self.z_channel+class_num, self.z_channel, 5, 1, 2),\n",
        "        nn.BatchNorm2d(self.z_channel),\n",
        "        nn.LeakyReLU(0.2),\n",
        "        nn.Conv2d(self.z_channel, self.z_channel, 3, 1, 1),\n",
        "        nn.BatchNorm2d(self.z_channel),\n",
        "        nn.LeakyReLU(0.2),\n",
        "        nn.Conv2d(self.z_channel, self.z_channel, 1, 1, 0),\n",
        "        )\n",
        "    self.mask = nn.Sequential(\n",
        "        nn.Conv2d(self.z_channel, 1, 1, 1, 0),\n",
        "        nn.Sigmoid(),\n",
        "        )\n",
        "\n",
        "    # 冻结vqgan的参数\n",
        "    for param in self.vqgan.parameters():\n",
        "      param.requires_grad = False\n",
        "\n",
        "  def forward0(self, x, label):\n",
        "    # 将类别标签转换为 one-hot 编码\n",
        "    label = label.unsqueeze(-1).unsqueeze(-1)  # 添加两个维度，使其与输入图像的维度相匹配\n",
        "    label = label.expand(label.size(0), label.size(1), x.size(2), x.size(3))  # 扩展为与输入图像相同的尺寸\n",
        "    x = self._conv_1(torch.cat([x, label], dim=1)) # 在通道维度上拼接输入图像和类别标签\n",
        "    x = self._conv_trans_1(x)\n",
        "    x = crop_image(x,self.input_size)\n",
        "    x = self.vqgan.change(x)\n",
        "    return self.vqgan(x)[0],x\n",
        "\n",
        "  def forward(self, x, label):\n",
        "    # 将类别标签转换为 one-hot 编码\n",
        "    z = self.encode(x) #torch.Size([32, 64, 7, 7])\n",
        "    label = label.unsqueeze(-1).unsqueeze(-1)  # 添加两个维度，使其与输入图像的维度相匹配\n",
        "    label = label.expand(label.size(0), label.size(1), z.size(2), z.size(3))  # 扩展为与输入图像相同的尺寸\n",
        "    z = self._conv(torch.cat([z, label], dim=1))\n",
        "    #z_, _, _ = self.vqgan.codebook(z)\n",
        "    x = self.decode(z)\n",
        "    x = self.vqgan.change(x)\n",
        "    return x,z,self.mask(z)\n",
        "\n",
        "  def encode(self, imgs):\n",
        "    encoded_images = self.vqgan.encoder(imgs)\n",
        "    quant_conv_encoded_images = self.vqgan.quant_conv(encoded_images)\n",
        "    return quant_conv_encoded_images\n",
        "\n",
        "  def decode(self, z):\n",
        "    #z, _, _ = self.vqgan.codebook(z)\n",
        "    post_quant_conv_mapping = self.vqgan.post_quant_conv(z)\n",
        "    decoded_images = self.vqgan.decoder(post_quant_conv_mapping)\n",
        "    return decoded_images\n",
        "\n",
        "\n",
        "class Server(BasicServer):\n",
        "  def initialize(self, *args, **kwargs):\n",
        "    # 指定随机种子创建随机数生成器对象\n",
        "    np.random.seed(0)\n",
        "    self.rng_sample = np.random.RandomState(42) #采样客户端专用的随机数生成器，以免在其他地方改变随机数列表\n",
        "  def pack(self, client_id, mtype=0, *args, **kwargs):\n",
        "    return {\n",
        "        \"model\": copy.deepcopy(self.model),\n",
        "        \"round\": self.current_round,\n",
        "    }\n",
        "  def sample(self):\n",
        "    all_clients = self.available_clients if 'available' in self.sample_option else [cid for cid in range(self.num_clients)]\n",
        "    # full sampling with unlimited communication resources of the server\n",
        "    if 'full' in self.sample_option:\n",
        "        return all_clients\n",
        "    # sample clients\n",
        "    elif 'uniform' in self.sample_option:\n",
        "        # original sample proposed by fedavg\n",
        "        selected_clients = list(\n",
        "            self.rng_sample.choice(all_clients, min(self.clients_per_round, len(all_clients)), replace=False)) if len(\n",
        "            all_clients) > 0 else []\n",
        "    elif 'md' in self.sample_option:\n",
        "        # the default setting that is introduced by FedProx, where the clients are sampled with the probability in proportion to their local_movielens_recommendation data sizes\n",
        "        local_data_vols = [self.clients[cid].datavol for cid in all_clients]\n",
        "        total_data_vol = sum(local_data_vols)\n",
        "        p = np.array(local_data_vols) / total_data_vol\n",
        "        selected_clients = list(self.rng_sample.choice(all_clients, self.clients_per_round, replace=True, p=p)) if len(\n",
        "            all_clients) > 0 else []\n",
        "    print('客户端选择：',selected_clients)\n",
        "    return selected_clients\n",
        "class Client(BasicClient):\n",
        "  def initialize(self, *args, **kwargs):\n",
        "    self.rng_local = np.random.RandomState(0) #专用的随机对象\n",
        "    self.z_dim = 62\n",
        "    if self.option['gpu']!='':\n",
        "      self.gpu_mode = 1\n",
        "    else:\n",
        "      self.gpu_mode = 0\n",
        "    self.gan_clip_grad = 10 #(默认为0)\n",
        "    #self.clip_grad = 10\n",
        "    self.class_num = self.option['class_num']\n",
        "    self.sample_num = self.class_num ** 2\n",
        "\n",
        "    data_shape = self.train_data[0][0].shape\n",
        "\n",
        "    vqgan = load_vqgan(os.path.join(\"/content/FLGo/checkpoints\", f\"{self.option['vqgan_args'].task}.vqgan_epoch_pre.pt\"),self.option['vqgan_args'])\n",
        "    self.vqgan2 = load_vqgan(os.path.join(\"/content/FLGo/checkpoints\", f\"{self.option['vqgan_args'].task}.vqgan_epoch.pt\"),self.option['vqgan_args'])\n",
        "    self.G = generator(self.z_dim,data_shape[1],vqgan,class_num=self.class_num)\n",
        "    self.A = augmentation(vqgan,input_dim=data_shape[0], input_size=data_shape[1],class_num=self.class_num).to(device=self.option['vqgan_args'].device)\n",
        "    self.D = discriminator(input_dim=data_shape[0], input_size=data_shape[1]).to(device=self.option['vqgan_args'].device)#, latent_dim=self.option['vqgan_args'].latent_dim).to(device=self.option['vqgan_args'].device)\n",
        "    self.G_optimizer = optim.Adam(self.G.parameters(), lr=self.option['G_lr'], betas=(self.option['vqgan_args'].beta1, self.option['vqgan_args'].beta2))\n",
        "    self.A_optimizer = optim.Adam(self.A.parameters(), lr=self.option['G_lr'], betas=(self.option['vqgan_args'].beta1, self.option['vqgan_args'].beta2))\n",
        "    self.D_optimizer = optim.Adam(self.D.parameters(), lr=self.option['D_lr'], betas=(self.option['vqgan_args'].beta1, self.option['vqgan_args'].beta2))\n",
        "    self.V_optimizer = optim.Adam(self.vqgan2.parameters(), lr=self.option['V_lr'], betas=(self.option['vqgan_args'].beta1, self.option['vqgan_args'].beta2))\n",
        "\n",
        "    sample_z_=self.generate_random_z(self.class_num,self.z_dim,self.gpu_mode)\n",
        "    self.sample_z_=sample_z_.unsqueeze(1).repeat(1,self.class_num,1).reshape(-1,self.z_dim)\n",
        "    sample_y_=self.generate_labels(self.class_num, self.class_num, self.gpu_mode, rng_local=self.rng_local)\n",
        "    self.sample_y_=sample_y_.unsqueeze(0).repeat(self.class_num,1,1).reshape(-1,self.class_num)\n",
        "    self.rslt_path = self.get_rslt_path()\n",
        "    if self.gpu_mode:\n",
        "      self.G.cuda()\n",
        "\n",
        "    # 冻结除了 decoder 之外的参数\n",
        "    for name, param in self.vqgan2.named_parameters():\n",
        "        if 'decoder' not in name:\n",
        "            param.requires_grad = False\n",
        "\n",
        "  def unpack(self, received_pkg):\n",
        "    return received_pkg['model'],received_pkg['round']\n",
        "  def get_loc_data(self):\n",
        "    date_num=len(self.train_data)#.indices)\n",
        "    data_loader = self.calculator.get_dataloader(self.train_data, batch_size=date_num)\n",
        "    y_ = data_loader.__iter__().__next__()[1]\n",
        "    y_vec_ = torch.zeros((y_.shape[0], 10)).scatter_(1, y_.type(torch.LongTensor).unsqueeze(1), 1)\n",
        "    c = y_vec_.sum(0)\n",
        "    print(\"client\",self.id,\"总样本数：\",date_num,\" 各类：\", c.int().numpy())\n",
        "    return c\n",
        "  def reply(self, svr_pkg):\n",
        "    model,self.round = self.unpack(svr_pkg) #svr_pkg (dict): the package received from the server\n",
        "    self.src_model = copy.deepcopy(model)\n",
        "    self.src_model.freeze_grad()\n",
        "    self.train(model)\n",
        "    cpkg = self.pack(model)\n",
        "    return cpkg #client_pkg (dict): the package to be send to the server\n",
        "\n",
        "  def train(self,global_model):\n",
        "    global_model.train()\n",
        "    self.G.train()\n",
        "    optimizer = self.calculator.get_optimizer(global_model, lr=self.learning_rate, weight_decay=self.weight_decay,\n",
        "                                              momentum=self.momentum)\n",
        "    for epoch in range(self.num_epochs):\n",
        "      for iter in range(self.num_steps):\n",
        "        batch_data = self.get_batch_data()\n",
        "        x_,y_ = batch_data\n",
        "        y_vec_ = torch.zeros((self.batch_size, self.class_num)).scatter_(1, y_.type(torch.LongTensor).unsqueeze(1), 1)\n",
        "        x_,y_vec_ = self.to_gpu([x_,y_vec_])\n",
        "        if self.option['batch_size'] != batch_data[1].shape[0]:\n",
        "          break\n",
        "        x0,y0 = x_,y_\n",
        "        print_head = \"Epoch: [%2d] [%4d/%4d]\" % ((epoch + 1), (iter + 1), client.num_steps)\n",
        "        self.train_step(x_,y_vec_, iter, global_model, optimizer, print_head)\n",
        "      with torch.no_grad():\n",
        "        if x0.shape[0]<self.class_num:\n",
        "          print(x0.shape[0])\n",
        "          break\n",
        "        self.visualize_results(epoch+1,x0,y0)\n",
        "    return\n",
        "\n",
        "  def train_step(self, x_, y_vec_, iter, global_model, optimizer, print_head):\n",
        "    z_ = self.generate_random_z(self.batch_size, self.z_dim, self.gpu_mode)\n",
        "    y_disc_ = self.generate_labels(self.G.class_num, self.batch_size, self.gpu_mode, rng_local=self.rng_local)\n",
        "    y_disc_2 = self.generate_labels(self.G.class_num, self.batch_size, self.gpu_mode, rng_local=self.rng_local,mod='rand')\n",
        "\n",
        "\n",
        "    G,Z = self.G(z_,y_disc_2)\n",
        "    Z0,_,_ = self.G.vqgan.encode(x_)\n",
        "    G_t = G\n",
        "    C_real = global_model(x_)\n",
        "\n",
        "    ## 训练分类模型\n",
        "    optimizer.zero_grad()\n",
        "    batch_data=[x_,torch.max(y_vec_, 1)[1]]\n",
        "    # calculate the loss of the model on batched dataset through task-specified calculator\n",
        "    C_src = self.src_model(G_t).detach()\n",
        "    C_ = global_model(G_t.detach())\n",
        "    logic_mean=(F.softmax(C_src, dim=-1) * y_disc_2).sum(-1).detach().mean()\n",
        "    logic_mask=(logic_mean>0.5).float()\n",
        "    distill_loss = F.mse_loss(C_src, C_)\n",
        "    loss = F.cross_entropy(C_real,y_vec_)+logic_mask*distill_loss\n",
        "\n",
        "    loss.backward(retain_graph=True)\n",
        "    if self.clip_grad>0:torch.nn.utils.clip_grad_norm_(parameters=global_model.parameters(), max_norm=self.clip_grad)\n",
        "    optimizer.step()\n",
        "\n",
        "    self.G_optimizer.zero_grad()\n",
        "    self.D_optimizer.zero_grad()\n",
        "\n",
        "    disc_real = self.D(Z0)\n",
        "    disc_fake = self.D(Z)\n",
        "\n",
        "    d_loss_real = torch.mean(F.relu(1. - disc_real))\n",
        "    d_loss_fake = torch.mean(F.relu(1. + disc_fake))\n",
        "    d_loss = d_loss_real + d_loss_fake\n",
        "    d_loss.backward(retain_graph=True)\n",
        "    self.D_optimizer.step()\n",
        "\n",
        "    disc_fake = self.D(G)\n",
        "    gd_loss = -torch.mean(disc_fake)\n",
        "    c_loss = F.cross_entropy(self.src_model(G), y_disc_2)\n",
        "    g_loss = 0*c_loss + gd_loss\n",
        "\n",
        "    g_loss.backward(retain_graph=True)\n",
        "    self.G_optimizer.step()\n",
        "\n",
        "    if iter % 100 == 0:\n",
        "      print(\"c_loss: %.2f, distill_loss%.2f, gd_loss%.2f\"\n",
        "      %(c_loss.item(),distill_loss.item(),gd_loss.item()))\n",
        "  @staticmethod\n",
        "  def mse_loss_clip(a,b,clip=0):\n",
        "    loss = F.mse_loss(a, b, reduce=False).mean(dim=(1,2,3))\n",
        "    loss[loss<clip] = 0\n",
        "    return loss.mean()\n",
        "\n",
        "  def to_gpu(self,data_tuple):\n",
        "    if self.gpu_mode:\n",
        "      return tuple(data_tensor.cuda() for data_tensor in data_tuple)\n",
        "    else:\n",
        "      return data_tuple\n",
        "  # Function to generate random z_ for G network:\n",
        "  @staticmethod\n",
        "  def generate_random_z(batch_size, z_dim, gpu_mode):\n",
        "    z_ = torch.rand((batch_size, z_dim))\n",
        "    if gpu_mode:\n",
        "      z_ = z_.cuda()\n",
        "    return z_\n",
        "  @staticmethod\n",
        "  def generate_labels(class_num, batch_size, gpu_mode, rng_local, mod=\"regu\"): #随机种子rng_local\n",
        "    weight = class_num * [float(1.0 / class_num)]\n",
        "    if mod == \"regu\":\n",
        "      mean_Y = torch.range(0, class_num - 1, dtype=torch.int64).repeat(batch_size // class_num)\n",
        "      mean_Y_ = torch.zeros((mean_Y.shape[0], class_num)).scatter_(1, mean_Y.type(torch.LongTensor).unsqueeze(1), 1)\n",
        "      y_disc_ = torch.from_numpy(rng_local.multinomial(1, weight, size=[batch_size % class_num])).type(torch.FloatTensor)\n",
        "      y_disc_ = torch.cat([mean_Y_, y_disc_], 0)\n",
        "    else:\n",
        "      y_disc_ = torch.from_numpy(rng_local.multinomial(1, weight, size=[batch_size])).type(torch.FloatTensor)\n",
        "    if gpu_mode:\n",
        "      y_disc_ = y_disc_.cuda()\n",
        "    return y_disc_\n",
        "  def visualize_results(self,epoch,x_=None,y_=None): #transform是归一化参数\n",
        "    self.G.eval()\n",
        "    self.A.eval()\n",
        "    self.vqgan2.eval()\n",
        "    if not os.path.exists(self.rslt_path):\n",
        "        os.makedirs(self.rslt_path)\n",
        "    image_frame_dim = int(np.floor(np.sqrt(self.sample_num)))\n",
        "    '''\n",
        "    size=x_.shape[-1]\n",
        "    x2=x_[:image_frame_dim].reshape(1,image_frame_dim,-1,size,size).repeat(image_frame_dim,1,1,1,1).permute(1,0,2,3,4)\n",
        "    x2=x2.reshape(image_frame_dim*image_frame_dim,-1,size,size)\n",
        "    y2 = y_[:image_frame_dim].unsqueeze(0).t().repeat(1,image_frame_dim).reshape(image_frame_dim*image_frame_dim)\n",
        "    y2 = torch.zeros((image_frame_dim*image_frame_dim, self.class_num)).scatter_(1, y2.type(torch.LongTensor).unsqueeze(1), 1)\n",
        "    if gpu_mode:\n",
        "      y2 = y2.cuda()\n",
        "    '''\n",
        "    G = self.G(self.sample_z_,self.sample_y_)[0]\n",
        "\n",
        "    imgs=[G]\n",
        "\n",
        "    for i, img in enumerate(imgs):\n",
        "      image=show_img(img,image_frame_dim,\\\n",
        "        self.rslt_path + '/%2d[%d]_ep%d' % (self.round,i,epoch) + '.png',transform=get_transform(self.train_data))\n",
        "\n",
        "\n",
        "  def get_rslt_path(self):\n",
        "    task = self.option['task'].replace('/','').replace('.','').replace('task','')\n",
        "    self.C=self.get_loc_data()\n",
        "    c = self.C.topk(k=10).indices\n",
        "    name='client '+str(self.id)+str(c.tolist())\n",
        "    return 'result_G/' + task + '/' + name\n",
        "\n",
        "  '''\n",
        "  def get_loc_data(self):\n",
        "    date_num=len(self.train_data.indices)\n",
        "    data_loader = self.calculator.get_dataloader(self.train_data, batch_size=date_num)\n",
        "    y_ = data_loader.__iter__().__next__()[1]\n",
        "    y_vec_ = torch.zeros((y_.shape[0], 10)).scatter_(1, y_.type(torch.LongTensor).unsqueeze(1), 1)\n",
        "    c = y_vec_.sum(0)\n",
        "    print(\"client\",self.id,\"总样本数：\",date_num,\" 各类：\", c.int().numpy())\n",
        "    return c\n",
        "    '''\n",
        "\n",
        "class test:\n",
        "    Server=Server\n",
        "    Client=Client\n",
        "\n",
        "\n",
        "#!rm -r $task\n",
        "if not os.path.exists(task): flgo.gen_task(config_dir10, task_path = task)\n",
        "option = {'clip_grad':10,'num_rounds':50, 'num_epochs':1, 'batch_size':32, 'learning_rate':0.1, 'gpu':0 if torch.cuda.is_available() else ''}\n",
        "option['vqgan_args']=args\n",
        "option['class_num']=10\n",
        "option['G_lr'] = 1e-3\n",
        "option['D_lr'] = 1e-2\n",
        "option['V_lr'] = 1e-4\n",
        "!rm -r /content/FLGo/result_G\n",
        "\n",
        "\n",
        "\n",
        "runner = flgo.init(task, test, option=option)\n",
        "#runner = flgo.init(task, fedavg, option=option, model=model_DC)\n",
        "torch.cuda.empty_cache()\n",
        "runner.model\n",
        "runner.run()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "cttY5PiVYOEc",
        "outputId": "78ef8099-4730-4b88-aca2-d2a491c2da92"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pytorch-msssim in /usr/local/lib/python3.10/dist-packages (1.0.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from pytorch-msssim) (2.0.1+cu118)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->pytorch-msssim) (3.12.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->pytorch-msssim) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->pytorch-msssim) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->pytorch-msssim) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->pytorch-msssim) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch->pytorch-msssim) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->pytorch-msssim) (3.27.4.1)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->pytorch-msssim) (16.0.6)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->pytorch-msssim) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->pytorch-msssim) (1.3.0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2023-09-29 12:42:03,633 fflow.py init [line:441] INFO Initializing devices: cuda:0 will be used for this running.\n",
            "<ipython-input-35-6fa5a1eebeb4>:434: UserWarning: torch.range is deprecated and will be removed in a future release because its behavior is inconsistent with Python's range builtin. Instead, use torch.arange, which produces values in [start, end).\n",
            "  mean_Y = torch.range(0, class_num - 1, dtype=torch.int64).repeat(batch_size // class_num)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "client 0 总样本数： 5389  各类： [   0  352 2210    6   19  203   49    0    0 2550]\n",
            "client 1 总样本数： 5291  各类： [   0    1   89   59 4208  111  157    0   42  624]\n",
            "client 2 总样本数： 5342  各类： [   0 1889    0  342  402    1 2152  552    3    1]\n",
            "client 3 总样本数： 5470  各类： [   0    0  501  158    1    0   26 4518  266    0]\n",
            "client 4 总样本数： 5474  各类： [  27    0 2198    0   94 1443    0  469    0 1243]\n",
            "client 5 总样本数： 5355  各类： [4917    0    0   76    0    3    0    0    0  359]\n",
            "client 6 总样本数： 5526  各类： [   2    0    0    0  498    9  760    0 3683  574]\n",
            "client 7 总样本数： 5309  各类： [  28 2880    0  169    7   11 2154   60    0    0]\n",
            "client 8 总样本数： 5493  各类： [   0  902  242   42    2 3102    0    0 1203    0]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2023-09-29 12:42:22,038 fflow.py init [line:479] INFO Use `<class 'flgo.simulator.default_simulator.Simulator'>` as the system simulator\n",
            "2023-09-29 12:42:22,041 fflow.py init [line:487] INFO Ready to start.\n",
            "2023-09-29 12:42:22,073 fedbase.py run [line:236] INFO --------------Initial Evaluation--------------\n",
            "2023-09-29 12:42:22,075 simple_logger.py log_once [line:14] INFO Current_time:0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "client 9 总样本数： 5357  各类： [ 366   24  126 4658   24    1   13   41   75   29]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2023-09-29 12:42:25,963 simple_logger.py log_once [line:28] INFO test_accuracy                 0.1142\n",
            "2023-09-29 12:42:25,965 simple_logger.py log_once [line:28] INFO test_loss                     2.3023\n",
            "2023-09-29 12:42:25,969 simple_logger.py log_once [line:28] INFO valid_accuracy                0.1153\n",
            "2023-09-29 12:42:25,972 simple_logger.py log_once [line:28] INFO mean_valid_accuracy           0.1163\n",
            "2023-09-29 12:42:25,974 simple_logger.py log_once [line:28] INFO std_valid_accuracy            0.2052\n",
            "2023-09-29 12:42:25,975 simple_logger.py log_once [line:28] INFO valid_loss                    2.3032\n",
            "2023-09-29 12:42:25,980 simple_logger.py log_once [line:28] INFO mean_valid_loss               2.3033\n",
            "2023-09-29 12:42:25,981 simple_logger.py log_once [line:28] INFO std_valid_loss                0.0488\n",
            "2023-09-29 12:42:25,982 fedbase.py run [line:239] INFO Eval Time Cost:               3.9072s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "客户端选择： [3, 9]\n",
            "c_loss: 2.30, distill_loss0.00, gd_loss-0.38\n",
            "c_loss: 2.31, distill_loss3.93, gd_loss-0.50\n",
            "c_loss: 2.30, distill_loss0.00, gd_loss-0.56\n",
            "c_loss: 2.30, distill_loss4.21, gd_loss-0.50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2023-09-29 12:42:33,211 fedbase.py run [line:246] INFO --------------Round 1--------------\n",
            "2023-09-29 12:42:33,212 simple_logger.py log_once [line:14] INFO Current_time:1\n",
            "2023-09-29 12:42:37,631 simple_logger.py log_once [line:28] INFO test_accuracy                 0.4112\n",
            "2023-09-29 12:42:37,632 simple_logger.py log_once [line:28] INFO test_loss                     2.1525\n",
            "2023-09-29 12:42:37,635 simple_logger.py log_once [line:28] INFO valid_accuracy                0.4104\n",
            "2023-09-29 12:42:37,638 simple_logger.py log_once [line:28] INFO mean_valid_accuracy           0.4090\n",
            "2023-09-29 12:42:37,641 simple_logger.py log_once [line:28] INFO std_valid_accuracy            0.2881\n",
            "2023-09-29 12:42:37,643 simple_logger.py log_once [line:28] INFO valid_loss                    2.1372\n",
            "2023-09-29 12:42:37,648 simple_logger.py log_once [line:28] INFO mean_valid_loss               2.1381\n",
            "2023-09-29 12:42:37,649 simple_logger.py log_once [line:28] INFO std_valid_loss                1.1641\n",
            "2023-09-29 12:42:37,650 fedbase.py run [line:251] INFO Eval Time Cost:               4.4387s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "客户端选择： [7, 6]\n",
            "c_loss: 3.32, distill_loss0.00, gd_loss-0.62\n",
            "c_loss: 3.67, distill_loss4.99, gd_loss-0.50\n",
            "c_loss: 3.38, distill_loss0.00, gd_loss-0.43\n",
            "c_loss: 3.72, distill_loss3.25, gd_loss-0.27\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2023-09-29 12:42:46,993 fedbase.py run [line:246] INFO --------------Round 2--------------\n",
            "2023-09-29 12:42:46,995 simple_logger.py log_once [line:14] INFO Current_time:2\n",
            "2023-09-29 12:42:52,061 simple_logger.py log_once [line:28] INFO test_accuracy                 0.6357\n",
            "2023-09-29 12:42:52,062 simple_logger.py log_once [line:28] INFO test_loss                     1.1157\n",
            "2023-09-29 12:42:52,065 simple_logger.py log_once [line:28] INFO valid_accuracy                0.6382\n",
            "2023-09-29 12:42:52,066 simple_logger.py log_once [line:28] INFO mean_valid_accuracy           0.6389\n",
            "2023-09-29 12:42:52,068 simple_logger.py log_once [line:28] INFO std_valid_accuracy            0.2183\n",
            "2023-09-29 12:42:52,070 simple_logger.py log_once [line:28] INFO valid_loss                    1.1187\n",
            "2023-09-29 12:42:52,073 simple_logger.py log_once [line:28] INFO mean_valid_loss               1.1172\n",
            "2023-09-29 12:42:52,074 simple_logger.py log_once [line:28] INFO std_valid_loss                0.5606\n",
            "2023-09-29 12:42:52,076 fedbase.py run [line:251] INFO Eval Time Cost:               5.0815s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "客户端选择： [1, 1]\n",
            "c_loss: 2.65, distill_loss0.00, gd_loss-0.36\n",
            "c_loss: 3.22, distill_loss3.61, gd_loss-0.50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2023-09-29 12:42:55,603 fedbase.py run [line:246] INFO --------------Round 3--------------\n",
            "2023-09-29 12:42:55,604 simple_logger.py log_once [line:14] INFO Current_time:3\n",
            "2023-09-29 12:42:58,796 simple_logger.py log_once [line:28] INFO test_accuracy                 0.5797\n",
            "2023-09-29 12:42:58,797 simple_logger.py log_once [line:28] INFO test_loss                     1.5163\n",
            "2023-09-29 12:42:58,800 simple_logger.py log_once [line:28] INFO valid_accuracy                0.5751\n",
            "2023-09-29 12:42:58,805 simple_logger.py log_once [line:28] INFO mean_valid_accuracy           0.5744\n",
            "2023-09-29 12:42:58,806 simple_logger.py log_once [line:28] INFO std_valid_accuracy            0.3041\n",
            "2023-09-29 12:42:58,808 simple_logger.py log_once [line:28] INFO valid_loss                    1.5499\n",
            "2023-09-29 12:42:58,810 simple_logger.py log_once [line:28] INFO mean_valid_loss               1.5503\n",
            "2023-09-29 12:42:58,812 simple_logger.py log_once [line:28] INFO std_valid_loss                1.4639\n",
            "2023-09-29 12:42:58,816 fedbase.py run [line:251] INFO Eval Time Cost:               3.2117s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "客户端选择： [0, 8]\n",
            "c_loss: 3.63, distill_loss0.00, gd_loss-0.37\n",
            "c_loss: 4.42, distill_loss2.09, gd_loss-0.50\n",
            "c_loss: 3.62, distill_loss0.00, gd_loss-0.56\n",
            "c_loss: 4.40, distill_loss1.88, gd_loss-0.50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2023-09-29 12:43:07,139 fedbase.py run [line:246] INFO --------------Round 4--------------\n",
            "2023-09-29 12:43:07,140 simple_logger.py log_once [line:14] INFO Current_time:4\n",
            "2023-09-29 12:43:10,361 simple_logger.py log_once [line:28] INFO test_accuracy                 0.7317\n",
            "2023-09-29 12:43:10,365 simple_logger.py log_once [line:28] INFO test_loss                     1.1465\n",
            "2023-09-29 12:43:10,366 simple_logger.py log_once [line:28] INFO valid_accuracy                0.7284\n",
            "2023-09-29 12:43:10,369 simple_logger.py log_once [line:28] INFO mean_valid_accuracy           0.7283\n",
            "2023-09-29 12:43:10,371 simple_logger.py log_once [line:28] INFO std_valid_accuracy            0.3157\n",
            "2023-09-29 12:43:10,376 simple_logger.py log_once [line:28] INFO valid_loss                    1.1454\n",
            "2023-09-29 12:43:10,377 simple_logger.py log_once [line:28] INFO mean_valid_loss               1.1452\n",
            "2023-09-29 12:43:10,378 simple_logger.py log_once [line:28] INFO std_valid_loss                1.4585\n",
            "2023-09-29 12:43:10,379 fedbase.py run [line:251] INFO Eval Time Cost:               3.2392s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "客户端选择： [6, 7]\n",
            "c_loss: 5.81, distill_loss0.00, gd_loss-0.50\n",
            "c_loss: 4.52, distill_loss2.07, gd_loss-0.50\n",
            "c_loss: 5.50, distill_loss0.00, gd_loss-0.50\n",
            "c_loss: 4.53, distill_loss3.19, gd_loss-0.25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2023-09-29 12:43:19,628 fedbase.py run [line:246] INFO --------------Round 5--------------\n",
            "2023-09-29 12:43:19,631 simple_logger.py log_once [line:14] INFO Current_time:5\n",
            "2023-09-29 12:43:23,203 simple_logger.py log_once [line:28] INFO test_accuracy                 0.8691\n",
            "2023-09-29 12:43:23,204 simple_logger.py log_once [line:28] INFO test_loss                     0.3692\n",
            "2023-09-29 12:43:23,207 simple_logger.py log_once [line:28] INFO valid_accuracy                0.8630\n",
            "2023-09-29 12:43:23,209 simple_logger.py log_once [line:28] INFO mean_valid_accuracy           0.8633\n",
            "2023-09-29 12:43:23,211 simple_logger.py log_once [line:28] INFO std_valid_accuracy            0.1324\n",
            "2023-09-29 12:43:23,213 simple_logger.py log_once [line:28] INFO valid_loss                    0.3793\n",
            "2023-09-29 12:43:23,215 simple_logger.py log_once [line:28] INFO mean_valid_loss               0.3787\n",
            "2023-09-29 12:43:23,216 simple_logger.py log_once [line:28] INFO std_valid_loss                0.3746\n",
            "2023-09-29 12:43:23,217 fedbase.py run [line:251] INFO Eval Time Cost:               3.5859s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "客户端选择： [0, 9]\n",
            "c_loss: 4.15, distill_loss0.00, gd_loss-0.25\n",
            "c_loss: 4.46, distill_loss7.06, gd_loss-0.30\n",
            "c_loss: 3.41, distill_loss0.00, gd_loss-0.50\n",
            "c_loss: 3.97, distill_loss1.71, gd_loss-0.50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2023-09-29 12:43:31,147 fedbase.py run [line:246] INFO --------------Round 6--------------\n",
            "2023-09-29 12:43:31,149 simple_logger.py log_once [line:14] INFO Current_time:6\n",
            "2023-09-29 12:43:34,616 simple_logger.py log_once [line:28] INFO test_accuracy                 0.9057\n",
            "2023-09-29 12:43:34,618 simple_logger.py log_once [line:28] INFO test_loss                     0.3244\n",
            "2023-09-29 12:43:34,620 simple_logger.py log_once [line:28] INFO valid_accuracy                0.8951\n",
            "2023-09-29 12:43:34,623 simple_logger.py log_once [line:28] INFO mean_valid_accuracy           0.8956\n",
            "2023-09-29 12:43:34,626 simple_logger.py log_once [line:28] INFO std_valid_accuracy            0.1182\n",
            "2023-09-29 12:43:34,627 simple_logger.py log_once [line:28] INFO valid_loss                    0.3308\n",
            "2023-09-29 12:43:34,632 simple_logger.py log_once [line:28] INFO mean_valid_loss               0.3288\n",
            "2023-09-29 12:43:34,634 simple_logger.py log_once [line:28] INFO std_valid_loss                0.3815\n",
            "2023-09-29 12:43:34,635 fedbase.py run [line:251] INFO Eval Time Cost:               3.4855s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "客户端选择： [8, 2]\n",
            "c_loss: 4.96, distill_loss0.00, gd_loss-0.50\n",
            "c_loss: 4.48, distill_loss1.88, gd_loss-0.50\n",
            "c_loss: 4.28, distill_loss0.00, gd_loss-0.38\n",
            "c_loss: 4.53, distill_loss3.37, gd_loss-0.50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2023-09-29 12:43:42,326 fedbase.py run [line:246] INFO --------------Round 7--------------\n",
            "2023-09-29 12:43:42,331 simple_logger.py log_once [line:14] INFO Current_time:7\n",
            "2023-09-29 12:43:46,562 simple_logger.py log_once [line:28] INFO test_accuracy                 0.9284\n",
            "2023-09-29 12:43:46,563 simple_logger.py log_once [line:28] INFO test_loss                     0.2178\n",
            "2023-09-29 12:43:46,566 simple_logger.py log_once [line:28] INFO valid_accuracy                0.9236\n",
            "2023-09-29 12:43:46,568 simple_logger.py log_once [line:28] INFO mean_valid_accuracy           0.9236\n",
            "2023-09-29 12:43:46,570 simple_logger.py log_once [line:28] INFO std_valid_accuracy            0.0762\n",
            "2023-09-29 12:43:46,571 simple_logger.py log_once [line:28] INFO valid_loss                    0.2344\n",
            "2023-09-29 12:43:46,573 simple_logger.py log_once [line:28] INFO mean_valid_loss               0.2345\n",
            "2023-09-29 12:43:46,574 simple_logger.py log_once [line:28] INFO std_valid_loss                0.2285\n",
            "2023-09-29 12:43:46,575 fedbase.py run [line:251] INFO Eval Time Cost:               4.2445s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "客户端选择： [1, 1]\n",
            "c_loss: 4.72, distill_loss0.00, gd_loss-0.37\n",
            "c_loss: 4.63, distill_loss1.85, gd_loss-0.50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2023-09-29 12:43:50,057 fedbase.py run [line:246] INFO --------------Round 8--------------\n",
            "2023-09-29 12:43:50,059 simple_logger.py log_once [line:14] INFO Current_time:8\n",
            "2023-09-29 12:43:53,674 simple_logger.py log_once [line:28] INFO test_accuracy                 0.8225\n",
            "2023-09-29 12:43:53,676 simple_logger.py log_once [line:28] INFO test_loss                     0.5710\n",
            "2023-09-29 12:43:53,679 simple_logger.py log_once [line:28] INFO valid_accuracy                0.8069\n",
            "2023-09-29 12:43:53,682 simple_logger.py log_once [line:28] INFO mean_valid_accuracy           0.8074\n",
            "2023-09-29 12:43:53,684 simple_logger.py log_once [line:28] INFO std_valid_accuracy            0.1983\n",
            "2023-09-29 12:43:53,690 simple_logger.py log_once [line:28] INFO valid_loss                    0.6093\n",
            "2023-09-29 12:43:53,691 simple_logger.py log_once [line:28] INFO mean_valid_loss               0.6073\n",
            "2023-09-29 12:43:53,694 simple_logger.py log_once [line:28] INFO std_valid_loss                0.6689\n",
            "2023-09-29 12:43:53,697 fedbase.py run [line:251] INFO Eval Time Cost:               3.6380s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "客户端选择： [3, 5]\n",
            "c_loss: 4.54, distill_loss0.00, gd_loss-0.50\n",
            "c_loss: 4.14, distill_loss5.42, gd_loss-0.50\n",
            "c_loss: 4.01, distill_loss0.00, gd_loss-0.47\n",
            "c_loss: 4.84, distill_loss1.73, gd_loss-0.50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2023-09-29 12:44:01,983 fedbase.py run [line:246] INFO --------------Round 9--------------\n",
            "2023-09-29 12:44:01,984 simple_logger.py log_once [line:14] INFO Current_time:9\n",
            "2023-09-29 12:44:05,262 simple_logger.py log_once [line:28] INFO test_accuracy                 0.9323\n",
            "2023-09-29 12:44:05,263 simple_logger.py log_once [line:28] INFO test_loss                     0.1897\n",
            "2023-09-29 12:44:05,265 simple_logger.py log_once [line:28] INFO valid_accuracy                0.9326\n",
            "2023-09-29 12:44:05,268 simple_logger.py log_once [line:28] INFO mean_valid_accuracy           0.9326\n",
            "2023-09-29 12:44:05,269 simple_logger.py log_once [line:28] INFO std_valid_accuracy            0.0423\n",
            "2023-09-29 12:44:05,272 simple_logger.py log_once [line:28] INFO valid_loss                    0.2018\n",
            "2023-09-29 12:44:05,279 simple_logger.py log_once [line:28] INFO mean_valid_loss               0.2018\n",
            "2023-09-29 12:44:05,281 simple_logger.py log_once [line:28] INFO std_valid_loss                0.1022\n",
            "2023-09-29 12:44:05,282 fedbase.py run [line:251] INFO Eval Time Cost:               3.2982s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "客户端选择： [4, 2]\n",
            "c_loss: 3.59, distill_loss0.00, gd_loss-0.50\n",
            "c_loss: 3.68, distill_loss1.98, gd_loss-0.50\n",
            "c_loss: 3.76, distill_loss0.00, gd_loss-0.52\n",
            "c_loss: 3.75, distill_loss1.46, gd_loss-0.50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2023-09-29 12:44:13,413 fedbase.py run [line:246] INFO --------------Round 10--------------\n",
            "2023-09-29 12:44:13,415 simple_logger.py log_once [line:14] INFO Current_time:10\n",
            "2023-09-29 12:44:16,548 simple_logger.py log_once [line:28] INFO test_accuracy                 0.9663\n",
            "2023-09-29 12:44:16,549 simple_logger.py log_once [line:28] INFO test_loss                     0.1072\n",
            "2023-09-29 12:44:16,552 simple_logger.py log_once [line:28] INFO valid_accuracy                0.9613\n",
            "2023-09-29 12:44:16,556 simple_logger.py log_once [line:28] INFO mean_valid_accuracy           0.9615\n",
            "2023-09-29 12:44:16,558 simple_logger.py log_once [line:28] INFO std_valid_accuracy            0.0278\n",
            "2023-09-29 12:44:16,561 simple_logger.py log_once [line:28] INFO valid_loss                    0.1257\n",
            "2023-09-29 12:44:16,564 simple_logger.py log_once [line:28] INFO mean_valid_loss               0.1250\n",
            "2023-09-29 12:44:16,565 simple_logger.py log_once [line:28] INFO std_valid_loss                0.0859\n",
            "2023-09-29 12:44:16,566 fedbase.py run [line:251] INFO Eval Time Cost:               3.1511s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "客户端选择： [6, 1]\n",
            "c_loss: 5.09, distill_loss0.00, gd_loss-0.75\n",
            "c_loss: 5.07, distill_loss1.03, gd_loss-0.20\n",
            "c_loss: 4.64, distill_loss0.00, gd_loss-0.50\n",
            "c_loss: 4.03, distill_loss3.45, gd_loss-0.51\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2023-09-29 12:44:24,638 fedbase.py run [line:246] INFO --------------Round 11--------------\n",
            "2023-09-29 12:44:24,640 simple_logger.py log_once [line:14] INFO Current_time:11\n",
            "2023-09-29 12:44:28,001 simple_logger.py log_once [line:28] INFO test_accuracy                 0.9043\n",
            "2023-09-29 12:44:28,002 simple_logger.py log_once [line:28] INFO test_loss                     0.3082\n",
            "2023-09-29 12:44:28,005 simple_logger.py log_once [line:28] INFO valid_accuracy                0.8939\n",
            "2023-09-29 12:44:28,009 simple_logger.py log_once [line:28] INFO mean_valid_accuracy           0.8939\n",
            "2023-09-29 12:44:28,011 simple_logger.py log_once [line:28] INFO std_valid_accuracy            0.0824\n",
            "2023-09-29 12:44:28,016 simple_logger.py log_once [line:28] INFO valid_loss                    0.3342\n",
            "2023-09-29 12:44:28,016 simple_logger.py log_once [line:28] INFO mean_valid_loss               0.3342\n",
            "2023-09-29 12:44:28,019 simple_logger.py log_once [line:28] INFO std_valid_loss                0.2608\n",
            "2023-09-29 12:44:28,019 fedbase.py run [line:251] INFO Eval Time Cost:               3.3794s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "客户端选择： [2, 3]\n",
            "c_loss: 4.56, distill_loss0.00, gd_loss-0.25\n",
            "c_loss: 4.06, distill_loss4.59, gd_loss-0.25\n",
            "c_loss: 5.66, distill_loss0.00, gd_loss-0.25\n",
            "c_loss: 5.15, distill_loss3.05, gd_loss-0.25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2023-09-29 12:44:35,234 fedbase.py run [line:246] INFO --------------Round 12--------------\n",
            "2023-09-29 12:44:35,240 simple_logger.py log_once [line:14] INFO Current_time:12\n",
            "2023-09-29 12:44:39,622 simple_logger.py log_once [line:28] INFO test_accuracy                 0.8496\n",
            "2023-09-29 12:44:39,623 simple_logger.py log_once [line:28] INFO test_loss                     0.5187\n",
            "2023-09-29 12:44:39,627 simple_logger.py log_once [line:28] INFO valid_accuracy                0.8490\n",
            "2023-09-29 12:44:39,630 simple_logger.py log_once [line:28] INFO mean_valid_accuracy           0.8493\n",
            "2023-09-29 12:44:39,631 simple_logger.py log_once [line:28] INFO std_valid_accuracy            0.1520\n",
            "2023-09-29 12:44:39,634 simple_logger.py log_once [line:28] INFO valid_loss                    0.5438\n",
            "2023-09-29 12:44:39,636 simple_logger.py log_once [line:28] INFO mean_valid_loss               0.5430\n",
            "2023-09-29 12:44:39,638 simple_logger.py log_once [line:28] INFO std_valid_loss                0.5760\n",
            "2023-09-29 12:44:39,640 fedbase.py run [line:251] INFO Eval Time Cost:               4.3993s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "客户端选择： [4, 7]\n",
            "c_loss: 5.01, distill_loss0.00, gd_loss-0.26\n",
            "c_loss: 5.42, distill_loss3.63, gd_loss-0.58\n",
            "c_loss: 4.97, distill_loss0.00, gd_loss-0.50\n",
            "c_loss: 5.52, distill_loss1.11, gd_loss-0.50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2023-09-29 12:44:46,675 fedbase.py run [line:246] INFO --------------Round 13--------------\n",
            "2023-09-29 12:44:46,677 simple_logger.py log_once [line:14] INFO Current_time:13\n",
            "2023-09-29 12:44:50,509 simple_logger.py log_once [line:28] INFO test_accuracy                 0.9745\n",
            "2023-09-29 12:44:50,514 simple_logger.py log_once [line:28] INFO test_loss                     0.0824\n",
            "2023-09-29 12:44:50,518 simple_logger.py log_once [line:28] INFO valid_accuracy                0.9690\n",
            "2023-09-29 12:44:50,520 simple_logger.py log_once [line:28] INFO mean_valid_accuracy           0.9691\n",
            "2023-09-29 12:44:50,523 simple_logger.py log_once [line:28] INFO std_valid_accuracy            0.0181\n",
            "2023-09-29 12:44:50,527 simple_logger.py log_once [line:28] INFO valid_loss                    0.0962\n",
            "2023-09-29 12:44:50,528 simple_logger.py log_once [line:28] INFO mean_valid_loss               0.0958\n",
            "2023-09-29 12:44:50,529 simple_logger.py log_once [line:28] INFO std_valid_loss                0.0565\n",
            "2023-09-29 12:44:50,530 fedbase.py run [line:251] INFO Eval Time Cost:               3.8537s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "客户端选择： [2, 5]\n",
            "c_loss: 4.42, distill_loss0.00, gd_loss-0.50\n",
            "c_loss: 4.73, distill_loss1.46, gd_loss-0.25\n",
            "c_loss: 4.73, distill_loss0.00, gd_loss-0.50\n",
            "c_loss: 5.03, distill_loss1.88, gd_loss-0.40\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2023-09-29 12:44:58,115 fedbase.py run [line:246] INFO --------------Round 14--------------\n",
            "2023-09-29 12:44:58,116 simple_logger.py log_once [line:14] INFO Current_time:14\n",
            "2023-09-29 12:45:01,381 simple_logger.py log_once [line:28] INFO test_accuracy                 0.9552\n",
            "2023-09-29 12:45:01,383 simple_logger.py log_once [line:28] INFO test_loss                     0.1347\n",
            "2023-09-29 12:45:01,386 simple_logger.py log_once [line:28] INFO valid_accuracy                0.9516\n",
            "2023-09-29 12:45:01,390 simple_logger.py log_once [line:28] INFO mean_valid_accuracy           0.9521\n",
            "2023-09-29 12:45:01,392 simple_logger.py log_once [line:28] INFO std_valid_accuracy            0.0417\n",
            "2023-09-29 12:45:01,403 simple_logger.py log_once [line:28] INFO valid_loss                    0.1399\n",
            "2023-09-29 12:45:01,406 simple_logger.py log_once [line:28] INFO mean_valid_loss               0.1384\n",
            "2023-09-29 12:45:01,409 simple_logger.py log_once [line:28] INFO std_valid_loss                0.1223\n",
            "2023-09-29 12:45:01,411 fedbase.py run [line:251] INFO Eval Time Cost:               3.2950s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "客户端选择： [5, 0]\n",
            "c_loss: 5.02, distill_loss0.00, gd_loss-0.75\n",
            "c_loss: 5.41, distill_loss3.39, gd_loss-0.50\n",
            "c_loss: 5.06, distill_loss0.00, gd_loss-0.50\n",
            "c_loss: 5.23, distill_loss0.60, gd_loss-0.50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2023-09-29 12:45:09,947 fedbase.py run [line:246] INFO --------------Round 15--------------\n",
            "2023-09-29 12:45:09,948 simple_logger.py log_once [line:14] INFO Current_time:15\n",
            "2023-09-29 12:45:13,146 simple_logger.py log_once [line:28] INFO test_accuracy                 0.9202\n",
            "2023-09-29 12:45:13,147 simple_logger.py log_once [line:28] INFO test_loss                     0.2626\n",
            "2023-09-29 12:45:13,151 simple_logger.py log_once [line:28] INFO valid_accuracy                0.9139\n",
            "2023-09-29 12:45:13,153 simple_logger.py log_once [line:28] INFO mean_valid_accuracy           0.9144\n",
            "2023-09-29 12:45:13,155 simple_logger.py log_once [line:28] INFO std_valid_accuracy            0.0817\n",
            "2023-09-29 12:45:13,156 simple_logger.py log_once [line:28] INFO valid_loss                    0.2818\n",
            "2023-09-29 12:45:13,158 simple_logger.py log_once [line:28] INFO mean_valid_loss               0.2798\n",
            "2023-09-29 12:45:13,159 simple_logger.py log_once [line:28] INFO std_valid_loss                0.2794\n",
            "2023-09-29 12:45:13,160 fedbase.py run [line:251] INFO Eval Time Cost:               3.2115s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "客户端选择： [6, 1]\n",
            "c_loss: 6.12, distill_loss0.00, gd_loss-0.25\n",
            "c_loss: 5.13, distill_loss1.68, gd_loss-0.25\n",
            "c_loss: 5.21, distill_loss0.00, gd_loss-0.50\n",
            "c_loss: 5.09, distill_loss2.74, gd_loss-0.75\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2023-09-29 12:45:21,329 fedbase.py run [line:246] INFO --------------Round 16--------------\n",
            "2023-09-29 12:45:21,330 simple_logger.py log_once [line:14] INFO Current_time:16\n",
            "2023-09-29 12:45:24,433 simple_logger.py log_once [line:28] INFO test_accuracy                 0.9338\n",
            "2023-09-29 12:45:24,435 simple_logger.py log_once [line:28] INFO test_loss                     0.2107\n",
            "2023-09-29 12:45:24,438 simple_logger.py log_once [line:28] INFO valid_accuracy                0.9259\n",
            "2023-09-29 12:45:24,443 simple_logger.py log_once [line:28] INFO mean_valid_accuracy           0.9262\n",
            "2023-09-29 12:45:24,444 simple_logger.py log_once [line:28] INFO std_valid_accuracy            0.0661\n",
            "2023-09-29 12:45:24,447 simple_logger.py log_once [line:28] INFO valid_loss                    0.2351\n",
            "2023-09-29 12:45:24,448 simple_logger.py log_once [line:28] INFO mean_valid_loss               0.2342\n",
            "2023-09-29 12:45:24,452 simple_logger.py log_once [line:28] INFO std_valid_loss                0.2166\n",
            "2023-09-29 12:45:24,453 fedbase.py run [line:251] INFO Eval Time Cost:               3.1230s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "客户端选择： [0, 9]\n",
            "c_loss: 4.15, distill_loss0.00, gd_loss-0.50\n",
            "c_loss: 5.27, distill_loss6.12, gd_loss-0.25\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-35-6fa5a1eebeb4>\u001b[0m in \u001b[0;36m<cell line: 507>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    505\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m \u001b[0mrunner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 507\u001b[0;31m \u001b[0mrunner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/content/FLGo/flgo/algorithm/fedbase.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    241\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m             \u001b[0;31m# iterate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 243\u001b[0;31m             \u001b[0mupdated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    244\u001b[0m             \u001b[0;31m# using logger to evaluate the model if the model is updated\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    245\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mupdated\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mTrue\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mupdated\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/FLGo/flgo/algorithm/fedbase.py\u001b[0m in \u001b[0;36miterate\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    272\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselected_clients\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m         \u001b[0;31m# training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 274\u001b[0;31m         \u001b[0mmodels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommunicate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselected_clients\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'model'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    275\u001b[0m         \u001b[0;31m# aggregate: pk = 1/K as default where K=len(selected_clients)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maggregate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/FLGo/flgo/simulator/base.py\u001b[0m in \u001b[0;36mcommunicate_with_dropout\u001b[0;34m(self, selected_clients, mtype, asynchronous)\u001b[0m\n\u001b[1;32m    465\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dropped_selected_clients\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcid\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcid\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mprob\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mselected_clients\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprobs_drop\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msimulator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mprob\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    466\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msimulator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_client_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dropped_selected_clients\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'dropped'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 467\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcommunicate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcid\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcid\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mselected_clients\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mcid\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dropped_selected_clients\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0masynchronous\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    468\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    469\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mcommunicate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mselected_clients\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0masynchronous\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/FLGo/flgo/simulator/base.py\u001b[0m in \u001b[0;36mcommunicate_with_clock\u001b[0;34m(self, selected_clients, mtype, asynchronous)\u001b[0m\n\u001b[1;32m    549\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcommunicate_with_clock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mselected_clients\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0masynchronous\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msimulator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_client_completeness\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mselected_clients\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 551\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcommunicate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mselected_clients\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0masynchronous\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    552\u001b[0m         \u001b[0;31m# If all the selected clients are unavailable, directly return the result without waiting.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m         \u001b[0;31m# Else if all the available clients have dropped out and not using asynchronous communication,  waiting for `tolerance_for_latency` time units.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/FLGo/flgo/algorithm/fedbase.py\u001b[0m in \u001b[0;36mcommunicate\u001b[0;34m(self, selected_clients, mtype, asynchronous)\u001b[0m\n\u001b[1;32m    304\u001b[0m                 \u001b[0mserver_pkg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclient_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    305\u001b[0m                 \u001b[0mserver_pkg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'__mtype__'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 306\u001b[0;31m                 \u001b[0mresponse_from_client_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommunicate_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclients\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mclient_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpackage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mserver_pkg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    307\u001b[0m                 \u001b[0mpackages_received_from_clients\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse_from_client_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/FLGo/flgo/simulator/base.py\u001b[0m in \u001b[0;36mdelayed_communicate_with\u001b[0;34m(self, target_id, package)\u001b[0m\n\u001b[1;32m    493\u001b[0m         \u001b[0;31m# Set downloading package sizes for clients for downloading cost estimation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msimulator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_variable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__download_package_size'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msize_of_package\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpackage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 495\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcommunicate_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpackage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    496\u001b[0m         \u001b[0;31m# Set uploading package sizes for clients for uploading cost estimation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    497\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msimulator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_variable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__upload_package_size'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize_of_package\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/FLGo/flgo/algorithm/fedbase.py\u001b[0m in \u001b[0;36mcommunicate_with\u001b[0;34m(self, target_id, package)\u001b[0m\n\u001b[1;32m    347\u001b[0m             \u001b[0mwill\u001b[0m \u001b[0mbe\u001b[0m \u001b[0;34m'None'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mlosing\u001b[0m \u001b[0mconnection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m         \"\"\"\n\u001b[0;32m--> 349\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBasicServer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommunicate_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpackage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    350\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclient_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/FLGo/flgo/algorithm/fedbase.py\u001b[0m in \u001b[0;36mcommunicate_with\u001b[0;34m(self, target_id, package)\u001b[0m\n\u001b[1;32m    188\u001b[0m             \u001b[0mclient_package\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0mobject\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mwill\u001b[0m \u001b[0mbe\u001b[0m \u001b[0;34m'None'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mlosing\u001b[0m \u001b[0mconnection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         \"\"\"\n\u001b[0;32m--> 190\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommunicator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpackage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    191\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minitialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/FLGo/flgo/__init__.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, source, target, package)\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpackage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;31m# send package to the target object with `package` and `mtype`, and then listen from it\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobjects_map\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage_handler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpackage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/content/FLGo/flgo/algorithm/fedbase.py\u001b[0m in \u001b[0;36mmessage_handler\u001b[0;34m(self, package)\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmtype\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"There is no action corresponding to message type {}.\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmtype\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpackage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mset_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflag\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-35-6fa5a1eebeb4>\u001b[0m in \u001b[0;36mreply\u001b[0;34m(self, svr_pkg)\u001b[0m\n\u001b[1;32m    334\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    335\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfreeze_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 336\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    337\u001b[0m     \u001b[0mcpkg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mcpkg\u001b[0m \u001b[0;31m#client_pkg (dict): the package to be send to the server\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-35-6fa5a1eebeb4>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, global_model)\u001b[0m\n\u001b[1;32m    353\u001b[0m         \u001b[0mx0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m         \u001b[0mprint_head\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Epoch: [%2d] [%4d/%4d]\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0miter\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 355\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_vec_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglobal_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprint_head\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    356\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx0\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m<\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclass_num\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-35-6fa5a1eebeb4>\u001b[0m in \u001b[0;36mtrain_step\u001b[0;34m(self, x_, y_vec_, iter, global_model, optimizer, print_head)\u001b[0m\n\u001b[1;32m    368\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    369\u001b[0m     \u001b[0mG\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mZ\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mG\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_disc_2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 370\u001b[0;31m     \u001b[0mZ0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvqgan\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    371\u001b[0m     \u001b[0mG_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mG\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    372\u001b[0m     \u001b[0mC_real\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mglobal_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/VQGAN/vqgan.py\u001b[0m in \u001b[0;36mencode\u001b[0;34m(self, imgs)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimgs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0mencoded_images\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimgs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0mquant_conv_encoded_images\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquant_conv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoded_images\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0mcodebook_mapping\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcodebook_indices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mq_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcodebook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquant_conv_encoded_images\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-3-118067f7cc78>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    111\u001b[0m             ).to(device=args.device)\n\u001b[1;32m    112\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mDecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-3-118067f7cc78>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mEncoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/batchnorm.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    169\u001b[0m         \u001b[0mused\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mnormalization\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0;32min\u001b[0m \u001b[0meval\u001b[0m \u001b[0mmode\u001b[0m \u001b[0mwhen\u001b[0m \u001b[0mbuffers\u001b[0m \u001b[0mare\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m         \"\"\"\n\u001b[0;32m--> 171\u001b[0;31m         return F.batch_norm(\n\u001b[0m\u001b[1;32m    172\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m             \u001b[0;31m# If buffers are not to be tracked, ensure that they won't be updated\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mbatch_norm\u001b[0;34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001b[0m\n\u001b[1;32m   2448\u001b[0m         \u001b[0m_verify_batch_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2449\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2450\u001b[0;31m     return torch.batch_norm(\n\u001b[0m\u001b[1;32m   2451\u001b[0m         \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrunning_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrunning_var\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackends\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcudnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menabled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2452\u001b[0m     )\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 运行"
      ],
      "metadata": {
        "id": "eB7owhyvFw6Q"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yvmg2LP-1_7u",
        "outputId": "a3686997-91d7-4923-b6ef-852f3bb6b64e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pytorch-msssim in /usr/local/lib/python3.10/dist-packages (1.0.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from pytorch-msssim) (2.0.1+cu118)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->pytorch-msssim) (3.12.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->pytorch-msssim) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->pytorch-msssim) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->pytorch-msssim) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->pytorch-msssim) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch->pytorch-msssim) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->pytorch-msssim) (3.27.4.1)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->pytorch-msssim) (16.0.6)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->pytorch-msssim) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->pytorch-msssim) (1.3.0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2023-09-29 17:06:10,520 fflow.py init [line:441] INFO Initializing devices: cuda:0 will be used for this running.\n",
            "<ipython-input-27-4cf629bde010>:444: UserWarning: torch.range is deprecated and will be removed in a future release because its behavior is inconsistent with Python's range builtin. Instead, use torch.arange, which produces values in [start, end).\n",
            "  mean_Y = torch.range(0, class_num - 1, dtype=torch.int64).repeat(batch_size // class_num)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "client 0 总样本数： 5389  各类： [   0  352 2210    6   19  203   49    0    0 2550]\n",
            "client 1 总样本数： 5291  各类： [   0    1   89   59 4208  111  157    0   42  624]\n",
            "client 2 总样本数： 5342  各类： [   0 1889    0  342  402    1 2152  552    3    1]\n",
            "client 3 总样本数： 5470  各类： [   0    0  501  158    1    0   26 4518  266    0]\n",
            "client 4 总样本数： 5474  各类： [  27    0 2198    0   94 1443    0  469    0 1243]\n",
            "client 5 总样本数： 5355  各类： [4917    0    0   76    0    3    0    0    0  359]\n",
            "client 6 总样本数： 5526  各类： [   2    0    0    0  498    9  760    0 3683  574]\n",
            "client 7 总样本数： 5309  各类： [  28 2880    0  169    7   11 2154   60    0    0]\n",
            "client 8 总样本数： 5493  各类： [   0  902  242   42    2 3102    0    0 1203    0]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2023-09-29 17:06:25,060 fflow.py init [line:479] INFO Use `<class 'flgo.simulator.default_simulator.Simulator'>` as the system simulator\n",
            "2023-09-29 17:06:25,061 fflow.py init [line:487] INFO Ready to start.\n",
            "2023-09-29 17:06:25,074 fedbase.py run [line:236] INFO --------------Initial Evaluation--------------\n",
            "2023-09-29 17:06:25,075 simple_logger.py log_once [line:14] INFO Current_time:0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "client 9 总样本数： 5357  各类： [ 366   24  126 4658   24    1   13   41   75   29]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2023-09-29 17:06:29,022 simple_logger.py log_once [line:28] INFO test_accuracy                 0.1142\n",
            "2023-09-29 17:06:29,028 simple_logger.py log_once [line:28] INFO test_loss                     2.3023\n",
            "2023-09-29 17:06:29,030 simple_logger.py log_once [line:28] INFO valid_accuracy                0.1153\n",
            "2023-09-29 17:06:29,034 simple_logger.py log_once [line:28] INFO mean_valid_accuracy           0.1163\n",
            "2023-09-29 17:06:29,037 simple_logger.py log_once [line:28] INFO std_valid_accuracy            0.2052\n",
            "2023-09-29 17:06:29,038 simple_logger.py log_once [line:28] INFO valid_loss                    2.3032\n",
            "2023-09-29 17:06:29,039 simple_logger.py log_once [line:28] INFO mean_valid_loss               2.3033\n",
            "2023-09-29 17:06:29,042 simple_logger.py log_once [line:28] INFO std_valid_loss                0.0488\n",
            "2023-09-29 17:06:29,043 fedbase.py run [line:239] INFO Eval Time Cost:               3.9675s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "客户端选择： [3, 9]\n",
            "c_loss: 2.30, distill_loss0.00, recon_loss2.57\n",
            "c_loss: 2.31, distill_loss12.76, recon_loss0.59\n",
            "c_loss: 2.30, distill_loss0.00, recon_loss2.33\n",
            "c_loss: 2.31, distill_loss11.39, recon_loss0.51\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2023-09-29 17:06:43,412 fedbase.py run [line:246] INFO --------------Round 1--------------\n",
            "2023-09-29 17:06:43,415 simple_logger.py log_once [line:14] INFO Current_time:1\n",
            "2023-09-29 17:06:46,830 simple_logger.py log_once [line:28] INFO test_accuracy                 0.4722\n",
            "2023-09-29 17:06:46,831 simple_logger.py log_once [line:28] INFO test_loss                     1.7959\n",
            "2023-09-29 17:06:46,835 simple_logger.py log_once [line:28] INFO valid_accuracy                0.4674\n",
            "2023-09-29 17:06:46,837 simple_logger.py log_once [line:28] INFO mean_valid_accuracy           0.4657\n",
            "2023-09-29 17:06:46,839 simple_logger.py log_once [line:28] INFO std_valid_accuracy            0.2948\n",
            "2023-09-29 17:06:46,842 simple_logger.py log_once [line:28] INFO valid_loss                    1.7892\n",
            "2023-09-29 17:06:46,845 simple_logger.py log_once [line:28] INFO mean_valid_loss               1.7911\n",
            "2023-09-29 17:06:46,846 simple_logger.py log_once [line:28] INFO std_valid_loss                0.9212\n",
            "2023-09-29 17:06:46,849 fedbase.py run [line:251] INFO Eval Time Cost:               3.4339s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "客户端选择： [7, 6]\n",
            "c_loss: 2.92, distill_loss0.00, recon_loss2.57\n",
            "c_loss: 1.30, distill_loss0.75, recon_loss1.66\n",
            "c_loss: 2.83, distill_loss0.00, recon_loss2.13\n",
            "c_loss: 1.38, distill_loss0.52, recon_loss1.51\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2023-09-29 17:07:01,112 fedbase.py run [line:246] INFO --------------Round 2--------------\n",
            "2023-09-29 17:07:01,114 simple_logger.py log_once [line:14] INFO Current_time:2\n",
            "2023-09-29 17:07:04,566 simple_logger.py log_once [line:28] INFO test_accuracy                 0.7763\n",
            "2023-09-29 17:07:04,568 simple_logger.py log_once [line:28] INFO test_loss                     0.9587\n",
            "2023-09-29 17:07:04,570 simple_logger.py log_once [line:28] INFO valid_accuracy                0.7723\n",
            "2023-09-29 17:07:04,572 simple_logger.py log_once [line:28] INFO mean_valid_accuracy           0.7730\n",
            "2023-09-29 17:07:04,574 simple_logger.py log_once [line:28] INFO std_valid_accuracy            0.1797\n",
            "2023-09-29 17:07:04,575 simple_logger.py log_once [line:28] INFO valid_loss                    0.9624\n",
            "2023-09-29 17:07:04,576 simple_logger.py log_once [line:28] INFO mean_valid_loss               0.9601\n",
            "2023-09-29 17:07:04,578 simple_logger.py log_once [line:28] INFO std_valid_loss                0.5738\n",
            "2023-09-29 17:07:04,579 fedbase.py run [line:251] INFO Eval Time Cost:               3.4650s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "客户端选择： [1, 1]\n",
            "c_loss: 2.51, distill_loss0.00, recon_loss2.39\n",
            "c_loss: 0.62, distill_loss0.10, recon_loss1.33\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2023-09-29 17:07:12,213 fedbase.py run [line:246] INFO --------------Round 3--------------\n",
            "2023-09-29 17:07:12,215 simple_logger.py log_once [line:14] INFO Current_time:3\n",
            "2023-09-29 17:07:15,554 simple_logger.py log_once [line:28] INFO test_accuracy                 0.8807\n",
            "2023-09-29 17:07:15,555 simple_logger.py log_once [line:28] INFO test_loss                     0.5146\n",
            "2023-09-29 17:07:15,560 simple_logger.py log_once [line:28] INFO valid_accuracy                0.8655\n",
            "2023-09-29 17:07:15,563 simple_logger.py log_once [line:28] INFO mean_valid_accuracy           0.8658\n",
            "2023-09-29 17:07:15,565 simple_logger.py log_once [line:28] INFO std_valid_accuracy            0.0715\n",
            "2023-09-29 17:07:15,570 simple_logger.py log_once [line:28] INFO valid_loss                    0.5456\n",
            "2023-09-29 17:07:15,571 simple_logger.py log_once [line:28] INFO mean_valid_loss               0.5450\n",
            "2023-09-29 17:07:15,574 simple_logger.py log_once [line:28] INFO std_valid_loss                0.2892\n",
            "2023-09-29 17:07:15,575 fedbase.py run [line:251] INFO Eval Time Cost:               3.3607s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "客户端选择： [0, 8]\n",
            "c_loss: 2.75, distill_loss0.00, recon_loss2.50\n",
            "c_loss: 0.43, distill_loss0.05, recon_loss1.62\n",
            "c_loss: 2.40, distill_loss0.00, recon_loss2.45\n",
            "c_loss: 0.45, distill_loss0.11, recon_loss1.68\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2023-09-29 17:07:30,765 fedbase.py run [line:246] INFO --------------Round 4--------------\n",
            "2023-09-29 17:07:30,766 simple_logger.py log_once [line:14] INFO Current_time:4\n",
            "2023-09-29 17:07:34,286 simple_logger.py log_once [line:28] INFO test_accuracy                 0.8710\n",
            "2023-09-29 17:07:34,289 simple_logger.py log_once [line:28] INFO test_loss                     0.4157\n",
            "2023-09-29 17:07:34,292 simple_logger.py log_once [line:28] INFO valid_accuracy                0.8642\n",
            "2023-09-29 17:07:34,295 simple_logger.py log_once [line:28] INFO mean_valid_accuracy           0.8640\n",
            "2023-09-29 17:07:34,297 simple_logger.py log_once [line:28] INFO std_valid_accuracy            0.1397\n",
            "2023-09-29 17:07:34,299 simple_logger.py log_once [line:28] INFO valid_loss                    0.4328\n",
            "2023-09-29 17:07:34,300 simple_logger.py log_once [line:28] INFO mean_valid_loss               0.4331\n",
            "2023-09-29 17:07:34,301 simple_logger.py log_once [line:28] INFO std_valid_loss                0.4177\n",
            "2023-09-29 17:07:34,302 fedbase.py run [line:251] INFO Eval Time Cost:               3.5365s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "客户端选择： [6, 7]\n",
            "c_loss: 1.07, distill_loss0.00, recon_loss1.64\n",
            "c_loss: 0.15, distill_loss0.09, recon_loss1.23\n",
            "c_loss: 1.16, distill_loss0.00, recon_loss1.21\n",
            "c_loss: 0.17, distill_loss0.08, recon_loss1.04\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2023-09-29 17:07:49,502 fedbase.py run [line:246] INFO --------------Round 5--------------\n",
            "2023-09-29 17:07:49,504 simple_logger.py log_once [line:14] INFO Current_time:5\n",
            "2023-09-29 17:07:53,205 simple_logger.py log_once [line:28] INFO test_accuracy                 0.9216\n",
            "2023-09-29 17:07:53,207 simple_logger.py log_once [line:28] INFO test_loss                     0.3084\n",
            "2023-09-29 17:07:53,210 simple_logger.py log_once [line:28] INFO valid_accuracy                0.9116\n",
            "2023-09-29 17:07:53,213 simple_logger.py log_once [line:28] INFO mean_valid_accuracy           0.9116\n",
            "2023-09-29 17:07:53,215 simple_logger.py log_once [line:28] INFO std_valid_accuracy            0.0885\n",
            "2023-09-29 17:07:53,217 simple_logger.py log_once [line:28] INFO valid_loss                    0.3264\n",
            "2023-09-29 17:07:53,220 simple_logger.py log_once [line:28] INFO mean_valid_loss               0.3264\n",
            "2023-09-29 17:07:53,222 simple_logger.py log_once [line:28] INFO std_valid_loss                0.3092\n",
            "2023-09-29 17:07:53,223 fedbase.py run [line:251] INFO Eval Time Cost:               3.7188s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "客户端选择： [0, 9]\n",
            "c_loss: 0.15, distill_loss0.00, recon_loss1.60\n",
            "c_loss: 0.14, distill_loss0.08, recon_loss1.22\n",
            "c_loss: 4.52, distill_loss0.00, recon_loss0.48\n",
            "c_loss: 0.67, distill_loss0.20, recon_loss1.63\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2023-09-29 17:08:07,197 fedbase.py run [line:246] INFO --------------Round 6--------------\n",
            "2023-09-29 17:08:07,198 simple_logger.py log_once [line:14] INFO Current_time:6\n",
            "2023-09-29 17:08:10,602 simple_logger.py log_once [line:28] INFO test_accuracy                 0.9479\n",
            "2023-09-29 17:08:10,603 simple_logger.py log_once [line:28] INFO test_loss                     0.2233\n",
            "2023-09-29 17:08:10,605 simple_logger.py log_once [line:28] INFO valid_accuracy                0.9398\n",
            "2023-09-29 17:08:10,608 simple_logger.py log_once [line:28] INFO mean_valid_accuracy           0.9400\n",
            "2023-09-29 17:08:10,610 simple_logger.py log_once [line:28] INFO std_valid_accuracy            0.0602\n",
            "2023-09-29 17:08:10,617 simple_logger.py log_once [line:28] INFO valid_loss                    0.2409\n",
            "2023-09-29 17:08:10,618 simple_logger.py log_once [line:28] INFO mean_valid_loss               0.2403\n",
            "2023-09-29 17:08:10,622 simple_logger.py log_once [line:28] INFO std_valid_loss                0.1823\n",
            "2023-09-29 17:08:10,624 fedbase.py run [line:251] INFO Eval Time Cost:               3.4264s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "客户端选择： [8, 2]\n",
            "c_loss: 0.23, distill_loss0.00, recon_loss1.51\n",
            "c_loss: 0.08, distill_loss0.04, recon_loss1.29\n",
            "c_loss: 2.70, distill_loss0.00, recon_loss2.29\n",
            "c_loss: 0.68, distill_loss0.03, recon_loss1.79\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2023-09-29 17:08:24,615 fedbase.py run [line:246] INFO --------------Round 7--------------\n",
            "2023-09-29 17:08:24,616 simple_logger.py log_once [line:14] INFO Current_time:7\n",
            "2023-09-29 17:08:28,334 simple_logger.py log_once [line:28] INFO test_accuracy                 0.9639\n",
            "2023-09-29 17:08:28,339 simple_logger.py log_once [line:28] INFO test_loss                     0.1775\n",
            "2023-09-29 17:08:28,341 simple_logger.py log_once [line:28] INFO valid_accuracy                0.9596\n",
            "2023-09-29 17:08:28,342 simple_logger.py log_once [line:28] INFO mean_valid_accuracy           0.9596\n",
            "2023-09-29 17:08:28,347 simple_logger.py log_once [line:28] INFO std_valid_accuracy            0.0348\n",
            "2023-09-29 17:08:28,349 simple_logger.py log_once [line:28] INFO valid_loss                    0.1903\n",
            "2023-09-29 17:08:28,350 simple_logger.py log_once [line:28] INFO mean_valid_loss               0.1904\n",
            "2023-09-29 17:08:28,351 simple_logger.py log_once [line:28] INFO std_valid_loss                0.1595\n",
            "2023-09-29 17:08:28,352 fedbase.py run [line:251] INFO Eval Time Cost:               3.7360s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "客户端选择： [1, 1]\n",
            "c_loss: 0.33, distill_loss0.00, recon_loss1.26\n",
            "c_loss: 0.17, distill_loss0.01, recon_loss1.34\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2023-09-29 17:08:35,263 fedbase.py run [line:246] INFO --------------Round 8--------------\n",
            "2023-09-29 17:08:35,264 simple_logger.py log_once [line:14] INFO Current_time:8\n",
            "2023-09-29 17:08:38,601 simple_logger.py log_once [line:28] INFO test_accuracy                 0.9531\n",
            "2023-09-29 17:08:38,603 simple_logger.py log_once [line:28] INFO test_loss                     0.1971\n",
            "2023-09-29 17:08:38,604 simple_logger.py log_once [line:28] INFO valid_accuracy                0.9468\n",
            "2023-09-29 17:08:38,606 simple_logger.py log_once [line:28] INFO mean_valid_accuracy           0.9469\n",
            "2023-09-29 17:08:38,608 simple_logger.py log_once [line:28] INFO std_valid_accuracy            0.0546\n",
            "2023-09-29 17:08:38,614 simple_logger.py log_once [line:28] INFO valid_loss                    0.2149\n",
            "2023-09-29 17:08:38,615 simple_logger.py log_once [line:28] INFO mean_valid_loss               0.2146\n",
            "2023-09-29 17:08:38,616 simple_logger.py log_once [line:28] INFO std_valid_loss                0.1890\n",
            "2023-09-29 17:08:38,617 fedbase.py run [line:251] INFO Eval Time Cost:               3.3534s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "客户端选择： [3, 5]\n",
            "c_loss: 5.77, distill_loss0.00, recon_loss0.48\n",
            "c_loss: 0.70, distill_loss0.11, recon_loss1.55\n",
            "c_loss: 2.48, distill_loss0.00, recon_loss3.00\n",
            "c_loss: 0.24, distill_loss0.08, recon_loss2.05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2023-09-29 17:08:52,619 fedbase.py run [line:246] INFO --------------Round 9--------------\n",
            "2023-09-29 17:08:52,621 simple_logger.py log_once [line:14] INFO Current_time:9\n",
            "2023-09-29 17:08:57,215 simple_logger.py log_once [line:28] INFO test_accuracy                 0.9720\n",
            "2023-09-29 17:08:57,216 simple_logger.py log_once [line:28] INFO test_loss                     0.1276\n",
            "2023-09-29 17:08:57,220 simple_logger.py log_once [line:28] INFO valid_accuracy                0.9676\n",
            "2023-09-29 17:08:57,222 simple_logger.py log_once [line:28] INFO mean_valid_accuracy           0.9677\n",
            "2023-09-29 17:08:57,224 simple_logger.py log_once [line:28] INFO std_valid_accuracy            0.0220\n",
            "2023-09-29 17:08:57,227 simple_logger.py log_once [line:28] INFO valid_loss                    0.1412\n",
            "2023-09-29 17:08:57,230 simple_logger.py log_once [line:28] INFO mean_valid_loss               0.1407\n",
            "2023-09-29 17:08:57,231 simple_logger.py log_once [line:28] INFO std_valid_loss                0.0563\n",
            "2023-09-29 17:08:57,232 fedbase.py run [line:251] INFO Eval Time Cost:               4.6113s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "客户端选择： [4, 2]\n",
            "c_loss: 0.11, distill_loss0.00, recon_loss1.29\n",
            "c_loss: 0.14, distill_loss0.04, recon_loss1.23\n",
            "c_loss: 2.60, distill_loss0.00, recon_loss2.69\n"
          ]
        }
      ],
      "source": [
        "from flgo.algorithm.fedbase import BasicServer, BasicClient\n",
        "import flgo.algorithm.fedavg as fedavg\n",
        "os.chdir('/content/GAN')\n",
        "#from infoGAN import infoGAN\n",
        "os.chdir(BASEPATH)\n",
        "import copy\n",
        "from flgo.utils import fmodule\n",
        "import flgo\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "import json\n",
        "import importlib\n",
        "!pip install pytorch-msssim\n",
        "from pytorch_msssim import ssim\n",
        "\n",
        "def masked_loss(A, B, mask, threshold = 0.5):\n",
        "  masked_A = A * mask      # 将掩码应用到特征图 A\n",
        "  masked_B = B * mask      # 将掩码应用到特征图 B\n",
        "  mask_mean = torch.mean(mask, dim=(2, 3))\n",
        "  # 将小于阈值的图像掩码置零，并计算非零元素的均值\n",
        "  loss_mask = torch.mean(torch.relu(threshold - mask_mean))\n",
        "  return F.mse_loss(masked_A, masked_B)+loss_mask\n",
        "\n",
        "def imageDiffLoss(input1, input2):\n",
        "  loss = 1 - ssim(input1, input2)\n",
        "  return loss\n",
        "\n",
        "def load_vqgan(checkpoint_path,args):\n",
        "  model = VQGAN_my(args)\n",
        "  model.load_checkpoint(checkpoint_path)\n",
        "  model = model.eval()\n",
        "  return model\n",
        "\n",
        "class discriminator(nn.Module):\n",
        "  # Network Architecture is exactly same as in infoGAN (https://arxiv.org/abs/1606.03657)\n",
        "  # Architecture : (64)4c2s-(128)4c2s_BL-FC1024_BL-FC1_S\n",
        "  def __init__(self, input_dim=1, output_dim=1, input_size=32, latent_dim=1):\n",
        "    super(discriminator, self).__init__()\n",
        "    self.input_dim = input_dim\n",
        "    self.output_dim = output_dim\n",
        "    self.input_size = input_size\n",
        "    if latent_dim==1:\n",
        "      self.fc_in_dim = 128 * (self.input_size // 4) * (self.input_size // 4)\n",
        "    else:\n",
        "      self.fc_in_dim = latent_dim * (self.input_size // 4) * (self.input_size // 4)\n",
        "    self.conv = nn.Sequential(\n",
        "        nn.Conv2d(self.input_dim, 64, 4, 2, 1),\n",
        "        nn.LeakyReLU(0.2),\n",
        "        nn.Conv2d(64, 128, 4, 2, 1),\n",
        "        nn.BatchNorm2d(128),\n",
        "        nn.LeakyReLU(0.2),\n",
        "    )\n",
        "    self.fc = nn.Sequential(\n",
        "        nn.Linear(self.fc_in_dim, 1024),\n",
        "        nn.BatchNorm1d(1024),\n",
        "        nn.LeakyReLU(0.2),\n",
        "        nn.Linear(1024, self.output_dim),\n",
        "        nn.Sigmoid(),\n",
        "    )\n",
        "\n",
        "  def forward(self, input, mod='latent'):#'all'):\n",
        "    if mod!='latent':\n",
        "      input = self.conv(input)\n",
        "    x = input.reshape(-1, self.fc_in_dim)\n",
        "    x = self.fc(x)\n",
        "\n",
        "    return x\n",
        "\n",
        "class Residual(nn.Module):\n",
        "  def __init__(self, in_channels, num_hiddens, num_residual_hiddens):\n",
        "    super(Residual, self).__init__()\n",
        "    self.num_hiddens = num_hiddens\n",
        "    self._block = nn.Sequential(\n",
        "        nn.ReLU(True),\n",
        "        nn.Conv2d(in_channels=in_channels,\n",
        "                  out_channels=num_residual_hiddens,\n",
        "                  kernel_size=3, stride=1, padding=1, bias=False),\n",
        "        nn.ReLU(True),\n",
        "        nn.Conv2d(in_channels=num_residual_hiddens,\n",
        "                  out_channels=num_hiddens,\n",
        "                  kernel_size=1, stride=1, bias=False)\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "      return x[:,:self.num_hiddens] + F.tanh(self._block(x))\n",
        "\n",
        "\n",
        "class ResidualStack(nn.Module):\n",
        "  def __init__(self, in_channels, num_hiddens, num_residual_layers, num_residual_hiddens):\n",
        "    super(ResidualStack, self).__init__()\n",
        "    self._num_residual_layers = num_residual_layers\n",
        "    self._layer0 = Residual(in_channels, num_hiddens, num_residual_hiddens)\n",
        "    self._layers = nn.ModuleList([Residual(num_hiddens, num_hiddens, num_residual_hiddens)\n",
        "                          for _ in range(self._num_residual_layers-1)])\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self._layer0(x)\n",
        "    for i in range(self._num_residual_layers-1):\n",
        "      x = self._layers[i](x)\n",
        "    return F.relu(x)\n",
        "\n",
        "class generator(nn.Module): #适用于图像大小是4的倍数的数据(mnist-28,cifa10-32)\n",
        "  def __init__(self, input_dim, input_size ,vqgan, class_num=10, latent_dim=1024):\n",
        "    super().__init__()\n",
        "    self.input_dim = input_dim\n",
        "    self.input_size = input_size\n",
        "    self.vqgan = vqgan\n",
        "    self.class_num = class_num\n",
        "    self.z_channel = self.vqgan.args.latent_dim\n",
        "    self.z_size = (self.input_size // 4)\n",
        "    self.G_z = nn.Sequential(\n",
        "            #nn.Linear(self.input_dim + self.class_num, latent_dim),\n",
        "            nn.Linear(self.input_dim, latent_dim),\n",
        "            nn.BatchNorm1d(latent_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(latent_dim, self.z_channel*self.z_size*self.z_size),\n",
        "            nn.BatchNorm1d(self.z_channel*self.z_size*self.z_size),\n",
        "            nn.ReLU(),\n",
        "        )\n",
        "\n",
        "    self.change_z= nn.Sequential(\n",
        "            nn.Conv2d(self.z_channel+class_num, self.z_channel, 5, 1, 2),\n",
        "            nn.BatchNorm2d(self.z_channel),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Conv2d(self.z_channel, self.z_channel, 5, 1, 2),\n",
        "            nn.BatchNorm2d(self.z_channel),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Conv2d(self.z_channel, self.z_channel, 5, 1, 2),\n",
        "            nn.BatchNorm2d(self.z_channel),\n",
        "            nn.LeakyReLU(0.2),\n",
        "        )\n",
        "\n",
        "    self._residual_stack= ResidualStack(in_channels=self.z_channel,\n",
        "              num_hiddens=self.z_channel,\n",
        "              num_residual_layers=self.z_channel,\n",
        "              num_residual_hiddens=2)\n",
        "\n",
        "    # 冻结vqgan的参数\n",
        "    for param in self.vqgan.parameters():\n",
        "      param.requires_grad = False\n",
        "\n",
        "\n",
        "  def forward(self, input, label, mod=\"z_in\"):\n",
        "    if mod !=\"z_in\":\n",
        "      input = self.G_z(input)#torch.cat([input, label], 1))\n",
        "      input = input.view(-1, self.z_channel, self.z_size, self.z_size)\n",
        "    label = label.unsqueeze(-1).unsqueeze(-1)  # 添加两个维度，使其与输入图像的维度相匹配\n",
        "    label = label.expand(label.size(0), label.size(1), input.size(2), input.size(3))  # 扩展为与输入图像相同的尺寸\n",
        "    z = self.change_z(torch.cat([input, label], 1))\n",
        "    #z = self._residual_stack(z)\n",
        "    x = self.z_to_image(z)\n",
        "    return x\n",
        "\n",
        "  def z_to_image(self, z):\n",
        "    z_vq, _, _ = self.vqgan.codebook(z)\n",
        "    image = self.vqgan.decode(z_vq)\n",
        "    return image,z_vq\n",
        "\n",
        "def crop_image(image, target_size):\n",
        "    # 获取原始图像的大小\n",
        "    original_size = image.shape[-1]\n",
        "\n",
        "    # 计算裁剪区域的边界\n",
        "    left = (original_size - target_size) // 2\n",
        "    top = (original_size - target_size) // 2\n",
        "    right = left + target_size\n",
        "    bottom = top + target_size\n",
        "\n",
        "    # 裁剪图像\n",
        "    cropped_image = image[:,:,top:bottom, left:right]\n",
        "\n",
        "    return cropped_image\n",
        "\n",
        "class augmentation(nn.Module):\n",
        "  def __init__(self, vqgan, input_dim=1, input_size=32, class_num=10):\n",
        "    super(augmentation, self).__init__()\n",
        "    self.vqgan = vqgan\n",
        "    self.input_dim = input_dim\n",
        "    self.input_size = input_size\n",
        "    self.class_num = class_num\n",
        "    self.z_channel = self.vqgan.args.latent_dim\n",
        "    self._conv_1 = nn.Sequential(\n",
        "        nn.Conv2d(self.input_dim+class_num, 32, 4, 2, 1),\n",
        "        nn.BatchNorm2d(32),\n",
        "        nn.LeakyReLU(0.2),\n",
        "        nn.Conv2d(32, 64, 4, 2, 1),\n",
        "        nn.BatchNorm2d(64),\n",
        "        nn.LeakyReLU(0.2),\n",
        "        nn.Conv2d(64, 64, 3, 1, 1),\n",
        "        nn.BatchNorm2d(64),\n",
        "        nn.LeakyReLU(0.2),)\n",
        "    self._conv_trans_1  = nn.Sequential(\n",
        "        nn.ConvTranspose2d(64, 64, 4, 2, 1),\n",
        "        nn.BatchNorm2d(64),\n",
        "        nn.LeakyReLU(0.2),\n",
        "        nn.ConvTranspose2d(64, 32, 4, 2, 1),\n",
        "        nn.BatchNorm2d(32),\n",
        "        nn.LeakyReLU(0.2),\n",
        "        nn.ConvTranspose2d(32, self.input_dim, 3, 1, 1),\n",
        "        nn.Tanh(),\n",
        "    )\n",
        "\n",
        "    self._conv = nn.Sequential(\n",
        "        nn.Conv2d(self.z_channel+class_num, self.z_channel, 5, 1, 2),\n",
        "        nn.BatchNorm2d(self.z_channel),\n",
        "        nn.LeakyReLU(0.2),\n",
        "        nn.Conv2d(self.z_channel, self.z_channel, 3, 1, 1),\n",
        "        nn.BatchNorm2d(self.z_channel),\n",
        "        nn.LeakyReLU(0.2),\n",
        "        nn.Conv2d(self.z_channel, self.z_channel, 3, 1, 1),\n",
        "        nn.BatchNorm2d(self.z_channel),\n",
        "        nn.LeakyReLU(0.2),\n",
        "        nn.Conv2d(self.z_channel, self.z_channel, 1, 1, 0),\n",
        "        )\n",
        "    self.mask = nn.Sequential(\n",
        "        nn.Conv2d(self.z_channel, 1, 1, 1, 0),\n",
        "        nn.Sigmoid(),\n",
        "        )\n",
        "\n",
        "    # 冻结vqgan的参数\n",
        "    for param in self.vqgan.parameters():\n",
        "      param.requires_grad = False\n",
        "\n",
        "  def forward0(self, x, label):\n",
        "    # 将类别标签转换为 one-hot 编码\n",
        "    label = label.unsqueeze(-1).unsqueeze(-1)  # 添加两个维度，使其与输入图像的维度相匹配\n",
        "    label = label.expand(label.size(0), label.size(1), x.size(2), x.size(3))  # 扩展为与输入图像相同的尺寸\n",
        "    x = self._conv_1(torch.cat([x, label], dim=1)) # 在通道维度上拼接输入图像和类别标签\n",
        "    x = self._conv_trans_1(x)\n",
        "    x = crop_image(x,self.input_size)\n",
        "    x = self.vqgan.change(x)\n",
        "    return self.vqgan(x)[0],x\n",
        "\n",
        "  def forward(self, x, label):\n",
        "    # 将类别标签转换为 one-hot 编码\n",
        "    z = self.encode(x) #torch.Size([32, 64, 7, 7])\n",
        "    label = label.unsqueeze(-1).unsqueeze(-1)  # 添加两个维度，使其与输入图像的维度相匹配\n",
        "    label = label.expand(label.size(0), label.size(1), z.size(2), z.size(3))  # 扩展为与输入图像相同的尺寸\n",
        "    z = self._conv(torch.cat([z, label], dim=1))\n",
        "    #z_, _, _ = self.vqgan.codebook(z)\n",
        "    x = self.decode(z)\n",
        "    x = self.vqgan.change(x)\n",
        "    return x,z,self.mask(z)\n",
        "\n",
        "  def encode(self, imgs):\n",
        "    encoded_images = self.vqgan.encoder(imgs)\n",
        "    quant_conv_encoded_images = self.vqgan.quant_conv(encoded_images)\n",
        "    return quant_conv_encoded_images\n",
        "\n",
        "  def decode(self, z):\n",
        "    z, _, _ = self.vqgan.codebook(z)\n",
        "    post_quant_conv_mapping = self.vqgan.post_quant_conv(z)\n",
        "    decoded_images = self.vqgan.decoder(post_quant_conv_mapping)\n",
        "    return decoded_images\n",
        "\n",
        "\n",
        "class Server(BasicServer):\n",
        "  def initialize(self, *args, **kwargs):\n",
        "    # 指定随机种子创建随机数生成器对象\n",
        "    np.random.seed(0)\n",
        "    self.rng_sample = np.random.RandomState(42) #采样客户端专用的随机数生成器，以免在其他地方改变随机数列表\n",
        "  def pack(self, client_id, mtype=0, *args, **kwargs):\n",
        "    return {\n",
        "        \"model\": copy.deepcopy(self.model),\n",
        "        \"round\": self.current_round,\n",
        "    }\n",
        "  def sample(self):\n",
        "    all_clients = self.available_clients if 'available' in self.sample_option else [cid for cid in range(self.num_clients)]\n",
        "    # full sampling with unlimited communication resources of the server\n",
        "    if 'full' in self.sample_option:\n",
        "        return all_clients\n",
        "    # sample clients\n",
        "    elif 'uniform' in self.sample_option:\n",
        "        # original sample proposed by fedavg\n",
        "        selected_clients = list(\n",
        "            self.rng_sample.choice(all_clients, min(self.clients_per_round, len(all_clients)), replace=False)) if len(\n",
        "            all_clients) > 0 else []\n",
        "    elif 'md' in self.sample_option:\n",
        "        # the default setting that is introduced by FedProx, where the clients are sampled with the probability in proportion to their local_movielens_recommendation data sizes\n",
        "        local_data_vols = [self.clients[cid].datavol for cid in all_clients]\n",
        "        total_data_vol = sum(local_data_vols)\n",
        "        p = np.array(local_data_vols) / total_data_vol\n",
        "        selected_clients = list(self.rng_sample.choice(all_clients, self.clients_per_round, replace=True, p=p)) if len(\n",
        "            all_clients) > 0 else []\n",
        "    print('客户端选择：',selected_clients)\n",
        "    return selected_clients\n",
        "class Client(BasicClient):\n",
        "  def initialize(self, *args, **kwargs):\n",
        "    self.rng_local = np.random.RandomState(0) #专用的随机对象\n",
        "    self.z_dim = 62\n",
        "    if self.option['gpu']!='':\n",
        "      self.gpu_mode = 1\n",
        "    else:\n",
        "      self.gpu_mode = 0\n",
        "    self.gan_clip_grad = 10 #(默认为0)\n",
        "    #self.clip_grad = 10\n",
        "    self.class_num = self.option['class_num']\n",
        "    self.sample_num = self.class_num ** 2\n",
        "\n",
        "    data_shape = self.train_data[0][0].shape\n",
        "\n",
        "    vqgan = load_vqgan(os.path.join(\"/content/FLGo/checkpoints\", f\"{self.option['vqgan_args'].task}.vqgan_epoch_pre.pt\"),self.option['vqgan_args'])\n",
        "    self.vqgan2 = load_vqgan(os.path.join(\"/content/FLGo/checkpoints\", f\"{self.option['vqgan_args'].task}.vqgan_epoch.pt\"),self.option['vqgan_args'])\n",
        "    self.G = generator(self.z_dim,data_shape[1],vqgan,class_num=self.class_num)\n",
        "    self.A = augmentation(vqgan,input_dim=data_shape[0], input_size=data_shape[1],class_num=self.class_num).to(device=self.option['vqgan_args'].device)\n",
        "    self.D = discriminator(input_dim=data_shape[0], input_size=data_shape[1]).to(device=self.option['vqgan_args'].device)#, latent_dim=self.option['vqgan_args'].latent_dim).to(device=self.option['vqgan_args'].device)\n",
        "    self.G_optimizer = optim.Adam(self.G.parameters(), lr=self.option['G_lr'], betas=(self.option['vqgan_args'].beta1, self.option['vqgan_args'].beta2))\n",
        "    self.A_optimizer = optim.Adam(self.A.parameters(), lr=self.option['G_lr'], betas=(self.option['vqgan_args'].beta1, self.option['vqgan_args'].beta2))\n",
        "    self.D_optimizer = optim.Adam(self.D.parameters(), lr=self.option['D_lr'], betas=(self.option['vqgan_args'].beta1, self.option['vqgan_args'].beta2))\n",
        "    self.V_optimizer = optim.Adam(self.vqgan2.parameters(), lr=self.option['V_lr'], betas=(self.option['vqgan_args'].beta1, self.option['vqgan_args'].beta2))\n",
        "\n",
        "    sample_z_=self.generate_random_z(self.class_num,self.z_dim,self.gpu_mode)\n",
        "    self.sample_z_=sample_z_.unsqueeze(1).repeat(1,self.class_num,1).reshape(-1,self.z_dim)\n",
        "    sample_y_=self.generate_labels(self.class_num, self.class_num, self.gpu_mode, rng_local=self.rng_local)\n",
        "    self.sample_y_=sample_y_.unsqueeze(0).repeat(self.class_num,1,1).reshape(-1,self.class_num)\n",
        "    self.rslt_path = self.get_rslt_path()\n",
        "    if self.gpu_mode:\n",
        "      self.G.cuda()\n",
        "\n",
        "    # 冻结除了 decoder 之外的参数\n",
        "    for name, param in self.vqgan2.named_parameters():\n",
        "        if 'decoder' not in name:\n",
        "            param.requires_grad = False\n",
        "\n",
        "  def unpack(self, received_pkg):\n",
        "    return received_pkg['model'],received_pkg['round']\n",
        "  def get_loc_data(self):\n",
        "    date_num=len(self.train_data)#.indices)\n",
        "    data_loader = self.calculator.get_dataloader(self.train_data, batch_size=date_num)\n",
        "    y_ = data_loader.__iter__().__next__()[1]\n",
        "    y_vec_ = torch.zeros((y_.shape[0], 10)).scatter_(1, y_.type(torch.LongTensor).unsqueeze(1), 1)\n",
        "    c = y_vec_.sum(0)\n",
        "    print(\"client\",self.id,\"总样本数：\",date_num,\" 各类：\", c.int().numpy())\n",
        "    return c\n",
        "  def reply(self, svr_pkg):\n",
        "    model,self.round = self.unpack(svr_pkg) #svr_pkg (dict): the package received from the server\n",
        "    self.src_model = copy.deepcopy(model)\n",
        "    self.src_model.freeze_grad()\n",
        "    self.train(model)\n",
        "    cpkg = self.pack(model)\n",
        "    return cpkg #client_pkg (dict): the package to be send to the server\n",
        "\n",
        "  def train(self,global_model):\n",
        "    global_model.train()\n",
        "    self.G.train()\n",
        "    self.A.train()\n",
        "    optimizer = self.calculator.get_optimizer(global_model, lr=self.learning_rate, weight_decay=self.weight_decay,\n",
        "                                              momentum=self.momentum)\n",
        "    for epoch in range(self.num_epochs):\n",
        "      for iter in range(self.num_steps):\n",
        "        batch_data = self.get_batch_data()\n",
        "        x_,y_ = batch_data\n",
        "        y_vec_ = torch.zeros((self.batch_size, self.class_num)).scatter_(1, y_.type(torch.LongTensor).unsqueeze(1), 1)\n",
        "        x_,y_vec_ = self.to_gpu([x_,y_vec_])\n",
        "        if self.option['batch_size'] != batch_data[1].shape[0]:\n",
        "          break\n",
        "        x0,y0 = x_,y_\n",
        "        print_head = \"Epoch: [%2d] [%4d/%4d]\" % ((epoch + 1), (iter + 1), client.num_steps)\n",
        "        self.train_step(x_,y_vec_, iter, global_model, optimizer, print_head)\n",
        "      with torch.no_grad():\n",
        "        if x0.shape[0]<self.class_num:\n",
        "          print(x0.shape[0])\n",
        "          break\n",
        "        self.visualize_results(epoch+1,x0,y0)\n",
        "    return\n",
        "\n",
        "  def train_step(self, x_, y_vec_, iter, global_model, optimizer, print_head):\n",
        "    z_ = self.generate_random_z(self.batch_size, self.z_dim, self.gpu_mode)\n",
        "    y_disc_ = self.generate_labels(self.G.class_num, self.batch_size, self.gpu_mode, rng_local=self.rng_local)\n",
        "    y_disc_2 = self.generate_labels(self.G.class_num, self.batch_size, self.gpu_mode, rng_local=self.rng_local,mod='rand')\n",
        "\n",
        "    G,Z,M = self.A(x_,y_disc_2)\n",
        "    G_v,_,_ = self.vqgan2(G)\n",
        "\n",
        "    G2,Z2,_ = self.A(x_,y_vec_)\n",
        "    G3,Z3,_ = self.A(G,y_vec_)\n",
        "    G4,Z4,_ = self.A(G.detach(),y_disc_2)\n",
        "    Z0 = self.A.encode(x_).detach()\n",
        "    G_t = G\n",
        "    #G_t,_ = self.A(G_v,y_disc_2)\n",
        "    #G_t,_,_ = self.vqgan2(G_t)\n",
        "\n",
        "    C_real = global_model(x_)\n",
        "    ## 训练分类模型\n",
        "    optimizer.zero_grad()\n",
        "    batch_data=[x_,torch.max(y_vec_, 1)[1]]\n",
        "    # calculate the loss of the model on batched dataset through task-specified calculator\n",
        "    C_src = self.src_model(G_t).detach()\n",
        "    C_ = global_model(G_t.detach())\n",
        "    logic_mean=(F.softmax(C_src, dim=-1) * y_disc_2).sum(-1).detach().mean()\n",
        "    logic_mask=(logic_mean>0.5).float()\n",
        "    distill_loss = F.mse_loss(C_src, C_)\n",
        "    loss = F.cross_entropy(C_real,y_vec_)+logic_mask*distill_loss\n",
        "\n",
        "    loss.backward(retain_graph=True)\n",
        "    if self.clip_grad>0:torch.nn.utils.clip_grad_norm_(parameters=global_model.parameters(), max_norm=self.clip_grad)\n",
        "    optimizer.step()\n",
        "\n",
        "    self.A_optimizer.zero_grad()\n",
        "\n",
        "    #d_loss = -torch.mean(disc_fake)\n",
        "    recon_loss = F.mse_loss(G2, x_)+F.mse_loss(G3, x_)#+F.mse_loss(G2_, x_)+F.mse_loss(G3_, x_)#+F.mse_loss(G2_v, x_)+F.mse_loss(G3_v, x_)\n",
        "    #z_loss = self.mse_loss_clip(Z0, Z2, 0)+self.mse_loss_clip(Z0, Z3, 0)+self.mse_loss_clip(Z0, Z, 0)\n",
        "    #z_loss = F.mse_loss(Z0, Z2)+0*F.mse_loss(Z0, Z3)+10*F.mse_loss(Z0, Z)\n",
        "    z_loss = F.mse_loss(Z0, Z2)+F.mse_loss(Z0, Z3)+10*F.mse_loss(Z0, Z)#masked_loss(Z0, Z3, M)#masked_loss(Z0, Z, M)#F.mse_loss(Z0, Z)\n",
        "    cycle_loss = F.mse_loss(G4.detach(), G)\n",
        "    c_loss = F.cross_entropy(self.src_model(G), y_disc_2)#+0.1*F.cross_entropy(self.src_model(G3), y_vec_)\n",
        "    G_loss = c_loss + z_loss #+ recon_loss#+ cycle_loss\n",
        "    G_loss.backward()\n",
        "\n",
        "    #if self.gan_clip_grad>0:torch.nn.utils.clip_grad_norm_(parameters=self.vqgan2.parameters(), max_norm=self.gan_clip_grad)\n",
        "    #self.V_optimizer.step()\n",
        "    if self.gan_clip_grad>0:torch.nn.utils.clip_grad_norm_(parameters=self.A.parameters(), max_norm=self.gan_clip_grad)\n",
        "    self.A_optimizer.step()\n",
        "    #if self.gan_clip_grad>0:torch.nn.utils.clip_grad_norm_(parameters=self.G.parameters(), max_norm=self.gan_clip_grad)\n",
        "    #self.G_optimizer.step()\n",
        "    if iter % 100 == 0:\n",
        "      print(\"c_loss: %.2f, distill_loss%.2f, recon_loss%.2f\"\n",
        "      %(c_loss.item(),distill_loss.item(),recon_loss.item()))\n",
        "  @staticmethod\n",
        "  def mse_loss_clip(a,b,clip=0):\n",
        "    loss = F.mse_loss(a, b, reduce=False).mean(dim=(1,2,3))\n",
        "    loss[loss<clip] = 0\n",
        "    return loss.mean()\n",
        "\n",
        "  def to_gpu(self,data_tuple):\n",
        "    if self.gpu_mode:\n",
        "      return tuple(data_tensor.cuda() for data_tensor in data_tuple)\n",
        "    else:\n",
        "      return data_tuple\n",
        "  # Function to generate random z_ for G network:\n",
        "  @staticmethod\n",
        "  def generate_random_z(batch_size, z_dim, gpu_mode):\n",
        "    z_ = torch.rand((batch_size, z_dim))\n",
        "    if gpu_mode:\n",
        "      z_ = z_.cuda()\n",
        "    return z_\n",
        "  @staticmethod\n",
        "  def generate_labels(class_num, batch_size, gpu_mode, rng_local, mod=\"regu\"): #随机种子rng_local\n",
        "    weight = class_num * [float(1.0 / class_num)]\n",
        "    if mod == \"regu\":\n",
        "      mean_Y = torch.range(0, class_num - 1, dtype=torch.int64).repeat(batch_size // class_num)\n",
        "      mean_Y_ = torch.zeros((mean_Y.shape[0], class_num)).scatter_(1, mean_Y.type(torch.LongTensor).unsqueeze(1), 1)\n",
        "      y_disc_ = torch.from_numpy(rng_local.multinomial(1, weight, size=[batch_size % class_num])).type(torch.FloatTensor)\n",
        "      y_disc_ = torch.cat([mean_Y_, y_disc_], 0)\n",
        "    else:\n",
        "      y_disc_ = torch.from_numpy(rng_local.multinomial(1, weight, size=[batch_size])).type(torch.FloatTensor)\n",
        "    if gpu_mode:\n",
        "      y_disc_ = y_disc_.cuda()\n",
        "    return y_disc_\n",
        "  def visualize_results(self,epoch,x_=None,y_=None): #transform是归一化参数\n",
        "    self.G.eval()\n",
        "    self.A.eval()\n",
        "    self.vqgan2.eval()\n",
        "    if not os.path.exists(self.rslt_path):\n",
        "        os.makedirs(self.rslt_path)\n",
        "    image_frame_dim = int(np.floor(np.sqrt(self.sample_num)))\n",
        "\n",
        "    size=x_.shape[-1]\n",
        "    x2=x_[:image_frame_dim].reshape(1,image_frame_dim,-1,size,size).repeat(image_frame_dim,1,1,1,1).permute(1,0,2,3,4)\n",
        "    x2=x2.reshape(image_frame_dim*image_frame_dim,-1,size,size)\n",
        "    y2 = y_[:image_frame_dim].unsqueeze(0).t().repeat(1,image_frame_dim).reshape(image_frame_dim*image_frame_dim)\n",
        "    y2 = torch.zeros((image_frame_dim*image_frame_dim, self.class_num)).scatter_(1, y2.type(torch.LongTensor).unsqueeze(1), 1)\n",
        "    if gpu_mode:\n",
        "      y2 = y2.cuda()\n",
        "\n",
        "    G = self.A(x2, self.sample_y_)[0]\n",
        "    G_v,_,_ = self.vqgan2(G)\n",
        "    G3 = self.A(G_v,y2)[0]\n",
        "    G3_v,_,_ = self.vqgan2(G3)\n",
        "    G4 = self.A(G_v,self.sample_y_)[0]\n",
        "    G4,_,_ = self.vqgan2(G4)\n",
        "    '''\n",
        "    print(y2)\n",
        "    print(self.sample_y_)\n",
        "    1/0\n",
        "    '''\n",
        "    imgs=[x2,G,G_v,G4,G3,G3_v]\n",
        "\n",
        "    for i, img in enumerate(imgs):\n",
        "      image=show_img(img,image_frame_dim,\\\n",
        "        self.rslt_path + '/%2d[%d]_ep%d' % (self.round,i,epoch) + '.png',transform=get_transform(self.train_data))\n",
        "\n",
        "\n",
        "  def get_rslt_path(self):\n",
        "    task = self.option['task'].replace('/','').replace('.','').replace('task','')\n",
        "    self.C=self.get_loc_data()\n",
        "    c = self.C.topk(k=10).indices\n",
        "    name='client '+str(self.id)+str(c.tolist())\n",
        "    return 'result_G/' + task + '/' + name\n",
        "\n",
        "  '''\n",
        "  def get_loc_data(self):\n",
        "    date_num=len(self.train_data.indices)\n",
        "    data_loader = self.calculator.get_dataloader(self.train_data, batch_size=date_num)\n",
        "    y_ = data_loader.__iter__().__next__()[1]\n",
        "    y_vec_ = torch.zeros((y_.shape[0], 10)).scatter_(1, y_.type(torch.LongTensor).unsqueeze(1), 1)\n",
        "    c = y_vec_.sum(0)\n",
        "    print(\"client\",self.id,\"总样本数：\",date_num,\" 各类：\", c.int().numpy())\n",
        "    return c\n",
        "    '''\n",
        "\n",
        "class test:\n",
        "    Server=Server\n",
        "    Client=Client\n",
        "\n",
        "\n",
        "#!rm -r $task\n",
        "if not os.path.exists(task): flgo.gen_task(config_dir10, task_path = task)\n",
        "option = {'clip_grad':10,'num_rounds':50, 'num_epochs':1, 'batch_size':32, 'learning_rate':0.1, 'gpu':0 if torch.cuda.is_available() else ''}\n",
        "option['vqgan_args']=args\n",
        "option['class_num']=10\n",
        "option['G_lr'] = 1e-3\n",
        "option['D_lr'] = 1e-2\n",
        "option['V_lr'] = 1e-4\n",
        "!rm -r /content/FLGo/result_G\n",
        "\n",
        "\n",
        "\n",
        "runner = flgo.init(task, test, option=option)\n",
        "#runner = flgo.init(task, fedavg, option=option, model=model_DC)\n",
        "torch.cuda.empty_cache()\n",
        "runner.model\n",
        "runner.run()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def compute_wasserstein_distance(p, q, epsilon, num_iterations):\n",
        "    # 初始化变量\n",
        "    height, width = p.size()\n",
        "    r = torch.ones(height, width) / (height * width)\n",
        "    c = torch.ones(height, width) / (height * width)\n",
        "\n",
        "    # 构造平滑核\n",
        "    kernel = torch.ones(1, 1, 3, 3).to(p.device)\n",
        "\n",
        "    for _ in range(num_iterations):\n",
        "        # 更新核矩阵K\n",
        "        K = torch.exp(-(p - q).pow(2) / epsilon)\n",
        "\n",
        "        # Sinkhorn迭代更新r和c\n",
        "        r = 1.0 / (torch.conv2d(c.unsqueeze(0).unsqueeze(0), kernel, padding=1).squeeze() + 1e-8)\n",
        "        c = 1.0 / (torch.conv2d(r.unsqueeze(0).unsqueeze(0), kernel, padding=1).squeeze() + 1e-8)\n",
        "\n",
        "    # 计算近似的Wasserstein距离\n",
        "    transport_cost = torch.sum(K * c)\n",
        "    entropy_reg = torch.sum(r * torch.log(r) + c * torch.log(c))\n",
        "    wasserstein_distance = (transport_cost - entropy_reg) / epsilon\n",
        "\n",
        "    return wasserstein_distance,K,c\n",
        "\n",
        "# 示例使用的是二维图像数据\n",
        "p = torch.rand(10, 10)  # 概率分布 p\n",
        "q = torch.rand(10, 10)  # 概率分布 q\n",
        "epsilon = 0.1\n",
        "num_iterations = 100\n",
        "\n",
        "distance,K,c = compute_wasserstein_distance(p, q, epsilon, num_iterations)\n",
        "print(\"Approximate Wasserstein Distance:\", distance.item())\n",
        "\n",
        "# 可视化概率分布和迭代过程\n",
        "fig, axes = plt.subplots(2, 2)\n",
        "axes[0, 0].imshow(p.cpu().numpy(), cmap='Blues')\n",
        "axes[0, 0].set_title(\"Probability Distribution p\")\n",
        "axes[0, 1].imshow(q.cpu().numpy(), cmap='Blues')\n",
        "axes[0, 1].set_title(\"Probability Distribution q\")\n",
        "axes[1, 0].imshow(K.squeeze().detach().cpu().numpy(), cmap='BuGn')\n",
        "axes[1, 0].set_title(\"Kernel K\")\n",
        "axes[1, 1].imshow(c.squeeze().detach().cpu().numpy(), cmap='YlGn')\n",
        "axes[1, 1].set_title(\"Weights c\")\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 470
        },
        "id": "rnCk30iPMZgQ",
        "outputId": "7c57fca4-e4ea-48cd-be7a-993d2e3507aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Approximate Wasserstein Distance: -34617.671875\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 4 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "在这个示例中，我们首先使用PyTorch生成随机的二维概率分布p和q。然后，我们计算了概率分布之间的Wasserstein距离，并将结果打印出来。\n",
        "\n",
        "接下来，我们使用subplots函数创建了一个2x2的图像网格，用于可视化概率分布和迭代过程的中间变量。imshow函数用于绘制图像，set_title函数用于设置标题。\n",
        "\n",
        "我们可以看到，第一行显示了概率分布p和q，第二行显示了核K和权重c。其中，核K表示概率分布之间的距离，越暗的区域表示距离越远；权重c表示每个概率分布在传输过程中的贡献，越亮的区域表示贡献越大。\n",
        "\n",
        "希望这个示例能够帮助您理解如何计算近似的Wasserstein距离，并使用可视化图像提供直观的例子！"
      ],
      "metadata": {
        "id": "dqCFw0TiPcyT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qYSQ44y2PGor",
        "outputId": "7ca7279b-f636-410c-86d0-e6b0fb80882e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-21 14:56:58,924 fflow.py init [line:441] INFO Initializing devices: cuda:0 will be used for this running.\n",
            "2023-09-21 14:56:58,960 fflow.py init [line:479] INFO Use `<class 'flgo.simulator.default_simulator.Simulator'>` as the system simulator\n",
            "2023-09-21 14:56:58,962 fflow.py init [line:487] INFO Ready to start.\n",
            "2023-09-21 14:56:58,964 fedbase.py run [line:236] INFO --------------Initial Evaluation--------------\n",
            "2023-09-21 14:56:58,966 simple_logger.py log_once [line:14] INFO Current_time:0\n",
            "2023-09-21 14:57:02,728 simple_logger.py log_once [line:28] INFO test_accuracy                 0.1024\n",
            "2023-09-21 14:57:02,730 simple_logger.py log_once [line:28] INFO test_loss                     2.3033\n",
            "2023-09-21 14:57:02,732 simple_logger.py log_once [line:28] INFO valid_accuracy                0.1014\n",
            "2023-09-21 14:57:02,734 simple_logger.py log_once [line:28] INFO mean_valid_accuracy           0.1036\n",
            "2023-09-21 14:57:02,736 simple_logger.py log_once [line:28] INFO std_valid_accuracy            0.2318\n",
            "2023-09-21 14:57:02,740 simple_logger.py log_once [line:28] INFO valid_loss                    2.3032\n",
            "2023-09-21 14:57:02,742 simple_logger.py log_once [line:28] INFO mean_valid_loss               2.3031\n",
            "2023-09-21 14:57:02,750 simple_logger.py log_once [line:28] INFO std_valid_loss                0.0274\n",
            "2023-09-21 14:57:02,752 fedbase.py run [line:239] INFO Eval Time Cost:               3.7862s\n",
            "2023-09-21 14:57:06,984 fedbase.py run [line:246] INFO --------------Round 1--------------\n",
            "2023-09-21 14:57:06,986 simple_logger.py log_once [line:14] INFO Current_time:1\n",
            "2023-09-21 14:57:10,818 simple_logger.py log_once [line:28] INFO test_accuracy                 0.1306\n",
            "2023-09-21 14:57:10,819 simple_logger.py log_once [line:28] INFO test_loss                     2.6481\n",
            "2023-09-21 14:57:10,825 simple_logger.py log_once [line:28] INFO valid_accuracy                0.1372\n",
            "2023-09-21 14:57:10,826 simple_logger.py log_once [line:28] INFO mean_valid_accuracy           0.1345\n",
            "2023-09-21 14:57:10,829 simple_logger.py log_once [line:28] INFO std_valid_accuracy            0.2358\n",
            "2023-09-21 14:57:10,831 simple_logger.py log_once [line:28] INFO valid_loss                    2.6478\n",
            "2023-09-21 14:57:10,835 simple_logger.py log_once [line:28] INFO mean_valid_loss               2.6561\n",
            "2023-09-21 14:57:10,836 simple_logger.py log_once [line:28] INFO std_valid_loss                0.8348\n",
            "2023-09-21 14:57:10,837 fedbase.py run [line:251] INFO Eval Time Cost:               3.8503s\n",
            "2023-09-21 14:57:13,939 fedbase.py run [line:246] INFO --------------Round 2--------------\n",
            "2023-09-21 14:57:13,940 simple_logger.py log_once [line:14] INFO Current_time:2\n",
            "2023-09-21 14:57:17,873 simple_logger.py log_once [line:28] INFO test_accuracy                 0.1456\n",
            "2023-09-21 14:57:17,876 simple_logger.py log_once [line:28] INFO test_loss                     3.0073\n",
            "2023-09-21 14:57:17,877 simple_logger.py log_once [line:28] INFO valid_accuracy                0.1444\n",
            "2023-09-21 14:57:17,880 simple_logger.py log_once [line:28] INFO mean_valid_accuracy           0.1425\n",
            "2023-09-21 14:57:17,882 simple_logger.py log_once [line:28] INFO std_valid_accuracy            0.1913\n",
            "2023-09-21 14:57:17,884 simple_logger.py log_once [line:28] INFO valid_loss                    2.9930\n",
            "2023-09-21 14:57:17,885 simple_logger.py log_once [line:28] INFO mean_valid_loss               3.0000\n",
            "2023-09-21 14:57:17,886 simple_logger.py log_once [line:28] INFO std_valid_loss                1.0454\n",
            "2023-09-21 14:57:17,887 fedbase.py run [line:251] INFO Eval Time Cost:               3.9466s\n",
            "2023-09-21 14:57:21,855 fedbase.py run [line:246] INFO --------------Round 3--------------\n",
            "2023-09-21 14:57:21,856 simple_logger.py log_once [line:14] INFO Current_time:3\n",
            "2023-09-21 14:57:25,614 simple_logger.py log_once [line:28] INFO test_accuracy                 0.2182\n",
            "2023-09-21 14:57:25,615 simple_logger.py log_once [line:28] INFO test_loss                     3.2814\n",
            "2023-09-21 14:57:25,618 simple_logger.py log_once [line:28] INFO valid_accuracy                0.2231\n",
            "2023-09-21 14:57:25,620 simple_logger.py log_once [line:28] INFO mean_valid_accuracy           0.2204\n",
            "2023-09-21 14:57:25,624 simple_logger.py log_once [line:28] INFO std_valid_accuracy            0.2784\n",
            "2023-09-21 14:57:25,625 simple_logger.py log_once [line:28] INFO valid_loss                    3.2681\n",
            "2023-09-21 14:57:25,628 simple_logger.py log_once [line:28] INFO mean_valid_loss               3.2874\n",
            "2023-09-21 14:57:25,630 simple_logger.py log_once [line:28] INFO std_valid_loss                1.9123\n",
            "2023-09-21 14:57:25,632 fedbase.py run [line:251] INFO Eval Time Cost:               3.7754s\n",
            "2023-09-21 14:57:28,753 fedbase.py run [line:246] INFO --------------Round 4--------------\n",
            "2023-09-21 14:57:28,755 simple_logger.py log_once [line:14] INFO Current_time:4\n",
            "2023-09-21 14:57:33,574 simple_logger.py log_once [line:28] INFO test_accuracy                 0.1829\n",
            "2023-09-21 14:57:33,578 simple_logger.py log_once [line:28] INFO test_loss                     3.9111\n",
            "2023-09-21 14:57:33,580 simple_logger.py log_once [line:28] INFO valid_accuracy                0.1834\n",
            "2023-09-21 14:57:33,586 simple_logger.py log_once [line:28] INFO mean_valid_accuracy           0.1814\n",
            "2023-09-21 14:57:33,588 simple_logger.py log_once [line:28] INFO std_valid_accuracy            0.2995\n",
            "2023-09-21 14:57:33,589 simple_logger.py log_once [line:28] INFO valid_loss                    3.9033\n",
            "2023-09-21 14:57:33,590 simple_logger.py log_once [line:28] INFO mean_valid_loss               3.9168\n",
            "2023-09-21 14:57:33,595 simple_logger.py log_once [line:28] INFO std_valid_loss                1.6908\n",
            "2023-09-21 14:57:33,596 fedbase.py run [line:251] INFO Eval Time Cost:               4.8411s\n",
            "2023-09-21 14:57:36,989 fedbase.py run [line:246] INFO --------------Round 5--------------\n",
            "2023-09-21 14:57:36,991 simple_logger.py log_once [line:14] INFO Current_time:5\n",
            "2023-09-21 14:57:40,656 simple_logger.py log_once [line:28] INFO test_accuracy                 0.2067\n",
            "2023-09-21 14:57:40,657 simple_logger.py log_once [line:28] INFO test_loss                     3.5657\n",
            "2023-09-21 14:57:40,661 simple_logger.py log_once [line:28] INFO valid_accuracy                0.2089\n",
            "2023-09-21 14:57:40,664 simple_logger.py log_once [line:28] INFO mean_valid_accuracy           0.2081\n",
            "2023-09-21 14:57:40,668 simple_logger.py log_once [line:28] INFO std_valid_accuracy            0.3124\n",
            "2023-09-21 14:57:40,674 simple_logger.py log_once [line:28] INFO valid_loss                    3.5497\n",
            "2023-09-21 14:57:40,675 simple_logger.py log_once [line:28] INFO mean_valid_loss               3.5595\n",
            "2023-09-21 14:57:40,679 simple_logger.py log_once [line:28] INFO std_valid_loss                1.8914\n",
            "2023-09-21 14:57:40,680 fedbase.py run [line:251] INFO Eval Time Cost:               3.6892s\n",
            "2023-09-21 14:57:43,735 fedbase.py run [line:246] INFO --------------Round 6--------------\n",
            "2023-09-21 14:57:43,737 simple_logger.py log_once [line:14] INFO Current_time:6\n",
            "2023-09-21 14:57:48,743 simple_logger.py log_once [line:28] INFO test_accuracy                 0.2396\n",
            "2023-09-21 14:57:48,744 simple_logger.py log_once [line:28] INFO test_loss                     2.8247\n",
            "2023-09-21 14:57:48,748 simple_logger.py log_once [line:28] INFO valid_accuracy                0.2365\n",
            "2023-09-21 14:57:48,751 simple_logger.py log_once [line:28] INFO mean_valid_accuracy           0.2372\n",
            "2023-09-21 14:57:48,753 simple_logger.py log_once [line:28] INFO std_valid_accuracy            0.2289\n",
            "2023-09-21 14:57:48,755 simple_logger.py log_once [line:28] INFO valid_loss                    2.8346\n",
            "2023-09-21 14:57:48,757 simple_logger.py log_once [line:28] INFO mean_valid_loss               2.8270\n",
            "2023-09-21 14:57:48,759 simple_logger.py log_once [line:28] INFO std_valid_loss                1.3246\n",
            "2023-09-21 14:57:48,761 fedbase.py run [line:251] INFO Eval Time Cost:               5.0246s\n",
            "2023-09-21 14:57:50,267 fedbase.py run [line:246] INFO --------------Round 7--------------\n",
            "2023-09-21 14:57:50,268 simple_logger.py log_once [line:14] INFO Current_time:7\n",
            "2023-09-21 14:57:53,897 simple_logger.py log_once [line:28] INFO test_accuracy                 0.2204\n",
            "2023-09-21 14:57:53,898 simple_logger.py log_once [line:28] INFO test_loss                     4.6245\n",
            "2023-09-21 14:57:53,903 simple_logger.py log_once [line:28] INFO valid_accuracy                0.2157\n",
            "2023-09-21 14:57:53,906 simple_logger.py log_once [line:28] INFO mean_valid_accuracy           0.2186\n",
            "2023-09-21 14:57:53,909 simple_logger.py log_once [line:28] INFO std_valid_accuracy            0.2671\n",
            "2023-09-21 14:57:53,911 simple_logger.py log_once [line:28] INFO valid_loss                    4.6121\n",
            "2023-09-21 14:57:53,917 simple_logger.py log_once [line:28] INFO mean_valid_loss               4.6069\n",
            "2023-09-21 14:57:53,918 simple_logger.py log_once [line:28] INFO std_valid_loss                2.3888\n",
            "2023-09-21 14:57:53,920 fedbase.py run [line:251] INFO Eval Time Cost:               3.6516s\n",
            "2023-09-21 14:57:56,894 fedbase.py run [line:246] INFO --------------Round 8--------------\n",
            "2023-09-21 14:57:56,895 simple_logger.py log_once [line:14] INFO Current_time:8\n",
            "2023-09-21 14:58:01,805 simple_logger.py log_once [line:28] INFO test_accuracy                 0.2324\n",
            "2023-09-21 14:58:01,807 simple_logger.py log_once [line:28] INFO test_loss                     2.7040\n",
            "2023-09-21 14:58:01,809 simple_logger.py log_once [line:28] INFO valid_accuracy                0.2239\n",
            "2023-09-21 14:58:01,812 simple_logger.py log_once [line:28] INFO mean_valid_accuracy           0.2264\n",
            "2023-09-21 14:58:01,816 simple_logger.py log_once [line:28] INFO std_valid_accuracy            0.2379\n",
            "2023-09-21 14:58:01,817 simple_logger.py log_once [line:28] INFO valid_loss                    2.7231\n",
            "2023-09-21 14:58:01,820 simple_logger.py log_once [line:28] INFO mean_valid_loss               2.7068\n",
            "2023-09-21 14:58:01,822 simple_logger.py log_once [line:28] INFO std_valid_loss                1.0702\n",
            "2023-09-21 14:58:01,824 fedbase.py run [line:251] INFO Eval Time Cost:               4.9290s\n",
            "2023-09-21 14:58:05,274 fedbase.py run [line:246] INFO --------------Round 9--------------\n",
            "2023-09-21 14:58:05,275 simple_logger.py log_once [line:14] INFO Current_time:9\n",
            "2023-09-21 14:58:08,997 simple_logger.py log_once [line:28] INFO test_accuracy                 0.3376\n",
            "2023-09-21 14:58:08,998 simple_logger.py log_once [line:28] INFO test_loss                     2.3319\n",
            "2023-09-21 14:58:09,004 simple_logger.py log_once [line:28] INFO valid_accuracy                0.3287\n",
            "2023-09-21 14:58:09,005 simple_logger.py log_once [line:28] INFO mean_valid_accuracy           0.3257\n",
            "2023-09-21 14:58:09,009 simple_logger.py log_once [line:28] INFO std_valid_accuracy            0.2822\n",
            "2023-09-21 14:58:09,011 simple_logger.py log_once [line:28] INFO valid_loss                    2.3333\n",
            "2023-09-21 14:58:09,013 simple_logger.py log_once [line:28] INFO mean_valid_loss               2.3482\n",
            "2023-09-21 14:58:09,014 simple_logger.py log_once [line:28] INFO std_valid_loss                1.3341\n",
            "2023-09-21 14:58:09,015 fedbase.py run [line:251] INFO Eval Time Cost:               3.7407s\n",
            "2023-09-21 14:58:12,551 fedbase.py run [line:246] INFO --------------Round 10--------------\n",
            "2023-09-21 14:58:12,555 simple_logger.py log_once [line:14] INFO Current_time:10\n",
            "2023-09-21 14:58:17,129 simple_logger.py log_once [line:28] INFO test_accuracy                 0.3216\n",
            "2023-09-21 14:58:17,131 simple_logger.py log_once [line:28] INFO test_loss                     2.4853\n",
            "2023-09-21 14:58:17,133 simple_logger.py log_once [line:28] INFO valid_accuracy                0.3158\n",
            "2023-09-21 14:58:17,135 simple_logger.py log_once [line:28] INFO mean_valid_accuracy           0.3132\n",
            "2023-09-21 14:58:17,137 simple_logger.py log_once [line:28] INFO std_valid_accuracy            0.2276\n",
            "2023-09-21 14:58:17,139 simple_logger.py log_once [line:28] INFO valid_loss                    2.4949\n",
            "2023-09-21 14:58:17,141 simple_logger.py log_once [line:28] INFO mean_valid_loss               2.5118\n",
            "2023-09-21 14:58:17,141 simple_logger.py log_once [line:28] INFO std_valid_loss                1.1870\n",
            "2023-09-21 14:58:17,142 fedbase.py run [line:251] INFO Eval Time Cost:               4.5873s\n",
            "2023-09-21 14:58:20,276 fedbase.py run [line:246] INFO --------------Round 11--------------\n",
            "2023-09-21 14:58:20,277 simple_logger.py log_once [line:14] INFO Current_time:11\n",
            "2023-09-21 14:58:24,019 simple_logger.py log_once [line:28] INFO test_accuracy                 0.3351\n",
            "2023-09-21 14:58:24,020 simple_logger.py log_once [line:28] INFO test_loss                     2.0053\n",
            "2023-09-21 14:58:24,024 simple_logger.py log_once [line:28] INFO valid_accuracy                0.3240\n",
            "2023-09-21 14:58:24,027 simple_logger.py log_once [line:28] INFO mean_valid_accuracy           0.3247\n",
            "2023-09-21 14:58:24,033 simple_logger.py log_once [line:28] INFO std_valid_accuracy            0.2291\n",
            "2023-09-21 14:58:24,034 simple_logger.py log_once [line:28] INFO valid_loss                    2.0409\n",
            "2023-09-21 14:58:24,036 simple_logger.py log_once [line:28] INFO mean_valid_loss               2.0378\n",
            "2023-09-21 14:58:24,039 simple_logger.py log_once [line:28] INFO std_valid_loss                0.7521\n",
            "2023-09-21 14:58:24,043 fedbase.py run [line:251] INFO Eval Time Cost:               3.7658s\n",
            "2023-09-21 14:58:28,176 fedbase.py run [line:246] INFO --------------Round 12--------------\n",
            "2023-09-21 14:58:28,179 simple_logger.py log_once [line:14] INFO Current_time:12\n",
            "2023-09-21 14:58:31,898 simple_logger.py log_once [line:28] INFO test_accuracy                 0.3621\n",
            "2023-09-21 14:58:31,900 simple_logger.py log_once [line:28] INFO test_loss                     2.2203\n",
            "2023-09-21 14:58:31,903 simple_logger.py log_once [line:28] INFO valid_accuracy                0.3509\n",
            "2023-09-21 14:58:31,905 simple_logger.py log_once [line:28] INFO mean_valid_accuracy           0.3502\n",
            "2023-09-21 14:58:31,907 simple_logger.py log_once [line:28] INFO std_valid_accuracy            0.2523\n",
            "2023-09-21 14:58:31,909 simple_logger.py log_once [line:28] INFO valid_loss                    2.2556\n",
            "2023-09-21 14:58:31,911 simple_logger.py log_once [line:28] INFO mean_valid_loss               2.2633\n",
            "2023-09-21 14:58:31,912 simple_logger.py log_once [line:28] INFO std_valid_loss                1.2296\n",
            "2023-09-21 14:58:31,913 fedbase.py run [line:251] INFO Eval Time Cost:               3.7341s\n",
            "2023-09-21 14:58:35,220 fedbase.py run [line:246] INFO --------------Round 13--------------\n",
            "2023-09-21 14:58:35,221 simple_logger.py log_once [line:14] INFO Current_time:13\n",
            "2023-09-21 14:58:39,326 simple_logger.py log_once [line:28] INFO test_accuracy                 0.3611\n",
            "2023-09-21 14:58:39,332 simple_logger.py log_once [line:28] INFO test_loss                     2.3792\n",
            "2023-09-21 14:58:39,336 simple_logger.py log_once [line:28] INFO valid_accuracy                0.3497\n",
            "2023-09-21 14:58:39,338 simple_logger.py log_once [line:28] INFO mean_valid_accuracy           0.3459\n",
            "2023-09-21 14:58:39,342 simple_logger.py log_once [line:28] INFO std_valid_accuracy            0.2911\n",
            "2023-09-21 14:58:39,343 simple_logger.py log_once [line:28] INFO valid_loss                    2.4035\n",
            "2023-09-21 14:58:39,344 simple_logger.py log_once [line:28] INFO mean_valid_loss               2.4224\n",
            "2023-09-21 14:58:39,346 simple_logger.py log_once [line:28] INFO std_valid_loss                1.4429\n",
            "2023-09-21 14:58:39,348 fedbase.py run [line:251] INFO Eval Time Cost:               4.1267s\n",
            "2023-09-21 14:58:43,227 fedbase.py run [line:246] INFO --------------Round 14--------------\n",
            "2023-09-21 14:58:43,228 simple_logger.py log_once [line:14] INFO Current_time:14\n",
            "2023-09-21 14:58:46,977 simple_logger.py log_once [line:28] INFO test_accuracy                 0.2867\n",
            "2023-09-21 14:58:46,978 simple_logger.py log_once [line:28] INFO test_loss                     3.3219\n",
            "2023-09-21 14:58:46,980 simple_logger.py log_once [line:28] INFO valid_accuracy                0.2874\n",
            "2023-09-21 14:58:46,983 simple_logger.py log_once [line:28] INFO mean_valid_accuracy           0.2896\n",
            "2023-09-21 14:58:46,987 simple_logger.py log_once [line:28] INFO std_valid_accuracy            0.2966\n",
            "2023-09-21 14:58:46,992 simple_logger.py log_once [line:28] INFO valid_loss                    3.3320\n",
            "2023-09-21 14:58:46,995 simple_logger.py log_once [line:28] INFO mean_valid_loss               3.3157\n",
            "2023-09-21 14:58:46,997 simple_logger.py log_once [line:28] INFO std_valid_loss                1.5792\n",
            "2023-09-21 14:58:46,998 fedbase.py run [line:251] INFO Eval Time Cost:               3.7700s\n",
            "2023-09-21 14:58:50,158 fedbase.py run [line:246] INFO --------------Round 15--------------\n",
            "2023-09-21 14:58:50,159 simple_logger.py log_once [line:14] INFO Current_time:15\n",
            "2023-09-21 14:58:55,064 simple_logger.py log_once [line:28] INFO test_accuracy                 0.3183\n",
            "2023-09-21 14:58:55,066 simple_logger.py log_once [line:28] INFO test_loss                     2.5472\n",
            "2023-09-21 14:58:55,069 simple_logger.py log_once [line:28] INFO valid_accuracy                0.3120\n",
            "2023-09-21 14:58:55,071 simple_logger.py log_once [line:28] INFO mean_valid_accuracy           0.3085\n",
            "2023-09-21 14:58:55,073 simple_logger.py log_once [line:28] INFO std_valid_accuracy            0.2624\n",
            "2023-09-21 14:58:55,074 simple_logger.py log_once [line:28] INFO valid_loss                    2.5729\n",
            "2023-09-21 14:58:55,075 simple_logger.py log_once [line:28] INFO mean_valid_loss               2.5974\n",
            "2023-09-21 14:58:55,077 simple_logger.py log_once [line:28] INFO std_valid_loss                1.5259\n",
            "2023-09-21 14:58:55,078 fedbase.py run [line:251] INFO Eval Time Cost:               4.9189s\n",
            "2023-09-21 14:58:58,349 fedbase.py run [line:246] INFO --------------Round 16--------------\n",
            "2023-09-21 14:58:58,350 simple_logger.py log_once [line:14] INFO Current_time:16\n",
            "2023-09-21 14:59:02,090 simple_logger.py log_once [line:28] INFO test_accuracy                 0.3667\n",
            "2023-09-21 14:59:02,091 simple_logger.py log_once [line:28] INFO test_loss                     1.9128\n",
            "2023-09-21 14:59:02,095 simple_logger.py log_once [line:28] INFO valid_accuracy                0.3655\n",
            "2023-09-21 14:59:02,098 simple_logger.py log_once [line:28] INFO mean_valid_accuracy           0.3659\n",
            "2023-09-21 14:59:02,100 simple_logger.py log_once [line:28] INFO std_valid_accuracy            0.2359\n",
            "2023-09-21 14:59:02,102 simple_logger.py log_once [line:28] INFO valid_loss                    1.9421\n",
            "2023-09-21 14:59:02,105 simple_logger.py log_once [line:28] INFO mean_valid_loss               1.9366\n",
            "2023-09-21 14:59:02,108 simple_logger.py log_once [line:28] INFO std_valid_loss                0.7693\n",
            "2023-09-21 14:59:02,110 fedbase.py run [line:251] INFO Eval Time Cost:               3.7601s\n",
            "2023-09-21 14:59:05,226 fedbase.py run [line:246] INFO --------------Round 17--------------\n",
            "2023-09-21 14:59:05,227 simple_logger.py log_once [line:14] INFO Current_time:17\n",
            "2023-09-21 14:59:10,262 simple_logger.py log_once [line:28] INFO test_accuracy                 0.3348\n",
            "2023-09-21 14:59:10,264 simple_logger.py log_once [line:28] INFO test_loss                     2.0714\n",
            "2023-09-21 14:59:10,266 simple_logger.py log_once [line:28] INFO valid_accuracy                0.3338\n",
            "2023-09-21 14:59:10,267 simple_logger.py log_once [line:28] INFO mean_valid_accuracy           0.3331\n",
            "2023-09-21 14:59:10,269 simple_logger.py log_once [line:28] INFO std_valid_accuracy            0.2510\n",
            "2023-09-21 14:59:10,271 simple_logger.py log_once [line:28] INFO valid_loss                    2.1027\n",
            "2023-09-21 14:59:10,277 simple_logger.py log_once [line:28] INFO mean_valid_loss               2.1121\n",
            "2023-09-21 14:59:10,279 simple_logger.py log_once [line:28] INFO std_valid_loss                1.0478\n",
            "2023-09-21 14:59:10,280 fedbase.py run [line:251] INFO Eval Time Cost:               5.0535s\n",
            "2023-09-21 14:59:13,396 fedbase.py run [line:246] INFO --------------Round 18--------------\n",
            "2023-09-21 14:59:13,398 simple_logger.py log_once [line:14] INFO Current_time:18\n",
            "2023-09-21 14:59:17,126 simple_logger.py log_once [line:28] INFO test_accuracy                 0.3485\n",
            "2023-09-21 14:59:17,128 simple_logger.py log_once [line:28] INFO test_loss                     2.6235\n",
            "2023-09-21 14:59:17,130 simple_logger.py log_once [line:28] INFO valid_accuracy                0.3443\n",
            "2023-09-21 14:59:17,132 simple_logger.py log_once [line:28] INFO mean_valid_accuracy           0.3448\n",
            "2023-09-21 14:59:17,137 simple_logger.py log_once [line:28] INFO std_valid_accuracy            0.2708\n",
            "2023-09-21 14:59:17,138 simple_logger.py log_once [line:28] INFO valid_loss                    2.6570\n",
            "2023-09-21 14:59:17,140 simple_logger.py log_once [line:28] INFO mean_valid_loss               2.6601\n",
            "2023-09-21 14:59:17,142 simple_logger.py log_once [line:28] INFO std_valid_loss                1.7780\n",
            "2023-09-21 14:59:17,144 fedbase.py run [line:251] INFO Eval Time Cost:               3.7462s\n",
            "2023-09-21 14:59:20,614 fedbase.py run [line:246] INFO --------------Round 19--------------\n",
            "2023-09-21 14:59:20,616 simple_logger.py log_once [line:14] INFO Current_time:19\n",
            "2023-09-21 14:59:25,054 simple_logger.py log_once [line:28] INFO test_accuracy                 0.3926\n",
            "2023-09-21 14:59:25,055 simple_logger.py log_once [line:28] INFO test_loss                     2.4315\n",
            "2023-09-21 14:59:25,057 simple_logger.py log_once [line:28] INFO valid_accuracy                0.3887\n",
            "2023-09-21 14:59:25,061 simple_logger.py log_once [line:28] INFO mean_valid_accuracy           0.3885\n",
            "2023-09-21 14:59:25,063 simple_logger.py log_once [line:28] INFO std_valid_accuracy            0.2664\n",
            "2023-09-21 14:59:25,064 simple_logger.py log_once [line:28] INFO valid_loss                    2.4743\n",
            "2023-09-21 14:59:25,065 simple_logger.py log_once [line:28] INFO mean_valid_loss               2.4823\n",
            "2023-09-21 14:59:25,067 simple_logger.py log_once [line:28] INFO std_valid_loss                1.7064\n",
            "2023-09-21 14:59:25,067 fedbase.py run [line:251] INFO Eval Time Cost:               4.4510s\n",
            "2023-09-21 14:59:26,608 fedbase.py run [line:246] INFO --------------Round 20--------------\n",
            "2023-09-21 14:59:26,609 simple_logger.py log_once [line:14] INFO Current_time:20\n",
            "2023-09-21 14:59:30,285 simple_logger.py log_once [line:28] INFO test_accuracy                 0.2146\n",
            "2023-09-21 14:59:30,286 simple_logger.py log_once [line:28] INFO test_loss                     2.9359\n",
            "2023-09-21 14:59:30,289 simple_logger.py log_once [line:28] INFO valid_accuracy                0.2067\n",
            "2023-09-21 14:59:30,292 simple_logger.py log_once [line:28] INFO mean_valid_accuracy           0.2067\n",
            "2023-09-21 14:59:30,294 simple_logger.py log_once [line:28] INFO std_valid_accuracy            0.2666\n",
            "2023-09-21 14:59:30,296 simple_logger.py log_once [line:28] INFO valid_loss                    2.9530\n",
            "2023-09-21 14:59:30,297 simple_logger.py log_once [line:28] INFO mean_valid_loss               2.9659\n",
            "2023-09-21 14:59:30,298 simple_logger.py log_once [line:28] INFO std_valid_loss                1.2486\n",
            "2023-09-21 14:59:30,299 fedbase.py run [line:251] INFO Eval Time Cost:               3.6899s\n",
            "2023-09-21 14:59:33,838 fedbase.py run [line:246] INFO --------------Round 21--------------\n",
            "2023-09-21 14:59:33,843 simple_logger.py log_once [line:14] INFO Current_time:21\n",
            "2023-09-21 14:59:38,505 simple_logger.py log_once [line:28] INFO test_accuracy                 0.3316\n",
            "2023-09-21 14:59:38,507 simple_logger.py log_once [line:28] INFO test_loss                     2.3309\n",
            "2023-09-21 14:59:38,509 simple_logger.py log_once [line:28] INFO valid_accuracy                0.3247\n",
            "2023-09-21 14:59:38,512 simple_logger.py log_once [line:28] INFO mean_valid_accuracy           0.3241\n",
            "2023-09-21 14:59:38,514 simple_logger.py log_once [line:28] INFO std_valid_accuracy            0.2473\n",
            "2023-09-21 14:59:38,522 simple_logger.py log_once [line:28] INFO valid_loss                    2.3397\n",
            "2023-09-21 14:59:38,523 simple_logger.py log_once [line:28] INFO mean_valid_loss               2.3405\n",
            "2023-09-21 14:59:38,524 simple_logger.py log_once [line:28] INFO std_valid_loss                0.9235\n",
            "2023-09-21 14:59:38,527 fedbase.py run [line:251] INFO Eval Time Cost:               4.6844s\n",
            "2023-09-21 14:59:41,572 fedbase.py run [line:246] INFO --------------Round 22--------------\n",
            "2023-09-21 14:59:41,574 simple_logger.py log_once [line:14] INFO Current_time:22\n",
            "2023-09-21 14:59:45,340 simple_logger.py log_once [line:28] INFO test_accuracy                 0.4179\n",
            "2023-09-21 14:59:45,341 simple_logger.py log_once [line:28] INFO test_loss                     1.6992\n",
            "2023-09-21 14:59:45,344 simple_logger.py log_once [line:28] INFO valid_accuracy                0.4046\n",
            "2023-09-21 14:59:45,347 simple_logger.py log_once [line:28] INFO mean_valid_accuracy           0.4069\n",
            "2023-09-21 14:59:45,349 simple_logger.py log_once [line:28] INFO std_valid_accuracy            0.2503\n",
            "2023-09-21 14:59:45,351 simple_logger.py log_once [line:28] INFO valid_loss                    1.7346\n",
            "2023-09-21 14:59:45,355 simple_logger.py log_once [line:28] INFO mean_valid_loss               1.7274\n",
            "2023-09-21 14:59:45,356 simple_logger.py log_once [line:28] INFO std_valid_loss                0.7371\n",
            "2023-09-21 14:59:45,358 fedbase.py run [line:251] INFO Eval Time Cost:               3.7842s\n",
            "2023-09-21 14:59:49,536 fedbase.py run [line:246] INFO --------------Round 23--------------\n",
            "2023-09-21 14:59:49,538 simple_logger.py log_once [line:14] INFO Current_time:23\n",
            "2023-09-21 14:59:53,291 simple_logger.py log_once [line:28] INFO test_accuracy                 0.3838\n",
            "2023-09-21 14:59:53,293 simple_logger.py log_once [line:28] INFO test_loss                     1.9522\n",
            "2023-09-21 14:59:53,295 simple_logger.py log_once [line:28] INFO valid_accuracy                0.3744\n",
            "2023-09-21 14:59:53,300 simple_logger.py log_once [line:28] INFO mean_valid_accuracy           0.3744\n",
            "2023-09-21 14:59:53,302 simple_logger.py log_once [line:28] INFO std_valid_accuracy            0.3091\n",
            "2023-09-21 14:59:53,303 simple_logger.py log_once [line:28] INFO valid_loss                    1.9809\n",
            "2023-09-21 14:59:53,304 simple_logger.py log_once [line:28] INFO mean_valid_loss               1.9787\n",
            "2023-09-21 14:59:53,306 simple_logger.py log_once [line:28] INFO std_valid_loss                0.9764\n",
            "2023-09-21 14:59:53,307 fedbase.py run [line:251] INFO Eval Time Cost:               3.7691s\n",
            "2023-09-21 14:59:54,835 fedbase.py run [line:246] INFO --------------Round 24--------------\n",
            "2023-09-21 14:59:54,836 simple_logger.py log_once [line:14] INFO Current_time:24\n",
            "2023-09-21 14:59:58,552 simple_logger.py log_once [line:28] INFO test_accuracy                 0.3065\n",
            "2023-09-21 14:59:58,553 simple_logger.py log_once [line:28] INFO test_loss                     3.2959\n",
            "2023-09-21 14:59:58,557 simple_logger.py log_once [line:28] INFO valid_accuracy                0.3069\n",
            "2023-09-21 14:59:58,559 simple_logger.py log_once [line:28] INFO mean_valid_accuracy           0.3088\n",
            "2023-09-21 14:59:58,561 simple_logger.py log_once [line:28] INFO std_valid_accuracy            0.2696\n",
            "2023-09-21 14:59:58,565 simple_logger.py log_once [line:28] INFO valid_loss                    3.3395\n",
            "2023-09-21 14:59:58,567 simple_logger.py log_once [line:28] INFO mean_valid_loss               3.3255\n",
            "2023-09-21 14:59:58,568 simple_logger.py log_once [line:28] INFO std_valid_loss                1.5635\n",
            "2023-09-21 14:59:58,569 fedbase.py run [line:251] INFO Eval Time Cost:               3.7324s\n",
            "2023-09-21 15:00:02,462 fedbase.py run [line:246] INFO --------------Round 25--------------\n",
            "2023-09-21 15:00:02,466 simple_logger.py log_once [line:14] INFO Current_time:25\n",
            "2023-09-21 15:00:06,309 simple_logger.py log_once [line:28] INFO test_accuracy                 0.3762\n",
            "2023-09-21 15:00:06,312 simple_logger.py log_once [line:28] INFO test_loss                     2.2962\n",
            "2023-09-21 15:00:06,315 simple_logger.py log_once [line:28] INFO valid_accuracy                0.3781\n",
            "2023-09-21 15:00:06,317 simple_logger.py log_once [line:28] INFO mean_valid_accuracy           0.3779\n",
            "2023-09-21 15:00:06,319 simple_logger.py log_once [line:28] INFO std_valid_accuracy            0.2656\n",
            "2023-09-21 15:00:06,325 simple_logger.py log_once [line:28] INFO valid_loss                    2.3497\n",
            "2023-09-21 15:00:06,326 simple_logger.py log_once [line:28] INFO mean_valid_loss               2.3544\n",
            "2023-09-21 15:00:06,331 simple_logger.py log_once [line:28] INFO std_valid_loss                1.4301\n",
            "2023-09-21 15:00:06,332 fedbase.py run [line:251] INFO Eval Time Cost:               3.8661s\n",
            "2023-09-21 15:00:09,490 fedbase.py run [line:246] INFO --------------Round 26--------------\n",
            "2023-09-21 15:00:09,491 simple_logger.py log_once [line:14] INFO Current_time:26\n",
            "2023-09-21 15:00:13,332 simple_logger.py log_once [line:28] INFO test_accuracy                 0.4148\n",
            "2023-09-21 15:00:13,339 simple_logger.py log_once [line:28] INFO test_loss                     2.0035\n",
            "2023-09-21 15:00:13,342 simple_logger.py log_once [line:28] INFO valid_accuracy                0.3980\n",
            "2023-09-21 15:00:13,344 simple_logger.py log_once [line:28] INFO mean_valid_accuracy           0.3983\n",
            "2023-09-21 15:00:13,346 simple_logger.py log_once [line:28] INFO std_valid_accuracy            0.2452\n",
            "2023-09-21 15:00:13,348 simple_logger.py log_once [line:28] INFO valid_loss                    2.0631\n",
            "2023-09-21 15:00:13,349 simple_logger.py log_once [line:28] INFO mean_valid_loss               2.0634\n",
            "2023-09-21 15:00:13,350 simple_logger.py log_once [line:28] INFO std_valid_loss                1.2249\n",
            "2023-09-21 15:00:13,352 fedbase.py run [line:251] INFO Eval Time Cost:               3.8605s\n",
            "2023-09-21 15:00:17,436 fedbase.py run [line:246] INFO --------------Round 27--------------\n",
            "2023-09-21 15:00:17,438 simple_logger.py log_once [line:14] INFO Current_time:27\n",
            "2023-09-21 15:00:21,161 simple_logger.py log_once [line:28] INFO test_accuracy                 0.4499\n",
            "2023-09-21 15:00:21,163 simple_logger.py log_once [line:28] INFO test_loss                     1.8244\n",
            "2023-09-21 15:00:21,166 simple_logger.py log_once [line:28] INFO valid_accuracy                0.4327\n",
            "2023-09-21 15:00:21,169 simple_logger.py log_once [line:28] INFO mean_valid_accuracy           0.4338\n",
            "2023-09-21 15:00:21,170 simple_logger.py log_once [line:28] INFO std_valid_accuracy            0.2048\n",
            "2023-09-21 15:00:21,174 simple_logger.py log_once [line:28] INFO valid_loss                    1.8984\n",
            "2023-09-21 15:00:21,176 simple_logger.py log_once [line:28] INFO mean_valid_loss               1.8925\n",
            "2023-09-21 15:00:21,177 simple_logger.py log_once [line:28] INFO std_valid_loss                0.7727\n",
            "2023-09-21 15:00:21,178 fedbase.py run [line:251] INFO Eval Time Cost:               3.7401s\n",
            "2023-09-21 15:00:24,244 fedbase.py run [line:246] INFO --------------Round 28--------------\n",
            "2023-09-21 15:00:24,245 simple_logger.py log_once [line:14] INFO Current_time:28\n",
            "2023-09-21 15:00:28,656 simple_logger.py log_once [line:28] INFO test_accuracy                 0.3666\n",
            "2023-09-21 15:00:28,662 simple_logger.py log_once [line:28] INFO test_loss                     2.4900\n",
            "2023-09-21 15:00:28,664 simple_logger.py log_once [line:28] INFO valid_accuracy                0.3498\n",
            "2023-09-21 15:00:28,666 simple_logger.py log_once [line:28] INFO mean_valid_accuracy           0.3507\n",
            "2023-09-21 15:00:28,668 simple_logger.py log_once [line:28] INFO std_valid_accuracy            0.2449\n",
            "2023-09-21 15:00:28,669 simple_logger.py log_once [line:28] INFO valid_loss                    2.5321\n",
            "2023-09-21 15:00:28,672 simple_logger.py log_once [line:28] INFO mean_valid_loss               2.5320\n",
            "2023-09-21 15:00:28,675 simple_logger.py log_once [line:28] INFO std_valid_loss                1.2804\n",
            "2023-09-21 15:00:28,676 fedbase.py run [line:251] INFO Eval Time Cost:               4.4309s\n",
            "2023-09-21 15:00:32,304 fedbase.py run [line:246] INFO --------------Round 29--------------\n",
            "2023-09-21 15:00:32,306 simple_logger.py log_once [line:14] INFO Current_time:29\n",
            "2023-09-21 15:00:36,096 simple_logger.py log_once [line:28] INFO test_accuracy                 0.3518\n",
            "2023-09-21 15:00:36,098 simple_logger.py log_once [line:28] INFO test_loss                     2.0864\n",
            "2023-09-21 15:00:36,100 simple_logger.py log_once [line:28] INFO valid_accuracy                0.3449\n",
            "2023-09-21 15:00:36,105 simple_logger.py log_once [line:28] INFO mean_valid_accuracy           0.3430\n",
            "2023-09-21 15:00:36,106 simple_logger.py log_once [line:28] INFO std_valid_accuracy            0.2525\n",
            "2023-09-21 15:00:36,110 simple_logger.py log_once [line:28] INFO valid_loss                    2.1279\n",
            "2023-09-21 15:00:36,113 simple_logger.py log_once [line:28] INFO mean_valid_loss               2.1377\n",
            "2023-09-21 15:00:36,116 simple_logger.py log_once [line:28] INFO std_valid_loss                0.9503\n",
            "2023-09-21 15:00:36,118 fedbase.py run [line:251] INFO Eval Time Cost:               3.8124s\n",
            "2023-09-21 15:00:39,254 fedbase.py run [line:246] INFO --------------Round 30--------------\n",
            "2023-09-21 15:00:39,255 simple_logger.py log_once [line:14] INFO Current_time:30\n",
            "2023-09-21 15:00:44,204 simple_logger.py log_once [line:28] INFO test_accuracy                 0.4675\n",
            "2023-09-21 15:00:44,206 simple_logger.py log_once [line:28] INFO test_loss                     1.7008\n",
            "2023-09-21 15:00:44,207 simple_logger.py log_once [line:28] INFO valid_accuracy                0.4537\n",
            "2023-09-21 15:00:44,214 simple_logger.py log_once [line:28] INFO mean_valid_accuracy           0.4546\n",
            "2023-09-21 15:00:44,216 simple_logger.py log_once [line:28] INFO std_valid_accuracy            0.2016\n",
            "2023-09-21 15:00:44,218 simple_logger.py log_once [line:28] INFO valid_loss                    1.7489\n",
            "2023-09-21 15:00:44,219 simple_logger.py log_once [line:28] INFO mean_valid_loss               1.7458\n",
            "2023-09-21 15:00:44,220 simple_logger.py log_once [line:28] INFO std_valid_loss                0.6701\n",
            "2023-09-21 15:00:44,221 fedbase.py run [line:251] INFO Eval Time Cost:               4.9662s\n",
            "2023-09-21 15:00:47,330 fedbase.py run [line:246] INFO --------------Round 31--------------\n",
            "2023-09-21 15:00:47,331 simple_logger.py log_once [line:14] INFO Current_time:31\n",
            "2023-09-21 15:00:51,021 simple_logger.py log_once [line:28] INFO test_accuracy                 0.4005\n",
            "2023-09-21 15:00:51,023 simple_logger.py log_once [line:28] INFO test_loss                     2.8121\n",
            "2023-09-21 15:00:51,027 simple_logger.py log_once [line:28] INFO valid_accuracy                0.3899\n",
            "2023-09-21 15:00:51,029 simple_logger.py log_once [line:28] INFO mean_valid_accuracy           0.3906\n",
            "2023-09-21 15:00:51,034 simple_logger.py log_once [line:28] INFO std_valid_accuracy            0.2640\n",
            "2023-09-21 15:00:51,036 simple_logger.py log_once [line:28] INFO valid_loss                    2.8893\n",
            "2023-09-21 15:00:51,038 simple_logger.py log_once [line:28] INFO mean_valid_loss               2.8913\n",
            "2023-09-21 15:00:51,039 simple_logger.py log_once [line:28] INFO std_valid_loss                1.8972\n",
            "2023-09-21 15:00:51,040 fedbase.py run [line:251] INFO Eval Time Cost:               3.7095s\n",
            "2023-09-21 15:00:54,335 fedbase.py run [line:246] INFO --------------Round 32--------------\n",
            "2023-09-21 15:00:54,337 simple_logger.py log_once [line:14] INFO Current_time:32\n",
            "2023-09-21 15:00:58,914 simple_logger.py log_once [line:28] INFO test_accuracy                 0.3873\n",
            "2023-09-21 15:00:58,915 simple_logger.py log_once [line:28] INFO test_loss                     1.9327\n",
            "2023-09-21 15:00:58,919 simple_logger.py log_once [line:28] INFO valid_accuracy                0.3766\n",
            "2023-09-21 15:00:58,921 simple_logger.py log_once [line:28] INFO mean_valid_accuracy           0.3754\n",
            "2023-09-21 15:00:58,925 simple_logger.py log_once [line:28] INFO std_valid_accuracy            0.1983\n",
            "2023-09-21 15:00:58,929 simple_logger.py log_once [line:28] INFO valid_loss                    1.9909\n",
            "2023-09-21 15:00:58,931 simple_logger.py log_once [line:28] INFO mean_valid_loss               2.0018\n",
            "2023-09-21 15:00:58,934 simple_logger.py log_once [line:28] INFO std_valid_loss                0.8390\n",
            "2023-09-21 15:00:58,935 fedbase.py run [line:251] INFO Eval Time Cost:               4.5984s\n",
            "2023-09-21 15:01:01,935 fedbase.py run [line:246] INFO --------------Round 33--------------\n",
            "2023-09-21 15:01:01,936 simple_logger.py log_once [line:14] INFO Current_time:33\n",
            "2023-09-21 15:01:05,644 simple_logger.py log_once [line:28] INFO test_accuracy                 0.3484\n",
            "2023-09-21 15:01:05,645 simple_logger.py log_once [line:28] INFO test_loss                     2.6555\n",
            "2023-09-21 15:01:05,646 simple_logger.py log_once [line:28] INFO valid_accuracy                0.3436\n",
            "2023-09-21 15:01:05,651 simple_logger.py log_once [line:28] INFO mean_valid_accuracy           0.3466\n",
            "2023-09-21 15:01:05,655 simple_logger.py log_once [line:28] INFO std_valid_accuracy            0.2386\n",
            "2023-09-21 15:01:05,657 simple_logger.py log_once [line:28] INFO valid_loss                    2.7519\n",
            "2023-09-21 15:01:05,658 simple_logger.py log_once [line:28] INFO mean_valid_loss               2.7346\n",
            "2023-09-21 15:01:05,662 simple_logger.py log_once [line:28] INFO std_valid_loss                1.1687\n",
            "2023-09-21 15:01:05,662 fedbase.py run [line:251] INFO Eval Time Cost:               3.7261s\n",
            "2023-09-21 15:01:09,524 fedbase.py run [line:246] INFO --------------Round 34--------------\n",
            "2023-09-21 15:01:09,528 simple_logger.py log_once [line:14] INFO Current_time:34\n",
            "2023-09-21 15:01:13,927 simple_logger.py log_once [line:28] INFO test_accuracy                 0.4595\n",
            "2023-09-21 15:01:13,929 simple_logger.py log_once [line:28] INFO test_loss                     1.7034\n",
            "2023-09-21 15:01:13,932 simple_logger.py log_once [line:28] INFO valid_accuracy                0.4522\n",
            "2023-09-21 15:01:13,935 simple_logger.py log_once [line:28] INFO mean_valid_accuracy           0.4526\n",
            "2023-09-21 15:01:13,939 simple_logger.py log_once [line:28] INFO std_valid_accuracy            0.2171\n",
            "2023-09-21 15:01:13,941 simple_logger.py log_once [line:28] INFO valid_loss                    1.7587\n",
            "2023-09-21 15:01:13,943 simple_logger.py log_once [line:28] INFO mean_valid_loss               1.7587\n",
            "2023-09-21 15:01:13,944 simple_logger.py log_once [line:28] INFO std_valid_loss                0.9230\n",
            "2023-09-21 15:01:13,945 fedbase.py run [line:251] INFO Eval Time Cost:               4.4174s\n",
            "2023-09-21 15:01:17,378 fedbase.py run [line:246] INFO --------------Round 35--------------\n",
            "2023-09-21 15:01:17,380 simple_logger.py log_once [line:14] INFO Current_time:35\n",
            "2023-09-21 15:01:21,379 simple_logger.py log_once [line:28] INFO test_accuracy                 0.3961\n",
            "2023-09-21 15:01:21,380 simple_logger.py log_once [line:28] INFO test_loss                     2.7245\n",
            "2023-09-21 15:01:21,383 simple_logger.py log_once [line:28] INFO valid_accuracy                0.3877\n",
            "2023-09-21 15:01:21,385 simple_logger.py log_once [line:28] INFO mean_valid_accuracy           0.3880\n",
            "2023-09-21 15:01:21,387 simple_logger.py log_once [line:28] INFO std_valid_accuracy            0.2710\n",
            "2023-09-21 15:01:21,391 simple_logger.py log_once [line:28] INFO valid_loss                    2.8490\n",
            "2023-09-21 15:01:21,395 simple_logger.py log_once [line:28] INFO mean_valid_loss               2.8526\n",
            "2023-09-21 15:01:21,397 simple_logger.py log_once [line:28] INFO std_valid_loss                1.9352\n",
            "2023-09-21 15:01:21,400 fedbase.py run [line:251] INFO Eval Time Cost:               4.0207s\n",
            "2023-09-21 15:01:23,662 fedbase.py run [line:246] INFO --------------Round 36--------------\n",
            "2023-09-21 15:01:23,665 simple_logger.py log_once [line:14] INFO Current_time:36\n",
            "2023-09-21 15:01:27,658 simple_logger.py log_once [line:28] INFO test_accuracy                 0.2996\n",
            "2023-09-21 15:01:27,659 simple_logger.py log_once [line:28] INFO test_loss                     3.6112\n",
            "2023-09-21 15:01:27,667 simple_logger.py log_once [line:28] INFO valid_accuracy                0.2936\n",
            "2023-09-21 15:01:27,669 simple_logger.py log_once [line:28] INFO mean_valid_accuracy           0.2970\n",
            "2023-09-21 15:01:27,671 simple_logger.py log_once [line:28] INFO std_valid_accuracy            0.2766\n",
            "2023-09-21 15:01:27,673 simple_logger.py log_once [line:28] INFO valid_loss                    3.6300\n",
            "2023-09-21 15:01:27,680 simple_logger.py log_once [line:28] INFO mean_valid_loss               3.6183\n",
            "2023-09-21 15:01:27,683 simple_logger.py log_once [line:28] INFO std_valid_loss                1.8911\n",
            "2023-09-21 15:01:27,685 fedbase.py run [line:251] INFO Eval Time Cost:               4.0200s\n",
            "2023-09-21 15:01:30,923 fedbase.py run [line:246] INFO --------------Round 37--------------\n",
            "2023-09-21 15:01:30,924 simple_logger.py log_once [line:14] INFO Current_time:37\n",
            "2023-09-21 15:01:35,169 simple_logger.py log_once [line:28] INFO test_accuracy                 0.4561\n",
            "2023-09-21 15:01:35,172 simple_logger.py log_once [line:28] INFO test_loss                     1.9771\n",
            "2023-09-21 15:01:35,176 simple_logger.py log_once [line:28] INFO valid_accuracy                0.4473\n",
            "2023-09-21 15:01:35,178 simple_logger.py log_once [line:28] INFO mean_valid_accuracy           0.4480\n",
            "2023-09-21 15:01:35,180 simple_logger.py log_once [line:28] INFO std_valid_accuracy            0.1993\n",
            "2023-09-21 15:01:35,181 simple_logger.py log_once [line:28] INFO valid_loss                    2.0346\n",
            "2023-09-21 15:01:35,183 simple_logger.py log_once [line:28] INFO mean_valid_loss               2.0329\n",
            "2023-09-21 15:01:35,184 simple_logger.py log_once [line:28] INFO std_valid_loss                0.9020\n",
            "2023-09-21 15:01:35,185 fedbase.py run [line:251] INFO Eval Time Cost:               4.2607s\n",
            "2023-09-21 15:01:39,208 fedbase.py run [line:246] INFO --------------Round 38--------------\n",
            "2023-09-21 15:01:39,209 simple_logger.py log_once [line:14] INFO Current_time:38\n",
            "2023-09-21 15:01:43,062 simple_logger.py log_once [line:28] INFO test_accuracy                 0.4344\n",
            "2023-09-21 15:01:43,063 simple_logger.py log_once [line:28] INFO test_loss                     1.9018\n",
            "2023-09-21 15:01:43,067 simple_logger.py log_once [line:28] INFO valid_accuracy                0.4285\n",
            "2023-09-21 15:01:43,069 simple_logger.py log_once [line:28] INFO mean_valid_accuracy           0.4281\n",
            "2023-09-21 15:01:43,071 simple_logger.py log_once [line:28] INFO std_valid_accuracy            0.2123\n",
            "2023-09-21 15:01:43,072 simple_logger.py log_once [line:28] INFO valid_loss                    1.9202\n",
            "2023-09-21 15:01:43,074 simple_logger.py log_once [line:28] INFO mean_valid_loss               1.9220\n",
            "2023-09-21 15:01:43,075 simple_logger.py log_once [line:28] INFO std_valid_loss                0.9304\n",
            "2023-09-21 15:01:43,076 fedbase.py run [line:251] INFO Eval Time Cost:               3.8670s\n",
            "2023-09-21 15:01:46,212 fedbase.py run [line:246] INFO --------------Round 39--------------\n",
            "2023-09-21 15:01:46,213 simple_logger.py log_once [line:14] INFO Current_time:39\n",
            "2023-09-21 15:01:51,146 simple_logger.py log_once [line:28] INFO test_accuracy                 0.4602\n",
            "2023-09-21 15:01:51,148 simple_logger.py log_once [line:28] INFO test_loss                     1.9179\n",
            "2023-09-21 15:01:51,156 simple_logger.py log_once [line:28] INFO valid_accuracy                0.4468\n",
            "2023-09-21 15:01:51,158 simple_logger.py log_once [line:28] INFO mean_valid_accuracy           0.4499\n",
            "2023-09-21 15:01:51,159 simple_logger.py log_once [line:28] INFO std_valid_accuracy            0.2391\n",
            "2023-09-21 15:01:51,161 simple_logger.py log_once [line:28] INFO valid_loss                    1.9744\n",
            "2023-09-21 15:01:51,163 simple_logger.py log_once [line:28] INFO mean_valid_loss               1.9601\n",
            "2023-09-21 15:01:51,164 simple_logger.py log_once [line:28] INFO std_valid_loss                1.0835\n",
            "2023-09-21 15:01:51,165 fedbase.py run [line:251] INFO Eval Time Cost:               4.9520s\n",
            "2023-09-21 15:01:54,281 fedbase.py run [line:246] INFO --------------Round 40--------------\n",
            "2023-09-21 15:01:54,283 simple_logger.py log_once [line:14] INFO Current_time:40\n",
            "2023-09-21 15:01:58,036 simple_logger.py log_once [line:28] INFO test_accuracy                 0.4423\n",
            "2023-09-21 15:01:58,037 simple_logger.py log_once [line:28] INFO test_loss                     1.7731\n",
            "2023-09-21 15:01:58,038 simple_logger.py log_once [line:28] INFO valid_accuracy                0.4328\n",
            "2023-09-21 15:01:58,043 simple_logger.py log_once [line:28] INFO mean_valid_accuracy           0.4329\n",
            "2023-09-21 15:01:58,049 simple_logger.py log_once [line:28] INFO std_valid_accuracy            0.2368\n",
            "2023-09-21 15:01:58,050 simple_logger.py log_once [line:28] INFO valid_loss                    1.8033\n",
            "2023-09-21 15:01:58,051 simple_logger.py log_once [line:28] INFO mean_valid_loss               1.8049\n",
            "2023-09-21 15:01:58,052 simple_logger.py log_once [line:28] INFO std_valid_loss                0.7757\n",
            "2023-09-21 15:01:58,053 fedbase.py run [line:251] INFO Eval Time Cost:               3.7705s\n",
            "2023-09-21 15:02:01,085 fedbase.py run [line:246] INFO --------------Round 41--------------\n",
            "2023-09-21 15:02:01,088 simple_logger.py log_once [line:14] INFO Current_time:41\n",
            "2023-09-21 15:02:06,039 simple_logger.py log_once [line:28] INFO test_accuracy                 0.4210\n",
            "2023-09-21 15:02:06,041 simple_logger.py log_once [line:28] INFO test_loss                     2.6132\n",
            "2023-09-21 15:02:06,043 simple_logger.py log_once [line:28] INFO valid_accuracy                0.4216\n",
            "2023-09-21 15:02:06,045 simple_logger.py log_once [line:28] INFO mean_valid_accuracy           0.4245\n",
            "2023-09-21 15:02:06,047 simple_logger.py log_once [line:28] INFO std_valid_accuracy            0.2075\n",
            "2023-09-21 15:02:06,048 simple_logger.py log_once [line:28] INFO valid_loss                    2.6912\n",
            "2023-09-21 15:02:06,050 simple_logger.py log_once [line:28] INFO mean_valid_loss               2.6787\n",
            "2023-09-21 15:02:06,051 simple_logger.py log_once [line:28] INFO std_valid_loss                1.2197\n",
            "2023-09-21 15:02:06,052 fedbase.py run [line:251] INFO Eval Time Cost:               4.9641s\n",
            "2023-09-21 15:02:07,657 fedbase.py run [line:246] INFO --------------Round 42--------------\n",
            "2023-09-21 15:02:07,658 simple_logger.py log_once [line:14] INFO Current_time:42\n",
            "2023-09-21 15:02:11,437 simple_logger.py log_once [line:28] INFO test_accuracy                 0.2728\n",
            "2023-09-21 15:02:11,438 simple_logger.py log_once [line:28] INFO test_loss                     4.5893\n",
            "2023-09-21 15:02:11,443 simple_logger.py log_once [line:28] INFO valid_accuracy                0.2631\n",
            "2023-09-21 15:02:11,445 simple_logger.py log_once [line:28] INFO mean_valid_accuracy           0.2617\n",
            "2023-09-21 15:02:11,446 simple_logger.py log_once [line:28] INFO std_valid_accuracy            0.2985\n",
            "2023-09-21 15:02:11,448 simple_logger.py log_once [line:28] INFO valid_loss                    4.6068\n",
            "2023-09-21 15:02:11,449 simple_logger.py log_once [line:28] INFO mean_valid_loss               4.6251\n",
            "2023-09-21 15:02:11,450 simple_logger.py log_once [line:28] INFO std_valid_loss                2.2468\n",
            "2023-09-21 15:02:11,451 fedbase.py run [line:251] INFO Eval Time Cost:               3.7933s\n",
            "2023-09-21 15:02:13,018 fedbase.py run [line:246] INFO --------------Round 43--------------\n",
            "2023-09-21 15:02:13,020 simple_logger.py log_once [line:14] INFO Current_time:43\n",
            "2023-09-21 15:02:18,180 simple_logger.py log_once [line:28] INFO test_accuracy                 0.2486\n",
            "2023-09-21 15:02:18,181 simple_logger.py log_once [line:28] INFO test_loss                     4.1852\n",
            "2023-09-21 15:02:18,186 simple_logger.py log_once [line:28] INFO valid_accuracy                0.2538\n",
            "2023-09-21 15:02:18,187 simple_logger.py log_once [line:28] INFO mean_valid_accuracy           0.2562\n",
            "2023-09-21 15:02:18,190 simple_logger.py log_once [line:28] INFO std_valid_accuracy            0.2846\n",
            "2023-09-21 15:02:18,191 simple_logger.py log_once [line:28] INFO valid_loss                    4.1859\n",
            "2023-09-21 15:02:18,192 simple_logger.py log_once [line:28] INFO mean_valid_loss               4.1563\n",
            "2023-09-21 15:02:18,193 simple_logger.py log_once [line:28] INFO std_valid_loss                2.0996\n",
            "2023-09-21 15:02:18,194 fedbase.py run [line:251] INFO Eval Time Cost:               5.1745s\n",
            "2023-09-21 15:02:19,781 fedbase.py run [line:246] INFO --------------Round 44--------------\n",
            "2023-09-21 15:02:19,782 simple_logger.py log_once [line:14] INFO Current_time:44\n",
            "2023-09-21 15:02:23,597 simple_logger.py log_once [line:28] INFO test_accuracy                 0.2903\n",
            "2023-09-21 15:02:23,599 simple_logger.py log_once [line:28] INFO test_loss                     4.3271\n",
            "2023-09-21 15:02:23,601 simple_logger.py log_once [line:28] INFO valid_accuracy                0.2886\n",
            "2023-09-21 15:02:23,603 simple_logger.py log_once [line:28] INFO mean_valid_accuracy           0.2909\n",
            "2023-09-21 15:02:23,605 simple_logger.py log_once [line:28] INFO std_valid_accuracy            0.2809\n",
            "2023-09-21 15:02:23,607 simple_logger.py log_once [line:28] INFO valid_loss                    4.3534\n",
            "2023-09-21 15:02:23,608 simple_logger.py log_once [line:28] INFO mean_valid_loss               4.3207\n",
            "2023-09-21 15:02:23,609 simple_logger.py log_once [line:28] INFO std_valid_loss                2.2435\n",
            "2023-09-21 15:02:23,610 fedbase.py run [line:251] INFO Eval Time Cost:               3.8277s\n",
            "2023-09-21 15:02:26,869 fedbase.py run [line:246] INFO --------------Round 45--------------\n",
            "2023-09-21 15:02:26,870 simple_logger.py log_once [line:14] INFO Current_time:45\n",
            "2023-09-21 15:02:31,817 simple_logger.py log_once [line:28] INFO test_accuracy                 0.4326\n",
            "2023-09-21 15:02:31,818 simple_logger.py log_once [line:28] INFO test_loss                     2.2818\n",
            "2023-09-21 15:02:31,821 simple_logger.py log_once [line:28] INFO valid_accuracy                0.4290\n",
            "2023-09-21 15:02:31,822 simple_logger.py log_once [line:28] INFO mean_valid_accuracy           0.4263\n",
            "2023-09-21 15:02:31,826 simple_logger.py log_once [line:28] INFO std_valid_accuracy            0.2774\n",
            "2023-09-21 15:02:31,828 simple_logger.py log_once [line:28] INFO valid_loss                    2.3066\n",
            "2023-09-21 15:02:31,829 simple_logger.py log_once [line:28] INFO mean_valid_loss               2.3235\n",
            "2023-09-21 15:02:31,830 simple_logger.py log_once [line:28] INFO std_valid_loss                1.5231\n",
            "2023-09-21 15:02:31,831 fedbase.py run [line:251] INFO Eval Time Cost:               4.9612s\n",
            "2023-09-21 15:02:34,984 fedbase.py run [line:246] INFO --------------Round 46--------------\n",
            "2023-09-21 15:02:34,985 simple_logger.py log_once [line:14] INFO Current_time:46\n",
            "2023-09-21 15:02:38,818 simple_logger.py log_once [line:28] INFO test_accuracy                 0.4476\n",
            "2023-09-21 15:02:38,819 simple_logger.py log_once [line:28] INFO test_loss                     2.2246\n",
            "2023-09-21 15:02:38,824 simple_logger.py log_once [line:28] INFO valid_accuracy                0.4454\n",
            "2023-09-21 15:02:38,825 simple_logger.py log_once [line:28] INFO mean_valid_accuracy           0.4447\n",
            "2023-09-21 15:02:38,827 simple_logger.py log_once [line:28] INFO std_valid_accuracy            0.2539\n",
            "2023-09-21 15:02:38,829 simple_logger.py log_once [line:28] INFO valid_loss                    2.2779\n",
            "2023-09-21 15:02:38,831 simple_logger.py log_once [line:28] INFO mean_valid_loss               2.2876\n",
            "2023-09-21 15:02:38,833 simple_logger.py log_once [line:28] INFO std_valid_loss                1.5233\n",
            "2023-09-21 15:02:38,834 fedbase.py run [line:251] INFO Eval Time Cost:               3.8491s\n",
            "2023-09-21 15:02:42,209 fedbase.py run [line:246] INFO --------------Round 47--------------\n",
            "2023-09-21 15:02:42,215 simple_logger.py log_once [line:14] INFO Current_time:47\n",
            "2023-09-21 15:02:46,974 simple_logger.py log_once [line:28] INFO test_accuracy                 0.3155\n",
            "2023-09-21 15:02:46,976 simple_logger.py log_once [line:28] INFO test_loss                     3.2309\n",
            "2023-09-21 15:02:46,978 simple_logger.py log_once [line:28] INFO valid_accuracy                0.3086\n",
            "2023-09-21 15:02:46,980 simple_logger.py log_once [line:28] INFO mean_valid_accuracy           0.3078\n",
            "2023-09-21 15:02:46,983 simple_logger.py log_once [line:28] INFO std_valid_accuracy            0.2729\n",
            "2023-09-21 15:02:46,985 simple_logger.py log_once [line:28] INFO valid_loss                    3.2630\n",
            "2023-09-21 15:02:46,987 simple_logger.py log_once [line:28] INFO mean_valid_loss               3.2646\n",
            "2023-09-21 15:02:46,988 simple_logger.py log_once [line:28] INFO std_valid_loss                1.4789\n",
            "2023-09-21 15:02:46,989 fedbase.py run [line:251] INFO Eval Time Cost:               4.7738s\n",
            "2023-09-21 15:02:50,160 fedbase.py run [line:246] INFO --------------Round 48--------------\n",
            "2023-09-21 15:02:50,161 simple_logger.py log_once [line:14] INFO Current_time:48\n",
            "2023-09-21 15:02:53,947 simple_logger.py log_once [line:28] INFO test_accuracy                 0.4487\n",
            "2023-09-21 15:02:53,948 simple_logger.py log_once [line:28] INFO test_loss                     1.8244\n",
            "2023-09-21 15:02:53,952 simple_logger.py log_once [line:28] INFO valid_accuracy                0.4404\n",
            "2023-09-21 15:02:53,956 simple_logger.py log_once [line:28] INFO mean_valid_accuracy           0.4395\n",
            "2023-09-21 15:02:53,958 simple_logger.py log_once [line:28] INFO std_valid_accuracy            0.2834\n",
            "2023-09-21 15:02:53,961 simple_logger.py log_once [line:28] INFO valid_loss                    1.8846\n",
            "2023-09-21 15:02:53,964 simple_logger.py log_once [line:28] INFO mean_valid_loss               1.8887\n",
            "2023-09-21 15:02:53,967 simple_logger.py log_once [line:28] INFO std_valid_loss                1.0481\n",
            "2023-09-21 15:02:53,969 fedbase.py run [line:251] INFO Eval Time Cost:               3.8079s\n",
            "2023-09-21 15:02:58,099 fedbase.py run [line:246] INFO --------------Round 49--------------\n",
            "2023-09-21 15:02:58,106 simple_logger.py log_once [line:14] INFO Current_time:49\n",
            "2023-09-21 15:03:01,891 simple_logger.py log_once [line:28] INFO test_accuracy                 0.3284\n",
            "2023-09-21 15:03:01,892 simple_logger.py log_once [line:28] INFO test_loss                     3.1134\n",
            "2023-09-21 15:03:01,894 simple_logger.py log_once [line:28] INFO valid_accuracy                0.3181\n",
            "2023-09-21 15:03:01,896 simple_logger.py log_once [line:28] INFO mean_valid_accuracy           0.3164\n",
            "2023-09-21 15:03:01,898 simple_logger.py log_once [line:28] INFO std_valid_accuracy            0.2823\n",
            "2023-09-21 15:03:01,901 simple_logger.py log_once [line:28] INFO valid_loss                    3.1784\n",
            "2023-09-21 15:03:01,903 simple_logger.py log_once [line:28] INFO mean_valid_loss               3.1947\n",
            "2023-09-21 15:03:01,904 simple_logger.py log_once [line:28] INFO std_valid_loss                1.7417\n",
            "2023-09-21 15:03:01,905 fedbase.py run [line:251] INFO Eval Time Cost:               3.7988s\n",
            "2023-09-21 15:03:04,913 fedbase.py run [line:246] INFO --------------Round 50--------------\n",
            "2023-09-21 15:03:04,914 simple_logger.py log_once [line:14] INFO Current_time:50\n",
            "2023-09-21 15:03:09,023 simple_logger.py log_once [line:28] INFO test_accuracy                 0.4644\n",
            "2023-09-21 15:03:09,025 simple_logger.py log_once [line:28] INFO test_loss                     1.7386\n",
            "2023-09-21 15:03:09,027 simple_logger.py log_once [line:28] INFO valid_accuracy                0.4471\n",
            "2023-09-21 15:03:09,029 simple_logger.py log_once [line:28] INFO mean_valid_accuracy           0.4514\n",
            "2023-09-21 15:03:09,031 simple_logger.py log_once [line:28] INFO std_valid_accuracy            0.2200\n",
            "2023-09-21 15:03:09,033 simple_logger.py log_once [line:28] INFO valid_loss                    1.7776\n",
            "2023-09-21 15:03:09,034 simple_logger.py log_once [line:28] INFO mean_valid_loss               1.7613\n",
            "2023-09-21 15:03:09,035 simple_logger.py log_once [line:28] INFO std_valid_loss                0.8585\n",
            "2023-09-21 15:03:09,036 fedbase.py run [line:251] INFO Eval Time Cost:               4.1222s\n",
            "2023-09-21 15:03:09,037 fedbase.py run [line:257] INFO =================End==================\n",
            "2023-09-21 15:03:09,038 fedbase.py run [line:258] INFO Total Time Cost:              370.0737s\n",
            "2023-09-21 15:03:09,039 fedbase.py run [line:260] WARNING flw.logger.output['option'] is not jsonable, and is automatically converted to string.\n",
            "2023-09-21 15:03:09,041 fedbase.py run [line:260] ERROR Failed to save flw.logger.output as results\n"
          ]
        }
      ],
      "source": [
        "runner = flgo.init(task, fedavg, option=option)\n",
        "runner.run()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b9A_ojMWwyFe"
      },
      "source": [
        "# 新建任务(数据划分、模型配置)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L01xn6ByW-vZ",
        "outputId": "5ec353d8-24f8-421c-b304-32e99a1beac4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "3136/64/7/7"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z4SCiLoOxJxU"
      },
      "outputs": [],
      "source": [
        "import flgo\n",
        "import flgo.benchmark.mnist_classification as mnist\n",
        "import flgo.algorithm.fedavg as fedavg\n",
        "import os\n",
        "task = './test_mnist'\n",
        "config_iid = {'benchmark':{'name':'flgo.benchmark.mnist_classification'},'partitioner':{'name': 'IIDPartitioner','para':{'num_clients':100}}}\n",
        "config_div01 = {'benchmark':{'name':'flgo.benchmark.mnist_classification'},'partitioner':{'name': 'DiversityPartitioner','para':{'num_clients':100, 'diversity':0.1}}}\n",
        "config_div05 = {'benchmark':{'name':'flgo.benchmark.mnist_classification'},'partitioner':{'name': 'DiversityPartitioner','para':{'num_clients':100, 'diversity':0.5}}}\n",
        "config_div09 = {'benchmark':{'name':'flgo.benchmark.mnist_classification'},'partitioner':{'name': 'DiversityPartitioner','para':{'num_clients':100, 'diversity':0.9}}}\n",
        "config_dir01 = {'benchmark':{'name':'flgo.benchmark.mnist_classification'},'partitioner':{'name': 'DirichletPartitioner','para':{'num_clients':100, 'alpha':0.1}}}\n",
        "config_dir10 = {'benchmark':{'name':'flgo.benchmark.mnist_classification'},'partitioner':{'name': 'DirichletPartitioner','para':{'num_clients':100, 'alpha':1.0}}}\n",
        "config_dir50 = {'benchmark':{'name':'flgo.benchmark.mnist_classification'},'partitioner':{'name': 'DirichletPartitioner','para':{'num_clients':100, 'alpha':5.0}}}\n",
        "\n",
        "if not os.path.exists(task): flgo.gen_task(config_iid, task_path = task)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jvRgzX1xYxL6"
      },
      "source": [
        "## 自定义log"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0RcRez1dYvDj",
        "outputId": "ea46bae0-c112-4fa6-b68d-f4b6124d60eb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        }
      ],
      "source": [
        "from flgo.experiment.logger import BasicLogger\n",
        "import numpy as np\n",
        "import flgo.simulator.base as ss\n",
        "from collections.abc import Mapping\n",
        "from collections import OrderedDict\n",
        "import wandb\n",
        "!wandb login 653413d82a5a0cc80ce1a3c484a6557e61b2a935\n",
        "\n",
        "class WandbLogger(BasicLogger):\n",
        "    def initialize(self):\n",
        "        wandb.init(project='FLGo'+self.option[\"task\"].replace('/',''), name=self.option[\"algorithm\"])\n",
        "        \"\"\"在输出output中记录各用户的本地数据量，用户使用self.participants属性访问，服务器使用self.coordinator属性访问。self.output的默认键值为空列表\"\"\"\n",
        "        for c in self.participants:\n",
        "            self.output['client_datavol'].append(len(c.train_data))\n",
        "\n",
        "    def show_current_output(self, yes_key=['train', 'test', 'valid'], no_key=['dist']):\n",
        "        wandb_log_dict = OrderedDict() #定义一个Mapping类，存放该step需要发给wandb的参数\n",
        "        for key, val in self.output.items():\n",
        "            a = [(yk in key) for yk in yes_key]\n",
        "            nf = [(nk not in key) for nk in no_key]\n",
        "            if np.all(nf) and np.any(a):\n",
        "                try:\n",
        "                    content = self.temp.format(key, val[-1])\n",
        "                    wandb_log_dict.update({key:val[-1]})\n",
        "                except:\n",
        "                    content = \"{}:\".format(key)+str(val[-1])\n",
        "                    wandb_log_dict.update({key:val[-1]})\n",
        "                self.info(content)\n",
        "        if isinstance(wandb_log_dict, Mapping):\n",
        "            wandb.log(wandb_log_dict)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PNuBCeTAsHYf"
      },
      "source": [
        "## 产生task"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fdd5X-JBsGe3",
        "outputId": "72b0b73e-7a46-44b1-f9cc-8987ad1ac267"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to /content/FLGo/flgo/benchmark/RAW_DATA/MNIST/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 9912422/9912422 [00:00<00:00, 102575789.43it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting /content/FLGo/flgo/benchmark/RAW_DATA/MNIST/MNIST/raw/train-images-idx3-ubyte.gz to /content/FLGo/flgo/benchmark/RAW_DATA/MNIST/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to /content/FLGo/flgo/benchmark/RAW_DATA/MNIST/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 28881/28881 [00:00<00:00, 28807537.18it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting /content/FLGo/flgo/benchmark/RAW_DATA/MNIST/MNIST/raw/train-labels-idx1-ubyte.gz to /content/FLGo/flgo/benchmark/RAW_DATA/MNIST/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to /content/FLGo/flgo/benchmark/RAW_DATA/MNIST/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "100%|██████████| 1648877/1648877 [00:00<00:00, 25913376.16it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting /content/FLGo/flgo/benchmark/RAW_DATA/MNIST/MNIST/raw/t10k-images-idx3-ubyte.gz to /content/FLGo/flgo/benchmark/RAW_DATA/MNIST/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to /content/FLGo/flgo/benchmark/RAW_DATA/MNIST/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4542/4542 [00:00<00:00, 1523432.93it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting /content/FLGo/flgo/benchmark/RAW_DATA/MNIST/MNIST/raw/t10k-labels-idx1-ubyte.gz to /content/FLGo/flgo/benchmark/RAW_DATA/MNIST/MNIST/raw\n",
            "\n",
            "Task ./mnist_iid has been successfully generated.\n",
            "Task ./mnist_div01 has been successfully generated.\n",
            "Task ./mnist_div05 has been successfully generated.\n",
            "Task ./mnist_div09 has been successfully generated.\n",
            "Error: 0.00458395\n",
            "Error: 0.00350481\n",
            "Error: 0.00301193\n",
            "Error: 0.00221803\n",
            "Error: 0.00215533\n",
            "Error: 0.00181578\n",
            "Error: 0.00179099\n",
            "Error: 0.00134548\n",
            "Error: 0.00134407\n",
            "Error: 0.00128806\n",
            "Error: 0.00091323\n",
            "Error: 0.00079102\n",
            "Error: 0.00078065\n",
            "Error: 0.00065212\n",
            "Error: 0.00062334\n",
            "Error: 0.00054423\n",
            "Error: 0.00018215\n",
            "Error: 0.00003193\n",
            "Error: 0.00002331\n",
            "Error: 0.00001684\n",
            "Error: 0.00001305\n",
            "Error: 0.00001198\n",
            "Error: 0.00000549\n",
            "Error: 0.00000405\n",
            "Error: 0.00000214\n",
            "Error: 0.00000104\n",
            "Task ./mnist_dir01 has been successfully generated.\n",
            "Error: 0.00164234\n",
            "Error: 0.00129964\n",
            "Error: 0.00115567\n",
            "Error: 0.00089481\n",
            "Error: 0.00079232\n",
            "Error: 0.00049996\n",
            "Error: 0.00043670\n",
            "Error: 0.00042448\n",
            "Error: 0.00027098\n",
            "Error: 0.00024495\n",
            "Error: 0.00009273\n",
            "Error: 0.00002686\n",
            "Error: 0.00002152\n",
            "Error: 0.00000983\n",
            "Error: 0.00000690\n",
            "Error: 0.00000517\n",
            "Error: 0.00000309\n",
            "Error: 0.00000164\n",
            "Error: 0.00000061\n",
            "Task ./mnist_dir10 has been successfully generated.\n",
            "Error: 0.00192088\n",
            "Error: 0.00183341\n",
            "Error: 0.00163593\n",
            "Error: 0.00157006\n",
            "Error: 0.00145020\n",
            "Error: 0.00138699\n",
            "Error: 0.00126332\n",
            "Error: 0.00118915\n",
            "Error: 0.00097228\n",
            "Error: 0.00088189\n",
            "Error: 0.00073733\n",
            "Error: 0.00072605\n",
            "Error: 0.00051892\n",
            "Error: 0.00046541\n",
            "Error: 0.00023342\n",
            "Error: 0.00020173\n",
            "Error: 0.00019567\n",
            "Error: 0.00012097\n",
            "Error: 0.00009075\n",
            "Error: 0.00006295\n",
            "Error: 0.00004145\n",
            "Error: 0.00002372\n",
            "Error: 0.00001540\n",
            "Error: 0.00000912\n",
            "Error: 0.00000609\n",
            "Error: 0.00000499\n",
            "Error: 0.00000281\n",
            "Error: 0.00000162\n",
            "Task ./mnist_dir50 has been successfully generated.\n"
          ]
        }
      ],
      "source": [
        "import flgo\n",
        "import flgo.benchmark.mnist_classification as mnist\n",
        "import flgo.algorithm.fedavg as fedavg\n",
        "import os\n",
        "\n",
        "config_iid = {'benchmark':{'name':'flgo.benchmark.mnist_classification'},'partitioner':{'name': 'IIDPartitioner','para':{'num_clients':100}}}\n",
        "config_div01 = {'benchmark':{'name':'flgo.benchmark.mnist_classification'},'partitioner':{'name': 'DiversityPartitioner','para':{'num_clients':100, 'diversity':0.1}}}\n",
        "config_div05 = {'benchmark':{'name':'flgo.benchmark.mnist_classification'},'partitioner':{'name': 'DiversityPartitioner','para':{'num_clients':100, 'diversity':0.5}}}\n",
        "config_div09 = {'benchmark':{'name':'flgo.benchmark.mnist_classification'},'partitioner':{'name': 'DiversityPartitioner','para':{'num_clients':100, 'diversity':0.9}}}\n",
        "config_dir01 = {'benchmark':{'name':'flgo.benchmark.mnist_classification'},'partitioner':{'name': 'DirichletPartitioner','para':{'num_clients':100, 'alpha':0.1}}}\n",
        "config_dir10 = {'benchmark':{'name':'flgo.benchmark.mnist_classification'},'partitioner':{'name': 'DirichletPartitioner','para':{'num_clients':100, 'alpha':1.0}}}\n",
        "config_dir50 = {'benchmark':{'name':'flgo.benchmark.mnist_classification'},'partitioner':{'name': 'DirichletPartitioner','para':{'num_clients':100, 'alpha':5.0}}}\n",
        "task_dict = {\n",
        "    './mnist_iid': config_iid,\n",
        "    './mnist_div01': config_div01,\n",
        "    './mnist_div05': config_div05,\n",
        "    './mnist_div09': config_div09,\n",
        "    './mnist_dir01': config_dir01,\n",
        "    './mnist_dir10': config_dir10,\n",
        "    './mnist_dir50': config_dir50,\n",
        "}\n",
        "\n",
        "for task in task_dict:\n",
        "    if not os.path.exists(task):\n",
        "        flgo.gen_task(task_dict[task], task)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ze-EXXlSySOb"
      },
      "source": [
        "# 联邦训练"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "08a7c7d8fef14323a13b43aa7a1dddb9",
            "cebaa5c272a143c5bcd266f519fc9ac0",
            "527272c4dbd24880a7481b26bb93d339",
            "216b149c52f443569b098cd8e9ab78f0",
            "1dfb66d8c1d34eba9e2d40481fa2f88a",
            "7e03033100384238a6546b96366c624c",
            "770859fd9af14213aeb55400247f1d79",
            "61416b9acadf44e9a8e4a175665513a0"
          ]
        },
        "id": "fpGwGwR9-X26",
        "outputId": "6dc89cd2-f0c5-4d37-e519-cb3be78019ce"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-05-16 13:10:05,468 fflow.py init [line:442] INFO Initializing devices: cpu will be used for this running.\n",
            "2023-05-16 13:10:05,504 fflow.py init [line:480] INFO Use `<class 'flgo.simulator.default_simulator.Simulator'>` as the system simulator\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Finishing last run (ID:x6bu2bxx) before initializing another..."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "08a7c7d8fef14323a13b43aa7a1dddb9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">devoted-firebrand-7</strong> at: <a href='https://wandb.ai/hermitt/FLGo/runs/x6bu2bxx' target=\"_blank\">https://wandb.ai/hermitt/FLGo/runs/x6bu2bxx</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20230516_125327-x6bu2bxx/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Successfully finished last run (ID:x6bu2bxx). Initializing new run:<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.15.2"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/FLGo/wandb/run-20230516_131005-kbmb92cg</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/hermitt/FLGo/runs/kbmb92cg' target=\"_blank\">fedavg</a></strong> to <a href='https://wandb.ai/hermitt/FLGo' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/hermitt/FLGo' target=\"_blank\">https://wandb.ai/hermitt/FLGo</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/hermitt/FLGo/runs/kbmb92cg' target=\"_blank\">https://wandb.ai/hermitt/FLGo/runs/kbmb92cg</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-05-16 13:10:11,978 fflow.py init [line:488] INFO Ready to start.\n",
            "2023-05-16 13:10:11,981 fedbase.py run [line:236] INFO --------------Initial Evaluation--------------\n",
            "2023-05-16 13:11:19,984 <ipython-input-39-277a8edb7e8a> show_current_output [line:28] INFO test_accuracy                 0.0845\n",
            "2023-05-16 13:11:19,988 <ipython-input-39-277a8edb7e8a> show_current_output [line:28] INFO test_loss                     2.3038\n",
            "2023-05-16 13:11:19,991 <ipython-input-39-277a8edb7e8a> show_current_output [line:28] INFO train_accuracy                0.0797\n",
            "2023-05-16 13:11:19,994 <ipython-input-39-277a8edb7e8a> show_current_output [line:28] INFO train_loss                    2.3045\n",
            "2023-05-16 13:11:19,997 <ipython-input-39-277a8edb7e8a> show_current_output [line:28] INFO valid_accuracy                0.0772\n",
            "2023-05-16 13:11:20,000 <ipython-input-39-277a8edb7e8a> show_current_output [line:28] INFO mean_valid_accuracy           0.0772\n",
            "2023-05-16 13:11:20,002 <ipython-input-39-277a8edb7e8a> show_current_output [line:28] INFO std_valid_accuracy            0.0365\n",
            "2023-05-16 13:11:20,005 <ipython-input-39-277a8edb7e8a> show_current_output [line:28] INFO valid_loss                    2.3038\n",
            "2023-05-16 13:11:20,007 <ipython-input-39-277a8edb7e8a> show_current_output [line:28] INFO mean_valid_loss               2.3038\n",
            "2023-05-16 13:11:20,009 <ipython-input-39-277a8edb7e8a> show_current_output [line:28] INFO std_valid_loss                0.0076\n",
            "2023-05-16 13:11:20,010 fedbase.py run [line:239] INFO Eval Time Cost:               68.0277s\n",
            "2023-05-16 13:11:40,037 fedbase.py run [line:246] INFO --------------Round 1--------------\n",
            "2023-05-16 13:12:48,790 <ipython-input-39-277a8edb7e8a> show_current_output [line:28] INFO test_accuracy                 0.5959\n",
            "2023-05-16 13:12:48,796 <ipython-input-39-277a8edb7e8a> show_current_output [line:28] INFO test_loss                     1.6045\n",
            "2023-05-16 13:12:48,802 <ipython-input-39-277a8edb7e8a> show_current_output [line:28] INFO train_accuracy                0.5889\n",
            "2023-05-16 13:12:48,806 <ipython-input-39-277a8edb7e8a> show_current_output [line:28] INFO train_loss                    1.6129\n",
            "2023-05-16 13:12:48,809 <ipython-input-39-277a8edb7e8a> show_current_output [line:28] INFO valid_accuracy                0.5805\n",
            "2023-05-16 13:12:48,811 <ipython-input-39-277a8edb7e8a> show_current_output [line:28] INFO mean_valid_accuracy           0.5805\n",
            "2023-05-16 13:12:48,814 <ipython-input-39-277a8edb7e8a> show_current_output [line:28] INFO std_valid_accuracy            0.0686\n",
            "2023-05-16 13:12:48,817 <ipython-input-39-277a8edb7e8a> show_current_output [line:28] INFO valid_loss                    1.6265\n",
            "2023-05-16 13:12:48,828 <ipython-input-39-277a8edb7e8a> show_current_output [line:28] INFO mean_valid_loss               1.6265\n",
            "2023-05-16 13:12:48,831 <ipython-input-39-277a8edb7e8a> show_current_output [line:28] INFO std_valid_loss                0.0651\n",
            "2023-05-16 13:12:48,832 fedbase.py run [line:251] INFO Eval Time Cost:               68.7883s\n",
            "2023-05-16 13:13:11,358 fedbase.py run [line:246] INFO --------------Round 2--------------\n",
            "2023-05-16 13:14:17,450 <ipython-input-39-277a8edb7e8a> show_current_output [line:28] INFO test_accuracy                 0.6536\n",
            "2023-05-16 13:14:17,454 <ipython-input-39-277a8edb7e8a> show_current_output [line:28] INFO test_loss                     1.2820\n",
            "2023-05-16 13:14:17,457 <ipython-input-39-277a8edb7e8a> show_current_output [line:28] INFO train_accuracy                0.6475\n",
            "2023-05-16 13:14:17,461 <ipython-input-39-277a8edb7e8a> show_current_output [line:28] INFO train_loss                    1.2963\n",
            "2023-05-16 13:14:17,466 <ipython-input-39-277a8edb7e8a> show_current_output [line:28] INFO valid_accuracy                0.6360\n",
            "2023-05-16 13:14:17,469 <ipython-input-39-277a8edb7e8a> show_current_output [line:28] INFO mean_valid_accuracy           0.6360\n",
            "2023-05-16 13:14:17,472 <ipython-input-39-277a8edb7e8a> show_current_output [line:28] INFO std_valid_accuracy            0.0586\n",
            "2023-05-16 13:14:17,475 <ipython-input-39-277a8edb7e8a> show_current_output [line:28] INFO valid_loss                    1.3141\n",
            "2023-05-16 13:14:17,477 <ipython-input-39-277a8edb7e8a> show_current_output [line:28] INFO mean_valid_loss               1.3141\n",
            "2023-05-16 13:14:17,479 <ipython-input-39-277a8edb7e8a> show_current_output [line:28] INFO std_valid_loss                0.0813\n",
            "2023-05-16 13:14:17,481 fedbase.py run [line:251] INFO Eval Time Cost:               66.1201s\n",
            "2023-05-16 13:14:40,268 fedbase.py run [line:246] INFO --------------Round 3--------------\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-40-d495de34622e>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mfedavg_runner\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mflgo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malgorithm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfedavg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLogger\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mWandbLogger\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moption\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'num_rounds'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'num_epochs'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'gpu'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m0\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mfedavg_runner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/content/FLGo/flgo/algorithm/fedbase.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    248\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_if_log\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_round\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval_interval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime_start\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Eval Time Cost'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 250\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_once\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Eval Time Cost'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m                 \u001b[0;31m# check if early stopping\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/FLGo/flgo/experiment/logger/__init__.py\u001b[0m in \u001b[0;36mlog_once\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2328\u001b[0m         \u001b[0mlocal_data_vols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatavol\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparticipants\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2329\u001b[0m         \u001b[0mtotal_data_vol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocal_data_vols\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2330\u001b[0;31m         \u001b[0mtrain_metrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoordinator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglobal_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflag\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2331\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmet_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmet_val\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_metrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2332\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'train_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmet_name\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'_dist'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmet_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/FLGo/flgo/algorithm/fedbase.py\u001b[0m in \u001b[0;36mglobal_test\u001b[0;34m(self, model, flag)\u001b[0m\n\u001b[1;32m    500\u001b[0m         \u001b[0mall_metrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcollections\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefaultdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    501\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclients\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 502\u001b[0;31m             \u001b[0mclient_metrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    503\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mmet_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmet_val\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mclient_metrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    504\u001b[0m                 \u001b[0mall_metrics\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmet_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmet_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/FLGo/flgo/utils/fmodule.py\u001b[0m in \u001b[0;36mcal_on_personal_gpu\u001b[0;34m(self, model, *args, **kargs)\u001b[0m\n\u001b[1;32m    927\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m         \u001b[0;31m# calculating\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 929\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mnew_kargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    930\u001b[0m         \u001b[0;31m# transter to original device\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morigin_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/FLGo/flgo/algorithm/fedbase.py\u001b[0m in \u001b[0;36mtest\u001b[0;34m(self, model, flag)\u001b[0m\n\u001b[1;32m    680\u001b[0m         \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflag\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'_data'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflag\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'_data'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    681\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdataset\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 682\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalculator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_batch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moption\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'num_workers'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    683\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    684\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/FLGo/flgo/benchmark/toolkits/cv/classification/__init__.py\u001b[0m in \u001b[0;36mtest\u001b[0;34m(self, model, dataset, batch_size, num_workers, pin_memory)\u001b[0m\n\u001b[1;32m    241\u001b[0m         \u001b[0mtotal_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m         \u001b[0mnum_correct\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 243\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mbatch_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_data\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    244\u001b[0m             \u001b[0mbatch_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    245\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    632\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 634\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    635\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    636\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    676\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    677\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 678\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    679\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    680\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataset.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    296\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 298\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    299\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/FLGo/flgo/benchmark/toolkits/cv/classification/__init__.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     35\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m                         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mperturbation\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/datasets/mnist.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0;31m# doing this so that it is consistent with all other datasets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m         \u001b[0;31m# to return a PIL Image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"L\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mfromarray\u001b[0;34m(obj, mode)\u001b[0m\n\u001b[1;32m   2826\u001b[0m     \u001b[0mshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"shape\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2827\u001b[0m     \u001b[0mndim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2828\u001b[0;31m     \u001b[0mstrides\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"strides\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2829\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2830\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "import torch\n",
        "fedavg_runner = flgo.init(task=task, algorithm=fedavg, Logger=WandbLogger, option={'num_rounds':5, 'num_epochs':1, 'gpu':0 if torch.cuda.is_available() else ''})\n",
        "fedavg_runner.run()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 887
        },
        "id": "ONW1htlBGJjq",
        "outputId": "432f7407-41f3-4217-9ca1-ff19df5df79e"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import flgo.experiment.analyzer\n",
        "analysis_plan = {\n",
        "    'Selector':{\n",
        "        'task': task,\n",
        "        'header':['fedavg']\n",
        "    },\n",
        "    'Painter':{\n",
        "        'Curve':[\n",
        "            {'args':{'x': 'communication_round', 'y':'valid_loss'}, 'fig_option':{'title':'valid loss on MNIST'}},\n",
        "            {'args':{'x': 'communication_round', 'y':'valid_accuracy'},  'fig_option':{'title':'valid accuracy on MNIST'}},\n",
        "        ]\n",
        "    }\n",
        "}\n",
        "flgo.experiment.analyzer.show(analysis_plan)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EWqQxDzCm-Z9"
      },
      "source": [
        "# AC+infoGAN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pzTPj-jnG9la",
        "outputId": "e8ad237c-b625-4b1e-f6ad-7098cd3b81ba"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([40, 2])"
            ]
          },
          "execution_count": 114,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "temp = torch.zeros((10, 1))\n",
        "for i in range(10):\n",
        "    temp[i, 0] = i\n",
        "torch.zeros((10, 10)).scatter_(1, temp.type(torch.LongTensor), 1).repeat(4,1) #(1~10)*4 Size([40, 10])\n",
        "torch.tensor([[1.,1.],[-1.,1.],[1.,-1.],[-1.,-1.]]).unsqueeze(1).repeat(1,10,1).reshape(-1,2).shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KISzUH3T3I8B"
      },
      "outputs": [],
      "source": [
        "sample_num=100\n",
        "class_num=10\n",
        "temp_c = torch.linspace(-1, 1, 10)\n",
        "sample_c2_ = torch.zeros((sample_num, 2))\n",
        "for i in range(class_num):\n",
        "    for j in range(class_num):\n",
        "        sample_c2_[i*class_num+j, 0] = temp_c[i]\n",
        "        sample_c2_[i*class_num+j, 1] = temp_c[j]\n",
        "four_corners=torch.tensor([[1.,1.],[-1.,1.],[1.,-1.],[-1.,-1.]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PRPCaUkjMoW5",
        "outputId": "5977fe71-7ff5-468f-fadd-2485d7092c47"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([-3.0588, -1.5882, -1.0000, -0.1176,  0.7647,  1.3529])\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "tensor([0.0044, 0.0801, 0.2384, 0.8829, 1.6438, 1.8747])"
            ]
          },
          "execution_count": 101,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "a,b,c=1,1,0.8823529411764706\n",
        "x=(torch.tensor([1,1.5,1.7,2,2.3,2.5])/1.7-1.2)*5\n",
        "print(x)\n",
        "x.tanh()+1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "iURcKaSw5tl4",
        "outputId": "532fe897-b65d-43ff-9271-4cbc021c8f2e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'benchmark': {'name': 'flgo.benchmark.mnist_classification'},\n",
              " 'partitioner': {'name': 'DirichletPartitioner',\n",
              "  'para': {'num_clients': 10, 'alpha': 1.0}}}"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x=torch.tensor([0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1.0])\n",
        "-x.log()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D4cNstDim1HV"
      },
      "outputs": [],
      "source": [
        "os.chdir('/content/GAN')\n",
        "import utils, torch, time, os, pickle, itertools\n",
        "from torch.utils.data import DataLoader\n",
        "#from torchsampler import ImbalancedDatasetSampler\n",
        "#import imageio\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt\n",
        "from dataloader import dataloader\n",
        "from ACGAN import ACGAN\n",
        "from infoGAN import discriminator#,generator\n",
        "from torchvision import transforms\n",
        "from main import parse_args\n",
        "from torch.autograd import grad\n",
        "os.chdir(BASEPATH)\n",
        "import cv2 as cv\n",
        "import random\n",
        "\n",
        "def add_noise(image, noise_type='gaussian', mean=0, std=0.1):\n",
        "    if noise_type == 'gaussian':\n",
        "        noise = torch.randn_like(image) * std + mean\n",
        "    elif noise_type == 'salt_and_pepper':\n",
        "        noise = torch.rand_like(image)\n",
        "        salt = noise >= 1 - std/2\n",
        "        pepper = noise <= std/2\n",
        "        noise[salt] = 1\n",
        "        noise[pepper] = 0\n",
        "    else:\n",
        "        raise ValueError(\"Unsupported noise type. Choose either 'gaussian' or 'salt_and_pepper'.\")\n",
        "\n",
        "    noisy_image = image + noise\n",
        "    noisy_image = torch.clamp(noisy_image, 0, 1)  # Clip values between 0 and 1\n",
        "\n",
        "    return noisy_image\n",
        "\n",
        "\n",
        "def create_gaussian_kernel(kernel_size, sigma):\n",
        "    # 计算高斯核权重\n",
        "    weight = torch.tensor([[[(x - kernel_size//2)**2 + (y - kernel_size//2)**2 for x in range(kernel_size)]] for y in range(kernel_size)])\n",
        "    weight = torch.exp(-0.5 * (weight / sigma**2))\n",
        "\n",
        "    # 标准化权重\n",
        "    weight = weight / torch.sum(weight)\n",
        "\n",
        "    # 重新调整权重维度，并添加通道维度\n",
        "    weight = weight.view(1, 1, kernel_size, kernel_size)\n",
        "\n",
        "    return weight\n",
        "\n",
        "def add_gaussian_blur(image_batch, kernel_size=7, sigma=2.):\n",
        "    # 创建一个高斯核，并根据输入图像张量的设备类型设置其设备类型\n",
        "    blur_kernel = create_gaussian_kernel(kernel_size, sigma).to(image_batch.device)\n",
        "\n",
        "    # 使用卷积操作进行高斯模糊\n",
        "    blurred_batch = F.conv2d(image_batch, blur_kernel, padding=kernel_size//2)\n",
        "\n",
        "    return blurred_batch\n",
        "\n",
        "\n",
        "\n",
        "def crop_image(image, target_size):\n",
        "    # 获取原始图像的大小\n",
        "    original_size = image.shape[-1]\n",
        "\n",
        "    # 计算裁剪区域的边界\n",
        "    left = (original_size - target_size) // 2\n",
        "    top = (original_size - target_size) // 2\n",
        "    right = left + target_size\n",
        "    bottom = top + target_size\n",
        "\n",
        "    # 裁剪图像\n",
        "    cropped_image = image[:,:,top:bottom, left:right]\n",
        "\n",
        "    return cropped_image\n",
        "class Residual(nn.Module):\n",
        "    def __init__(self, in_channels, num_hiddens, num_residual_hiddens):\n",
        "        super(Residual, self).__init__()\n",
        "        self._block = nn.Sequential(\n",
        "            nn.ReLU(True),\n",
        "            nn.Conv2d(in_channels=in_channels,\n",
        "                      out_channels=num_residual_hiddens,\n",
        "                      kernel_size=3, stride=1, padding=1, bias=False),\n",
        "            nn.ReLU(True),\n",
        "            nn.Conv2d(in_channels=num_residual_hiddens,\n",
        "                      out_channels=num_hiddens,\n",
        "                      kernel_size=1, stride=1, bias=False)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return x + self._block(x)\n",
        "\n",
        "\n",
        "class ResidualStack(nn.Module):\n",
        "    def __init__(self, in_channels, num_hiddens, num_residual_layers, num_residual_hiddens):\n",
        "        super(ResidualStack, self).__init__()\n",
        "        self._num_residual_layers = num_residual_layers\n",
        "        self._layers = nn.ModuleList([Residual(in_channels, num_hiddens, num_residual_hiddens)\n",
        "                             for _ in range(self._num_residual_layers)])\n",
        "\n",
        "    def forward(self, x):\n",
        "        for i in range(self._num_residual_layers):\n",
        "            x = self._layers[i](x)\n",
        "        return F.relu(x)\n",
        "\n",
        "class generator(nn.Module):\n",
        "    def __init__(self, input_dim=100, output_dim=1, input_size=32, len_discrete_code=10, len_continuous_code=2, class_num=10, num_filters=64, num_blocks=1):\n",
        "    #def __init__(self, input_channels, output_channels, num_classes, num_filters=64, num_blocks=9):\n",
        "        super(generator, self).__init__()\n",
        "        self.input_dim = input_dim\n",
        "        self.output_dim = output_dim\n",
        "        self.input_size = input_size\n",
        "        self.class_num = class_num\n",
        "        self._conv_1 = nn.Sequential(\n",
        "            nn.Conv2d(self.output_dim, 32, 4, 2, 1),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Conv2d(32, 64, 4, 2, 1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Conv2d(64, 64, 5, 1, 2),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.LeakyReLU(0.2),)\n",
        "        self.conv_out = nn.Sequential(\n",
        "            nn.ConvTranspose2d(16, self.output_dim, 5, 1, 2),\n",
        "            nn.Tanh(),)\n",
        "        '''\n",
        "        self._residual_stack = nn.Sequential(\n",
        "            nn.Conv2d(32, 128, 5, 1, 2),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            )\n",
        "        '''\n",
        "        self._conv_trans_0 = nn.Conv2d(64+class_num, 64, 1, 1, 0)\n",
        "        self._residual_stack = ResidualStack(in_channels=64,\n",
        "                            num_hiddens=64,\n",
        "                            num_residual_layers=64,\n",
        "                            num_residual_hiddens=3)\n",
        "        self._conv_trans_1  = nn.Sequential(\n",
        "            nn.ConvTranspose2d(64+class_num, 32, 4, 2, 1),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.ConvTranspose2d(32, 16, 4, 2, 1),\n",
        "            nn.BatchNorm2d(16),\n",
        "            nn.LeakyReLU(0.2),\n",
        "        )\n",
        "\n",
        "    def forward(self, x, label,mod=0):\n",
        "\n",
        "        x = self._conv_1(x) # 在通道维度上拼接输入图像和类别标签\n",
        "        #x = self._conv_trans_0(torch.cat([x, label], dim=1))\n",
        "        #x = self._residual_stack(x)\n",
        "        # 将类别标签转换为 one-hot 编码\n",
        "        label = label.unsqueeze(-1).unsqueeze(-1)  # 添加两个维度，使其与输入图像的维度相匹配\n",
        "        label = label.expand(label.size(0), label.size(1), x.size(2), x.size(3))  # 扩展为与输入图像相同的尺寸\n",
        "\n",
        "        x = self._conv_trans_1(torch.cat([x, label], dim=1))\n",
        "        x = crop_image(x,self.input_size)\n",
        "        if mod==0:\n",
        "          return self.conv_out(x),0\n",
        "        else:\n",
        "          return self.conv_out(x),0\n",
        "          return self.conv_out(x.detach()),0\n",
        "\n",
        "class generator0(nn.Module):\n",
        "    # Network Architecture is exactly same as in infoGAN (https://arxiv.org/abs/1606.03657)\n",
        "    # Architecture : FC1024_BR-FC7x7x128_BR-(64)4dc2s_BR-(1)4dc2s_S\n",
        "    def __init__(self, input_dim=100, output_dim=1, input_size=32, len_discrete_code=10, len_continuous_code=2):\n",
        "        super(generator, self).__init__()\n",
        "        self.input_dim = input_dim\n",
        "        self.output_dim = output_dim\n",
        "        self.input_size = input_size\n",
        "        self.len_discrete_code = len_discrete_code  # categorical distribution (i.e. label)\n",
        "        self.len_continuous_code = len_continuous_code  # gaussian distribution (e.g. rotation, thickness)\n",
        "        self.fc_size = (self.input_size+3) // 4\n",
        "\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(self.input_dim + self.len_discrete_code + self.len_continuous_code, 1024),\n",
        "            nn.BatchNorm1d(1024),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(1024, 128 * self.fc_size * self.fc_size),\n",
        "            nn.BatchNorm1d(128 * self.fc_size * self.fc_size),\n",
        "            nn.ReLU(),\n",
        "        )\n",
        "        self.deconv = nn.Sequential(\n",
        "            nn.ConvTranspose2d(128, 64, 4, 2, 1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(),\n",
        "            nn.ConvTranspose2d(64, 64, 4, 2, 1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(),\n",
        "            nn.ConvTranspose2d(64, self.output_dim, 3, 1, 1),\n",
        "            nn.Tanh(),\n",
        "        )\n",
        "        self.deconv2 = nn.Sequential(\n",
        "            nn.Conv2d(self.output_dim, 64, 4, 2, 1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Conv2d(64, 32, 4, 2, 1),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.ConvTranspose2d(32, self.output_dim, 3, 1, 1),\n",
        "            #nn.Tanh(),\n",
        "        )\n",
        "        utils.initialize_weights(self)\n",
        "\n",
        "    def forward(self, input, cont_code, dist_code):\n",
        "        x = torch.cat([input, cont_code, dist_code], 1)\n",
        "        x = self.fc(x)\n",
        "        x = x.view(-1, 128, self.fc_size, self.fc_size)\n",
        "        x = self.deconv(x)\n",
        "        x2 = x+self.deconv2(x)\n",
        "        x = crop_image(x,self.input_size)\n",
        "        x2 = crop_image(x2,self.input_size)\n",
        "        return x,x2\n",
        "\n",
        "class PatchGAN(nn.Module):\n",
        "    def __init__(self, input_dim=1, output_dim=1, input_size=32, len_discrete_code=10, len_continuous_code=2):\n",
        "        super(PatchGAN, self).__init__()\n",
        "        self.input_dim = input_dim\n",
        "        self.output_dim = output_dim\n",
        "        self.input_size = input_size\n",
        "        self.len_discrete_code = len_discrete_code  # categorical distribution (i.e. label)\n",
        "        self.len_continuous_code = len_continuous_code  # gaussian distribution (e.g. rotation, thickness)\n",
        "        self.conv1 = nn.Sequential(\n",
        "            nn.Conv2d(self.input_dim, 64, 3, 1, 1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            #nn.AvgPool2d(2),\n",
        "            #nn.MaxPool2d(2), # 添加最大池化层，池化核大小为2x2，步幅为2\n",
        "            nn.Conv2d(64, 128, 1, 1, 0),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            #nn.AvgPool2d(2),\n",
        "        )\n",
        "\n",
        "        self.conv2 = nn.Sequential(\n",
        "            nn.Conv2d(self.input_dim, 64, 4, 2, 1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Conv2d(64, 128, 4, 2, 1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.LeakyReLU(0.2),\n",
        "        )\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(128 * (self.input_size // 4) * (self.input_size // 4), 1024),\n",
        "            nn.BatchNorm1d(1024),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Linear(1024, self.output_dim + self.len_continuous_code + self.len_discrete_code),\n",
        "            # nn.Sigmoid(),\n",
        "        )\n",
        "        self.pool = nn.AvgPool2d(2)  # 添加池化层，平均池化，池化核大小为2x2\n",
        "        self.patch_conv = nn.Conv2d(128, self.output_dim, 1, 1, 0)  # PatchGAN-specific convolution\n",
        "        #self.patch_conv = nn.Conv2d(128, self.output_dim, 1, 1, 0)  # PatchGAN-specific convolution\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "        self.init()\n",
        "\n",
        "        # 定义数据增强的变换操作，包括水平翻转\n",
        "        self.data_augmentation0 = transforms.Compose([\n",
        "            transforms.RandomHorizontalFlip(p=0.5),  # 添加水平翻转，概率为100%\n",
        "        ])\n",
        "\n",
        "        self.data_augmentation = transforms.Compose([\n",
        "            transforms.RandomRotation(degrees=180),  # 随机旋转角度范围为-15到+15度\n",
        "        ])\n",
        "        '''\n",
        "        self.data_augmentation = transforms.Compose([\n",
        "            transforms.RandomChoice([\n",
        "            #transforms.RandomRotation(degrees=90),  # ±90度\n",
        "            transforms.RandomRotation(degrees=180),  # 180度\n",
        "            transforms.RandomRotation(degrees=0),  # 0度，即不旋转\n",
        "            ])\n",
        "        ])\n",
        "        '''\n",
        "    def init(self):\n",
        "        utils.initialize_weights(self)\n",
        "    def forward(self, input, augment=False):\n",
        "\n",
        "        x = input.clone()\n",
        "\n",
        "        if augment:\n",
        "          x = self.data_augmentation0(x)\n",
        "          x = self.data_augmentation(x)\n",
        "\n",
        "        x = self.conv1(input)\n",
        "        x = self.patch_conv(x)\n",
        "        x = self.sigmoid(x)\n",
        "        output1 = torch.mean(x, dim=3).mean(dim=2).squeeze(1)\n",
        "        x1 = self.conv2(input)\n",
        "        x1 = x1.view(-1, 128 * (self.input_size // 4) * (self.input_size // 4))\n",
        "        output2 = self.fc(x1)\n",
        "        a = F.sigmoid(output2[:, self.output_dim])\n",
        "        b = output2[:, self.output_dim:self.output_dim + self.len_continuous_code]\n",
        "        c = output2[:, self.output_dim + self.len_continuous_code:]\n",
        "        return output1,a,b,c\n",
        "\n",
        "def uniformly_sample_labels(real_label_upper, real_label_lower, batch_size):\n",
        "    \"\"\" Uniformly samples batch_size number of label values within a provided range.\n",
        "    \"\"\"\n",
        "    soft_labels = torch.tensor([random.uniform(real_label_lower, real_label_upper) for _ in range(batch_size)])\n",
        "    return soft_labels\n",
        "\n",
        "###############################################################################\n",
        "from flgo.utils.fmodule import FModule\n",
        "\n",
        "class discriminator_pro(discriminator,FModule):\n",
        "    def forward(self, input, mode='test'):\n",
        "      a,b,c = discriminator.forward(self,input) # 调用discriminator的forward方法 使用discriminator类的名称来调用它的forward方法，而不是使用super()。\n",
        "      if mode == 'train':\n",
        "        return a, b, c\n",
        "      elif mode == 'test':\n",
        "        return c\n",
        "\n",
        "class generator_pro(generator):\n",
        "    def __init__(self, transform, *args, **kwargs):\n",
        "      self.std,self.mean=get_Normalize_mean_std(transform)\n",
        "      if type(self.std)==tuple:\n",
        "        self.std,self.mean=self.std[0],self.mean[0]\n",
        "      generator.__init__(self, *args, **kwargs)\n",
        "    def change(self,x): #[-1, 1]将范围内的值转换为[0, 1]范围内的值的过程\n",
        "      x = x*0.5+0.5\n",
        "      return (x-self.mean)/np.clip(self.std,1e-5,None)\n",
        "    def forward(self, *args, **kwargs):\n",
        "      x = generator.forward(self,*args, **kwargs)[0]\n",
        "      return self.change(x)#,self.change(x2)\n",
        "\n",
        "##########################################################################################################\n",
        "from torchvision import datasets, transforms\n",
        "import copy\n",
        "\n",
        "def get_Normalize_mean_std(transform):\n",
        "  for t in transform.transforms:\n",
        "    if isinstance(t, transforms.Normalize):\n",
        "        return t.std,t.mean\n",
        "def get_transform(dataset):\n",
        "  if hasattr(dataset, 'transform'):\n",
        "    return dataset.transform\n",
        "  else: #针对嵌套很多层的情况，递归调用来寻找dataset中的transform\n",
        "    return get_transform(dataset.dataset)\n",
        "def new_normalize(dataset1,mean,std):\n",
        "  dataset2 = copy.deepcopy(dataset1) # 创建dataset2并复制dataset1的所有样本，deepcopy创建新对象\n",
        "  for t in get_transform(dataset2).transforms: # 遍历transform2的所有操作\n",
        "    if isinstance(t, transforms.Normalize): # 如果操作是Normalize，则替换mean和std的值\n",
        "      t.mean,t.std = mean,std\n",
        "  return dataset2\n",
        "\n",
        "def add_by_c(a, c, mod='sum'): # 将同类别c(one_hot)的相加 (Right example: a:3*2 c:3*3 / a:4*2 c:4*3)\n",
        "  if len(a.size())==1:\n",
        "    a=a.unsqueeze(-1)\n",
        "  if a.size(0) != c.size(0):\n",
        "    raise ValueError(f\"Input tensors a and c must have the same size along dimension 0. \"\n",
        "                      f\"Got a size a:{a.size(0)}*{a.size(1)} and c size c:{c.size(0)}*{c.size(1)}. \"\n",
        "                      f\"(Right example: a:{a.size(0)}*{a.size(1)} c:{a.size(0)}*{c.size(1)} or \"\n",
        "                      f\"a:{c.size(0)}*{a.size(1)} c:{c.size(0)}*{c.size(1)})\")\n",
        "  grouped_sum = torch.matmul(c.unsqueeze(2), a.unsqueeze(1)).sum(0)\n",
        "  if mod == 'sum':\n",
        "    return grouped_sum\n",
        "  elif mod == 'mean':\n",
        "    return grouped_sum/c.sum(0).unsqueeze(1).clamp(1e-5)\n",
        "  else:\n",
        "    raise ValueError(f\"Invalid mod value. Expected 'sum' or 'mean', but got '{mod}'.\")\n",
        "###########################################################################################################\n",
        "\n",
        "class my_ACGAN(ACGAN):\n",
        "    def __init__(self, client, args, data_shape ,input_size ,loc_c=None, name=None):\n",
        "        self.lambda_ = 5 #for WGAN_GP\n",
        "        self.global_loss = 0 #for 平衡\n",
        "        self.rng_local = np.random.RandomState(0) #专用的随机对象\n",
        "        self.lrG=args.lrG\n",
        "        self.lrD=args.lrD\n",
        "        self.beta1, self.beta2 = args.beta1, args.beta2\n",
        "\n",
        "        #import wandb\n",
        "        #!wandb login 653413d82a5a0cc80ce1a3c484a6557e61b2a935\n",
        "        #wandb.init(project='FLGo-GAN')\n",
        "        self.wandb_fn=False\n",
        "        self.loc_c=loc_c\n",
        "\n",
        "\n",
        "        # parameters\n",
        "        #self.epoch = args.epoch\n",
        "        self.batch_size = args.batch_size\n",
        "        self.save_dir = args.save_dir\n",
        "        self.result_dir = args.result_dir\n",
        "        self.task = args.task\n",
        "        self.dataset = args.task\n",
        "        self.log_dir = args.log_dir\n",
        "        self.gpu_mode = args.gpu_mode\n",
        "        if name==None:\n",
        "          self.model_name = type(self).__name__\n",
        "        else:\n",
        "          self.model_name = name\n",
        "        self.input_size = input_size\n",
        "        self.z_dim = 62\n",
        "        self.class_num = 10\n",
        "        self.sample_num = self.class_num ** 2\n",
        "\n",
        "        self.logic_by_c=np.ones(self.class_num)\n",
        "\n",
        "\n",
        "        self.len_continuous_code = 2        # gaussian distribution (e.g. rotation, thickness)\n",
        "\n",
        "        # networks init\n",
        "        self.G = generator_pro(get_transform(client.train_data),input_dim=self.z_dim, output_dim=data_shape, input_size=self.input_size, len_discrete_code=self.class_num, len_continuous_code=self.len_continuous_code)\n",
        "        #self.D = Model(input_dim=data_shape, input_size=self.input_size)\n",
        "        self.D = None\n",
        "        self.D_p = PatchGAN(input_dim=data_shape, input_size=self.input_size)\n",
        "\n",
        "        self.G_optimizer = optim.Adam(self.G.parameters(), lr=args.lrG, betas=(args.beta1, args.beta2))\n",
        "        #self.D_optimizer = optim.Adam(self.D.parameters(), lr=args.lrD, betas=(args.beta1, args.beta2))\n",
        "        self.D_p_optimizer = optim.Adam(self.D_p.parameters(), lr=args.lrD, betas=(args.beta1, args.beta2))\n",
        "\n",
        "        self.info_optimizer = optim.Adam(itertools.chain(self.G.parameters(), self.D_p.parameters()), lr=args.lrD, betas=(args.beta1, args.beta2))\n",
        "        #self.info_optimizer = optim.Adam(itertools.chain(self.G.parameters(), self.D.parameters()), lr=args.lrD, betas=(args.beta1, args.beta2))\n",
        "\n",
        "        #self.C_optimizer = client.calculator.get_optimizer(self.D, lr=client.learning_rate, weight_decay=client.weight_decay,momentum=client.momentum)\n",
        "\n",
        "        if self.gpu_mode:\n",
        "            self.G.cuda()\n",
        "            self.D_p.cuda()\n",
        "            self.BCE_loss = nn.BCELoss().cuda()\n",
        "            self.CE_loss = nn.CrossEntropyLoss().cuda()\n",
        "            self.BCE_loss_unreduce = nn.BCELoss(reduce=False).cuda()\n",
        "            self.CE_loss_unreduce = nn.CrossEntropyLoss(reduce=False).cuda()\n",
        "            self.MSE_losss_unreduce = nn.MSELoss(reduce=False).cuda()\n",
        "            self.MSE_loss = nn.MSELoss().cuda()\n",
        "        else:\n",
        "            self.BCE_loss = nn.BCELoss()\n",
        "            self.CE_loss = nn.CrossEntropyLoss()\n",
        "            self.MSE_loss = nn.MSELoss()\n",
        "\n",
        "        print('---------- Networks architecture -------------')\n",
        "        utils.print_network(self.G)\n",
        "        #utils.print_network(self.D)\n",
        "        print('-----------------------------------------------')\n",
        "\n",
        "        # fixed noise & condition\n",
        "        self.sample_z_ = self.z_change(torch.zeros((self.sample_num, self.z_dim)))\n",
        "        for i in range(self.class_num):\n",
        "            self.sample_z_[i * self.class_num] = torch.rand(1, self.z_dim)\n",
        "            for j in range(1, self.class_num):\n",
        "                self.sample_z_[i * self.class_num + j] = self.sample_z_[i * self.class_num]\n",
        "\n",
        "        temp = torch.zeros((self.class_num, 1))\n",
        "        for i in range(self.class_num):\n",
        "            temp[i, 0] = i\n",
        "\n",
        "        temp_y = torch.zeros((self.sample_num, 1))\n",
        "        for i in range(self.class_num):\n",
        "            temp_y[i * self.class_num: (i + 1) * self.class_num] = temp\n",
        "\n",
        "        self.four_y_  = torch.zeros((self.class_num, self.class_num)).scatter_(1, temp.type(torch.LongTensor), 1).repeat(4,1) #(1~10)*4 Size([40, 10])\n",
        "        self.sample_y_ = torch.zeros((self.sample_num, self.class_num)).scatter_(1, temp_y.type(torch.LongTensor), 1)\n",
        "        self.sample_c_ = torch.zeros((self.sample_num, self.len_continuous_code))\n",
        "\n",
        "        # manipulating two continuous code\n",
        "        self.sample_z2_ = self.z_change(torch.rand((1, self.z_dim)).expand(self.sample_num, self.z_dim))\n",
        "        self.sample_y2_ = torch.zeros(self.sample_num, self.class_num)\n",
        "        self.sample_y2_[:, 2] = 1 #[:,要网格采样的数字]\n",
        "\n",
        "        temp_c = torch.linspace(-1, 1, 10)\n",
        "        self.sample_c2_ = torch.zeros((self.sample_num, 2))\n",
        "        for i in range(self.class_num):\n",
        "            for j in range(self.class_num):\n",
        "                self.sample_c2_[i*self.class_num+j, 0] = temp_c[i]\n",
        "                self.sample_c2_[i*self.class_num+j, 1] = temp_c[j]\n",
        "\n",
        "        if self.gpu_mode:\n",
        "            self.sample_z_, self.sample_y_, self.sample_c_, self.sample_z2_, self.sample_y2_, self.sample_c2_ = \\\n",
        "                self.sample_z_.cuda(), self.sample_y_.cuda(), self.sample_c_.cuda(), self.sample_z2_.cuda(), \\\n",
        "                self.sample_y2_.cuda(), self.sample_c2_.cuda()\n",
        "    def D_real(self,D,mod='BCE'):\n",
        "        if mod=='BCE':\n",
        "          return self.BCE_loss(D, self.y_real_)\n",
        "        #return F.l1_loss(D, self.y_real_) #LSGAN\n",
        "        else:\n",
        "          return -torch.mean(D) #Wasserstein\n",
        "    def D_real_unreduce(self,D):\n",
        "        #return F.l1_loss(D, self.y_real_) #LSGAN\n",
        "        return self.BCE_loss_unreduce(D, self.y_real_)\n",
        "        #return -D #Wasserstein\n",
        "    def D_fake(self,D,mod='BCE'):\n",
        "        if mod=='BCE':\n",
        "          return self.BCE_loss(D, self.y_fake_)\n",
        "        #return F.l1_loss(D, self.y_fake_) #LSGAN\n",
        "        else:\n",
        "          return torch.mean(D) #Wasserstein\n",
        "    def D_fake_unreduce(self,D):\n",
        "        #return F.l1_loss(D, self.y_real_) #LSGAN\n",
        "        return self.BCE_loss_unreduce(D, self.y_fake_)\n",
        "    def C_loss(self,C,Y):\n",
        "        return self.CE_loss(C, torch.max(Y, 1)[1])\n",
        "        #return F.l1_loss(C, Y)\n",
        "    def C_loss_unreduce(self,C,Y):\n",
        "        #return F.l1_loss(C, Y)\n",
        "        C_loss = self.CE_loss_unreduce(C, torch.max(Y, 1)[1])\n",
        "        return C_loss\n",
        "    def alpha(self,pre,y):\n",
        "        C_softmax = F.softmax(pre,dim=-1)\n",
        "        C_logic = (C_softmax*y).sum(-1)\n",
        "        C_max = C_softmax.max(-1).values\n",
        "        return (-(C_logic/C_max).log()).detach(),C_logic\n",
        "\n",
        "\n",
        "    def E_loss(self,model,x_,G):\n",
        "        E_real = model.get_embedding(x_)\n",
        "        E_fake = model.get_embedding(G)\n",
        "        return F.l1_loss(E_real.mean(0), E_fake.mean(0))\n",
        "    def E_loss_by_c(self,E,Y_taget,E_by_c,mask_by_c):\n",
        "        E_taget = (Y_taget@E_by_c).detach()\n",
        "        mask = (Y_taget@mask_by_c).detach()\n",
        "        return (F.l1_loss(E, E_taget,reduce=False).mean(-1)*mask).mean()\n",
        "    def acc(self,C_pre,y):\n",
        "        C_pre2 = C_pre.max(-1).indices\n",
        "        C_pre2 = torch.zeros((y.shape[0], self.class_num)).scatter_(1, C_pre2.type(torch.LongTensor).unsqueeze(1), 1)\n",
        "        if self.gpu_mode:\n",
        "          C_pre2=C_pre2.cuda()\n",
        "        return (C_pre2*y).sum(-1).detach(),C_pre2 #是否正确\n",
        "\n",
        "    # Function to generate random z_ for G network:\n",
        "    @staticmethod\n",
        "    def generate_random_z(batch_size, z_dim, gpu_mode):\n",
        "        z_ = torch.rand((batch_size, z_dim))\n",
        "        if gpu_mode:\n",
        "            z_ = z_.cuda()\n",
        "        return z_\n",
        "\n",
        "    # Function to generate labels for discriminator and classifier:\n",
        "    @staticmethod\n",
        "    def generate_labels(class_num, batch_size, rng_local, mod=\"regu\"):\n",
        "        weight = class_num * [float(1.0 / class_num)]\n",
        "        if mod == \"regu\":\n",
        "          mean_Y = torch.range(0, class_num - 1, dtype=torch.int64).repeat(batch_size // class_num)\n",
        "          mean_Y_ = torch.zeros((mean_Y.shape[0], class_num)).scatter_(1, mean_Y.type(torch.LongTensor).unsqueeze(1), 1)\n",
        "          y_disc_ = torch.from_numpy(rng_local.multinomial(1, weight, size=[batch_size % class_num])).type(torch.FloatTensor)\n",
        "          y_disc_ = torch.cat([mean_Y_, y_disc_], 0)\n",
        "          return y_disc_\n",
        "        else:\n",
        "          return torch.from_numpy(rng_local.multinomial(1, weight, size=[batch_size])).type(torch.FloatTensor)\n",
        "\n",
        "    def z_change(self,z):\n",
        "        return z\n",
        "        #m=(z<0.5).float()\n",
        "        #return (z*0.5)*m+(1-0.5*(1-z))*(1-m)\n",
        "\n",
        "    def train_step(self, client, x_, y_vec_, iter, y_distribution, global_model, optimizer, print_head):\n",
        "        batch_size = client.batch_size\n",
        "\n",
        "        # Generate random z_ for G network\n",
        "        z_ = self.generate_random_z(batch_size, self.z_dim, self.gpu_mode)\n",
        "        z_ =self.z_change(z_)\n",
        "        z0 = torch.ones_like(z_)*0.5\n",
        "\n",
        "        # Generate labels for discriminator and classifier\n",
        "        y_disc_ = self.generate_labels(self.class_num, batch_size, self.rng_local)\n",
        "        y_disc_2 = self.generate_labels(self.class_num, batch_size, self.rng_local,mod='rand')\n",
        "        y_cont_ = torch.from_numpy(self.rng_local.uniform(-1, 1, size=(batch_size, 2))).type(torch.FloatTensor)\n",
        "        if self.gpu_mode:\n",
        "            y_disc_,y_disc_2, y_cont_,z0 = y_disc_.cuda(),y_disc_2.cuda(), y_cont_.cuda(),z0.cuda()\n",
        "\n",
        "        self.C_optimizer.zero_grad()\n",
        "        _, _, C = self.D(x_, mode='train')\n",
        "        G_ = self.G(x_, y_disc_2)\n",
        "        G2 = self.G(x_, y_vec_, mod=1)\n",
        "        G3 = self.G(G_, y_vec_)\n",
        "        _, _, C_local = self.D(G_, mode='train')\n",
        "        C_global = global_model(G_)\n",
        "        #C_fake_loss = F.mse_loss(C_local, C_global)\n",
        "        C_fake_loss = F.mse_loss(C_local, C_global)#+ 0.1*F.mse_loss(C_local, y_disc_)\n",
        "        C_loss = self.C_loss(C, y_vec_)+C_fake_loss\n",
        "        C_loss.backward(retain_graph=True)\n",
        "        if client.clip_grad>0:torch.nn.utils.clip_grad_norm_(parameters=self.D.parameters(), max_norm=client.clip_grad)\n",
        "        self.C_optimizer.step()\n",
        "\n",
        "        # update D network\n",
        "        self.D_p_optimizer.zero_grad()\n",
        "\n",
        "        D_real_p,D_real, _, _ = self.D_p(x_,augment=True)\n",
        "        D_fake_p,D_fake, _, _ = self.D_p(G_)\n",
        "        D_fake_p2,D_fake2, _, _ = self.D_p(G_)\n",
        "        D_real_loss = 0*self.D_real(D_real)+self.D_real(D_real_p)#,mod='was')#+self.BCE_loss(D_real_p, self.y_real_)\n",
        "        D_fake_loss = 0*self.D_fake(D_fake2)+self.D_fake(D_fake_p2)#+self.D_fake(D_fake_p)#,mod='was')#+self.BCE_loss(D_fake_p, self.y_fake_)\n",
        "\n",
        "        C_real_loss = self.C_loss(C, y_vec_)#self.C_loss(C, y_vec_)\n",
        "        C_fake_loss = F.mse_loss(C_local, C_global)\n",
        "\n",
        "        D_loss = D_real_loss + D_fake_loss  #+C_real_loss+C_fake_loss\n",
        "        self.train_hist['D_loss'].append(D_loss.item())\n",
        "\n",
        "        D_loss.backward(retain_graph=True)\n",
        "        if client.clip_grad>0:torch.nn.utils.clip_grad_norm_(parameters=self.D_p.parameters(), max_norm=client.clip_grad)\n",
        "        self.D_p_optimizer.step()\n",
        "\n",
        "        # update G network\n",
        "        self.G_optimizer.zero_grad()\n",
        "\n",
        "\n",
        "        D_fake_p,D_fake, D_cont, D_disc = self.D_p(G_)\n",
        "        D_fake_p2,D_fake2, _, _ = self.D_p(G2)\n",
        "        #D_fake, D_cont, C_fake = self.D(G_, mode='train')\n",
        "        _, _, C_pre = global_model(G_, mode='train')\n",
        "        logic = (F.softmax(C_pre, dim=-1) * y_disc_2).sum(-1)\n",
        "        #D_loss_G = self.D_real_unreduce(D_fake)+self.D_real_unreduce(D_fake_p)\n",
        "        #D_loss_G = (self.D_real_unreduce(D_fake2)*logic.detach()).mean()+self.D_real(D_fake_p,mod='was')\n",
        "        D_loss_G = self.D_real(D_fake_p2)+self.D_real(D_fake_p)#mod='was')\n",
        "        #D_loss_G = (self.D_real_unreduce(D_fake)+(self.D_real_unreduce(D_fake_p))*logic.detach()).mean()\n",
        "\n",
        "        #G_loss = D_loss_G+self.C_loss(C_pre, y_disc_2)+0.5*F.mse_loss(G2, x_)+0.5*F.mse_loss(G3, x_) #+self.C_loss(D_disc, y_disc_)# (D_loss_G*logic.detach()).mean()\n",
        "        #recon_loss = F.mse_loss(G3, x_,reduce=False).reshape(batch_size,-1).mean(-1)\n",
        "        #recon_loss = F.mse_loss(F.max_pool2d(G3,2), F.max_pool2d(x_,2))\n",
        "        recon_loss = F.l1_loss(G2, x_)+F.l1_loss(G3, x_)\n",
        "        c_loss = self.C_loss(C_pre, y_disc_2)\n",
        "        #mask = logic<0.9\n",
        "        mask = logic<0.9\n",
        "        #G_loss = D_loss_G+5*(c_loss*(1-logic.detach())).mean()+recon_loss#(recon_loss*mask.float()).mean()\n",
        "        G_loss = D_loss_G+c_loss+0.1*recon_loss#(recon_loss*mask.float()).mean()\n",
        "\n",
        "        self.train_hist['G_loss'].append(G_loss.item())\n",
        "\n",
        "\n",
        "        G_loss.backward(retain_graph=True)\n",
        "        if client.clip_grad>0:torch.nn.utils.clip_grad_norm_(parameters=self.G.parameters(), max_norm=client.clip_grad)\n",
        "        self.G_optimizer.step()\n",
        "        '''\n",
        "        # information loss\n",
        "        disc_loss = self.CE_loss(D_disc, torch.max(y_disc_, 1)[1])\n",
        "        cont_loss = self.MSE_loss(D_cont, y_cont_)\n",
        "        info_loss = disc_loss + cont_loss\n",
        "\n",
        "        info_loss.backward()\n",
        "        self.info_optimizer.step()\n",
        "        '''\n",
        "        if iter % 100 == 0:\n",
        "            #print(print_head + \" DR: %.2f|DF: %.2f\" % (D_real_loss.item(), D_fake_loss.item()))\n",
        "            #with torch.no_grad(): #慢\n",
        "                #print(client.test(self.D))\n",
        "            #print(add_by_c(weight, y_disc_, mod='mean').squeeze())\n",
        "            #print(add_by_c(weight, y_disc_, mod='mean').squeeze())\n",
        "            print(self.global_loss)\n",
        "\n",
        "            print('=================================================================   ')\n",
        "\n",
        "        # Clean up\n",
        "        del z_, y_disc_, y_cont_\n",
        "\n",
        "    def train_step0(self, client, x_, y_vec_, iter, y_distribution, global_model, optimizer, print_head):\n",
        "        batch_size = client.batch_size\n",
        "\n",
        "        # Generate random z_ for G network\n",
        "        z_ = self.generate_random_z(batch_size, self.z_dim, self.gpu_mode)\n",
        "        z_ =self.z_change(z_)\n",
        "        z0 = torch.ones_like(z_)*0.5\n",
        "\n",
        "        # Generate labels for discriminator and classifier\n",
        "        y_disc_ = self.generate_labels(self.class_num, batch_size, self.rng_local)\n",
        "        y_disc_2 = self.generate_labels(self.class_num, batch_size, self.rng_local,mod='rand')\n",
        "        y_cont_ = torch.from_numpy(self.rng_local.uniform(-1, 1, size=(batch_size, 2))).type(torch.FloatTensor)\n",
        "        if self.gpu_mode:\n",
        "            y_disc_,y_disc_2, y_cont_,z0 = y_disc_.cuda(),y_disc_2.cuda(), y_cont_.cuda(),z0.cuda()\n",
        "\n",
        "        self.C_optimizer.zero_grad()\n",
        "        _, _, C = self.D(x_, mode='train')\n",
        "        G_,G2 = self.G(z_, y_cont_, y_disc_)\n",
        "        y_global = global_model(x_)\n",
        "        C_global = global_model(G_)\n",
        "        _, _, C_local = self.D(G_, mode='train')\n",
        "        #D_loss = self.BCE_loss(D_real, self.y_real_)+self.BCE_loss(D_fake, self.y_fake_)\n",
        "        logic = (F.softmax(C_global, dim=-1) * y_disc_).sum(-1)\n",
        "        logic_by_c = add_by_c(logic, y_disc_, mod='mean').detach()\n",
        "        #C_fake_loss = F.mse_loss(C_local, C_global)\n",
        "        C_fake_loss = F.mse_loss(C_local, C_global)+ 0.1*F.mse_loss(C_local, y_disc_2)\n",
        "        temperature= logic_by_c.mean().detach()#如何设计蒸馏温度*D_fake.mean().detach()\n",
        "        C_loss = self.C_loss(C, y_vec_)+C_fake_loss#*temperature\n",
        "        C_loss.backward(retain_graph=True)\n",
        "        if client.clip_grad>0:torch.nn.utils.clip_grad_norm_(parameters=self.D.parameters(), max_norm=client.clip_grad)\n",
        "        self.C_optimizer.step()\n",
        "\n",
        "        # update D network\n",
        "        self.D_p_optimizer.zero_grad()\n",
        "\n",
        "        D_real_p,D_real, _, _ = self.D_p(x_,augment=True)\n",
        "        D_fake_p,D_fake, D_cont, C_local = self.D_p(G_)\n",
        "        D_fake_p2,D_fake2, _, _ = self.D_p(G2)\n",
        "        D_real_loss = self.D_real(D_real)+self.D_real(D_real_p)#,mod='was')#+self.BCE_loss(D_real_p, self.y_real_)\n",
        "        D_fake_loss = self.D_fake(D_fake2)+self.D_fake(D_fake_p)#,mod='was')#+self.BCE_loss(D_fake_p, self.y_fake_)\n",
        "\n",
        "        C_real_loss = self.C_loss(C, y_vec_)#self.C_loss(C, y_vec_)\n",
        "        C_fake_loss = F.mse_loss(C_local, C_global)\n",
        "        cont_loss = self.MSE_loss(D_cont, y_cont_)\n",
        "        D_loss = D_real_loss + D_fake_loss +cont_loss #+C_real_loss+C_fake_loss\n",
        "        self.train_hist['D_loss'].append(D_loss.item())\n",
        "\n",
        "        D_loss.backward(retain_graph=True)\n",
        "        if client.clip_grad>0:torch.nn.utils.clip_grad_norm_(parameters=self.D_p.parameters(), max_norm=client.clip_grad)\n",
        "        self.D_p_optimizer.step()\n",
        "\n",
        "        # update G network\n",
        "        self.G_optimizer.zero_grad()\n",
        "\n",
        "        G_,G2 = self.G(z_, y_cont_, y_disc_)\n",
        "        D_fake_p,D_fake, D_cont, D_disc = self.D_p(G_)\n",
        "        D_fake_p2,D_fake2, _, _ = self.D_p(G2)\n",
        "        #D_fake, D_cont, C_fake = self.D(G_, mode='train')\n",
        "        _, _, C_pre = global_model(G_, mode='train')\n",
        "        cont_loss = self.MSE_loss(D_cont, y_cont_)\n",
        "        logic = (F.softmax(C_pre, dim=-1) * y_disc_).sum(-1)\n",
        "        #D_loss_G = self.D_real_unreduce(D_fake)+self.D_real_unreduce(D_fake_p)\n",
        "        #D_loss_G = (self.D_real_unreduce(D_fake2)*logic.detach()).mean()+self.D_real(D_fake_p,mod='was')\n",
        "        D_loss_G = self.D_real(D_fake2)+self.D_real(D_fake_p)#,mod='was')\n",
        "        #D_loss_G = (self.D_real_unreduce(D_fake)+(self.D_real_unreduce(D_fake_p))*logic.detach()).mean()\n",
        "\n",
        "        G_loss = D_loss_G+self.C_loss(C_pre, y_disc_)+cont_loss #+self.C_loss(D_disc, y_disc_)# (D_loss_G*logic.detach()).mean()\n",
        "\n",
        "        self.train_hist['G_loss'].append(G_loss.item())\n",
        "\n",
        "        G_loss.backward(retain_graph=True)\n",
        "        if client.clip_grad>0:torch.nn.utils.clip_grad_norm_(parameters=self.G.parameters(), max_norm=client.clip_grad)\n",
        "        self.G_optimizer.step()\n",
        "        '''\n",
        "        # information loss\n",
        "        disc_loss = self.CE_loss(D_disc, torch.max(y_disc_, 1)[1])\n",
        "        cont_loss = self.MSE_loss(D_cont, y_cont_)\n",
        "        info_loss = disc_loss + cont_loss\n",
        "\n",
        "        info_loss.backward()\n",
        "        self.info_optimizer.step()\n",
        "        '''\n",
        "        if iter % 100 == 0:\n",
        "            #print(print_head + \" DR: %.2f|DF: %.2f\" % (D_real_loss.item(), D_fake_loss.item()))\n",
        "            #with torch.no_grad(): #慢\n",
        "                #print(client.test(self.D))\n",
        "            #print(add_by_c(weight, y_disc_, mod='mean').squeeze())\n",
        "            #print(add_by_c(weight, y_disc_, mod='mean').squeeze())\n",
        "            print(self.global_loss)\n",
        "\n",
        "            print('=================================================================   ')\n",
        "\n",
        "        # Clean up\n",
        "        del z_, y_disc_, y_cont_\n",
        "\n",
        "\n",
        "    def lr_adapt_fun(self,D_fake_loss,D_loss_G):\n",
        "        lr_D_adapt = (D_fake_loss/D_loss_G.clamp(min=1e-5)).detach().cpu().numpy()\n",
        "        lr_G_adapt = (D_loss_G/D_fake_loss.clamp(min=1e-5)).detach().cpu().numpy()\n",
        "        lr_D_adapt=np.clip(2*lr_D_adapt, 1e-5, 1)\n",
        "        lr_G_adapt=np.clip(0.5*lr_G_adapt, 1, 10)\n",
        "        #for param_group in self.G_optimizer.param_groups:\n",
        "            #param_group['lr'] = self.lrG*lr_G_adapt\n",
        "        for param_group in self.D_optimizer.param_groups:\n",
        "            param_group['lr'] = self.lrD*lr_D_adapt\n",
        "            #param_group['lr'] = np.clip(param_group['lr']*(lr_delta+1), 1e-5, 1)\n",
        "        #print(\"|%.2f|%.2f|  |%.2f|%.2f|\" %\n",
        "                  #(D_fake_loss.item(),D_loss_G.item(),lr_D_adapt,lr_G_adapt))\n",
        "    def train(self,client,gan_epoch,global_model=None,optimizer=None):\n",
        "        self.lr_adapt = 1\n",
        "        train_data = client.train_data\n",
        "        batch_size = client.batch_size\n",
        "        # 注意\n",
        "        #data_loader = DataLoader(new_normalize(train_data,mean=0.5,std=0.5), \\\n",
        "        #batch_size=self.batch_size)\n",
        "        rslt_path = self.result_dir + '/' + self.task + '/' + self.model_name #+ '/round' + str(client.round)\n",
        "        print(rslt_path)\n",
        "        self.train_hist = {}\n",
        "        self.train_hist['D_loss'] = []\n",
        "        self.train_hist['G_loss'] = []\n",
        "        self.train_hist['per_epoch_time'] = []\n",
        "        self.train_hist['total_time'] = []\n",
        "\n",
        "        # Using soft labels for the discriminator on real data during training.\n",
        "        real_label_upper = 1\n",
        "        real_label_lower = 0.8\n",
        "        #self.y_real_ = uniformly_sample_labels( real_label_upper, real_label_lower, batch_size)\n",
        "        #self.y_fake_ = torch.zeros(batch_size)\n",
        "        self.y_real_, self.y_fake_ = torch.ones(batch_size), torch.zeros(batch_size)\n",
        "\n",
        "        if self.gpu_mode:\n",
        "            self.y_real_, self.y_fake_ = self.y_real_.cuda(), self.y_fake_.cuda()\n",
        "\n",
        "        print(self.model_name,': training start!!')\n",
        "        start_time = time.time()\n",
        "\n",
        "        y_distribution = torch.zeros(self.class_num)\n",
        "        global_loss = []\n",
        "        #self.C_optimizer = client.calculator.get_optimizer(global_model, lr=client.learning_rate, weight_decay=client.weight_decay,momentum=client.momentum)\n",
        "        self.C_optimizer = client.calculator.get_optimizer(self.D, lr=client.learning_rate, weight_decay=client.weight_decay,momentum=client.momentum)\n",
        "        self.D_optimizer = optim.Adam(self.D.parameters(), lr=self.lrD, betas=(self.beta1, self.beta2))\n",
        "        #self.info_optimizer = optim.Adam( \\\n",
        "        #itertools.chain(self.G.parameters(), self.D.parameters()), lr=0.001*self.lrD, betas=(self.beta1, self.beta2))\n",
        "        #具有与self.D_optimizer相同的参数配置\n",
        "        #self.local_D_optimizer = type(self.D_optimizer)(client.local_d.parameters(), lr=self.D_optimizer.defaults['lr'], betas=self.D_optimizer.defaults['betas'])\n",
        "        #self.local_D_optimizer = type(self.D_optimizer)(client.local_d.parameters(), lr=0.0002, betas=self.D_optimizer.defaults['betas'])\n",
        "\n",
        "\n",
        "        for epoch in range(client.num_epochs):\n",
        "            self.G.train()\n",
        "            self.D.train()\n",
        "            #client.local_d.train()\n",
        "            epoch_start_time = time.time()\n",
        "            for iter,_ in enumerate(range(client.num_steps)):\n",
        "                batch_data = client.get_batch_data()\n",
        "                x_, y_ = batch_data\n",
        "                if batch_size != y_.shape[0]:\n",
        "                    break\n",
        "                y_vec_ = torch.zeros((batch_size, self.class_num)).scatter_(1, y_.type(torch.LongTensor).unsqueeze(1), 1)\n",
        "                if self.gpu_mode:\n",
        "                    x_, y_vec_, y_distribution = x_.cuda(), y_vec_.cuda(), y_distribution.cuda()\n",
        "                if epoch == 0: #统计分布,计算初始损失\n",
        "                    y_distribution += y_vec_.sum(0)\n",
        "                    global_loss.append((F.softmax(global_model(x_))*y_vec_).sum(-1).mean().item())\n",
        "                    self.global_loss=np.mean(global_loss)\n",
        "\n",
        "                print_head = \"Epoch: [%2d] [%4d/%4d]\" % ((epoch + 1), (iter + 1), client.num_steps)\n",
        "                self.train_step(client,x_, y_vec_, iter, y_distribution, global_model, optimizer, print_head)\n",
        "\n",
        "            self.train_hist['per_epoch_time'].append(time.time() - epoch_start_time)\n",
        "            with torch.no_grad():\n",
        "                samples = self.visualize_results(client,(epoch+1),get_transform(client.train_data),rslt_path)\n",
        "        self.train_hist['total_time'].append(time.time() - start_time)\n",
        "        print(\"Avg one epoch time: %.2f, total %d epochs time: %.2f\" % (np.mean(self.train_hist['per_epoch_time']),\n",
        "                                            gan_epoch, self.train_hist['total_time'][0]))\n",
        "        print(\"Training finish!... save training results\")\n",
        "\n",
        "        self.save()\n",
        "        #utils.generate_animation(rslt_path + '/',gan_epoch)\n",
        "        #utils.loss_plot(self.train_hist, os.path.join(self.save_dir, self.task, self.model_name), self.model_name)\n",
        "        del x_, y_vec_, y_distribution\n",
        "        return samples\n",
        "    def show_img(self,samples,transform,image_frame_dim,path):\n",
        "        if self.gpu_mode:\n",
        "            samples = samples.cpu().data.numpy().transpose(0, 2, 3, 1)\n",
        "        else:\n",
        "            samples = samples.data.numpy().transpose(0, 2, 3, 1)\n",
        "        std,mean=get_Normalize_mean_std(transform)\n",
        "        samples = samples*std+mean #反归一化\n",
        "        img_float = np.squeeze(utils.merge(samples[:image_frame_dim * image_frame_dim, :, :, :], [image_frame_dim, image_frame_dim]  ))\n",
        "        image = np.clip((img_float * 255),0, 255).astype(np.uint8)\n",
        "        # 将 RGB 图像数据转换为 BGR 顺序, 因为OpenCV 中，默认的颜色通道顺序是 BGR（蓝绿红），而不是常见的 RGB（红绿蓝）\n",
        "        image = cv.cvtColor(image, cv.COLOR_RGB2BGR)\n",
        "        cv.imwrite(path, image)\n",
        "        return image\n",
        "\n",
        "    def visualize_results(self, client, epoch, transform, rslt_path, fix=True): #transform是归一化参数\n",
        "        self.G.eval()\n",
        "        ########################################\n",
        "        #std,mean=get_Normalize_mean_std(transform)\n",
        "        if not os.path.exists(rslt_path):\n",
        "            os.makedirs(rslt_path)\n",
        "        ########################################\n",
        "        image_frame_dim = int(np.floor(np.sqrt(self.sample_num)))\n",
        "\n",
        "        batch_data = client.get_batch_data()\n",
        "        x_, y_ = batch_data\n",
        "        size=x_.shape[-1]\n",
        "        x2=x_[:image_frame_dim].reshape(1,image_frame_dim,-1,size,size).repeat(image_frame_dim,1,1,1,1).permute(1,0,2,3,4)\n",
        "        y2=y_[:image_frame_dim].unsqueeze(0).t().repeat(1,image_frame_dim).reshape(image_frame_dim*image_frame_dim)\n",
        "        y2 = torch.zeros((image_frame_dim*image_frame_dim, self.class_num)).scatter_(1, y2.type(torch.LongTensor).unsqueeze(1), 1)\n",
        "        x2=x2.reshape(image_frame_dim*image_frame_dim,-1,size,size)\n",
        "        self.show_img(x2,transform,image_frame_dim,\\\n",
        "            rslt_path + '/' + str(client.round) + '-%03d' % epoch + '.png')\n",
        "        \"\"\" style by class \"\"\"\n",
        "        if self.gpu_mode:\n",
        "          x2,y2 = x2.cuda(),y2.cuda()\n",
        "        samples = self.G(x2,self.sample_y_)\n",
        "        syn = self.D.get_embedding(samples) #特征\n",
        "        image=self.show_img(samples,transform,image_frame_dim,\\\n",
        "            rslt_path + '/round' + str(client.round)  + '_epoch%03d' % epoch + '.png')\n",
        "        print(self.sample_y_.shape,y2.shape)\n",
        "        samples = self.G(samples,y2)\n",
        "        syn = self.D.get_embedding(samples) #特征\n",
        "        image=self.show_img(samples,transform,image_frame_dim,\\\n",
        "            rslt_path + '/round' + str(client.round)  + '_epoch%03d' % epoch + '2.png')\n",
        "\n",
        "        return syn.mean(0)\n",
        "        #[id，类别]\n",
        "\n",
        "    def visualize_results0(self, client, epoch, transform, rslt_path, fix=True): #transform是归一化参数\n",
        "        self.G.eval()\n",
        "        ########################################\n",
        "        #std,mean=get_Normalize_mean_std(transform)\n",
        "        if not os.path.exists(rslt_path):\n",
        "            os.makedirs(rslt_path)\n",
        "        ########################################\n",
        "        image_frame_dim = int(np.floor(np.sqrt(self.sample_num)))\n",
        "\n",
        "        \"\"\" style by class \"\"\"\n",
        "        samples,_ = self.G(self.sample_z_, self.sample_c_, self.sample_y_)\n",
        "        syn = self.D.get_embedding(samples) #特征\n",
        "        image=self.show_img(samples,transform,image_frame_dim,\\\n",
        "            rslt_path + '/round' + str(client.round)  + '_epoch%03d' % epoch + '.png')\n",
        "        #image2=self.show_img(samples2,transform,image_frame_dim,\\\n",
        "            #rslt_path + '/round' + str(client.round) + '_epoch%03d' % epoch + '2.png')\n",
        "        \"\"\" manipulating two continous codes \"\"\"\n",
        "        samples,_ = self.G(self.sample_z2_, self.sample_c2_, self.sample_y2_)\n",
        "        #print(\"samples:\",samples.min(),samples.max())\n",
        "        #################################################################################################################\n",
        "        image=self.show_img(samples,transform,image_frame_dim,\\\n",
        "            rslt_path + '/_round' + str(client.round) + '_epoch%03d' % epoch + '.png')\n",
        "\n",
        "        if self.wandb_fn==True:\n",
        "            wandb.Image(image)\n",
        "        '''\n",
        "        batch_data = client.get_batch_data()\n",
        "        x_, y_ = batch_data\n",
        "        self.show_img(x_[:25],transform,5,\\\n",
        "            rslt_path + '/' + str(client.round) + '-%03d' % epoch + '.png')\n",
        "        print(\"x:\",x_.min(),x_.max())\n",
        "        '''\n",
        "        #################################################################################################################\n",
        "        syn = syn.reshape(image_frame_dim,image_frame_dim,-1)\n",
        "        #img = syn.mean(0).cpu().detach().numpy()\n",
        "        #new_img = cv.resize(img,None,fx=10,fy=10)\n",
        "        #cv.imwrite(rslt_path + '/_round' + str(client.round) + 'syn_%03d' % epoch + '.png',new_img)\n",
        "        return syn.mean(0)\n",
        "        #[id，类别]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8cqA9BoiblII"
      },
      "source": [
        "# ACGAN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nuxTxvYdbkKg"
      },
      "outputs": [],
      "source": [
        "os.chdir('/content/GAN')\n",
        "import utils, torch, time, os, pickle, itertools\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt\n",
        "from dataloader import dataloader\n",
        "from ACGAN import ACGAN,discriminator,generator\n",
        "from main import parse_args\n",
        "from torch.autograd import grad\n",
        "os.chdir(BASEPATH)\n",
        "\n",
        "##########################################################################################################\n",
        "from torchvision import datasets, transforms\n",
        "import copy\n",
        "\n",
        "def get_Normalize_mean_std(transform):\n",
        "  for t in transform.transforms:\n",
        "    if isinstance(t, transforms.Normalize):\n",
        "        return t.mean,t.std\n",
        "def get_transform(dataset):\n",
        "  if hasattr(dataset, 'transform'):\n",
        "    return dataset.transform\n",
        "  else: #针对嵌套很多层的情况，递归调用来寻找dataset中的transform\n",
        "    return get_transform(dataset.dataset)\n",
        "def new_normalize(dataset1,mean,std):\n",
        "  dataset2 = copy.deepcopy(dataset1) # 创建dataset2并复制dataset1的所有样本，deepcopy创建新对象\n",
        "  for t in get_transform(dataset2).transforms: # 遍历transform2的所有操作\n",
        "    if isinstance(t, transforms.Normalize): # 如果操作是Normalize，则替换mean和std的值\n",
        "      t.mean,t.std = mean,std\n",
        "  return dataset2\n",
        "###########################################################################################################\n",
        "\n",
        "class my_ACGAN(ACGAN):\n",
        "    def __init__(self, args, data_shape, loc_c, name=None):\n",
        "        self.lambda_ = 5 #for WGAN_GP\n",
        "\n",
        "        # parameters\n",
        "        #self.epoch = args.epoch\n",
        "        self.batch_size = args.batch_size\n",
        "        self.save_dir = args.save_dir\n",
        "        self.result_dir = args.result_dir\n",
        "        self.task = args.task\n",
        "        self.dataset = args.task\n",
        "        self.log_dir = args.log_dir\n",
        "        self.gpu_mode = args.gpu_mode\n",
        "        if name==None:\n",
        "          self.model_name = type(self).__name__\n",
        "        else:\n",
        "          self.model_name = name\n",
        "        self.input_size = args.input_size\n",
        "        self.z_dim = 62\n",
        "        self.class_num = 10\n",
        "        self.sample_num = self.class_num ** 2\n",
        "\n",
        "        # networks init\n",
        "        self.G = generator(input_dim=self.z_dim, output_dim=data_shape, input_size=self.input_size,latent_dim=512)\n",
        "        self.G2 = nn.Linear(in_features=data_shape, out_features=data_shape)\n",
        "        self.D = discriminator(input_dim=data_shape, output_dim=1, input_size=self.input_size,latent_dim=512)\n",
        "        self.G_optimizer = optim.Adam(self.G.parameters(), lr=args.lrG, betas=(args.beta1, args.beta2))\n",
        "        self.D_optimizer = optim.Adam(self.D.parameters(), lr=args.lrD, betas=(args.beta1, args.beta2))\n",
        "\n",
        "        if self.gpu_mode:\n",
        "            self.G.cuda()\n",
        "            self.D.cuda()\n",
        "            self.BCE_loss = nn.BCELoss().cuda()\n",
        "            self.CE_loss = nn.CrossEntropyLoss().cuda()\n",
        "            self.CE_loss_unreduce = nn.CrossEntropyLoss(reduce=False).cuda()\n",
        "        else:\n",
        "            self.BCE_loss = nn.BCELoss()\n",
        "            self.CE_loss = nn.CrossEntropyLoss()\n",
        "\n",
        "        print('---------- Networks architecture -------------')\n",
        "        utils.print_network(self.G)\n",
        "        utils.print_network(self.D)\n",
        "        print('-----------------------------------------------')\n",
        "\n",
        "        # fixed noise & condition\n",
        "        self.sample_z_ = torch.zeros((self.sample_num, self.z_dim))\n",
        "        for i in range(self.class_num):\n",
        "            self.sample_z_[i*self.class_num] = torch.rand(1, self.z_dim)\n",
        "            for j in range(1, self.class_num):\n",
        "                self.sample_z_[i*self.class_num + j] = self.sample_z_[i*self.class_num]\n",
        "\n",
        "        temp = torch.zeros((self.class_num, 1))\n",
        "        for i in range(self.class_num):\n",
        "            temp[i, 0] = i\n",
        "\n",
        "        temp_y = torch.zeros((self.sample_num, 1))\n",
        "        for i in range(self.class_num):\n",
        "            temp_y[i*self.class_num: (i+1)*self.class_num] = temp\n",
        "\n",
        "        self.sample_y_ = torch.zeros((self.sample_num, self.class_num)).scatter_(1, temp_y.type(torch.LongTensor), 1)\n",
        "        if self.gpu_mode:\n",
        "            self.sample_z_, self.sample_y_ = self.sample_z_.cuda(), self.sample_y_.cuda()\n",
        "    def GG(self,z,y):\n",
        "        x = self.G(z,y)\n",
        "        return x,self.G2(x)\n",
        "    def D_real(self,D):\n",
        "        #return self.BCE_loss(D, self.y_real_)\n",
        "        return -torch.mean(D) #Wasserstein\n",
        "    def D_fake(self,D):\n",
        "        #return self.BCE_loss(D, self.y_fake_)\n",
        "        return torch.mean(D) #Wasserstein\n",
        "    def train_step(self, x_, y_, iter, y_distribution, global_model=None):\n",
        "        z_ = torch.rand((self.batch_size, self.z_dim))\n",
        "        y_vec_ = torch.zeros((self.batch_size, self.class_num)).scatter_(1, y_.type(torch.LongTensor).unsqueeze(1), 1)\n",
        "        y_disc_ = torch.from_numpy(\n",
        "                  np.random.multinomial(1, self.class_num * [float(1.0 / self.class_num)],\n",
        "                                        size=[self.batch_size])).type(torch.FloatTensor)\n",
        "\n",
        "        if self.gpu_mode:\n",
        "            x_, z_, y_vec_,y_disc_, y_distribution = x_.cuda(), z_.cuda(), y_vec_.cuda(), y_disc_.cuda(),y_distribution.cuda()\n",
        "\n",
        "        # update D network\n",
        "        self.D_optimizer.zero_grad()\n",
        "\n",
        "        D_real, C_real = self.D(x_)\n",
        "        D_real_loss = self.D_real(D_real)\n",
        "        C_real_loss = self.CE_loss(C_real, torch.max(y_vec_, 1)[1])\n",
        "\n",
        "\n",
        "        G_ = self.G(z_, y_vec_)\n",
        "        D_fake, C_fake = self.D(G_)\n",
        "\n",
        "        G_2 = self.G(z_, y_disc_)\n",
        "        D_fake2 , C_fake2 = self.D(G_2)\n",
        "\n",
        "        #D_fake_loss = self.BCE_loss(D_fake, self.y_fake_) + self.BCE_loss(D_fake2, self.y_fake_)\n",
        "        D_fake_loss = self.D_fake(D_fake)\n",
        "        C_fake_loss = self.CE_loss(C_fake, torch.max(y_vec_, 1)[1])\n",
        "\n",
        "        D_fake_loss2 = self.D_fake(D_fake2)\n",
        "        C_fake_loss2 = self.CE_loss(C_fake2, torch.max(y_disc_, 1)[1])\n",
        "        #C_fake_loss2 = self.CE_loss(C_fake2, torch.max(y_disc_, 1)[1]) + F.l1_loss(C_fake2, global_model(G_2))\n",
        "\n",
        "        #D_loss = 2*D_real_loss + C_real_loss + D_fake_loss + C_fake_loss + D_fake_loss2 + C_fake_loss2\n",
        "\n",
        "        D_loss = 2*D_real_loss + 2*C_real_loss + D_fake_loss + D_fake_loss2 + 2*C_fake_loss2\n",
        "\n",
        "        #D_loss = D_real_loss + C_real_loss + D_fake_loss2 + C_fake_loss2\n",
        "\n",
        "        self.train_hist['D_loss'].append(D_loss.item())\n",
        "\n",
        "        D_loss.backward()\n",
        "        self.D_optimizer.step()\n",
        "        #optimizer.step()\n",
        "\n",
        "        # update G network\n",
        "        self.G_optimizer.zero_grad()\n",
        "\n",
        "        G_ = self.G(z_, y_vec_)\n",
        "        D_fake, C_fake = self.D(G_)\n",
        "        #G_loss1 = self.BCE_loss(D_fake, self.y_real_) + self.CE_loss(C_fake, torch.max(y_vec_, 1)[1])\n",
        "        G_loss1 = self.D_real(D_fake) + self.CE_loss(C_fake, torch.max(y_vec_, 1)[1]) #Wasserstein\n",
        "\n",
        "        G_2 = self.G(z_, y_disc_)\n",
        "        D_fake2, C_fake2 = self.D(G_2)\n",
        "        #w = (y_distribution/y_distribution.max())**0.1\n",
        "        #w = (w.clamp(min=0.9)*y_disc_).sum(-1)\n",
        "        C_loss2 = self.CE_loss(C_fake2, torch.max(y_disc_, 1)[1])\n",
        "        if global_model!=None:\n",
        "          C_loss2_2 = self.CE_loss_unreduce(global_model(G_2), torch.max(y_disc_, 1)[1])\n",
        "          C_loss2 += 0.2*(C_loss2_2).mean()\n",
        "        #C_loss2 = C_loss2_1 + (C_loss2_2).mean()\n",
        "        #C_loss2 = C_loss2_1 + 0.05*(C_loss2_2*C_loss2_2).mean()\n",
        "        #C_loss2 = C_loss2_1 + 0.03*(C_loss2_2*C_loss2_2*C_loss2_2).mean()\n",
        "        #C_loss2 =(0.1*C_loss2_2).mean()#不如加D的分类损失，相当把分类能力蒸馏到本地的同时进行生成，分类不至于太过强大而过拟合\n",
        "\n",
        "        G_loss2 = self.D_real(D_fake2) #+ 0.1*C_loss2 #Wasserstein\n",
        "\n",
        "        G_loss = G_loss1 + G_loss2\n",
        "        #G_loss = G_loss2\n",
        "\n",
        "        self.train_hist['G_loss'].append(G_loss.item())\n",
        "\n",
        "        G_loss.backward()\n",
        "        self.G_optimizer.step()\n",
        "\n",
        "        return D_loss,G_loss\n",
        "\n",
        "    def gradient_penalty(self,x_,G_): #WGAN_GP\n",
        "        alpha = torch.rand((self.batch_size, 1, 1, 1))\n",
        "        if self.gpu_mode:\n",
        "            alpha = alpha.cuda()\n",
        "        x_hat = alpha * x_.data + (1 - alpha) * G_.data\n",
        "        x_hat.requires_grad = True\n",
        "\n",
        "        pred_hat , _ = self.D(x_hat)\n",
        "        if self.gpu_mode:\n",
        "            gradients = grad(outputs=pred_hat, inputs=x_hat, grad_outputs=torch.ones(pred_hat.size()).cuda(),\n",
        "                          create_graph=True, retain_graph=True, only_inputs=True)[0]\n",
        "        else:\n",
        "            gradients = grad(outputs=pred_hat, inputs=x_hat, grad_outputs=torch.ones(pred_hat.size()),\n",
        "                              create_graph=True, retain_graph=True, only_inputs=True)[0]\n",
        "\n",
        "        gradient_penalty = self.lambda_ * ((gradients.view(gradients.size()[0], -1).norm(2, 1) - 1) ** 2).mean()\n",
        "        return gradient_penalty\n",
        "\n",
        "    def train(self,client,train_data,gan_epoch,global_model=None,optimizer=None,round=0):\n",
        "        data_loader = DataLoader(new_normalize(train_data,mean=0.5,std=0.5), \\\n",
        "                                 batch_size=self.batch_size)\n",
        "        rslt_path = self.result_dir + '/' + self.task + '/' + self.model_name + '/round' + str(round)\n",
        "        print(rslt_path)\n",
        "        self.train_hist = {}\n",
        "        self.train_hist['D_loss'] = []\n",
        "        self.train_hist['G_loss'] = []\n",
        "        self.train_hist['per_epoch_time'] = []\n",
        "        self.train_hist['total_time'] = []\n",
        "\n",
        "        self.y_real_, self.y_fake_ = torch.ones(self.batch_size, 1), torch.zeros(self.batch_size, 1)\n",
        "        if self.gpu_mode:\n",
        "            self.y_real_, self.y_fake_ = self.y_real_.cuda(), self.y_fake_.cuda()\n",
        "\n",
        "        self.D.train()\n",
        "        print(self.model_name,': training start!!')\n",
        "        start_time = time.time()\n",
        "\n",
        "        y_distribution = torch.zeros(self.class_num)\n",
        "        for epoch in range(gan_epoch):\n",
        "            self.G.train()\n",
        "            epoch_start_time = time.time()\n",
        "            for iter, (x_, y_) in enumerate(data_loader):\n",
        "                if epoch == 0: #统计分布\n",
        "                    y_vec_ = torch.zeros((self.batch_size, self.class_num)).scatter_(1, y_.type(torch.LongTensor).unsqueeze(1), 1)\n",
        "                    y_distribution += y_vec_.sum(0)\n",
        "                if iter == data_loader.dataset.__len__() // self.batch_size:\n",
        "                    break\n",
        "                D_loss,G_loss = self.train_step(x_, y_, iter, y_distribution, global_model )\n",
        "                #if ((iter + 1) % 100) == 0:\n",
        "                if ((iter + 1) % 50) == 0:\n",
        "                    print(\"Epoch: [%2d] [%4d/%4d] D_loss: %.8f, G_loss: %.8f\" %\n",
        "                          ((epoch + 1), (iter + 1), data_loader.dataset.__len__() // self.batch_size, D_loss.item(), G_loss.item()))\n",
        "\n",
        "            self.train_hist['per_epoch_time'].append(time.time() - epoch_start_time)\n",
        "            with torch.no_grad():\n",
        "                self.visualize_results((epoch+1),get_transform(data_loader),rslt_path)\n",
        "        self.train_hist['total_time'].append(time.time() - start_time)\n",
        "        print(\"Avg one epoch time: %.2f, total %d epochs time: %.2f\" % (np.mean(self.train_hist['per_epoch_time']),\n",
        "                                            gan_epoch, self.train_hist['total_time'][0]))\n",
        "        print(\"Training finish!... save training results\")\n",
        "\n",
        "        self.save()\n",
        "        utils.generate_animation(rslt_path + '/',gan_epoch)\n",
        "        utils.loss_plot(self.train_hist, os.path.join(self.save_dir, self.task, self.model_name), self.model_name)\n",
        "\n",
        "    def visualize_results(self, epoch, transform, rslt_path, fix=True): #transform是归一化参数\n",
        "        self.G.eval()\n",
        "\n",
        "        if not os.path.exists(rslt_path):\n",
        "            os.makedirs(rslt_path)\n",
        "\n",
        "        image_frame_dim = int(np.floor(np.sqrt(self.sample_num)))\n",
        "\n",
        "        if fix:\n",
        "            \"\"\" fixed noise \"\"\"\n",
        "            samples = self.G(self.sample_z_, self.sample_y_)\n",
        "        else:\n",
        "            \"\"\" random noise \"\"\"\n",
        "            sample_y_ = torch.zeros(self.batch_size, self.class_num).scatter_(1, torch.randint(0, self.class_num - 1, (self.batch_size, 1)).type(torch.LongTensor), 1)\n",
        "            sample_z_ = torch.rand((self.batch_size, self.z_dim))\n",
        "            if self.gpu_mode:\n",
        "                sample_z_, sample_y_ = sample_z_.cuda(), sample_y_.cuda()\n",
        "\n",
        "            samples = self.G(sample_z_, sample_y_)\n",
        "\n",
        "        if self.gpu_mode:\n",
        "            samples = samples.cpu().data.numpy().transpose(0, 2, 3, 1)\n",
        "        else:\n",
        "            samples = samples.data.numpy().transpose(0, 2, 3, 1)\n",
        "\n",
        "        std,mean=get_Normalize_mean_std(transform)\n",
        "        samples = samples*std+mean #反归一化\n",
        "        utils.save_images(samples[:image_frame_dim * image_frame_dim, :, :, :], [image_frame_dim, image_frame_dim],\n",
        "                          rslt_path + '/' + '_epoch%03d' % epoch + '.png')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PlRy7Z3vYJBG",
        "outputId": "e00d7387-e667-4e6e-bb9c-6cae3107cb27"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Compose(\n",
            "    ToTensor()\n",
            "    Normalize(mean=0.5, std=0.5)\n",
            ")\n",
            "Compose(\n",
            "    ToTensor()\n",
            "    Normalize(mean=0.1307, std=0.3081)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "#测试new_normalize\n",
        "transform1 = transforms.Compose([transforms.ToTensor(), transforms.Normalize(mean=(0.5), std=(0.5))])\n",
        "dataset1 = datasets.MNIST('data/mnist', train=True, download=True, transform=transform1)\n",
        "dataset2 = new_normalize(dataset1,mean=0.1307,std=0.3081)\n",
        "print(dataset1.transform)\n",
        "print(dataset2.transform)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vQlkkzwrhSAK"
      },
      "source": [
        "# 流程拆解"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I1ERWVmCL1w7",
        "outputId": "09291c8b-d824-4e7f-99ca-b755e8531c43"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.5488135039273248\n",
            "0.417022004702574\n",
            "0.7151893663724195\n",
            "0.7203244934421581\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "# 创建第一个随机数生成器对象\n",
        "rng1 = np.random.RandomState(0)\n",
        "\n",
        "# 创建第二个随机数生成器对象\n",
        "rng2 = np.random.RandomState(1)\n",
        "\n",
        "# 使用第一个生成器生成随机数\n",
        "random_number_1 = rng1.random()\n",
        "print(random_number_1)  # 输出: 0.5488135039273248\n",
        "\n",
        "# 使用第二个生成器生成随机数\n",
        "random_number_2 = rng2.random()\n",
        "print(random_number_2)  # 输出: 0.417022004702574\n",
        "\n",
        "# 在不同位置再次生成随机数\n",
        "random_number_3 = rng1.random()\n",
        "#random_number_3 = rng1.random()\n",
        "print(random_number_3)  # 输出: 0.6027633760716439\n",
        "\n",
        "random_number_4 = rng2.random()\n",
        "print(random_number_4)  # 输出: 0.7203244934421581"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_c3qbq7LN9UY",
        "outputId": "8915b88f-ae34-4c0b-b8fd-aa57629e78c4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "5\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "# 创建随机数生成器对象\n",
        "rng = np.random.RandomState(0)\n",
        "\n",
        "# 一维数组\n",
        "array = np.array([1, 2, 3, 4, 5])\n",
        "\n",
        "# 使用随机数生成器对象的choice方法进行随机选择\n",
        "random_choice = rng.choice(array)\n",
        "print(random_choice)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z6-PiNR1Yvum"
      },
      "outputs": [],
      "source": [
        "cp -r /content/FLGo/flgo/benchmark2 /content/FLGo/flgo/benchmark3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "0jR2p20YhV-K",
        "outputId": "a7ba940b-536a-44ca-d538-c730d3766ea8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "参数： Namespace(gan_type='GAN', dataset='mnist', split='', epoch=1, batch_size=64, input_size=28, save_dir='models', result_dir='results', log_dir='logs', lrG=0.005, lrD=0.01, beta1=0.5, beta2=0.999, gpu_mode=True, benchmark_mode=True)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-09 13:58:01,323 fflow.py init [line:441] INFO Initializing devices: cuda:0 will be used for this running.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "client 0 总样本数： 5389  各类： [   0  352 2210    6   19  203   49    0    0 2550]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
            "  warnings.warn(warning.format(ret))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "---------- Networks architecture -------------\n",
            "generator_pro(\n",
            "  (_conv_1): Sequential(\n",
            "    (0): Conv2d(1, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
            "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): LeakyReLU(negative_slope=0.2)\n",
            "    (3): Conv2d(32, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
            "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): LeakyReLU(negative_slope=0.2)\n",
            "    (6): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
            "    (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (8): LeakyReLU(negative_slope=0.2)\n",
            "  )\n",
            "  (conv_out): Sequential(\n",
            "    (0): ConvTranspose2d(16, 1, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
            "    (1): Tanh()\n",
            "  )\n",
            "  (_conv_trans_0): Conv2d(74, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "  (_residual_stack): ResidualStack(\n",
            "    (_layers): ModuleList(\n",
            "      (0-63): 64 x Residual(\n",
            "        (_block): Sequential(\n",
            "          (0): ReLU(inplace=True)\n",
            "          (1): Conv2d(64, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (2): ReLU(inplace=True)\n",
            "          (3): Conv2d(3, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (_conv_trans_1): Sequential(\n",
            "    (0): ConvTranspose2d(74, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
            "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): LeakyReLU(negative_slope=0.2)\n",
            "    (3): ConvTranspose2d(32, 16, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
            "    (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): LeakyReLU(negative_slope=0.2)\n",
            "  )\n",
            ")\n",
            "Total number of parameters: 310465\n",
            "-----------------------------------------------\n",
            "client 1 总样本数： 5291  各类： [   0    1   89   59 4208  111  157    0   42  624]\n",
            "---------- Networks architecture -------------\n",
            "generator_pro(\n",
            "  (_conv_1): Sequential(\n",
            "    (0): Conv2d(1, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
            "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): LeakyReLU(negative_slope=0.2)\n",
            "    (3): Conv2d(32, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
            "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): LeakyReLU(negative_slope=0.2)\n",
            "    (6): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
            "    (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (8): LeakyReLU(negative_slope=0.2)\n",
            "  )\n",
            "  (conv_out): Sequential(\n",
            "    (0): ConvTranspose2d(16, 1, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
            "    (1): Tanh()\n",
            "  )\n",
            "  (_conv_trans_0): Conv2d(74, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "  (_residual_stack): ResidualStack(\n",
            "    (_layers): ModuleList(\n",
            "      (0-63): 64 x Residual(\n",
            "        (_block): Sequential(\n",
            "          (0): ReLU(inplace=True)\n",
            "          (1): Conv2d(64, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (2): ReLU(inplace=True)\n",
            "          (3): Conv2d(3, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (_conv_trans_1): Sequential(\n",
            "    (0): ConvTranspose2d(74, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
            "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): LeakyReLU(negative_slope=0.2)\n",
            "    (3): ConvTranspose2d(32, 16, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
            "    (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): LeakyReLU(negative_slope=0.2)\n",
            "  )\n",
            ")\n",
            "Total number of parameters: 310465\n",
            "-----------------------------------------------\n",
            "client 2 总样本数： 5342  各类： [   0 1889    0  342  402    1 2152  552    3    1]\n",
            "---------- Networks architecture -------------\n",
            "generator_pro(\n",
            "  (_conv_1): Sequential(\n",
            "    (0): Conv2d(1, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
            "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): LeakyReLU(negative_slope=0.2)\n",
            "    (3): Conv2d(32, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
            "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): LeakyReLU(negative_slope=0.2)\n",
            "    (6): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
            "    (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (8): LeakyReLU(negative_slope=0.2)\n",
            "  )\n",
            "  (conv_out): Sequential(\n",
            "    (0): ConvTranspose2d(16, 1, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
            "    (1): Tanh()\n",
            "  )\n",
            "  (_conv_trans_0): Conv2d(74, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "  (_residual_stack): ResidualStack(\n",
            "    (_layers): ModuleList(\n",
            "      (0-63): 64 x Residual(\n",
            "        (_block): Sequential(\n",
            "          (0): ReLU(inplace=True)\n",
            "          (1): Conv2d(64, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (2): ReLU(inplace=True)\n",
            "          (3): Conv2d(3, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (_conv_trans_1): Sequential(\n",
            "    (0): ConvTranspose2d(74, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
            "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): LeakyReLU(negative_slope=0.2)\n",
            "    (3): ConvTranspose2d(32, 16, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
            "    (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): LeakyReLU(negative_slope=0.2)\n",
            "  )\n",
            ")\n",
            "Total number of parameters: 310465\n",
            "-----------------------------------------------\n",
            "client 3 总样本数： 5470  各类： [   0    0  501  158    1    0   26 4518  266    0]\n",
            "---------- Networks architecture -------------\n",
            "generator_pro(\n",
            "  (_conv_1): Sequential(\n",
            "    (0): Conv2d(1, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
            "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): LeakyReLU(negative_slope=0.2)\n",
            "    (3): Conv2d(32, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
            "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): LeakyReLU(negative_slope=0.2)\n",
            "    (6): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
            "    (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (8): LeakyReLU(negative_slope=0.2)\n",
            "  )\n",
            "  (conv_out): Sequential(\n",
            "    (0): ConvTranspose2d(16, 1, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
            "    (1): Tanh()\n",
            "  )\n",
            "  (_conv_trans_0): Conv2d(74, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "  (_residual_stack): ResidualStack(\n",
            "    (_layers): ModuleList(\n",
            "      (0-63): 64 x Residual(\n",
            "        (_block): Sequential(\n",
            "          (0): ReLU(inplace=True)\n",
            "          (1): Conv2d(64, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (2): ReLU(inplace=True)\n",
            "          (3): Conv2d(3, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (_conv_trans_1): Sequential(\n",
            "    (0): ConvTranspose2d(74, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
            "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): LeakyReLU(negative_slope=0.2)\n",
            "    (3): ConvTranspose2d(32, 16, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
            "    (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): LeakyReLU(negative_slope=0.2)\n",
            "  )\n",
            ")\n",
            "Total number of parameters: 310465\n",
            "-----------------------------------------------\n",
            "client 4 总样本数： 5474  各类： [  27    0 2198    0   94 1443    0  469    0 1243]\n",
            "---------- Networks architecture -------------\n",
            "generator_pro(\n",
            "  (_conv_1): Sequential(\n",
            "    (0): Conv2d(1, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
            "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): LeakyReLU(negative_slope=0.2)\n",
            "    (3): Conv2d(32, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
            "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): LeakyReLU(negative_slope=0.2)\n",
            "    (6): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
            "    (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (8): LeakyReLU(negative_slope=0.2)\n",
            "  )\n",
            "  (conv_out): Sequential(\n",
            "    (0): ConvTranspose2d(16, 1, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
            "    (1): Tanh()\n",
            "  )\n",
            "  (_conv_trans_0): Conv2d(74, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "  (_residual_stack): ResidualStack(\n",
            "    (_layers): ModuleList(\n",
            "      (0-63): 64 x Residual(\n",
            "        (_block): Sequential(\n",
            "          (0): ReLU(inplace=True)\n",
            "          (1): Conv2d(64, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (2): ReLU(inplace=True)\n",
            "          (3): Conv2d(3, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (_conv_trans_1): Sequential(\n",
            "    (0): ConvTranspose2d(74, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
            "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): LeakyReLU(negative_slope=0.2)\n",
            "    (3): ConvTranspose2d(32, 16, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
            "    (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): LeakyReLU(negative_slope=0.2)\n",
            "  )\n",
            ")\n",
            "Total number of parameters: 310465\n",
            "-----------------------------------------------\n",
            "client 5 总样本数： 5355  各类： [4917    0    0   76    0    3    0    0    0  359]\n",
            "---------- Networks architecture -------------\n",
            "generator_pro(\n",
            "  (_conv_1): Sequential(\n",
            "    (0): Conv2d(1, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
            "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): LeakyReLU(negative_slope=0.2)\n",
            "    (3): Conv2d(32, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
            "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): LeakyReLU(negative_slope=0.2)\n",
            "    (6): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
            "    (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (8): LeakyReLU(negative_slope=0.2)\n",
            "  )\n",
            "  (conv_out): Sequential(\n",
            "    (0): ConvTranspose2d(16, 1, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
            "    (1): Tanh()\n",
            "  )\n",
            "  (_conv_trans_0): Conv2d(74, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "  (_residual_stack): ResidualStack(\n",
            "    (_layers): ModuleList(\n",
            "      (0-63): 64 x Residual(\n",
            "        (_block): Sequential(\n",
            "          (0): ReLU(inplace=True)\n",
            "          (1): Conv2d(64, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (2): ReLU(inplace=True)\n",
            "          (3): Conv2d(3, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (_conv_trans_1): Sequential(\n",
            "    (0): ConvTranspose2d(74, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
            "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): LeakyReLU(negative_slope=0.2)\n",
            "    (3): ConvTranspose2d(32, 16, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
            "    (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): LeakyReLU(negative_slope=0.2)\n",
            "  )\n",
            ")\n",
            "Total number of parameters: 310465\n",
            "-----------------------------------------------\n",
            "client 6 总样本数： 5526  各类： [   2    0    0    0  498    9  760    0 3683  574]\n",
            "---------- Networks architecture -------------\n",
            "generator_pro(\n",
            "  (_conv_1): Sequential(\n",
            "    (0): Conv2d(1, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
            "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): LeakyReLU(negative_slope=0.2)\n",
            "    (3): Conv2d(32, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
            "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): LeakyReLU(negative_slope=0.2)\n",
            "    (6): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
            "    (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (8): LeakyReLU(negative_slope=0.2)\n",
            "  )\n",
            "  (conv_out): Sequential(\n",
            "    (0): ConvTranspose2d(16, 1, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
            "    (1): Tanh()\n",
            "  )\n",
            "  (_conv_trans_0): Conv2d(74, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "  (_residual_stack): ResidualStack(\n",
            "    (_layers): ModuleList(\n",
            "      (0-63): 64 x Residual(\n",
            "        (_block): Sequential(\n",
            "          (0): ReLU(inplace=True)\n",
            "          (1): Conv2d(64, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (2): ReLU(inplace=True)\n",
            "          (3): Conv2d(3, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (_conv_trans_1): Sequential(\n",
            "    (0): ConvTranspose2d(74, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
            "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): LeakyReLU(negative_slope=0.2)\n",
            "    (3): ConvTranspose2d(32, 16, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
            "    (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): LeakyReLU(negative_slope=0.2)\n",
            "  )\n",
            ")\n",
            "Total number of parameters: 310465\n",
            "-----------------------------------------------\n",
            "client 7 总样本数： 5309  各类： [  28 2880    0  169    7   11 2154   60    0    0]\n",
            "---------- Networks architecture -------------\n",
            "generator_pro(\n",
            "  (_conv_1): Sequential(\n",
            "    (0): Conv2d(1, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
            "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): LeakyReLU(negative_slope=0.2)\n",
            "    (3): Conv2d(32, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
            "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): LeakyReLU(negative_slope=0.2)\n",
            "    (6): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
            "    (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (8): LeakyReLU(negative_slope=0.2)\n",
            "  )\n",
            "  (conv_out): Sequential(\n",
            "    (0): ConvTranspose2d(16, 1, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
            "    (1): Tanh()\n",
            "  )\n",
            "  (_conv_trans_0): Conv2d(74, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "  (_residual_stack): ResidualStack(\n",
            "    (_layers): ModuleList(\n",
            "      (0-63): 64 x Residual(\n",
            "        (_block): Sequential(\n",
            "          (0): ReLU(inplace=True)\n",
            "          (1): Conv2d(64, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (2): ReLU(inplace=True)\n",
            "          (3): Conv2d(3, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (_conv_trans_1): Sequential(\n",
            "    (0): ConvTranspose2d(74, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
            "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): LeakyReLU(negative_slope=0.2)\n",
            "    (3): ConvTranspose2d(32, 16, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
            "    (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): LeakyReLU(negative_slope=0.2)\n",
            "  )\n",
            ")\n",
            "Total number of parameters: 310465\n",
            "-----------------------------------------------\n",
            "client 8 总样本数： 5493  各类： [   0  902  242   42    2 3102    0    0 1203    0]\n",
            "---------- Networks architecture -------------\n",
            "generator_pro(\n",
            "  (_conv_1): Sequential(\n",
            "    (0): Conv2d(1, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
            "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): LeakyReLU(negative_slope=0.2)\n",
            "    (3): Conv2d(32, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
            "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): LeakyReLU(negative_slope=0.2)\n",
            "    (6): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
            "    (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (8): LeakyReLU(negative_slope=0.2)\n",
            "  )\n",
            "  (conv_out): Sequential(\n",
            "    (0): ConvTranspose2d(16, 1, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
            "    (1): Tanh()\n",
            "  )\n",
            "  (_conv_trans_0): Conv2d(74, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "  (_residual_stack): ResidualStack(\n",
            "    (_layers): ModuleList(\n",
            "      (0-63): 64 x Residual(\n",
            "        (_block): Sequential(\n",
            "          (0): ReLU(inplace=True)\n",
            "          (1): Conv2d(64, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (2): ReLU(inplace=True)\n",
            "          (3): Conv2d(3, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (_conv_trans_1): Sequential(\n",
            "    (0): ConvTranspose2d(74, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
            "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): LeakyReLU(negative_slope=0.2)\n",
            "    (3): ConvTranspose2d(32, 16, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
            "    (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): LeakyReLU(negative_slope=0.2)\n",
            "  )\n",
            ")\n",
            "Total number of parameters: 310465\n",
            "-----------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-09 13:58:14,076 fflow.py init [line:479] INFO Use `<class 'flgo.simulator.default_simulator.Simulator'>` as the system simulator\n",
            "2023-09-09 13:58:14,078 fflow.py init [line:487] INFO Ready to start.\n",
            "2023-09-09 13:58:14,085 fedbase.py run [line:236] INFO --------------Initial Evaluation--------------\n",
            "2023-09-09 13:58:14,086 simple_logger.py log_once [line:14] INFO Current_time:0\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "client 9 总样本数： 5357  各类： [ 366   24  126 4658   24    1   13   41   75   29]\n",
            "---------- Networks architecture -------------\n",
            "generator_pro(\n",
            "  (_conv_1): Sequential(\n",
            "    (0): Conv2d(1, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
            "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): LeakyReLU(negative_slope=0.2)\n",
            "    (3): Conv2d(32, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
            "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): LeakyReLU(negative_slope=0.2)\n",
            "    (6): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
            "    (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (8): LeakyReLU(negative_slope=0.2)\n",
            "  )\n",
            "  (conv_out): Sequential(\n",
            "    (0): ConvTranspose2d(16, 1, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
            "    (1): Tanh()\n",
            "  )\n",
            "  (_conv_trans_0): Conv2d(74, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "  (_residual_stack): ResidualStack(\n",
            "    (_layers): ModuleList(\n",
            "      (0-63): 64 x Residual(\n",
            "        (_block): Sequential(\n",
            "          (0): ReLU(inplace=True)\n",
            "          (1): Conv2d(64, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (2): ReLU(inplace=True)\n",
            "          (3): Conv2d(3, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (_conv_trans_1): Sequential(\n",
            "    (0): ConvTranspose2d(74, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
            "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): LeakyReLU(negative_slope=0.2)\n",
            "    (3): ConvTranspose2d(32, 16, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
            "    (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): LeakyReLU(negative_slope=0.2)\n",
            "  )\n",
            ")\n",
            "Total number of parameters: 310465\n",
            "-----------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-09 13:58:18,509 simple_logger.py log_once [line:28] INFO test_accuracy                 0.1125\n",
            "2023-09-09 13:58:18,510 simple_logger.py log_once [line:28] INFO test_loss                     2.3030\n",
            "2023-09-09 13:58:18,514 simple_logger.py log_once [line:28] INFO valid_accuracy                0.1032\n",
            "2023-09-09 13:58:18,515 simple_logger.py log_once [line:28] INFO mean_valid_accuracy           0.1021\n",
            "2023-09-09 13:58:18,520 simple_logger.py log_once [line:28] INFO std_valid_accuracy            0.1514\n",
            "2023-09-09 13:58:18,522 simple_logger.py log_once [line:28] INFO valid_loss                    2.3033\n",
            "2023-09-09 13:58:18,525 simple_logger.py log_once [line:28] INFO mean_valid_loss               2.3035\n",
            "2023-09-09 13:58:18,527 simple_logger.py log_once [line:28] INFO std_valid_loss                0.0101\n",
            "2023-09-09 13:58:18,530 fedbase.py run [line:239] INFO Eval Time Cost:               4.4442s\n",
            "<ipython-input-4-5bb4fcee325c>:810: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  global_loss.append((F.softmax(global_model(x_))*y_vec_).sum(-1).mean().item())\n",
            "<ipython-input-4-5bb4fcee325c>:534: UserWarning: torch.range is deprecated and will be removed in a future release because its behavior is inconsistent with Python's range builtin. Instead, use torch.arange, which produces values in [start, end).\n",
            "  mean_Y = torch.range(0, class_num - 1, dtype=torch.int64).repeat(batch_size // class_num)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "客户端选择： [3, 9]\n",
            "results/mnist_dir10/client 9[3, 0, 2, 8, 7, 9, 1, 4, 6, 5]\n",
            "client 9[3, 0, 2, 8, 7, 9, 1, 4, 6, 5] : training start!!\n",
            "0.09891659766435623\n",
            "=================================================================   \n",
            "0.09891706550180322\n",
            "=================================================================   \n",
            "torch.Size([100, 10]) torch.Size([100, 10])\n",
            "Avg one epoch time: 7.69, total 1 epochs time: 7.72\n",
            "Training finish!... save training results\n",
            "results/mnist_dir10/client 3[7, 2, 8, 3, 6, 4, 5, 9, 0, 1]\n",
            "client 3[7, 2, 8, 3, 6, 4, 5, 9, 0, 1] : training start!!\n",
            "0.10060808807611465\n",
            "=================================================================   \n",
            "0.10064628860442945\n",
            "=================================================================   \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-09 13:58:34,834 fedbase.py run [line:246] INFO --------------Round 1--------------\n",
            "2023-09-09 13:58:34,835 simple_logger.py log_once [line:14] INFO Current_time:1\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([100, 10]) torch.Size([100, 10])\n",
            "Avg one epoch time: 8.45, total 1 epochs time: 8.48\n",
            "Training finish!... save training results\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-09 13:58:38,008 simple_logger.py log_once [line:28] INFO test_accuracy                 0.2817\n",
            "2023-09-09 13:58:38,010 simple_logger.py log_once [line:28] INFO test_loss                     2.1572\n",
            "2023-09-09 13:58:38,012 simple_logger.py log_once [line:28] INFO valid_accuracy                0.2799\n",
            "2023-09-09 13:58:38,013 simple_logger.py log_once [line:28] INFO mean_valid_accuracy           0.2799\n",
            "2023-09-09 13:58:38,015 simple_logger.py log_once [line:28] INFO std_valid_accuracy            0.2913\n",
            "2023-09-09 13:58:38,017 simple_logger.py log_once [line:28] INFO valid_loss                    2.1578\n",
            "2023-09-09 13:58:38,018 simple_logger.py log_once [line:28] INFO mean_valid_loss               2.1584\n",
            "2023-09-09 13:58:38,020 simple_logger.py log_once [line:28] INFO std_valid_loss                0.2873\n",
            "2023-09-09 13:58:38,021 fedbase.py run [line:251] INFO Eval Time Cost:               3.1856s\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "客户端选择： [7, 6]\n",
            "results/mnist_dir10/client 6[8, 6, 9, 4, 5, 0, 7, 1, 2, 3]\n",
            "client 6[8, 6, 9, 4, 5, 0, 7, 1, 2, 3] : training start!!\n",
            "0.11721787601709366\n",
            "=================================================================   \n",
            "0.11552672220928835\n",
            "=================================================================   \n",
            "torch.Size([100, 10]) torch.Size([100, 10])\n",
            "Avg one epoch time: 9.65, total 1 epochs time: 9.68\n",
            "Training finish!... save training results\n",
            "results/mnist_dir10/client 7[1, 6, 3, 7, 0, 5, 4, 8, 9, 2]\n",
            "client 7[1, 6, 3, 7, 0, 5, 4, 8, 9, 2] : training start!!\n",
            "0.09432409703731537\n",
            "=================================================================   \n",
            "0.08952401430890111\n",
            "=================================================================   \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-09 13:58:55,568 fedbase.py run [line:246] INFO --------------Round 2--------------\n",
            "2023-09-09 13:58:55,573 simple_logger.py log_once [line:14] INFO Current_time:2\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([100, 10]) torch.Size([100, 10])\n",
            "Avg one epoch time: 7.72, total 1 epochs time: 7.75\n",
            "Training finish!... save training results\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-09 13:58:59,613 simple_logger.py log_once [line:28] INFO test_accuracy                 0.5857\n",
            "2023-09-09 13:58:59,614 simple_logger.py log_once [line:28] INFO test_loss                     1.5487\n",
            "2023-09-09 13:58:59,618 simple_logger.py log_once [line:28] INFO valid_accuracy                0.5863\n",
            "2023-09-09 13:58:59,621 simple_logger.py log_once [line:28] INFO mean_valid_accuracy           0.5866\n",
            "2023-09-09 13:58:59,623 simple_logger.py log_once [line:28] INFO std_valid_accuracy            0.2711\n",
            "2023-09-09 13:58:59,624 simple_logger.py log_once [line:28] INFO valid_loss                    1.5376\n",
            "2023-09-09 13:58:59,627 simple_logger.py log_once [line:28] INFO mean_valid_loss               1.5356\n",
            "2023-09-09 13:58:59,629 simple_logger.py log_once [line:28] INFO std_valid_loss                0.5233\n",
            "2023-09-09 13:58:59,631 fedbase.py run [line:251] INFO Eval Time Cost:               4.0584s\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "客户端选择： [1, 1]\n",
            "results/mnist_dir10/client 1[4, 9, 6, 5, 2, 3, 8, 1, 7, 0]\n",
            "client 1[4, 9, 6, 5, 2, 3, 8, 1, 7, 0] : training start!!\n",
            "0.29193049669265747\n",
            "=================================================================   \n",
            "0.2879748699983748\n",
            "=================================================================   \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-09 13:59:07,451 fedbase.py run [line:246] INFO --------------Round 3--------------\n",
            "2023-09-09 13:59:07,453 simple_logger.py log_once [line:14] INFO Current_time:3\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([100, 10]) torch.Size([100, 10])\n",
            "Avg one epoch time: 7.74, total 1 epochs time: 7.76\n",
            "Training finish!... save training results\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-09 13:59:11,886 simple_logger.py log_once [line:28] INFO test_accuracy                 0.6502\n",
            "2023-09-09 13:59:11,887 simple_logger.py log_once [line:28] INFO test_loss                     1.0457\n",
            "2023-09-09 13:59:11,891 simple_logger.py log_once [line:28] INFO valid_accuracy                0.6426\n",
            "2023-09-09 13:59:11,894 simple_logger.py log_once [line:28] INFO mean_valid_accuracy           0.6422\n",
            "2023-09-09 13:59:11,897 simple_logger.py log_once [line:28] INFO std_valid_accuracy            0.2418\n",
            "2023-09-09 13:59:11,899 simple_logger.py log_once [line:28] INFO valid_loss                    1.0644\n",
            "2023-09-09 13:59:11,902 simple_logger.py log_once [line:28] INFO mean_valid_loss               1.0647\n",
            "2023-09-09 13:59:11,906 simple_logger.py log_once [line:28] INFO std_valid_loss                0.7216\n",
            "2023-09-09 13:59:11,907 fedbase.py run [line:251] INFO Eval Time Cost:               4.4540s\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "客户端选择： [0, 8]\n",
            "results/mnist_dir10/client 0[9, 2, 1, 5, 6, 4, 3, 8, 0, 7]\n",
            "client 0[9, 2, 1, 5, 6, 4, 3, 8, 0, 7] : training start!!\n",
            "0.6721240282058716\n",
            "=================================================================   \n",
            "0.6985542538142441\n",
            "=================================================================   \n",
            "torch.Size([100, 10]) torch.Size([100, 10])\n",
            "Avg one epoch time: 7.96, total 1 epochs time: 7.99\n",
            "Training finish!... save training results\n",
            "results/mnist_dir10/client 8[5, 8, 1, 2, 3, 4, 9, 0, 7, 6]\n",
            "client 8[5, 8, 1, 2, 3, 4, 9, 0, 7, 6] : training start!!\n",
            "0.5003905892372131\n",
            "=================================================================   \n",
            "0.5466600030955702\n",
            "=================================================================   \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-09 13:59:28,637 fedbase.py run [line:246] INFO --------------Round 4--------------\n",
            "2023-09-09 13:59:28,638 simple_logger.py log_once [line:14] INFO Current_time:4\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([100, 10]) torch.Size([100, 10])\n",
            "Avg one epoch time: 8.63, total 1 epochs time: 8.66\n",
            "Training finish!... save training results\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-09 13:59:31,793 simple_logger.py log_once [line:28] INFO test_accuracy                 0.7133\n",
            "2023-09-09 13:59:31,794 simple_logger.py log_once [line:28] INFO test_loss                     1.0739\n",
            "2023-09-09 13:59:31,799 simple_logger.py log_once [line:28] INFO valid_accuracy                0.7132\n",
            "2023-09-09 13:59:31,801 simple_logger.py log_once [line:28] INFO mean_valid_accuracy           0.7133\n",
            "2023-09-09 13:59:31,804 simple_logger.py log_once [line:28] INFO std_valid_accuracy            0.3150\n",
            "2023-09-09 13:59:31,806 simple_logger.py log_once [line:28] INFO valid_loss                    1.0685\n",
            "2023-09-09 13:59:31,807 simple_logger.py log_once [line:28] INFO mean_valid_loss               1.0696\n",
            "2023-09-09 13:59:31,808 simple_logger.py log_once [line:28] INFO std_valid_loss                1.3659\n",
            "2023-09-09 13:59:31,809 fedbase.py run [line:251] INFO Eval Time Cost:               3.1713s\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "客户端选择： [6, 7]\n",
            "results/mnist_dir10/client 6[8, 6, 9, 4, 5, 0, 7, 1, 2, 3]\n",
            "client 6[8, 6, 9, 4, 5, 0, 7, 1, 2, 3] : training start!!\n",
            "0.7283065319061279\n",
            "=================================================================   \n",
            "0.7264273626969593\n",
            "=================================================================   \n",
            "torch.Size([100, 10]) torch.Size([100, 10])\n",
            "Avg one epoch time: 8.67, total 1 epochs time: 8.70\n",
            "Training finish!... save training results\n",
            "results/mnist_dir10/client 7[1, 6, 3, 7, 0, 5, 4, 8, 9, 2]\n",
            "client 7[1, 6, 3, 7, 0, 5, 4, 8, 9, 2] : training start!!\n",
            "0.8925402760505676\n",
            "=================================================================   \n",
            "0.8500473410776346\n",
            "=================================================================   \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-09 13:59:48,429 fedbase.py run [line:246] INFO --------------Round 5--------------\n",
            "2023-09-09 13:59:48,431 simple_logger.py log_once [line:14] INFO Current_time:5\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([100, 10]) torch.Size([100, 10])\n",
            "Avg one epoch time: 7.74, total 1 epochs time: 7.78\n",
            "Training finish!... save training results\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-09 13:59:52,641 simple_logger.py log_once [line:28] INFO test_accuracy                 0.7907\n",
            "2023-09-09 13:59:52,642 simple_logger.py log_once [line:28] INFO test_loss                     0.5807\n",
            "2023-09-09 13:59:52,644 simple_logger.py log_once [line:28] INFO valid_accuracy                0.7863\n",
            "2023-09-09 13:59:52,647 simple_logger.py log_once [line:28] INFO mean_valid_accuracy           0.7862\n",
            "2023-09-09 13:59:52,648 simple_logger.py log_once [line:28] INFO std_valid_accuracy            0.2607\n",
            "2023-09-09 13:59:52,650 simple_logger.py log_once [line:28] INFO valid_loss                    0.5918\n",
            "2023-09-09 13:59:52,652 simple_logger.py log_once [line:28] INFO mean_valid_loss               0.5918\n",
            "2023-09-09 13:59:52,653 simple_logger.py log_once [line:28] INFO std_valid_loss                0.6632\n",
            "2023-09-09 13:59:52,654 fedbase.py run [line:251] INFO Eval Time Cost:               4.2235s\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "客户端选择： [0, 9]\n",
            "results/mnist_dir10/client 0[9, 2, 1, 5, 6, 4, 3, 8, 0, 7]\n",
            "client 0[9, 2, 1, 5, 6, 4, 3, 8, 0, 7] : training start!!\n",
            "0.8568225502967834\n",
            "=================================================================   \n",
            "0.8686423024328629\n",
            "=================================================================   \n",
            "torch.Size([100, 10]) torch.Size([100, 10])\n",
            "Avg one epoch time: 7.90, total 1 epochs time: 7.93\n",
            "Training finish!... save training results\n",
            "results/mnist_dir10/client 9[3, 0, 2, 8, 7, 9, 1, 4, 6, 5]\n",
            "client 9[3, 0, 2, 8, 7, 9, 1, 4, 6, 5] : training start!!\n",
            "0.6620180606842041\n",
            "=================================================================   \n",
            "0.6278042754914501\n",
            "=================================================================   \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-09 14:00:09,351 fedbase.py run [line:246] INFO --------------Round 6--------------\n",
            "2023-09-09 14:00:09,352 simple_logger.py log_once [line:14] INFO Current_time:6\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([100, 10]) torch.Size([100, 10])\n",
            "Avg one epoch time: 8.47, total 1 epochs time: 8.50\n",
            "Training finish!... save training results\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-09 14:00:12,588 simple_logger.py log_once [line:28] INFO test_accuracy                 0.9030\n",
            "2023-09-09 14:00:12,590 simple_logger.py log_once [line:28] INFO test_loss                     0.2954\n",
            "2023-09-09 14:00:12,597 simple_logger.py log_once [line:28] INFO valid_accuracy                0.8999\n",
            "2023-09-09 14:00:12,598 simple_logger.py log_once [line:28] INFO mean_valid_accuracy           0.9003\n",
            "2023-09-09 14:00:12,600 simple_logger.py log_once [line:28] INFO std_valid_accuracy            0.1006\n",
            "2023-09-09 14:00:12,604 simple_logger.py log_once [line:28] INFO valid_loss                    0.3026\n",
            "2023-09-09 14:00:12,606 simple_logger.py log_once [line:28] INFO mean_valid_loss               0.3013\n",
            "2023-09-09 14:00:12,606 simple_logger.py log_once [line:28] INFO std_valid_loss                0.2658\n",
            "2023-09-09 14:00:12,607 fedbase.py run [line:251] INFO Eval Time Cost:               3.2551s\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "客户端选择： [8, 2]\n",
            "results/mnist_dir10/client 8[5, 8, 1, 2, 3, 4, 9, 0, 7, 6]\n",
            "client 8[5, 8, 1, 2, 3, 4, 9, 0, 7, 6] : training start!!\n",
            "0.8324941396713257\n",
            "=================================================================   \n",
            "0.8272947474281387\n",
            "=================================================================   \n",
            "torch.Size([100, 10]) torch.Size([100, 10])\n",
            "Avg one epoch time: 8.72, total 1 epochs time: 8.75\n",
            "Training finish!... save training results\n",
            "results/mnist_dir10/client 2[6, 1, 7, 4, 3, 8, 9, 5, 2, 0]\n",
            "client 2[6, 1, 7, 4, 3, 8, 9, 5, 2, 0] : training start!!\n",
            "0.9063405394554138\n",
            "=================================================================   \n",
            "0.9110897094896524\n",
            "=================================================================   \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-09 14:00:29,675 fedbase.py run [line:246] INFO --------------Round 7--------------\n",
            "2023-09-09 14:00:29,681 simple_logger.py log_once [line:14] INFO Current_time:7\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([100, 10]) torch.Size([100, 10])\n",
            "Avg one epoch time: 8.17, total 1 epochs time: 8.21\n",
            "Training finish!... save training results\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-09 14:00:33,192 simple_logger.py log_once [line:28] INFO test_accuracy                 0.9419\n",
            "2023-09-09 14:00:33,193 simple_logger.py log_once [line:28] INFO test_loss                     0.1993\n",
            "2023-09-09 14:00:33,199 simple_logger.py log_once [line:28] INFO valid_accuracy                0.9348\n",
            "2023-09-09 14:00:33,200 simple_logger.py log_once [line:28] INFO mean_valid_accuracy           0.9347\n",
            "2023-09-09 14:00:33,206 simple_logger.py log_once [line:28] INFO std_valid_accuracy            0.0743\n",
            "2023-09-09 14:00:33,207 simple_logger.py log_once [line:28] INFO valid_loss                    0.2093\n",
            "2023-09-09 14:00:33,209 simple_logger.py log_once [line:28] INFO mean_valid_loss               0.2096\n",
            "2023-09-09 14:00:33,212 simple_logger.py log_once [line:28] INFO std_valid_loss                0.2243\n",
            "2023-09-09 14:00:33,216 fedbase.py run [line:251] INFO Eval Time Cost:               3.5346s\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "客户端选择： [1, 1]\n",
            "results/mnist_dir10/client 1[4, 9, 6, 5, 2, 3, 8, 1, 7, 0]\n",
            "client 1[4, 9, 6, 5, 2, 3, 8, 1, 7, 0] : training start!!\n",
            "0.9398808479309082\n",
            "=================================================================   \n",
            "0.9315240790348241\n",
            "=================================================================   \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-09 14:00:41,138 fedbase.py run [line:246] INFO --------------Round 8--------------\n",
            "2023-09-09 14:00:41,144 simple_logger.py log_once [line:14] INFO Current_time:8\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([100, 10]) torch.Size([100, 10])\n",
            "Avg one epoch time: 7.79, total 1 epochs time: 7.82\n",
            "Training finish!... save training results\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-09 14:00:45,359 simple_logger.py log_once [line:28] INFO test_accuracy                 0.8919\n",
            "2023-09-09 14:00:45,360 simple_logger.py log_once [line:28] INFO test_loss                     0.3271\n",
            "2023-09-09 14:00:45,365 simple_logger.py log_once [line:28] INFO valid_accuracy                0.8862\n",
            "2023-09-09 14:00:45,368 simple_logger.py log_once [line:28] INFO mean_valid_accuracy           0.8861\n",
            "2023-09-09 14:00:45,369 simple_logger.py log_once [line:28] INFO std_valid_accuracy            0.1108\n",
            "2023-09-09 14:00:45,371 simple_logger.py log_once [line:28] INFO valid_loss                    0.3487\n",
            "2023-09-09 14:00:45,372 simple_logger.py log_once [line:28] INFO mean_valid_loss               0.3490\n",
            "2023-09-09 14:00:45,374 simple_logger.py log_once [line:28] INFO std_valid_loss                0.3215\n",
            "2023-09-09 14:00:45,375 fedbase.py run [line:251] INFO Eval Time Cost:               4.2312s\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "客户端选择： [3, 5]\n",
            "results/mnist_dir10/client 3[7, 2, 8, 3, 6, 4, 5, 9, 0, 1]\n",
            "client 3[7, 2, 8, 3, 6, 4, 5, 9, 0, 1] : training start!!\n",
            "0.7925887107849121\n",
            "=================================================================   \n",
            "0.7449040353888332\n",
            "=================================================================   \n",
            "torch.Size([100, 10]) torch.Size([100, 10])\n",
            "Avg one epoch time: 7.99, total 1 epochs time: 8.02\n",
            "Training finish!... save training results\n",
            "results/mnist_dir10/client 5[0, 9, 3, 5, 7, 1, 8, 4, 6, 2]\n",
            "client 5[0, 9, 3, 5, 7, 1, 8, 4, 6, 2] : training start!!\n",
            "0.45453470945358276\n",
            "=================================================================   \n",
            "0.42048062251345947\n",
            "=================================================================   \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-09 14:01:01,863 fedbase.py run [line:246] INFO --------------Round 9--------------\n",
            "2023-09-09 14:01:01,864 simple_logger.py log_once [line:14] INFO Current_time:9\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([100, 10]) torch.Size([100, 10])\n",
            "Avg one epoch time: 8.35, total 1 epochs time: 8.38\n",
            "Training finish!... save training results\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-09 14:01:05,141 simple_logger.py log_once [line:28] INFO test_accuracy                 0.9510\n",
            "2023-09-09 14:01:05,143 simple_logger.py log_once [line:28] INFO test_loss                     0.1953\n",
            "2023-09-09 14:01:05,147 simple_logger.py log_once [line:28] INFO valid_accuracy                0.9471\n",
            "2023-09-09 14:01:05,150 simple_logger.py log_once [line:28] INFO mean_valid_accuracy           0.9473\n",
            "2023-09-09 14:01:05,155 simple_logger.py log_once [line:28] INFO std_valid_accuracy            0.0240\n",
            "2023-09-09 14:01:05,156 simple_logger.py log_once [line:28] INFO valid_loss                    0.2096\n",
            "2023-09-09 14:01:05,158 simple_logger.py log_once [line:28] INFO mean_valid_loss               0.2093\n",
            "2023-09-09 14:01:05,161 simple_logger.py log_once [line:28] INFO std_valid_loss                0.0911\n",
            "2023-09-09 14:01:05,162 fedbase.py run [line:251] INFO Eval Time Cost:               3.2979s\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "客户端选择： [4, 2]\n",
            "results/mnist_dir10/client 2[6, 1, 7, 4, 3, 8, 9, 5, 2, 0]\n",
            "client 2[6, 1, 7, 4, 3, 8, 9, 5, 2, 0] : training start!!\n",
            "0.833840548992157\n",
            "=================================================================   \n",
            "0.8245809036906403\n",
            "=================================================================   \n",
            "torch.Size([100, 10]) torch.Size([100, 10])\n",
            "Avg one epoch time: 8.35, total 1 epochs time: 8.38\n",
            "Training finish!... save training results\n",
            "results/mnist_dir10/client 4[2, 5, 9, 7, 4, 0, 8, 3, 6, 1]\n",
            "client 4[2, 5, 9, 7, 4, 0, 8, 3, 6, 1] : training start!!\n",
            "0.7930159568786621\n",
            "=================================================================   \n",
            "0.8737813676937972\n",
            "=================================================================   \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-09 14:01:21,975 fedbase.py run [line:246] INFO --------------Round 10--------------\n",
            "2023-09-09 14:01:21,977 simple_logger.py log_once [line:14] INFO Current_time:10\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([100, 10]) torch.Size([100, 10])\n",
            "Avg one epoch time: 8.28, total 1 epochs time: 8.31\n",
            "Training finish!... save training results\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-09 14:01:25,737 simple_logger.py log_once [line:28] INFO test_accuracy                 0.9643\n",
            "2023-09-09 14:01:25,738 simple_logger.py log_once [line:28] INFO test_loss                     0.1191\n",
            "2023-09-09 14:01:25,745 simple_logger.py log_once [line:28] INFO valid_accuracy                0.9623\n",
            "2023-09-09 14:01:25,748 simple_logger.py log_once [line:28] INFO mean_valid_accuracy           0.9625\n",
            "2023-09-09 14:01:25,750 simple_logger.py log_once [line:28] INFO std_valid_accuracy            0.0278\n",
            "2023-09-09 14:01:25,753 simple_logger.py log_once [line:28] INFO valid_loss                    0.1295\n",
            "2023-09-09 14:01:25,756 simple_logger.py log_once [line:28] INFO mean_valid_loss               0.1287\n",
            "2023-09-09 14:01:25,757 simple_logger.py log_once [line:28] INFO std_valid_loss                0.0887\n",
            "2023-09-09 14:01:25,759 fedbase.py run [line:251] INFO Eval Time Cost:               3.7813s\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "客户端选择： [6, 1]\n",
            "results/mnist_dir10/client 1[4, 9, 6, 5, 2, 3, 8, 1, 7, 0]\n",
            "client 1[4, 9, 6, 5, 2, 3, 8, 1, 7, 0] : training start!!\n",
            "0.9590757489204407\n",
            "=================================================================   \n",
            "0.9606681950021498\n",
            "=================================================================   \n",
            "torch.Size([100, 10]) torch.Size([100, 10])\n",
            "Avg one epoch time: 7.61, total 1 epochs time: 7.64\n",
            "Training finish!... save training results\n",
            "results/mnist_dir10/client 6[8, 6, 9, 4, 5, 0, 7, 1, 2, 3]\n",
            "client 6[8, 6, 9, 4, 5, 0, 7, 1, 2, 3] : training start!!\n",
            "0.8502587080001831\n",
            "=================================================================   \n",
            "0.8193918696724543\n",
            "=================================================================   \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-09 14:01:42,061 fedbase.py run [line:246] INFO --------------Round 11--------------\n",
            "2023-09-09 14:01:42,062 simple_logger.py log_once [line:14] INFO Current_time:11\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([100, 10]) torch.Size([100, 10])\n",
            "Avg one epoch time: 8.53, total 1 epochs time: 8.56\n",
            "Training finish!... save training results\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-09 14:01:45,185 simple_logger.py log_once [line:28] INFO test_accuracy                 0.8668\n",
            "2023-09-09 14:01:45,187 simple_logger.py log_once [line:28] INFO test_loss                     0.4549\n",
            "2023-09-09 14:01:45,192 simple_logger.py log_once [line:28] INFO valid_accuracy                0.8504\n",
            "2023-09-09 14:01:45,194 simple_logger.py log_once [line:28] INFO mean_valid_accuracy           0.8499\n",
            "2023-09-09 14:01:45,199 simple_logger.py log_once [line:28] INFO std_valid_accuracy            0.1009\n",
            "2023-09-09 14:01:45,200 simple_logger.py log_once [line:28] INFO valid_loss                    0.4836\n",
            "2023-09-09 14:01:45,205 simple_logger.py log_once [line:28] INFO mean_valid_loss               0.4847\n",
            "2023-09-09 14:01:45,207 simple_logger.py log_once [line:28] INFO std_valid_loss                0.3065\n",
            "2023-09-09 14:01:45,208 fedbase.py run [line:251] INFO Eval Time Cost:               3.1459s\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "客户端选择： [2, 3]\n",
            "results/mnist_dir10/client 2[6, 1, 7, 4, 3, 8, 9, 5, 2, 0]\n",
            "client 2[6, 1, 7, 4, 3, 8, 9, 5, 2, 0] : training start!!\n",
            "0.7399051189422607\n",
            "=================================================================   \n",
            "0.7236505617009531\n",
            "=================================================================   \n",
            "torch.Size([100, 10]) torch.Size([100, 10])\n",
            "Avg one epoch time: 8.30, total 1 epochs time: 8.33\n",
            "Training finish!... save training results\n",
            "results/mnist_dir10/client 3[7, 2, 8, 3, 6, 4, 5, 9, 0, 1]\n",
            "client 3[7, 2, 8, 3, 6, 4, 5, 9, 0, 1] : training start!!\n",
            "0.6499636173248291\n",
            "=================================================================   \n",
            "0.6585694451143246\n",
            "=================================================================   \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-09 14:02:01,847 fedbase.py run [line:246] INFO --------------Round 12--------------\n",
            "2023-09-09 14:02:01,850 simple_logger.py log_once [line:14] INFO Current_time:12\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([100, 10]) torch.Size([100, 10])\n",
            "Avg one epoch time: 8.15, total 1 epochs time: 8.19\n",
            "Training finish!... save training results\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-09 14:02:05,365 simple_logger.py log_once [line:28] INFO test_accuracy                 0.8938\n",
            "2023-09-09 14:02:05,367 simple_logger.py log_once [line:28] INFO test_loss                     0.3108\n",
            "2023-09-09 14:02:05,371 simple_logger.py log_once [line:28] INFO valid_accuracy                0.8891\n",
            "2023-09-09 14:02:05,374 simple_logger.py log_once [line:28] INFO mean_valid_accuracy           0.8892\n",
            "2023-09-09 14:02:05,376 simple_logger.py log_once [line:28] INFO std_valid_accuracy            0.1048\n",
            "2023-09-09 14:02:05,377 simple_logger.py log_once [line:28] INFO valid_loss                    0.3335\n",
            "2023-09-09 14:02:05,379 simple_logger.py log_once [line:28] INFO mean_valid_loss               0.3333\n",
            "2023-09-09 14:02:05,380 simple_logger.py log_once [line:28] INFO std_valid_loss                0.3241\n",
            "2023-09-09 14:02:05,381 fedbase.py run [line:251] INFO Eval Time Cost:               3.5310s\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "客户端选择： [4, 7]\n",
            "results/mnist_dir10/client 4[2, 5, 9, 7, 4, 0, 8, 3, 6, 1]\n",
            "client 4[2, 5, 9, 7, 4, 0, 8, 3, 6, 1] : training start!!\n",
            "0.6908445358276367\n",
            "=================================================================   \n",
            "0.7526119599247924\n",
            "=================================================================   \n",
            "torch.Size([100, 10]) torch.Size([100, 10])\n",
            "Avg one epoch time: 8.24, total 1 epochs time: 8.28\n",
            "Training finish!... save training results\n",
            "results/mnist_dir10/client 7[1, 6, 3, 7, 0, 5, 4, 8, 9, 2]\n",
            "client 7[1, 6, 3, 7, 0, 5, 4, 8, 9, 2] : training start!!\n",
            "0.9426652193069458\n",
            "=================================================================   \n",
            "0.9435473898849865\n",
            "=================================================================   \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-09 14:02:22,005 fedbase.py run [line:246] INFO --------------Round 13--------------\n",
            "2023-09-09 14:02:22,006 simple_logger.py log_once [line:14] INFO Current_time:13\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([100, 10]) torch.Size([100, 10])\n",
            "Avg one epoch time: 8.20, total 1 epochs time: 8.23\n",
            "Training finish!... save training results\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-09 14:02:25,245 simple_logger.py log_once [line:28] INFO test_accuracy                 0.9639\n",
            "2023-09-09 14:02:25,246 simple_logger.py log_once [line:28] INFO test_loss                     0.1366\n",
            "2023-09-09 14:02:25,251 simple_logger.py log_once [line:28] INFO valid_accuracy                0.9620\n",
            "2023-09-09 14:02:25,254 simple_logger.py log_once [line:28] INFO mean_valid_accuracy           0.9620\n",
            "2023-09-09 14:02:25,258 simple_logger.py log_once [line:28] INFO std_valid_accuracy            0.0281\n",
            "2023-09-09 14:02:25,259 simple_logger.py log_once [line:28] INFO valid_loss                    0.1470\n",
            "2023-09-09 14:02:25,262 simple_logger.py log_once [line:28] INFO mean_valid_loss               0.1470\n",
            "2023-09-09 14:02:25,263 simple_logger.py log_once [line:28] INFO std_valid_loss                0.1191\n",
            "2023-09-09 14:02:25,264 fedbase.py run [line:251] INFO Eval Time Cost:               3.2580s\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "客户端选择： [2, 5]\n",
            "results/mnist_dir10/client 2[6, 1, 7, 4, 3, 8, 9, 5, 2, 0]\n",
            "client 2[6, 1, 7, 4, 3, 8, 9, 5, 2, 0] : training start!!\n",
            "0.961050271987915\n",
            "=================================================================   \n",
            "0.9635915880156035\n",
            "=================================================================   \n",
            "torch.Size([100, 10]) torch.Size([100, 10])\n",
            "Avg one epoch time: 8.81, total 1 epochs time: 8.83\n",
            "Training finish!... save training results\n",
            "results/mnist_dir10/client 5[0, 9, 3, 5, 7, 1, 8, 4, 6, 2]\n",
            "client 5[0, 9, 3, 5, 7, 1, 8, 4, 6, 2] : training start!!\n",
            "0.737980306148529\n",
            "=================================================================   \n",
            "0.7314081280538351\n",
            "=================================================================   \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-09 14:02:42,857 fedbase.py run [line:246] INFO --------------Round 14--------------\n",
            "2023-09-09 14:02:42,858 simple_logger.py log_once [line:14] INFO Current_time:14\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([100, 10]) torch.Size([100, 10])\n",
            "Avg one epoch time: 8.64, total 1 epochs time: 8.67\n",
            "Training finish!... save training results\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-09 14:02:46,211 simple_logger.py log_once [line:28] INFO test_accuracy                 0.9577\n",
            "2023-09-09 14:02:46,212 simple_logger.py log_once [line:28] INFO test_loss                     0.1621\n",
            "2023-09-09 14:02:46,215 simple_logger.py log_once [line:28] INFO valid_accuracy                0.9551\n",
            "2023-09-09 14:02:46,217 simple_logger.py log_once [line:28] INFO mean_valid_accuracy           0.9556\n",
            "2023-09-09 14:02:46,218 simple_logger.py log_once [line:28] INFO std_valid_accuracy            0.0360\n",
            "2023-09-09 14:02:46,220 simple_logger.py log_once [line:28] INFO valid_loss                    0.1680\n",
            "2023-09-09 14:02:46,222 simple_logger.py log_once [line:28] INFO mean_valid_loss               0.1669\n",
            "2023-09-09 14:02:46,223 simple_logger.py log_once [line:28] INFO std_valid_loss                0.1084\n",
            "2023-09-09 14:02:46,224 fedbase.py run [line:251] INFO Eval Time Cost:               3.3654s\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "客户端选择： [5, 0]\n",
            "results/mnist_dir10/client 0[9, 2, 1, 5, 6, 4, 3, 8, 0, 7]\n",
            "client 0[9, 2, 1, 5, 6, 4, 3, 8, 0, 7] : training start!!\n",
            "0.873197078704834\n",
            "=================================================================   \n",
            "0.9020550610995529\n",
            "=================================================================   \n",
            "torch.Size([100, 10]) torch.Size([100, 10])\n",
            "Avg one epoch time: 8.57, total 1 epochs time: 8.61\n",
            "Training finish!... save training results\n",
            "results/mnist_dir10/client 5[0, 9, 3, 5, 7, 1, 8, 4, 6, 2]\n",
            "client 5[0, 9, 3, 5, 7, 1, 8, 4, 6, 2] : training start!!\n",
            "0.8012830018997192\n",
            "=================================================================   \n",
            "0.7970168454812305\n",
            "=================================================================   \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-09 14:03:03,288 fedbase.py run [line:246] INFO --------------Round 15--------------\n",
            "2023-09-09 14:03:03,289 simple_logger.py log_once [line:14] INFO Current_time:15\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([100, 10]) torch.Size([100, 10])\n",
            "Avg one epoch time: 8.31, total 1 epochs time: 8.34\n",
            "Training finish!... save training results\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-09 14:03:07,110 simple_logger.py log_once [line:28] INFO test_accuracy                 0.9303\n",
            "2023-09-09 14:03:07,112 simple_logger.py log_once [line:28] INFO test_loss                     0.2199\n",
            "2023-09-09 14:03:07,116 simple_logger.py log_once [line:28] INFO valid_accuracy                0.9239\n",
            "2023-09-09 14:03:07,118 simple_logger.py log_once [line:28] INFO mean_valid_accuracy           0.9244\n",
            "2023-09-09 14:03:07,119 simple_logger.py log_once [line:28] INFO std_valid_accuracy            0.0648\n",
            "2023-09-09 14:03:07,125 simple_logger.py log_once [line:28] INFO valid_loss                    0.2303\n",
            "2023-09-09 14:03:07,126 simple_logger.py log_once [line:28] INFO mean_valid_loss               0.2287\n",
            "2023-09-09 14:03:07,127 simple_logger.py log_once [line:28] INFO std_valid_loss                0.1818\n",
            "2023-09-09 14:03:07,128 fedbase.py run [line:251] INFO Eval Time Cost:               3.8395s\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "客户端选择： [6, 1]\n",
            "results/mnist_dir10/client 1[4, 9, 6, 5, 2, 3, 8, 1, 7, 0]\n",
            "client 1[4, 9, 6, 5, 2, 3, 8, 1, 7, 0] : training start!!\n",
            "0.9218599796295166\n",
            "=================================================================   \n",
            "0.8642343383024235\n",
            "=================================================================   \n",
            "torch.Size([100, 10]) torch.Size([100, 10])\n",
            "Avg one epoch time: 8.20, total 1 epochs time: 8.23\n",
            "Training finish!... save training results\n",
            "results/mnist_dir10/client 6[8, 6, 9, 4, 5, 0, 7, 1, 2, 3]\n",
            "client 6[8, 6, 9, 4, 5, 0, 7, 1, 2, 3] : training start!!\n",
            "0.5886183381080627\n",
            "=================================================================   \n",
            "0.6838312125442052\n",
            "=================================================================   \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-09 14:03:24,094 fedbase.py run [line:246] INFO --------------Round 16--------------\n",
            "2023-09-09 14:03:24,095 simple_logger.py log_once [line:14] INFO Current_time:16\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([100, 10]) torch.Size([100, 10])\n",
            "Avg one epoch time: 8.62, total 1 epochs time: 8.65\n",
            "Training finish!... save training results\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-09 14:03:27,372 simple_logger.py log_once [line:28] INFO test_accuracy                 0.9478\n",
            "2023-09-09 14:03:27,374 simple_logger.py log_once [line:28] INFO test_loss                     0.2020\n",
            "2023-09-09 14:03:27,377 simple_logger.py log_once [line:28] INFO valid_accuracy                0.9418\n",
            "2023-09-09 14:03:27,379 simple_logger.py log_once [line:28] INFO mean_valid_accuracy           0.9419\n",
            "2023-09-09 14:03:27,381 simple_logger.py log_once [line:28] INFO std_valid_accuracy            0.0451\n",
            "2023-09-09 14:03:27,385 simple_logger.py log_once [line:28] INFO valid_loss                    0.2142\n",
            "2023-09-09 14:03:27,386 simple_logger.py log_once [line:28] INFO mean_valid_loss               0.2141\n",
            "2023-09-09 14:03:27,389 simple_logger.py log_once [line:28] INFO std_valid_loss                0.1238\n",
            "2023-09-09 14:03:27,390 fedbase.py run [line:251] INFO Eval Time Cost:               3.2951s\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "客户端选择： [0, 9]\n",
            "results/mnist_dir10/client 0[9, 2, 1, 5, 6, 4, 3, 8, 0, 7]\n",
            "client 0[9, 2, 1, 5, 6, 4, 3, 8, 0, 7] : training start!!\n",
            "0.9110004901885986\n",
            "=================================================================   \n",
            "0.9359661441038151\n",
            "=================================================================   \n",
            "torch.Size([100, 10]) torch.Size([100, 10])\n",
            "Avg one epoch time: 8.54, total 1 epochs time: 8.57\n",
            "Training finish!... save training results\n",
            "results/mnist_dir10/client 9[3, 0, 2, 8, 7, 9, 1, 4, 6, 5]\n",
            "client 9[3, 0, 2, 8, 7, 9, 1, 4, 6, 5] : training start!!\n",
            "0.8737199306488037\n",
            "=================================================================   \n",
            "0.8118316708224835\n",
            "=================================================================   \n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-516231328048>\u001b[0m in \u001b[0;36m<cell line: 208>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[0mrunner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m \u001b[0mrunner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/content/FLGo/flgo/algorithm/fedbase.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    241\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m             \u001b[0;31m# iterate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 243\u001b[0;31m             \u001b[0mupdated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    244\u001b[0m             \u001b[0;31m# using logger to evaluate the model if the model is updated\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    245\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mupdated\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mTrue\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mupdated\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/FLGo/flgo/algorithm/fedbase.py\u001b[0m in \u001b[0;36miterate\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    272\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselected_clients\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m         \u001b[0;31m# training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 274\u001b[0;31m         \u001b[0mmodels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommunicate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselected_clients\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'model'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    275\u001b[0m         \u001b[0;31m# aggregate: pk = 1/K as default where K=len(selected_clients)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maggregate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/FLGo/flgo/simulator/base.py\u001b[0m in \u001b[0;36mcommunicate_with_dropout\u001b[0;34m(self, selected_clients, mtype, asynchronous)\u001b[0m\n\u001b[1;32m    465\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dropped_selected_clients\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcid\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcid\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mprob\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mselected_clients\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprobs_drop\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msimulator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mprob\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    466\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msimulator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_client_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dropped_selected_clients\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'dropped'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 467\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcommunicate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcid\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcid\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mselected_clients\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mcid\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dropped_selected_clients\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0masynchronous\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    468\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    469\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mcommunicate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mselected_clients\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0masynchronous\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/FLGo/flgo/simulator/base.py\u001b[0m in \u001b[0;36mcommunicate_with_clock\u001b[0;34m(self, selected_clients, mtype, asynchronous)\u001b[0m\n\u001b[1;32m    549\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcommunicate_with_clock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mselected_clients\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0masynchronous\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msimulator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_client_completeness\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mselected_clients\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 551\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcommunicate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mselected_clients\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0masynchronous\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    552\u001b[0m         \u001b[0;31m# If all the selected clients are unavailable, directly return the result without waiting.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m         \u001b[0;31m# Else if all the available clients have dropped out and not using asynchronous communication,  waiting for `tolerance_for_latency` time units.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/FLGo/flgo/algorithm/fedbase.py\u001b[0m in \u001b[0;36mcommunicate\u001b[0;34m(self, selected_clients, mtype, asynchronous)\u001b[0m\n\u001b[1;32m    304\u001b[0m                 \u001b[0mserver_pkg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclient_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    305\u001b[0m                 \u001b[0mserver_pkg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'__mtype__'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 306\u001b[0;31m                 \u001b[0mresponse_from_client_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommunicate_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclients\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mclient_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpackage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mserver_pkg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    307\u001b[0m                 \u001b[0mpackages_received_from_clients\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse_from_client_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/FLGo/flgo/simulator/base.py\u001b[0m in \u001b[0;36mdelayed_communicate_with\u001b[0;34m(self, target_id, package)\u001b[0m\n\u001b[1;32m    493\u001b[0m         \u001b[0;31m# Set downloading package sizes for clients for downloading cost estimation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msimulator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_variable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__download_package_size'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msize_of_package\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpackage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 495\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcommunicate_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpackage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    496\u001b[0m         \u001b[0;31m# Set uploading package sizes for clients for uploading cost estimation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    497\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msimulator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_variable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__upload_package_size'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize_of_package\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/FLGo/flgo/algorithm/fedbase.py\u001b[0m in \u001b[0;36mcommunicate_with\u001b[0;34m(self, target_id, package)\u001b[0m\n\u001b[1;32m    347\u001b[0m             \u001b[0mwill\u001b[0m \u001b[0mbe\u001b[0m \u001b[0;34m'None'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mlosing\u001b[0m \u001b[0mconnection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m         \"\"\"\n\u001b[0;32m--> 349\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBasicServer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommunicate_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpackage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    350\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclient_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/FLGo/flgo/algorithm/fedbase.py\u001b[0m in \u001b[0;36mcommunicate_with\u001b[0;34m(self, target_id, package)\u001b[0m\n\u001b[1;32m    188\u001b[0m             \u001b[0mclient_package\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0mobject\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mwill\u001b[0m \u001b[0mbe\u001b[0m \u001b[0;34m'None'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mlosing\u001b[0m \u001b[0mconnection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         \"\"\"\n\u001b[0;32m--> 190\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommunicator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpackage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    191\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minitialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/FLGo/flgo/__init__.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, source, target, package)\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpackage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;31m# send package to the target object with `package` and `mtype`, and then listen from it\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobjects_map\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage_handler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpackage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/content/FLGo/flgo/algorithm/fedbase.py\u001b[0m in \u001b[0;36mmessage_handler\u001b[0;34m(self, package)\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmtype\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"There is no action corresponding to message type {}.\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmtype\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpackage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mset_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflag\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-5-516231328048>\u001b[0m in \u001b[0;36mreply\u001b[0;34m(self, svr_pkg)\u001b[0m\n\u001b[1;32m     96\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgan\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mD_p\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msamples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgan\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mgan_args\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mglobal_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m     \u001b[0mcpkg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgan\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mD\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mcpkg\u001b[0m \u001b[0;31m#client_pkg (dict): the package to be send to the server\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-4-5bb4fcee325c>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, client, gan_epoch, global_model, optimizer)\u001b[0m\n\u001b[1;32m    812\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m                 \u001b[0mprint_head\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Epoch: [%2d] [%4d/%4d]\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0miter\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 814\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclient\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_vec_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_distribution\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglobal_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprint_head\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    815\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    816\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_hist\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'per_epoch_time'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mepoch_start_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-4-5bb4fcee325c>\u001b[0m in \u001b[0;36mtrain_step\u001b[0;34m(self, client, x_, y_vec_, iter, y_distribution, global_model, optimizer, print_head)\u001b[0m\n\u001b[1;32m    620\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 622\u001b[0;31m         \u001b[0mG_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    623\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_grad\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_grad_norm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_norm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_grad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    624\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mG_optimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    485\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m             )\n\u001b[0;32m--> 487\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    488\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    198\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    201\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "from flgo.algorithm.fedbase import BasicServer, BasicClient\n",
        "import flgo.algorithm.fedavg as fedavg\n",
        "os.chdir('/content/GAN')\n",
        "#from infoGAN import infoGAN\n",
        "os.chdir(BASEPATH)\n",
        "import copy\n",
        "from flgo.utils import fmodule\n",
        "import flgo\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "import json\n",
        "import importlib\n",
        "\n",
        "def get_default_model(task):\n",
        "  with open(os.path.join(task, 'info'), 'r') as inf:\n",
        "    task_info = json.load(inf)\n",
        "  benchmark = task_info['benchmark']\n",
        "  bmk_module = importlib.import_module(benchmark)\n",
        "  model = getattr(bmk_module, 'default_model')\n",
        "  return model.Model\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# 使用生成器对象生成随机数\n",
        "#random_number = rng_sample.random()\n",
        "#print(random_number)\n",
        "\n",
        "\n",
        "class Server(BasicServer):\n",
        "  def initialize(self, *args, **kwargs):\n",
        "    # 指定随机种子创建随机数生成器对象\n",
        "    np.random.seed(0)\n",
        "    self.rng_sample = np.random.RandomState(42) #采样客户端专用的随机数生成器，以免在其他地方改变随机数列表\n",
        "  def pack(self, client_id, mtype=0, *args, **kwargs):\n",
        "    return {\n",
        "        \"model\": copy.deepcopy(self.model),\n",
        "        \"round\": self.current_round,\n",
        "    }\n",
        "  def sample(self):\n",
        "    all_clients = self.available_clients if 'available' in self.sample_option else [cid for cid in range(self.num_clients)]\n",
        "    # full sampling with unlimited communication resources of the server\n",
        "    if 'full' in self.sample_option:\n",
        "        return all_clients\n",
        "    # sample clients\n",
        "    elif 'uniform' in self.sample_option:\n",
        "        # original sample proposed by fedavg\n",
        "        selected_clients = list(\n",
        "            self.rng_sample.choice(all_clients, min(self.clients_per_round, len(all_clients)), replace=False)) if len(\n",
        "            all_clients) > 0 else []\n",
        "    elif 'md' in self.sample_option:\n",
        "        # the default setting that is introduced by FedProx, where the clients are sampled with the probability in proportion to their local_movielens_recommendation data sizes\n",
        "        local_data_vols = [self.clients[cid].datavol for cid in all_clients]\n",
        "        total_data_vol = sum(local_data_vols)\n",
        "        p = np.array(local_data_vols) / total_data_vol\n",
        "        selected_clients = list(self.rng_sample.choice(all_clients, self.clients_per_round, replace=True, p=p)) if len(\n",
        "            all_clients) > 0 else []\n",
        "    print('客户端选择：',selected_clients)\n",
        "    return selected_clients\n",
        "class Client(BasicClient):\n",
        "  def initialize(self, *args, **kwargs):\n",
        "    self.clip_grad = 20 #(默认为0)\n",
        "    self.clip_grad_GAN = 20 #20\n",
        "    data_shape = self.train_data[0][0].shape\n",
        "    gan_args.task = self.option['task'].replace('/','').replace('.','')\n",
        "    self.C=self.get_loc_data()\n",
        "    c = self.C.topk(k=10).indices\n",
        "    self.gan = my_ACGAN(self,gan_args,data_shape[0],data_shape[1],loc_c=self.C,name='client '+str(self.id)+str(c.tolist()))\n",
        "    #self.local_d = self.gan.D.__class__().to(self.gan.D.get_device())\n",
        "  def unpack(self, received_pkg):\n",
        "    return received_pkg['model'],received_pkg['round']\n",
        "  def get_loc_data(self):\n",
        "    date_num=len(self.train_data.indices)\n",
        "    data_loader = self.calculator.get_dataloader(self.train_data, batch_size=date_num)\n",
        "    y_ = data_loader.__iter__().__next__()[1]\n",
        "    y_vec_ = torch.zeros((y_.shape[0], 10)).scatter_(1, y_.type(torch.LongTensor).unsqueeze(1), 1)\n",
        "    c = y_vec_.sum(0)\n",
        "    print(\"client\",self.id,\"总样本数：\",date_num,\" 各类：\", c.int().numpy())\n",
        "    return c\n",
        "  def reply0(self, svr_pkg):\n",
        "    model,self.round = self.unpack(svr_pkg) #svr_pkg (dict): the package received from the server\n",
        "    self.train(model)\n",
        "    cpkg = self.pack(model)\n",
        "    return cpkg #client_pkg (dict): the package to be send to the server\n",
        "  def reply(self, svr_pkg):\n",
        "    model,self.round = self.unpack(svr_pkg) #svr_pkg (dict): the package received from the server\n",
        "    if self.gan.D==None:\n",
        "      self.gan.D=copy.deepcopy(model)\n",
        "    else:\n",
        "      params_d,params_cont,params_z = self.gan.D.fc_d.state_dict(),self.gan.D.fc_cont.state_dict(),self.gan.D.fc_z.state_dict()\n",
        "      params = model.state_dict()\n",
        "      self.gan.D.load_state_dict(params)#要注意两者的初始化不同\n",
        "      #self.gan.D.fc_d.load_state_dict(params_d)\n",
        "      self.gan.D.fc_cont.load_state_dict(params_cont)\n",
        "      self.gan.D.fc_z.load_state_dict(params_z)\n",
        "      self.gan.D_p.init()\n",
        "\n",
        "    self.samples = self.gan.train(self,gan_args.epoch,global_model=model)\n",
        "    cpkg = self.pack(self.gan.D)\n",
        "    return cpkg #client_pkg (dict): the package to be send to the server\n",
        "  '''\n",
        "  def train(self, model):\n",
        "    model.train()\n",
        "    optimizer = self.calculator.get_optimizer(model, lr=self.learning_rate, weight_decay=self.weight_decay, momentum=self.momentum)\n",
        "    for iter in range(self.num_steps):\n",
        "        # get a batch of data\n",
        "        batch_data = self.get_batch_data()\n",
        "        model.zero_grad()\n",
        "        # calculate the loss of the model on batched dataset through task-specified calculator\n",
        "        loss = self.calculator.compute_loss(model, batch_data)['loss']\n",
        "        loss.backward()\n",
        "        if self.clip_grad>0:torch.nn.utils.clip_grad_norm_(parameters=model.parameters(), max_norm=self.clip_grad)\n",
        "        optimizer.step()\n",
        "    return\n",
        "  '''\n",
        "class test:\n",
        "    Server=Server\n",
        "    Client=Client\n",
        "class test2:\n",
        "    Server=Server\n",
        "    Client=BasicClient\n",
        "\n",
        "gan_args=parse_args()\n",
        "gan_args.gpu_mode=torch.cuda.is_available()\n",
        "gan_args.epoch=1\n",
        "gan_args.lrD=0.01\n",
        "gan_args.lrG=0.005\n",
        "#gan_args.batch_size=10\n",
        "print('参数：',gan_args)\n",
        "\n",
        "task,benchmark = './mnist_dir10' , 'flgo.benchmark.mnist_classification'\n",
        "#task,benchmark = './cifar10_dir10','flgo.benchmark.cifar10_classification'\n",
        "#task,benchmark  = './svhn_dir10','flgo.benchmark.svhn_classification'\n",
        "#task,benchmark = './fashion_dir10', 'flgo.benchmark.fashion_classification'\n",
        "config_dir01 = {'benchmark':{'name':benchmark},'partitioner':{'name': 'DirichletPartitioner',\\\n",
        "          'para':{'num_clients':10, 'alpha':0.1}}}\n",
        "config_dir10 = {'benchmark':{'name':benchmark},'partitioner':{'name': 'DirichletPartitioner',\\\n",
        "          'para':{'num_clients':10, 'alpha':1.0}}}\n",
        "config_dir100 = {'benchmark':{'name':benchmark},'partitioner':{'name': 'DirichletPartitioner',\\\n",
        "          'para':{'num_clients':10, 'alpha':10.0}}}\n",
        "\n",
        "#!rm -r $task\n",
        "if not os.path.exists(task): flgo.gen_task(config_dir10, task_path = task)\n",
        "option = {'num_rounds':50, 'num_epochs':1, 'batch_size':32, 'learning_rate':0.1, 'gpu':0 if torch.cuda.is_available() else ''}\n",
        "!rm -r /content/FLGo/results\n",
        "\n",
        "base_Model=get_default_model(task)\n",
        "\n",
        "# 定义一个自定义的模型类 Model，继承自 base_Model\n",
        "class Model(base_Model):\n",
        "    def __init__(self):\n",
        "        # 调用基类 base_Model 的初始化方法\n",
        "        base_Model.__init__(self)\n",
        "        # 获取模型最后一层的名称\n",
        "        first_layer_name,self.fc_layer_name = self.get_first_last_layer_name()\n",
        "        last_layer = getattr(self, self.fc_layer_name)\n",
        "        first_layer = getattr(self, first_layer_name)\n",
        "        # 获取最后一层的输入维度\n",
        "        input_dim = last_layer.in_features\n",
        "        self.fc_d = nn.Linear(input_dim, 1) #output_dim\n",
        "        self.fc_cont = nn.Linear(input_dim, 2) #len_continuous_code\n",
        "        self.fc_z = nn.Linear(input_dim, 62) #len_continuous_code\n",
        "        utils.initialize_weights(self)\n",
        "    def __class__(self): #重要\n",
        "        return Model()\n",
        "    def forward(self, x, mode='test'):\n",
        "        emb = self.get_embedding(x)\n",
        "        return self.get_result(emb,mode)\n",
        "    def get_result(self, emb, mode='test'):\n",
        "        # 获取最后一层的全连接层\n",
        "        fc = getattr(self, self.fc_layer_name)\n",
        "        c = fc(emb)\n",
        "        if mode=='test':\n",
        "          return c\n",
        "        else:\n",
        "          x2 = self.fc_d(emb).squeeze()\n",
        "          a = F.sigmoid(x2)\n",
        "          b = self.fc_cont(emb)\n",
        "        if mode=='train':\n",
        "          return a, b, c\n",
        "        else:\n",
        "          z = self.fc_z(emb)\n",
        "          return a, b, c, z\n",
        "    def get_first_last_layer_name(self):\n",
        "      # 遍历模型的子模块，获取最后一层的名称,再加一个获取第一层名称\n",
        "      last_layer_name = None\n",
        "      first_layer_name = None\n",
        "      # 遍历模型的子模块，通过 self.named_children() 获取子模块的名称和实例\n",
        "      for name, _ in self.named_children():\n",
        "          if first_layer_name is None:\n",
        "              first_layer_name = name  # 获取第一层的名称\n",
        "          last_layer_name = name  # 遍历，每次更新最后一层的名称\n",
        "      return first_layer_name, last_layer_name\n",
        "\n",
        "def init_local_module(object):\n",
        "    pass\n",
        "def init_global_module(object):\n",
        "    if 'Server' in object.__class__.__name__: #重要\n",
        "        object.model = Model().to(object.device)\n",
        "class model_DC:\n",
        "    init_local_module = init_local_module\n",
        "    init_global_module = init_global_module\n",
        "\n",
        "runner = flgo.init(task, test, option=option, model=model_DC)\n",
        "#runner = flgo.init(task, fedavg, option=option, model=model_DC)\n",
        "torch.cuda.empty_cache()\n",
        "runner.model\n",
        "runner.run()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cqcBJ9nGOprQ",
        "outputId": "9f0fd3aa-c4b9-456b-a3f6-2869152d47b6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "8"
            ]
          },
          "execution_count": 47,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "32//4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pgA2h6KWeiW6",
        "outputId": "dcf25ae2-3edb-4a1c-b757-bdeba46ef7a5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "33.94112549695428"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 这样设计的patchGAN判别器怎么样\n",
        "self.conv1 = nn.Sequential(\n",
        "            nn.Conv2d(self.input_dim, 64, 3, 2, 1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Conv2d(64, 128, 1, 1, 0),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Conv2d(128, self.output_dim, 3, 1, 0),\n",
        "        )\n",
        "self.patch_conv = nn.Conv2d(128, self.output_dim, 3, 1, 1)  # PatchGAN-specific convolution\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z78_t0TL2USm"
      },
      "outputs": [],
      "source": [
        "cp /content/FLGo/flgo/benchmark/mnist_classification/model/cnn.py /content/FLGo/flgo/benchmark/fashion_classification/model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4RkBzg0acz_z",
        "outputId": "f0f1b19f-b73c-49e0-fc32-59a399504b63"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-10-945fd2cc06fd>:5: UserWarning: torch.range is deprecated and will be removed in a future release because its behavior is inconsistent with Python's range builtin. Instead, use torch.arange, which produces values in [start, end).\n",
            "  mean_Y=torch.range(0,9,dtype=torch.int64).repeat(batch_size//class_num)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
              "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
              "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
              "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "batch_size=32\n",
        "class_num=10\n",
        "w=np.ones(10)\n",
        "w=w/w.sum()\n",
        "mean_Y=torch.range(0,9,dtype=torch.int64).repeat(batch_size//class_num)\n",
        "mean_Y_ = torch.zeros((mean_Y.shape[0], class_num)).scatter_(1, mean_Y.type(torch.LongTensor).unsqueeze(1), 1)\n",
        "y2=torch.from_numpy(np.random.multinomial(1, w, size=[batch_size%class_num])).type(torch.FloatTensor)\n",
        "y2=torch.cat([mean_Y_,y2],0)\n",
        "y2\n",
        "#torch.from_numpy(np.random.multinomial(1, w, size=[batch_size%class_num])).type(torch.FloatTensor)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "53Qt4HAXbqqk",
        "outputId": "555982d9-8e1a-40f6-f985-a098180eefe6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([0., 1., 2., 3., 4., 5., 6., 7., 8., 9.])"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "a.mean(-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tD9ntkpoYXaI",
        "outputId": "549c49a8-8aa9-4467-8440-9a405e9adf54"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-29-40d19fc0d24c>:1: UserWarning: torch.range is deprecated and will be removed in a future release because its behavior is inconsistent with Python's range builtin. Instead, use torch.arange, which produces values in [start, end).\n",
            "  a=torch.range(0,9).unsqueeze(-1).repeat(1,3)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "tensor([1., 0., 1., 0., 0., 1., 0., 1., 1., 0., 1., 0., 1., 0., 0., 1., 0., 1.,\n",
              "        1., 0., 1., 0., 1., 0., 0., 1., 0., 1., 1., 0., 1., 1.])"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "a=torch.range(0,9).unsqueeze(-1).repeat(1,3)\n",
        "b=(torch.rand(10)>0.5).float()\n",
        "y2@b"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "XqQ1AceIQJyO",
        "outputId": "ba0b312d-4871-4a02-eca3-d8e91d6657f8"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-08-22 13:07:41,001 fflow.py init [line:441] INFO Initializing devices: cuda:0 will be used for this running.\n",
            "2023-08-22 13:07:41,045 fflow.py init [line:479] INFO Use `<class 'flgo.simulator.default_simulator.Simulator'>` as the system simulator\n",
            "2023-08-22 13:07:41,051 fflow.py init [line:487] INFO Ready to start.\n",
            "2023-08-22 13:07:41,081 fedbase.py run [line:236] INFO --------------Initial Evaluation--------------\n",
            "2023-08-22 13:07:41,085 simple_logger.py log_once [line:14] INFO Current_time:0\n",
            "2023-08-22 13:07:51,970 simple_logger.py log_once [line:28] INFO test_accuracy                 0.0740\n",
            "2023-08-22 13:07:51,971 simple_logger.py log_once [line:28] INFO test_loss                     2.3097\n",
            "2023-08-22 13:07:51,975 simple_logger.py log_once [line:28] INFO valid_accuracy                0.0770\n",
            "2023-08-22 13:07:51,979 simple_logger.py log_once [line:28] INFO mean_valid_accuracy           0.0771\n",
            "2023-08-22 13:07:51,981 simple_logger.py log_once [line:28] INFO std_valid_accuracy            0.0995\n",
            "2023-08-22 13:07:51,983 simple_logger.py log_once [line:28] INFO valid_loss                    2.3081\n",
            "2023-08-22 13:07:51,986 simple_logger.py log_once [line:28] INFO mean_valid_loss               2.3081\n",
            "2023-08-22 13:07:51,987 simple_logger.py log_once [line:28] INFO std_valid_loss                0.0309\n",
            "2023-08-22 13:07:51,989 fedbase.py run [line:239] INFO Eval Time Cost:               10.9036s\n",
            "2023-08-22 13:07:58,078 fedbase.py run [line:246] INFO --------------Round 1--------------\n",
            "2023-08-22 13:07:58,079 simple_logger.py log_once [line:14] INFO Current_time:1\n",
            "2023-08-22 13:08:08,328 simple_logger.py log_once [line:28] INFO test_accuracy                 0.1224\n",
            "2023-08-22 13:08:08,335 simple_logger.py log_once [line:28] INFO test_loss                     2.5536\n",
            "2023-08-22 13:08:08,336 simple_logger.py log_once [line:28] INFO valid_accuracy                0.1279\n",
            "2023-08-22 13:08:08,338 simple_logger.py log_once [line:28] INFO mean_valid_accuracy           0.1285\n",
            "2023-08-22 13:08:08,340 simple_logger.py log_once [line:28] INFO std_valid_accuracy            0.1801\n",
            "2023-08-22 13:08:08,341 simple_logger.py log_once [line:28] INFO valid_loss                    2.5600\n",
            "2023-08-22 13:08:08,342 simple_logger.py log_once [line:28] INFO mean_valid_loss               2.5592\n",
            "2023-08-22 13:08:08,343 simple_logger.py log_once [line:28] INFO std_valid_loss                0.7916\n",
            "2023-08-22 13:08:08,344 fedbase.py run [line:251] INFO Eval Time Cost:               10.2652s\n",
            "2023-08-22 13:08:13,879 fedbase.py run [line:246] INFO --------------Round 2--------------\n",
            "2023-08-22 13:08:13,881 simple_logger.py log_once [line:14] INFO Current_time:2\n",
            "2023-08-22 13:08:25,559 simple_logger.py log_once [line:28] INFO test_accuracy                 0.3155\n",
            "2023-08-22 13:08:25,561 simple_logger.py log_once [line:28] INFO test_loss                     3.1146\n",
            "2023-08-22 13:08:25,564 simple_logger.py log_once [line:28] INFO valid_accuracy                0.3110\n",
            "2023-08-22 13:08:25,567 simple_logger.py log_once [line:28] INFO mean_valid_accuracy           0.3125\n",
            "2023-08-22 13:08:25,571 simple_logger.py log_once [line:28] INFO std_valid_accuracy            0.2507\n",
            "2023-08-22 13:08:25,573 simple_logger.py log_once [line:28] INFO valid_loss                    3.0670\n",
            "2023-08-22 13:08:25,575 simple_logger.py log_once [line:28] INFO mean_valid_loss               3.0659\n",
            "2023-08-22 13:08:25,578 simple_logger.py log_once [line:28] INFO std_valid_loss                2.0708\n",
            "2023-08-22 13:08:25,581 fedbase.py run [line:251] INFO Eval Time Cost:               11.6998s\n",
            "2023-08-22 13:08:30,485 fedbase.py run [line:246] INFO --------------Round 3--------------\n",
            "2023-08-22 13:08:30,487 simple_logger.py log_once [line:14] INFO Current_time:3\n",
            "2023-08-22 13:08:41,640 simple_logger.py log_once [line:28] INFO test_accuracy                 0.4556\n",
            "2023-08-22 13:08:41,642 simple_logger.py log_once [line:28] INFO test_loss                     3.3912\n",
            "2023-08-22 13:08:41,645 simple_logger.py log_once [line:28] INFO valid_accuracy                0.4453\n",
            "2023-08-22 13:08:41,648 simple_logger.py log_once [line:28] INFO mean_valid_accuracy           0.4446\n",
            "2023-08-22 13:08:41,652 simple_logger.py log_once [line:28] INFO std_valid_accuracy            0.3345\n",
            "2023-08-22 13:08:41,653 simple_logger.py log_once [line:28] INFO valid_loss                    3.3855\n",
            "2023-08-22 13:08:41,656 simple_logger.py log_once [line:28] INFO mean_valid_loss               3.3895\n",
            "2023-08-22 13:08:41,657 simple_logger.py log_once [line:28] INFO std_valid_loss                3.0474\n",
            "2023-08-22 13:08:41,661 fedbase.py run [line:251] INFO Eval Time Cost:               11.1735s\n",
            "2023-08-22 13:08:46,735 fedbase.py run [line:246] INFO --------------Round 4--------------\n",
            "2023-08-22 13:08:46,736 simple_logger.py log_once [line:14] INFO Current_time:4\n",
            "2023-08-22 13:08:57,779 simple_logger.py log_once [line:28] INFO test_accuracy                 0.5034\n",
            "2023-08-22 13:08:57,781 simple_logger.py log_once [line:28] INFO test_loss                     1.5871\n",
            "2023-08-22 13:08:57,782 simple_logger.py log_once [line:28] INFO valid_accuracy                0.5142\n",
            "2023-08-22 13:08:57,785 simple_logger.py log_once [line:28] INFO mean_valid_accuracy           0.5151\n",
            "2023-08-22 13:08:57,790 simple_logger.py log_once [line:28] INFO std_valid_accuracy            0.2247\n",
            "2023-08-22 13:08:57,792 simple_logger.py log_once [line:28] INFO valid_loss                    1.5280\n",
            "2023-08-22 13:08:57,794 simple_logger.py log_once [line:28] INFO mean_valid_loss               1.5254\n",
            "2023-08-22 13:08:57,794 simple_logger.py log_once [line:28] INFO std_valid_loss                0.7069\n",
            "2023-08-22 13:08:57,795 fedbase.py run [line:251] INFO Eval Time Cost:               11.0589s\n",
            "2023-08-22 13:09:03,476 fedbase.py run [line:246] INFO --------------Round 5--------------\n",
            "2023-08-22 13:09:03,478 simple_logger.py log_once [line:14] INFO Current_time:5\n",
            "2023-08-22 13:09:13,623 simple_logger.py log_once [line:28] INFO test_accuracy                 0.5461\n",
            "2023-08-22 13:09:13,625 simple_logger.py log_once [line:28] INFO test_loss                     1.7319\n",
            "2023-08-22 13:09:13,627 simple_logger.py log_once [line:28] INFO valid_accuracy                0.5427\n",
            "2023-08-22 13:09:13,629 simple_logger.py log_once [line:28] INFO mean_valid_accuracy           0.5435\n",
            "2023-08-22 13:09:13,631 simple_logger.py log_once [line:28] INFO std_valid_accuracy            0.2875\n",
            "2023-08-22 13:09:13,634 simple_logger.py log_once [line:28] INFO valid_loss                    1.6159\n",
            "2023-08-22 13:09:13,636 simple_logger.py log_once [line:28] INFO mean_valid_loss               1.6130\n",
            "2023-08-22 13:09:13,637 simple_logger.py log_once [line:28] INFO std_valid_loss                1.1696\n",
            "2023-08-22 13:09:13,638 fedbase.py run [line:251] INFO Eval Time Cost:               10.1596s\n",
            "2023-08-22 13:09:19,758 fedbase.py run [line:246] INFO --------------Round 6--------------\n",
            "2023-08-22 13:09:19,760 simple_logger.py log_once [line:14] INFO Current_time:6\n",
            "2023-08-22 13:09:30,667 simple_logger.py log_once [line:28] INFO test_accuracy                 0.4493\n",
            "2023-08-22 13:09:30,673 simple_logger.py log_once [line:28] INFO test_loss                     2.2269\n",
            "2023-08-22 13:09:30,674 simple_logger.py log_once [line:28] INFO valid_accuracy                0.4423\n",
            "2023-08-22 13:09:30,678 simple_logger.py log_once [line:28] INFO mean_valid_accuracy           0.4431\n",
            "2023-08-22 13:09:30,681 simple_logger.py log_once [line:28] INFO std_valid_accuracy            0.3330\n",
            "2023-08-22 13:09:30,683 simple_logger.py log_once [line:28] INFO valid_loss                    2.1834\n",
            "2023-08-22 13:09:30,684 simple_logger.py log_once [line:28] INFO mean_valid_loss               2.1804\n",
            "2023-08-22 13:09:30,685 simple_logger.py log_once [line:28] INFO std_valid_loss                1.4440\n",
            "2023-08-22 13:09:30,688 fedbase.py run [line:251] INFO Eval Time Cost:               10.9284s\n",
            "2023-08-22 13:09:33,506 fedbase.py run [line:246] INFO --------------Round 7--------------\n",
            "2023-08-22 13:09:33,507 simple_logger.py log_once [line:14] INFO Current_time:7\n",
            "2023-08-22 13:09:44,392 simple_logger.py log_once [line:28] INFO test_accuracy                 0.5166\n",
            "2023-08-22 13:09:44,398 simple_logger.py log_once [line:28] INFO test_loss                     2.2204\n",
            "2023-08-22 13:09:44,399 simple_logger.py log_once [line:28] INFO valid_accuracy                0.5281\n",
            "2023-08-22 13:09:44,404 simple_logger.py log_once [line:28] INFO mean_valid_accuracy           0.5268\n",
            "2023-08-22 13:09:44,405 simple_logger.py log_once [line:28] INFO std_valid_accuracy            0.2798\n",
            "2023-08-22 13:09:44,407 simple_logger.py log_once [line:28] INFO valid_loss                    2.0187\n",
            "2023-08-22 13:09:44,412 simple_logger.py log_once [line:28] INFO mean_valid_loss               2.0240\n",
            "2023-08-22 13:09:44,414 simple_logger.py log_once [line:28] INFO std_valid_loss                1.5566\n",
            "2023-08-22 13:09:44,415 fedbase.py run [line:251] INFO Eval Time Cost:               10.9079s\n",
            "2023-08-22 13:09:49,623 fedbase.py run [line:246] INFO --------------Round 8--------------\n",
            "2023-08-22 13:09:49,625 simple_logger.py log_once [line:14] INFO Current_time:8\n",
            "2023-08-22 13:10:00,680 simple_logger.py log_once [line:28] INFO test_accuracy                 0.5720\n",
            "2023-08-22 13:10:00,681 simple_logger.py log_once [line:28] INFO test_loss                     1.5088\n",
            "2023-08-22 13:10:00,684 simple_logger.py log_once [line:28] INFO valid_accuracy                0.5621\n",
            "2023-08-22 13:10:00,685 simple_logger.py log_once [line:28] INFO mean_valid_accuracy           0.5612\n",
            "2023-08-22 13:10:00,687 simple_logger.py log_once [line:28] INFO std_valid_accuracy            0.2940\n",
            "2023-08-22 13:10:00,689 simple_logger.py log_once [line:28] INFO valid_loss                    1.4753\n",
            "2023-08-22 13:10:00,690 simple_logger.py log_once [line:28] INFO mean_valid_loss               1.4785\n",
            "2023-08-22 13:10:00,692 simple_logger.py log_once [line:28] INFO std_valid_loss                1.0177\n",
            "2023-08-22 13:10:00,692 fedbase.py run [line:251] INFO Eval Time Cost:               11.0679s\n",
            "2023-08-22 13:10:05,589 fedbase.py run [line:246] INFO --------------Round 9--------------\n",
            "2023-08-22 13:10:05,591 simple_logger.py log_once [line:14] INFO Current_time:9\n",
            "2023-08-22 13:10:16,656 simple_logger.py log_once [line:28] INFO test_accuracy                 0.7272\n",
            "2023-08-22 13:10:16,657 simple_logger.py log_once [line:28] INFO test_loss                     0.8573\n",
            "2023-08-22 13:10:16,659 simple_logger.py log_once [line:28] INFO valid_accuracy                0.7081\n",
            "2023-08-22 13:10:16,661 simple_logger.py log_once [line:28] INFO mean_valid_accuracy           0.7073\n",
            "2023-08-22 13:10:16,663 simple_logger.py log_once [line:28] INFO std_valid_accuracy            0.1839\n",
            "2023-08-22 13:10:16,666 simple_logger.py log_once [line:28] INFO valid_loss                    0.8546\n",
            "2023-08-22 13:10:16,668 simple_logger.py log_once [line:28] INFO mean_valid_loss               0.8560\n",
            "2023-08-22 13:10:16,669 simple_logger.py log_once [line:28] INFO std_valid_loss                0.3758\n",
            "2023-08-22 13:10:16,672 fedbase.py run [line:251] INFO Eval Time Cost:               11.0810s\n",
            "2023-08-22 13:10:21,731 fedbase.py run [line:246] INFO --------------Round 10--------------\n",
            "2023-08-22 13:10:21,733 simple_logger.py log_once [line:14] INFO Current_time:10\n",
            "2023-08-22 13:10:33,572 simple_logger.py log_once [line:28] INFO test_accuracy                 0.6788\n",
            "2023-08-22 13:10:33,573 simple_logger.py log_once [line:28] INFO test_loss                     1.0468\n",
            "2023-08-22 13:10:33,576 simple_logger.py log_once [line:28] INFO valid_accuracy                0.6617\n",
            "2023-08-22 13:10:33,579 simple_logger.py log_once [line:28] INFO mean_valid_accuracy           0.6602\n",
            "2023-08-22 13:10:33,584 simple_logger.py log_once [line:28] INFO std_valid_accuracy            0.2620\n",
            "2023-08-22 13:10:33,585 simple_logger.py log_once [line:28] INFO valid_loss                    1.0453\n",
            "2023-08-22 13:10:33,587 simple_logger.py log_once [line:28] INFO mean_valid_loss               1.0498\n",
            "2023-08-22 13:10:33,590 simple_logger.py log_once [line:28] INFO std_valid_loss                0.7480\n",
            "2023-08-22 13:10:33,591 fedbase.py run [line:251] INFO Eval Time Cost:               11.8574s\n",
            "2023-08-22 13:10:39,669 fedbase.py run [line:246] INFO --------------Round 11--------------\n",
            "2023-08-22 13:10:39,671 simple_logger.py log_once [line:14] INFO Current_time:11\n",
            "2023-08-22 13:10:50,060 simple_logger.py log_once [line:28] INFO test_accuracy                 0.6505\n",
            "2023-08-22 13:10:50,062 simple_logger.py log_once [line:28] INFO test_loss                     1.1230\n",
            "2023-08-22 13:10:50,064 simple_logger.py log_once [line:28] INFO valid_accuracy                0.6740\n",
            "2023-08-22 13:10:50,066 simple_logger.py log_once [line:28] INFO mean_valid_accuracy           0.6733\n",
            "2023-08-22 13:10:50,067 simple_logger.py log_once [line:28] INFO std_valid_accuracy            0.1869\n",
            "2023-08-22 13:10:50,069 simple_logger.py log_once [line:28] INFO valid_loss                    0.9943\n",
            "2023-08-22 13:10:50,070 simple_logger.py log_once [line:28] INFO mean_valid_loss               0.9960\n",
            "2023-08-22 13:10:50,071 simple_logger.py log_once [line:28] INFO std_valid_loss                0.4891\n",
            "2023-08-22 13:10:50,072 fedbase.py run [line:251] INFO Eval Time Cost:               10.4010s\n",
            "2023-08-22 13:10:57,090 fedbase.py run [line:246] INFO --------------Round 12--------------\n",
            "2023-08-22 13:10:57,092 simple_logger.py log_once [line:14] INFO Current_time:12\n",
            "2023-08-22 13:11:08,410 simple_logger.py log_once [line:28] INFO test_accuracy                 0.5437\n",
            "2023-08-22 13:11:08,414 simple_logger.py log_once [line:28] INFO test_loss                     1.5851\n",
            "2023-08-22 13:11:08,418 simple_logger.py log_once [line:28] INFO valid_accuracy                0.5628\n",
            "2023-08-22 13:11:08,420 simple_logger.py log_once [line:28] INFO mean_valid_accuracy           0.5609\n",
            "2023-08-22 13:11:08,424 simple_logger.py log_once [line:28] INFO std_valid_accuracy            0.2710\n",
            "2023-08-22 13:11:08,425 simple_logger.py log_once [line:28] INFO valid_loss                    1.4493\n",
            "2023-08-22 13:11:08,426 simple_logger.py log_once [line:28] INFO mean_valid_loss               1.4559\n",
            "2023-08-22 13:11:08,428 simple_logger.py log_once [line:28] INFO std_valid_loss                0.9216\n",
            "2023-08-22 13:11:08,429 fedbase.py run [line:251] INFO Eval Time Cost:               11.3376s\n",
            "2023-08-22 13:11:13,452 fedbase.py run [line:246] INFO --------------Round 13--------------\n",
            "2023-08-22 13:11:13,453 simple_logger.py log_once [line:14] INFO Current_time:13\n",
            "2023-08-22 13:11:24,902 simple_logger.py log_once [line:28] INFO test_accuracy                 0.7601\n",
            "2023-08-22 13:11:24,903 simple_logger.py log_once [line:28] INFO test_loss                     0.7848\n",
            "2023-08-22 13:11:24,906 simple_logger.py log_once [line:28] INFO valid_accuracy                0.7692\n",
            "2023-08-22 13:11:24,909 simple_logger.py log_once [line:28] INFO mean_valid_accuracy           0.7690\n",
            "2023-08-22 13:11:24,911 simple_logger.py log_once [line:28] INFO std_valid_accuracy            0.1007\n",
            "2023-08-22 13:11:24,914 simple_logger.py log_once [line:28] INFO valid_loss                    0.7140\n",
            "2023-08-22 13:11:24,915 simple_logger.py log_once [line:28] INFO mean_valid_loss               0.7145\n",
            "2023-08-22 13:11:24,921 simple_logger.py log_once [line:28] INFO std_valid_loss                0.2896\n",
            "2023-08-22 13:11:24,923 fedbase.py run [line:251] INFO Eval Time Cost:               11.4703s\n",
            "2023-08-22 13:11:29,959 fedbase.py run [line:246] INFO --------------Round 14--------------\n",
            "2023-08-22 13:11:29,960 simple_logger.py log_once [line:14] INFO Current_time:14\n",
            "2023-08-22 13:11:41,006 simple_logger.py log_once [line:28] INFO test_accuracy                 0.7120\n",
            "2023-08-22 13:11:41,008 simple_logger.py log_once [line:28] INFO test_loss                     0.9659\n",
            "2023-08-22 13:11:41,011 simple_logger.py log_once [line:28] INFO valid_accuracy                0.7412\n",
            "2023-08-22 13:11:41,015 simple_logger.py log_once [line:28] INFO mean_valid_accuracy           0.7409\n",
            "2023-08-22 13:11:41,017 simple_logger.py log_once [line:28] INFO std_valid_accuracy            0.1522\n",
            "2023-08-22 13:11:41,018 simple_logger.py log_once [line:28] INFO valid_loss                    0.8316\n",
            "2023-08-22 13:11:41,020 simple_logger.py log_once [line:28] INFO mean_valid_loss               0.8326\n",
            "2023-08-22 13:11:41,021 simple_logger.py log_once [line:28] INFO std_valid_loss                0.5040\n",
            "2023-08-22 13:11:41,022 fedbase.py run [line:251] INFO Eval Time Cost:               11.0617s\n",
            "2023-08-22 13:11:43,509 fedbase.py run [line:246] INFO --------------Round 15--------------\n",
            "2023-08-22 13:11:43,510 simple_logger.py log_once [line:14] INFO Current_time:15\n",
            "2023-08-22 13:11:54,663 simple_logger.py log_once [line:28] INFO test_accuracy                 0.3889\n",
            "2023-08-22 13:11:54,664 simple_logger.py log_once [line:28] INFO test_loss                     3.2715\n",
            "2023-08-22 13:11:54,668 simple_logger.py log_once [line:28] INFO valid_accuracy                0.3987\n",
            "2023-08-22 13:11:54,671 simple_logger.py log_once [line:28] INFO mean_valid_accuracy           0.3975\n",
            "2023-08-22 13:11:54,673 simple_logger.py log_once [line:28] INFO std_valid_accuracy            0.2782\n",
            "2023-08-22 13:11:54,678 simple_logger.py log_once [line:28] INFO valid_loss                    3.3322\n",
            "2023-08-22 13:11:54,679 simple_logger.py log_once [line:28] INFO mean_valid_loss               3.3458\n",
            "2023-08-22 13:11:54,682 simple_logger.py log_once [line:28] INFO std_valid_loss                2.4266\n",
            "2023-08-22 13:11:54,684 fedbase.py run [line:251] INFO Eval Time Cost:               11.1743s\n",
            "2023-08-22 13:11:59,803 fedbase.py run [line:246] INFO --------------Round 16--------------\n",
            "2023-08-22 13:11:59,810 simple_logger.py log_once [line:14] INFO Current_time:16\n",
            "2023-08-22 13:12:10,746 simple_logger.py log_once [line:28] INFO test_accuracy                 0.7327\n",
            "2023-08-22 13:12:10,748 simple_logger.py log_once [line:28] INFO test_loss                     0.8769\n",
            "2023-08-22 13:12:10,752 simple_logger.py log_once [line:28] INFO valid_accuracy                0.7452\n",
            "2023-08-22 13:12:10,754 simple_logger.py log_once [line:28] INFO mean_valid_accuracy           0.7449\n",
            "2023-08-22 13:12:10,757 simple_logger.py log_once [line:28] INFO std_valid_accuracy            0.1634\n",
            "2023-08-22 13:12:10,760 simple_logger.py log_once [line:28] INFO valid_loss                    0.8042\n",
            "2023-08-22 13:12:10,761 simple_logger.py log_once [line:28] INFO mean_valid_loss               0.8045\n",
            "2023-08-22 13:12:10,765 simple_logger.py log_once [line:28] INFO std_valid_loss                0.5176\n",
            "2023-08-22 13:12:10,766 fedbase.py run [line:251] INFO Eval Time Cost:               10.9567s\n",
            "2023-08-22 13:12:16,892 fedbase.py run [line:246] INFO --------------Round 17--------------\n",
            "2023-08-22 13:12:16,893 simple_logger.py log_once [line:14] INFO Current_time:17\n",
            "2023-08-22 13:12:27,284 simple_logger.py log_once [line:28] INFO test_accuracy                 0.7058\n",
            "2023-08-22 13:12:27,289 simple_logger.py log_once [line:28] INFO test_loss                     0.9846\n",
            "2023-08-22 13:12:27,294 simple_logger.py log_once [line:28] INFO valid_accuracy                0.7315\n",
            "2023-08-22 13:12:27,297 simple_logger.py log_once [line:28] INFO mean_valid_accuracy           0.7314\n",
            "2023-08-22 13:12:27,298 simple_logger.py log_once [line:28] INFO std_valid_accuracy            0.1073\n",
            "2023-08-22 13:12:27,300 simple_logger.py log_once [line:28] INFO valid_loss                    0.8655\n",
            "2023-08-22 13:12:27,302 simple_logger.py log_once [line:28] INFO mean_valid_loss               0.8650\n",
            "2023-08-22 13:12:27,304 simple_logger.py log_once [line:28] INFO std_valid_loss                0.3539\n",
            "2023-08-22 13:12:27,305 fedbase.py run [line:251] INFO Eval Time Cost:               10.4122s\n",
            "2023-08-22 13:12:30,592 fedbase.py run [line:246] INFO --------------Round 18--------------\n",
            "2023-08-22 13:12:30,594 simple_logger.py log_once [line:14] INFO Current_time:18\n",
            "2023-08-22 13:12:40,757 simple_logger.py log_once [line:28] INFO test_accuracy                 0.5431\n",
            "2023-08-22 13:12:40,759 simple_logger.py log_once [line:28] INFO test_loss                     2.0851\n",
            "2023-08-22 13:12:40,762 simple_logger.py log_once [line:28] INFO valid_accuracy                0.5573\n",
            "2023-08-22 13:12:40,765 simple_logger.py log_once [line:28] INFO mean_valid_accuracy           0.5563\n",
            "2023-08-22 13:12:40,767 simple_logger.py log_once [line:28] INFO std_valid_accuracy            0.2650\n",
            "2023-08-22 13:12:40,769 simple_logger.py log_once [line:28] INFO valid_loss                    1.9123\n",
            "2023-08-22 13:12:40,770 simple_logger.py log_once [line:28] INFO mean_valid_loss               1.9192\n",
            "2023-08-22 13:12:40,771 simple_logger.py log_once [line:28] INFO std_valid_loss                1.4437\n",
            "2023-08-22 13:12:40,772 fedbase.py run [line:251] INFO Eval Time Cost:               10.1787s\n",
            "2023-08-22 13:12:46,519 fedbase.py run [line:246] INFO --------------Round 19--------------\n",
            "2023-08-22 13:12:46,520 simple_logger.py log_once [line:14] INFO Current_time:19\n",
            "2023-08-22 13:12:57,497 simple_logger.py log_once [line:28] INFO test_accuracy                 0.6438\n",
            "2023-08-22 13:12:57,499 simple_logger.py log_once [line:28] INFO test_loss                     1.3616\n",
            "2023-08-22 13:12:57,503 simple_logger.py log_once [line:28] INFO valid_accuracy                0.6490\n",
            "2023-08-22 13:12:57,507 simple_logger.py log_once [line:28] INFO mean_valid_accuracy           0.6475\n",
            "2023-08-22 13:12:57,510 simple_logger.py log_once [line:28] INFO std_valid_accuracy            0.2711\n",
            "2023-08-22 13:12:57,512 simple_logger.py log_once [line:28] INFO valid_loss                    1.3274\n",
            "2023-08-22 13:12:57,515 simple_logger.py log_once [line:28] INFO mean_valid_loss               1.3337\n",
            "2023-08-22 13:12:57,517 simple_logger.py log_once [line:28] INFO std_valid_loss                1.2215\n",
            "2023-08-22 13:12:57,520 fedbase.py run [line:251] INFO Eval Time Cost:               11.0000s\n",
            "2023-08-22 13:12:59,978 fedbase.py run [line:246] INFO --------------Round 20--------------\n",
            "2023-08-22 13:12:59,980 simple_logger.py log_once [line:14] INFO Current_time:20\n",
            "2023-08-22 13:13:10,903 simple_logger.py log_once [line:28] INFO test_accuracy                 0.5921\n",
            "2023-08-22 13:13:10,904 simple_logger.py log_once [line:28] INFO test_loss                     1.5317\n",
            "2023-08-22 13:13:10,907 simple_logger.py log_once [line:28] INFO valid_accuracy                0.6191\n",
            "2023-08-22 13:13:10,908 simple_logger.py log_once [line:28] INFO mean_valid_accuracy           0.6204\n",
            "2023-08-22 13:13:10,910 simple_logger.py log_once [line:28] INFO std_valid_accuracy            0.2260\n",
            "2023-08-22 13:13:10,911 simple_logger.py log_once [line:28] INFO valid_loss                    1.3971\n",
            "2023-08-22 13:13:10,913 simple_logger.py log_once [line:28] INFO mean_valid_loss               1.3927\n",
            "2023-08-22 13:13:10,914 simple_logger.py log_once [line:28] INFO std_valid_loss                0.8903\n",
            "2023-08-22 13:13:10,915 fedbase.py run [line:251] INFO Eval Time Cost:               10.9356s\n",
            "2023-08-22 13:13:15,723 fedbase.py run [line:246] INFO --------------Round 21--------------\n",
            "2023-08-22 13:13:15,724 simple_logger.py log_once [line:14] INFO Current_time:21\n",
            "2023-08-22 13:13:26,990 simple_logger.py log_once [line:28] INFO test_accuracy                 0.7730\n",
            "2023-08-22 13:13:26,991 simple_logger.py log_once [line:28] INFO test_loss                     0.7608\n",
            "2023-08-22 13:13:26,992 simple_logger.py log_once [line:28] INFO valid_accuracy                0.7930\n",
            "2023-08-22 13:13:26,994 simple_logger.py log_once [line:28] INFO mean_valid_accuracy           0.7931\n",
            "2023-08-22 13:13:26,996 simple_logger.py log_once [line:28] INFO std_valid_accuracy            0.1178\n",
            "2023-08-22 13:13:26,999 simple_logger.py log_once [line:28] INFO valid_loss                    0.6972\n",
            "2023-08-22 13:13:27,005 simple_logger.py log_once [line:28] INFO mean_valid_loss               0.6965\n",
            "2023-08-22 13:13:27,006 simple_logger.py log_once [line:28] INFO std_valid_loss                0.4284\n",
            "2023-08-22 13:13:27,007 fedbase.py run [line:251] INFO Eval Time Cost:               11.2828s\n",
            "2023-08-22 13:13:31,856 fedbase.py run [line:246] INFO --------------Round 22--------------\n",
            "2023-08-22 13:13:31,858 simple_logger.py log_once [line:14] INFO Current_time:22\n",
            "2023-08-22 13:13:42,852 simple_logger.py log_once [line:28] INFO test_accuracy                 0.7001\n",
            "2023-08-22 13:13:42,854 simple_logger.py log_once [line:28] INFO test_loss                     1.1465\n",
            "2023-08-22 13:13:42,857 simple_logger.py log_once [line:28] INFO valid_accuracy                0.7138\n",
            "2023-08-22 13:13:42,858 simple_logger.py log_once [line:28] INFO mean_valid_accuracy           0.7140\n",
            "2023-08-22 13:13:42,860 simple_logger.py log_once [line:28] INFO std_valid_accuracy            0.1786\n",
            "2023-08-22 13:13:42,862 simple_logger.py log_once [line:28] INFO valid_loss                    1.0396\n",
            "2023-08-22 13:13:42,863 simple_logger.py log_once [line:28] INFO mean_valid_loss               1.0382\n",
            "2023-08-22 13:13:42,864 simple_logger.py log_once [line:28] INFO std_valid_loss                0.7252\n",
            "2023-08-22 13:13:42,865 fedbase.py run [line:251] INFO Eval Time Cost:               11.0075s\n",
            "2023-08-22 13:13:47,910 fedbase.py run [line:246] INFO --------------Round 23--------------\n",
            "2023-08-22 13:13:47,912 simple_logger.py log_once [line:14] INFO Current_time:23\n",
            "2023-08-22 13:13:58,888 simple_logger.py log_once [line:28] INFO test_accuracy                 0.7300\n",
            "2023-08-22 13:13:58,890 simple_logger.py log_once [line:28] INFO test_loss                     0.9282\n",
            "2023-08-22 13:13:58,894 simple_logger.py log_once [line:28] INFO valid_accuracy                0.7503\n",
            "2023-08-22 13:13:58,898 simple_logger.py log_once [line:28] INFO mean_valid_accuracy           0.7503\n",
            "2023-08-22 13:13:58,900 simple_logger.py log_once [line:28] INFO std_valid_accuracy            0.1587\n",
            "2023-08-22 13:13:58,902 simple_logger.py log_once [line:28] INFO valid_loss                    0.8488\n",
            "2023-08-22 13:13:58,908 simple_logger.py log_once [line:28] INFO mean_valid_loss               0.8487\n",
            "2023-08-22 13:13:58,909 simple_logger.py log_once [line:28] INFO std_valid_loss                0.5578\n",
            "2023-08-22 13:13:58,911 fedbase.py run [line:251] INFO Eval Time Cost:               10.9990s\n",
            "2023-08-22 13:14:01,622 fedbase.py run [line:246] INFO --------------Round 24--------------\n",
            "2023-08-22 13:14:01,628 simple_logger.py log_once [line:14] INFO Current_time:24\n",
            "2023-08-22 13:14:12,600 simple_logger.py log_once [line:28] INFO test_accuracy                 0.5601\n",
            "2023-08-22 13:14:12,601 simple_logger.py log_once [line:28] INFO test_loss                     2.1818\n",
            "2023-08-22 13:14:12,603 simple_logger.py log_once [line:28] INFO valid_accuracy                0.5650\n",
            "2023-08-22 13:14:12,608 simple_logger.py log_once [line:28] INFO mean_valid_accuracy           0.5642\n",
            "2023-08-22 13:14:12,609 simple_logger.py log_once [line:28] INFO std_valid_accuracy            0.2139\n",
            "2023-08-22 13:14:12,611 simple_logger.py log_once [line:28] INFO valid_loss                    2.0605\n",
            "2023-08-22 13:14:12,613 simple_logger.py log_once [line:28] INFO mean_valid_loss               2.0643\n",
            "2023-08-22 13:14:12,614 simple_logger.py log_once [line:28] INFO std_valid_loss                1.1040\n",
            "2023-08-22 13:14:12,615 fedbase.py run [line:251] INFO Eval Time Cost:               10.9873s\n",
            "2023-08-22 13:14:18,569 fedbase.py run [line:246] INFO --------------Round 25--------------\n",
            "2023-08-22 13:14:18,570 simple_logger.py log_once [line:14] INFO Current_time:25\n",
            "2023-08-22 13:14:28,706 simple_logger.py log_once [line:28] INFO test_accuracy                 0.7086\n",
            "2023-08-22 13:14:28,712 simple_logger.py log_once [line:28] INFO test_loss                     1.2035\n",
            "2023-08-22 13:14:28,714 simple_logger.py log_once [line:28] INFO valid_accuracy                0.7075\n",
            "2023-08-22 13:14:28,716 simple_logger.py log_once [line:28] INFO mean_valid_accuracy           0.7065\n",
            "2023-08-22 13:14:28,718 simple_logger.py log_once [line:28] INFO std_valid_accuracy            0.2176\n",
            "2023-08-22 13:14:28,719 simple_logger.py log_once [line:28] INFO valid_loss                    1.1881\n",
            "2023-08-22 13:14:28,720 simple_logger.py log_once [line:28] INFO mean_valid_loss               1.1928\n",
            "2023-08-22 13:14:28,723 simple_logger.py log_once [line:28] INFO std_valid_loss                0.9865\n",
            "2023-08-22 13:14:28,724 fedbase.py run [line:251] INFO Eval Time Cost:               10.1539s\n",
            "2023-08-22 13:14:34,637 fedbase.py run [line:246] INFO --------------Round 26--------------\n",
            "2023-08-22 13:14:34,638 simple_logger.py log_once [line:14] INFO Current_time:26\n",
            "2023-08-22 13:14:46,495 simple_logger.py log_once [line:28] INFO test_accuracy                 0.7493\n",
            "2023-08-22 13:14:46,497 simple_logger.py log_once [line:28] INFO test_loss                     0.8839\n",
            "2023-08-22 13:14:46,502 simple_logger.py log_once [line:28] INFO valid_accuracy                0.7691\n",
            "2023-08-22 13:14:46,503 simple_logger.py log_once [line:28] INFO mean_valid_accuracy           0.7698\n",
            "2023-08-22 13:14:46,505 simple_logger.py log_once [line:28] INFO std_valid_accuracy            0.1060\n",
            "2023-08-22 13:14:46,507 simple_logger.py log_once [line:28] INFO valid_loss                    0.7855\n",
            "2023-08-22 13:14:46,509 simple_logger.py log_once [line:28] INFO mean_valid_loss               0.7829\n",
            "2023-08-22 13:14:46,510 simple_logger.py log_once [line:28] INFO std_valid_loss                0.3637\n",
            "2023-08-22 13:14:46,515 fedbase.py run [line:251] INFO Eval Time Cost:               11.8766s\n",
            "2023-08-22 13:14:52,368 fedbase.py run [line:246] INFO --------------Round 27--------------\n",
            "2023-08-22 13:14:52,369 simple_logger.py log_once [line:14] INFO Current_time:27\n",
            "2023-08-22 13:15:03,485 simple_logger.py log_once [line:28] INFO test_accuracy                 0.7205\n",
            "2023-08-22 13:15:03,486 simple_logger.py log_once [line:28] INFO test_loss                     1.1401\n",
            "2023-08-22 13:15:03,489 simple_logger.py log_once [line:28] INFO valid_accuracy                0.7311\n",
            "2023-08-22 13:15:03,491 simple_logger.py log_once [line:28] INFO mean_valid_accuracy           0.7308\n",
            "2023-08-22 13:15:03,492 simple_logger.py log_once [line:28] INFO std_valid_accuracy            0.1464\n",
            "2023-08-22 13:15:03,494 simple_logger.py log_once [line:28] INFO valid_loss                    1.0437\n",
            "2023-08-22 13:15:03,495 simple_logger.py log_once [line:28] INFO mean_valid_loss               1.0453\n",
            "2023-08-22 13:15:03,497 simple_logger.py log_once [line:28] INFO std_valid_loss                0.5860\n",
            "2023-08-22 13:15:03,498 fedbase.py run [line:251] INFO Eval Time Cost:               11.1285s\n",
            "2023-08-22 13:15:08,349 fedbase.py run [line:246] INFO --------------Round 28--------------\n",
            "2023-08-22 13:15:08,350 simple_logger.py log_once [line:14] INFO Current_time:28\n",
            "2023-08-22 13:15:20,527 simple_logger.py log_once [line:28] INFO test_accuracy                 0.7775\n",
            "2023-08-22 13:15:20,528 simple_logger.py log_once [line:28] INFO test_loss                     0.8088\n",
            "2023-08-22 13:15:20,529 simple_logger.py log_once [line:28] INFO valid_accuracy                0.8025\n",
            "2023-08-22 13:15:20,531 simple_logger.py log_once [line:28] INFO mean_valid_accuracy           0.8023\n",
            "2023-08-22 13:15:20,533 simple_logger.py log_once [line:28] INFO std_valid_accuracy            0.1234\n",
            "2023-08-22 13:15:20,541 simple_logger.py log_once [line:28] INFO valid_loss                    0.6740\n",
            "2023-08-22 13:15:20,543 simple_logger.py log_once [line:28] INFO mean_valid_loss               0.6749\n",
            "2023-08-22 13:15:20,544 simple_logger.py log_once [line:28] INFO std_valid_loss                0.4544\n",
            "2023-08-22 13:15:20,546 fedbase.py run [line:251] INFO Eval Time Cost:               12.1959s\n",
            "2023-08-22 13:15:26,030 fedbase.py run [line:246] INFO --------------Round 29--------------\n",
            "2023-08-22 13:15:26,037 simple_logger.py log_once [line:14] INFO Current_time:29\n",
            "2023-08-22 13:15:36,673 simple_logger.py log_once [line:28] INFO test_accuracy                 0.7565\n",
            "2023-08-22 13:15:36,674 simple_logger.py log_once [line:28] INFO test_loss                     0.8512\n",
            "2023-08-22 13:15:36,675 simple_logger.py log_once [line:28] INFO valid_accuracy                0.7705\n",
            "2023-08-22 13:15:36,677 simple_logger.py log_once [line:28] INFO mean_valid_accuracy           0.7705\n",
            "2023-08-22 13:15:36,680 simple_logger.py log_once [line:28] INFO std_valid_accuracy            0.1078\n",
            "2023-08-22 13:15:36,683 simple_logger.py log_once [line:28] INFO valid_loss                    0.7620\n",
            "2023-08-22 13:15:36,687 simple_logger.py log_once [line:28] INFO mean_valid_loss               0.7618\n",
            "2023-08-22 13:15:36,688 simple_logger.py log_once [line:28] INFO std_valid_loss                0.3761\n",
            "2023-08-22 13:15:36,689 fedbase.py run [line:251] INFO Eval Time Cost:               10.6521s\n",
            "2023-08-22 13:15:42,760 fedbase.py run [line:246] INFO --------------Round 30--------------\n",
            "2023-08-22 13:15:42,762 simple_logger.py log_once [line:14] INFO Current_time:30\n",
            "2023-08-22 13:15:53,222 simple_logger.py log_once [line:28] INFO test_accuracy                 0.7429\n",
            "2023-08-22 13:15:53,225 simple_logger.py log_once [line:28] INFO test_loss                     1.0965\n",
            "2023-08-22 13:15:53,227 simple_logger.py log_once [line:28] INFO valid_accuracy                0.7542\n",
            "2023-08-22 13:15:53,228 simple_logger.py log_once [line:28] INFO mean_valid_accuracy           0.7538\n",
            "2023-08-22 13:15:53,230 simple_logger.py log_once [line:28] INFO std_valid_accuracy            0.1306\n",
            "2023-08-22 13:15:53,232 simple_logger.py log_once [line:28] INFO valid_loss                    1.0014\n",
            "2023-08-22 13:15:53,233 simple_logger.py log_once [line:28] INFO mean_valid_loss               1.0031\n",
            "2023-08-22 13:15:53,234 simple_logger.py log_once [line:28] INFO std_valid_loss                0.5479\n",
            "2023-08-22 13:15:53,235 fedbase.py run [line:251] INFO Eval Time Cost:               10.4734s\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-8bc706ddbfce>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mrunner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mrunner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/content/FLGo/flgo/algorithm/fedbase.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    241\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m             \u001b[0;31m# iterate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 243\u001b[0;31m             \u001b[0mupdated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    244\u001b[0m             \u001b[0;31m# using logger to evaluate the model if the model is updated\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    245\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mupdated\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mTrue\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mupdated\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/FLGo/flgo/algorithm/fedbase.py\u001b[0m in \u001b[0;36miterate\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    272\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselected_clients\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m         \u001b[0;31m# training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 274\u001b[0;31m         \u001b[0mmodels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommunicate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselected_clients\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'model'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    275\u001b[0m         \u001b[0;31m# aggregate: pk = 1/K as default where K=len(selected_clients)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maggregate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/FLGo/flgo/simulator/base.py\u001b[0m in \u001b[0;36mcommunicate_with_dropout\u001b[0;34m(self, selected_clients, mtype, asynchronous)\u001b[0m\n\u001b[1;32m    465\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dropped_selected_clients\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcid\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcid\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mprob\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mselected_clients\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprobs_drop\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msimulator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mprob\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    466\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msimulator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_client_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dropped_selected_clients\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'dropped'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 467\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcommunicate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcid\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcid\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mselected_clients\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mcid\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dropped_selected_clients\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0masynchronous\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    468\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    469\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mcommunicate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mselected_clients\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0masynchronous\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/FLGo/flgo/simulator/base.py\u001b[0m in \u001b[0;36mcommunicate_with_clock\u001b[0;34m(self, selected_clients, mtype, asynchronous)\u001b[0m\n\u001b[1;32m    549\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcommunicate_with_clock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mselected_clients\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0masynchronous\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msimulator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_client_completeness\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mselected_clients\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 551\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcommunicate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mselected_clients\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0masynchronous\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    552\u001b[0m         \u001b[0;31m# If all the selected clients are unavailable, directly return the result without waiting.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m         \u001b[0;31m# Else if all the available clients have dropped out and not using asynchronous communication,  waiting for `tolerance_for_latency` time units.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/FLGo/flgo/algorithm/fedbase.py\u001b[0m in \u001b[0;36mcommunicate\u001b[0;34m(self, selected_clients, mtype, asynchronous)\u001b[0m\n\u001b[1;32m    304\u001b[0m                 \u001b[0mserver_pkg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclient_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    305\u001b[0m                 \u001b[0mserver_pkg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'__mtype__'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 306\u001b[0;31m                 \u001b[0mresponse_from_client_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommunicate_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclients\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mclient_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpackage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mserver_pkg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    307\u001b[0m                 \u001b[0mpackages_received_from_clients\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse_from_client_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/FLGo/flgo/simulator/base.py\u001b[0m in \u001b[0;36mdelayed_communicate_with\u001b[0;34m(self, target_id, package)\u001b[0m\n\u001b[1;32m    493\u001b[0m         \u001b[0;31m# Set downloading package sizes for clients for downloading cost estimation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msimulator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_variable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__download_package_size'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msize_of_package\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpackage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 495\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcommunicate_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpackage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    496\u001b[0m         \u001b[0;31m# Set uploading package sizes for clients for uploading cost estimation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    497\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msimulator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_variable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__upload_package_size'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize_of_package\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/FLGo/flgo/algorithm/fedbase.py\u001b[0m in \u001b[0;36mcommunicate_with\u001b[0;34m(self, target_id, package)\u001b[0m\n\u001b[1;32m    347\u001b[0m             \u001b[0mwill\u001b[0m \u001b[0mbe\u001b[0m \u001b[0;34m'None'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mlosing\u001b[0m \u001b[0mconnection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m         \"\"\"\n\u001b[0;32m--> 349\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBasicServer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommunicate_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpackage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    350\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclient_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/FLGo/flgo/algorithm/fedbase.py\u001b[0m in \u001b[0;36mcommunicate_with\u001b[0;34m(self, target_id, package)\u001b[0m\n\u001b[1;32m    188\u001b[0m             \u001b[0mclient_package\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0mobject\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mwill\u001b[0m \u001b[0mbe\u001b[0m \u001b[0;34m'None'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mlosing\u001b[0m \u001b[0mconnection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         \"\"\"\n\u001b[0;32m--> 190\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommunicator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpackage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    191\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minitialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/FLGo/flgo/__init__.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, source, target, package)\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpackage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;31m# send package to the target object with `package` and `mtype`, and then listen from it\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobjects_map\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage_handler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpackage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/content/FLGo/flgo/algorithm/fedbase.py\u001b[0m in \u001b[0;36mmessage_handler\u001b[0;34m(self, package)\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmtype\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"There is no action corresponding to message type {}.\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmtype\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpackage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mset_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflag\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/FLGo/flgo/algorithm/fedbase.py\u001b[0m in \u001b[0;36mreply\u001b[0;34m(self, svr_pkg)\u001b[0m\n\u001b[1;32m    710\u001b[0m         \"\"\"\n\u001b[1;32m    711\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msvr_pkg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 712\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    713\u001b[0m         \u001b[0mcpkg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    714\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcpkg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/FLGo/flgo/simulator/base.py\u001b[0m in \u001b[0;36mtrain_with_incomplete_update\u001b[0;34m(self, model, *args, **kwargs)\u001b[0m\n\u001b[1;32m    528\u001b[0m         \u001b[0mold_num_steps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_steps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    529\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_steps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_working_amount\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 530\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    531\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_steps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mold_num_steps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    532\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/FLGo/flgo/utils/fmodule.py\u001b[0m in \u001b[0;36mcal_on_personal_gpu\u001b[0;34m(self, model, *args, **kargs)\u001b[0m\n\u001b[1;32m    927\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m         \u001b[0;31m# calculating\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 929\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mnew_kargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    930\u001b[0m         \u001b[0;31m# transter to original device\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morigin_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/FLGo/flgo/algorithm/fedbase.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, model)\u001b[0m\n\u001b[1;32m    657\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0miter\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    658\u001b[0m             \u001b[0;31m# get a batch of data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 659\u001b[0;31m             \u001b[0mbatch_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_batch_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    660\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    661\u001b[0m             \u001b[0;31m# calculate the loss of the model on batched dataset through task-specified calculator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/FLGo/flgo/algorithm/fedbase.py\u001b[0m in \u001b[0;36mget_batch_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    836\u001b[0m                                                                    pin_memory=self.option['pin_memory'])\n\u001b[1;32m    837\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 838\u001b[0;31m             \u001b[0mbatch_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    839\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    840\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    631\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    632\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 633\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    634\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    635\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    675\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    676\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 677\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    678\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    679\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataset.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    296\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 298\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    299\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/FLGo/flgo/benchmark/toolkits/cv/classification/__init__.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     36\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m                         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mperturbation\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/datasets/svhn.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_transform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, tensor)\u001b[0m\n\u001b[1;32m    275\u001b[0m             \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mNormalized\u001b[0m \u001b[0mTensor\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m         \"\"\"\n\u001b[0;32m--> 277\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py\u001b[0m in \u001b[0;36mnormalize\u001b[0;34m(tensor, mean, std, inplace)\u001b[0m\n\u001b[1;32m    361\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"img should be Tensor Image. Got {type(tensor)}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 363\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mF_t\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/transforms/_functional_tensor.py\u001b[0m in \u001b[0;36mnormalize\u001b[0;34m(tensor, mean, std, inplace)\u001b[0m\n\u001b[1;32m    918\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m     \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 920\u001b[0;31m     \u001b[0mmean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    921\u001b[0m     \u001b[0mstd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    922\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mstd\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "import flgo.algorithm.fedavg as fedprox\n",
        "runner = flgo.init(task, fedavg, option=option)\n",
        "torch.cuda.empty_cache()\n",
        "runner.model\n",
        "runner.run()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "BqIePGm0IVV_",
        "outputId": "4fc1f60d-8f12-46fc-8c1a-3950f9415d27"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-08-16 21:27:00,657 fflow.py init [line:441] INFO Initializing devices: cuda:0 will be used for this running.\n",
            "2023-08-16 21:27:00,696 fflow.py init [line:479] INFO Use `<class 'flgo.simulator.default_simulator.Simulator'>` as the system simulator\n",
            "2023-08-16 21:27:00,698 fflow.py init [line:487] INFO Ready to start.\n",
            "2023-08-16 21:27:00,716 fedbase.py run [line:236] INFO --------------Initial Evaluation--------------\n",
            "2023-08-16 21:27:00,717 simple_logger.py log_once [line:14] INFO Current_time:0\n",
            "2023-08-16 21:27:03,936 simple_logger.py log_once [line:28] INFO test_accuracy                 0.1169\n",
            "2023-08-16 21:27:03,938 simple_logger.py log_once [line:28] INFO test_loss                     2.3035\n",
            "2023-08-16 21:27:03,941 simple_logger.py log_once [line:28] INFO valid_accuracy                0.1151\n",
            "2023-08-16 21:27:03,943 simple_logger.py log_once [line:28] INFO mean_valid_accuracy           0.1151\n",
            "2023-08-16 21:27:03,945 simple_logger.py log_once [line:28] INFO std_valid_accuracy            0.2255\n",
            "2023-08-16 21:27:03,946 simple_logger.py log_once [line:28] INFO valid_loss                    2.3035\n",
            "2023-08-16 21:27:03,948 simple_logger.py log_once [line:28] INFO mean_valid_loss               2.3035\n",
            "2023-08-16 21:27:03,950 simple_logger.py log_once [line:28] INFO std_valid_loss                0.0112\n",
            "2023-08-16 21:27:03,950 fedbase.py run [line:239] INFO Eval Time Cost:               3.2335s\n",
            "2023-08-16 21:27:06,744 fedbase.py run [line:246] INFO --------------Round 1--------------\n",
            "2023-08-16 21:27:06,745 simple_logger.py log_once [line:14] INFO Current_time:1\n",
            "2023-08-16 21:27:10,057 simple_logger.py log_once [line:28] INFO test_accuracy                 0.1000\n",
            "2023-08-16 21:27:10,058 simple_logger.py log_once [line:28] INFO test_loss                     5.0659\n",
            "2023-08-16 21:27:10,061 simple_logger.py log_once [line:28] INFO valid_accuracy                0.1000\n",
            "2023-08-16 21:27:10,064 simple_logger.py log_once [line:28] INFO mean_valid_accuracy           0.1000\n",
            "2023-08-16 21:27:10,071 simple_logger.py log_once [line:28] INFO std_valid_accuracy            0.3000\n",
            "2023-08-16 21:27:10,074 simple_logger.py log_once [line:28] INFO valid_loss                    5.0547\n",
            "2023-08-16 21:27:10,075 simple_logger.py log_once [line:28] INFO mean_valid_loss               5.0554\n",
            "2023-08-16 21:27:10,076 simple_logger.py log_once [line:28] INFO std_valid_loss                2.3154\n",
            "2023-08-16 21:27:10,077 fedbase.py run [line:251] INFO Eval Time Cost:               3.3326s\n",
            "2023-08-16 21:27:13,998 fedbase.py run [line:246] INFO --------------Round 2--------------\n",
            "2023-08-16 21:27:14,000 simple_logger.py log_once [line:14] INFO Current_time:2\n",
            "2023-08-16 21:27:17,238 simple_logger.py log_once [line:28] INFO test_accuracy                 0.1000\n",
            "2023-08-16 21:27:17,239 simple_logger.py log_once [line:28] INFO test_loss                     3.2256\n",
            "2023-08-16 21:27:17,243 simple_logger.py log_once [line:28] INFO valid_accuracy                0.0998\n",
            "2023-08-16 21:27:17,246 simple_logger.py log_once [line:28] INFO mean_valid_accuracy           0.0995\n",
            "2023-08-16 21:27:17,248 simple_logger.py log_once [line:28] INFO std_valid_accuracy            0.2985\n",
            "2023-08-16 21:27:17,250 simple_logger.py log_once [line:28] INFO valid_loss                    3.2326\n",
            "2023-08-16 21:27:17,252 simple_logger.py log_once [line:28] INFO mean_valid_loss               3.2331\n",
            "2023-08-16 21:27:17,256 simple_logger.py log_once [line:28] INFO std_valid_loss                1.3466\n",
            "2023-08-16 21:27:17,257 fedbase.py run [line:251] INFO Eval Time Cost:               3.2574s\n",
            "2023-08-16 21:27:19,975 fedbase.py run [line:246] INFO --------------Round 3--------------\n",
            "2023-08-16 21:27:19,976 simple_logger.py log_once [line:14] INFO Current_time:3\n",
            "2023-08-16 21:27:23,134 simple_logger.py log_once [line:28] INFO test_accuracy                 0.1031\n",
            "2023-08-16 21:27:23,135 simple_logger.py log_once [line:28] INFO test_loss                     2.4670\n",
            "2023-08-16 21:27:23,139 simple_logger.py log_once [line:28] INFO valid_accuracy                0.1017\n",
            "2023-08-16 21:27:23,142 simple_logger.py log_once [line:28] INFO mean_valid_accuracy           0.1017\n",
            "2023-08-16 21:27:23,146 simple_logger.py log_once [line:28] INFO std_valid_accuracy            0.2995\n",
            "2023-08-16 21:27:23,147 simple_logger.py log_once [line:28] INFO valid_loss                    2.4669\n",
            "2023-08-16 21:27:23,150 simple_logger.py log_once [line:28] INFO mean_valid_loss               2.4670\n",
            "2023-08-16 21:27:23,152 simple_logger.py log_once [line:28] INFO std_valid_loss                0.5179\n",
            "2023-08-16 21:27:23,155 fedbase.py run [line:251] INFO Eval Time Cost:               3.1785s\n",
            "2023-08-16 21:27:27,017 fedbase.py run [line:246] INFO --------------Round 4--------------\n",
            "2023-08-16 21:27:27,019 simple_logger.py log_once [line:14] INFO Current_time:4\n",
            "2023-08-16 21:27:30,402 simple_logger.py log_once [line:28] INFO test_accuracy                 0.1000\n",
            "2023-08-16 21:27:30,403 simple_logger.py log_once [line:28] INFO test_loss                     6.0026\n",
            "2023-08-16 21:27:30,406 simple_logger.py log_once [line:28] INFO valid_accuracy                0.1004\n",
            "2023-08-16 21:27:30,408 simple_logger.py log_once [line:28] INFO mean_valid_accuracy           0.1008\n",
            "2023-08-16 21:27:30,410 simple_logger.py log_once [line:28] INFO std_valid_accuracy            0.2997\n",
            "2023-08-16 21:27:30,412 simple_logger.py log_once [line:28] INFO valid_loss                    6.0098\n",
            "2023-08-16 21:27:30,417 simple_logger.py log_once [line:28] INFO mean_valid_loss               6.0076\n",
            "2023-08-16 21:27:30,418 simple_logger.py log_once [line:28] INFO std_valid_loss                2.7885\n",
            "2023-08-16 21:27:30,420 fedbase.py run [line:251] INFO Eval Time Cost:               3.4012s\n",
            "2023-08-16 21:27:33,090 fedbase.py run [line:246] INFO --------------Round 5--------------\n",
            "2023-08-16 21:27:33,092 simple_logger.py log_once [line:14] INFO Current_time:5\n",
            "2023-08-16 21:27:36,251 simple_logger.py log_once [line:28] INFO test_accuracy                 0.1000\n",
            "2023-08-16 21:27:36,252 simple_logger.py log_once [line:28] INFO test_loss                     2.3639\n",
            "2023-08-16 21:27:36,255 simple_logger.py log_once [line:28] INFO valid_accuracy                0.1000\n",
            "2023-08-16 21:27:36,260 simple_logger.py log_once [line:28] INFO mean_valid_accuracy           0.1000\n",
            "2023-08-16 21:27:36,261 simple_logger.py log_once [line:28] INFO std_valid_accuracy            0.3000\n",
            "2023-08-16 21:27:36,265 simple_logger.py log_once [line:28] INFO valid_loss                    2.3651\n",
            "2023-08-16 21:27:36,266 simple_logger.py log_once [line:28] INFO mean_valid_loss               2.3654\n",
            "2023-08-16 21:27:36,267 simple_logger.py log_once [line:28] INFO std_valid_loss                0.4778\n",
            "2023-08-16 21:27:36,268 fedbase.py run [line:251] INFO Eval Time Cost:               3.1767s\n",
            "2023-08-16 21:27:40,011 fedbase.py run [line:246] INFO --------------Round 6--------------\n",
            "2023-08-16 21:27:40,013 simple_logger.py log_once [line:14] INFO Current_time:6\n",
            "2023-08-16 21:27:43,379 simple_logger.py log_once [line:28] INFO test_accuracy                 0.1810\n",
            "2023-08-16 21:27:43,381 simple_logger.py log_once [line:28] INFO test_loss                     2.9429\n",
            "2023-08-16 21:27:43,387 simple_logger.py log_once [line:28] INFO valid_accuracy                0.1819\n",
            "2023-08-16 21:27:43,388 simple_logger.py log_once [line:28] INFO mean_valid_accuracy           0.1815\n",
            "2023-08-16 21:27:43,390 simple_logger.py log_once [line:28] INFO std_valid_accuracy            0.3634\n",
            "2023-08-16 21:27:43,393 simple_logger.py log_once [line:28] INFO valid_loss                    2.9462\n",
            "2023-08-16 21:27:43,397 simple_logger.py log_once [line:28] INFO mean_valid_loss               2.9472\n",
            "2023-08-16 21:27:43,398 simple_logger.py log_once [line:28] INFO std_valid_loss                1.2152\n",
            "2023-08-16 21:27:43,399 fedbase.py run [line:251] INFO Eval Time Cost:               3.3856s\n",
            "2023-08-16 21:27:44,892 fedbase.py run [line:246] INFO --------------Round 7--------------\n",
            "2023-08-16 21:27:44,893 simple_logger.py log_once [line:14] INFO Current_time:7\n",
            "2023-08-16 21:27:48,111 simple_logger.py log_once [line:28] INFO test_accuracy                 0.1000\n",
            "2023-08-16 21:27:48,113 simple_logger.py log_once [line:28] INFO test_loss                     10.7936\n",
            "2023-08-16 21:27:48,116 simple_logger.py log_once [line:28] INFO valid_accuracy                0.1000\n",
            "2023-08-16 21:27:48,119 simple_logger.py log_once [line:28] INFO mean_valid_accuracy           0.1000\n",
            "2023-08-16 21:27:48,121 simple_logger.py log_once [line:28] INFO std_valid_accuracy            0.3000\n",
            "2023-08-16 21:27:48,127 simple_logger.py log_once [line:28] INFO valid_loss                    10.8689\n",
            "2023-08-16 21:27:48,128 simple_logger.py log_once [line:28] INFO mean_valid_loss               10.8695\n",
            "2023-08-16 21:27:48,129 simple_logger.py log_once [line:28] INFO std_valid_loss                4.4262\n",
            "2023-08-16 21:27:48,131 fedbase.py run [line:251] INFO Eval Time Cost:               3.2381s\n",
            "2023-08-16 21:27:51,084 fedbase.py run [line:246] INFO --------------Round 8--------------\n",
            "2023-08-16 21:27:51,091 simple_logger.py log_once [line:14] INFO Current_time:8\n",
            "2023-08-16 21:27:55,320 simple_logger.py log_once [line:28] INFO test_accuracy                 0.1026\n",
            "2023-08-16 21:27:55,321 simple_logger.py log_once [line:28] INFO test_loss                     18.9376\n",
            "2023-08-16 21:27:55,325 simple_logger.py log_once [line:28] INFO valid_accuracy                0.1023\n",
            "2023-08-16 21:27:55,328 simple_logger.py log_once [line:28] INFO mean_valid_accuracy           0.1023\n",
            "2023-08-16 21:27:55,330 simple_logger.py log_once [line:28] INFO std_valid_accuracy            0.2993\n",
            "2023-08-16 21:27:55,333 simple_logger.py log_once [line:28] INFO valid_loss                    18.9667\n",
            "2023-08-16 21:27:55,335 simple_logger.py log_once [line:28] INFO mean_valid_loss               18.9698\n",
            "2023-08-16 21:27:55,337 simple_logger.py log_once [line:28] INFO std_valid_loss                12.1998\n",
            "2023-08-16 21:27:55,338 fedbase.py run [line:251] INFO Eval Time Cost:               4.2476s\n",
            "2023-08-16 21:27:58,022 fedbase.py run [line:246] INFO --------------Round 9--------------\n",
            "2023-08-16 21:27:58,025 simple_logger.py log_once [line:14] INFO Current_time:9\n",
            "2023-08-16 21:28:01,430 simple_logger.py log_once [line:28] INFO test_accuracy                 0.1000\n",
            "2023-08-16 21:28:01,431 simple_logger.py log_once [line:28] INFO test_loss                     3.0068\n",
            "2023-08-16 21:28:01,432 simple_logger.py log_once [line:28] INFO valid_accuracy                0.0998\n",
            "2023-08-16 21:28:01,436 simple_logger.py log_once [line:28] INFO mean_valid_accuracy           0.0998\n",
            "2023-08-16 21:28:01,439 simple_logger.py log_once [line:28] INFO std_valid_accuracy            0.2995\n",
            "2023-08-16 21:28:01,440 simple_logger.py log_once [line:28] INFO valid_loss                    3.0093\n",
            "2023-08-16 21:28:01,444 simple_logger.py log_once [line:28] INFO mean_valid_loss               3.0099\n",
            "2023-08-16 21:28:01,446 simple_logger.py log_once [line:28] INFO std_valid_loss                1.6037\n",
            "2023-08-16 21:28:01,447 fedbase.py run [line:251] INFO Eval Time Cost:               3.4240s\n",
            "2023-08-16 21:28:04,364 fedbase.py run [line:246] INFO --------------Round 10--------------\n",
            "2023-08-16 21:28:04,369 simple_logger.py log_once [line:14] INFO Current_time:10\n",
            "2023-08-16 21:28:08,672 simple_logger.py log_once [line:28] INFO test_accuracy                 0.1996\n",
            "2023-08-16 21:28:08,673 simple_logger.py log_once [line:28] INFO test_loss                     7.9837\n",
            "2023-08-16 21:28:08,677 simple_logger.py log_once [line:28] INFO valid_accuracy                0.1995\n",
            "2023-08-16 21:28:08,679 simple_logger.py log_once [line:28] INFO mean_valid_accuracy           0.1995\n",
            "2023-08-16 21:28:08,681 simple_logger.py log_once [line:28] INFO std_valid_accuracy            0.3990\n",
            "2023-08-16 21:28:08,684 simple_logger.py log_once [line:28] INFO valid_loss                    8.0166\n",
            "2023-08-16 21:28:08,686 simple_logger.py log_once [line:28] INFO mean_valid_loss               8.0192\n",
            "2023-08-16 21:28:08,688 simple_logger.py log_once [line:28] INFO std_valid_loss                7.5231\n",
            "2023-08-16 21:28:08,689 fedbase.py run [line:251] INFO Eval Time Cost:               4.3202s\n",
            "2023-08-16 21:28:11,506 fedbase.py run [line:246] INFO --------------Round 11--------------\n",
            "2023-08-16 21:28:11,507 simple_logger.py log_once [line:14] INFO Current_time:11\n",
            "2023-08-16 21:28:14,725 simple_logger.py log_once [line:28] INFO test_accuracy                 0.1194\n",
            "2023-08-16 21:28:14,726 simple_logger.py log_once [line:28] INFO test_loss                     2.2997\n",
            "2023-08-16 21:28:14,727 simple_logger.py log_once [line:28] INFO valid_accuracy                0.1183\n",
            "2023-08-16 21:28:14,731 simple_logger.py log_once [line:28] INFO mean_valid_accuracy           0.1183\n",
            "2023-08-16 21:28:14,733 simple_logger.py log_once [line:28] INFO std_valid_accuracy            0.2925\n",
            "2023-08-16 21:28:14,735 simple_logger.py log_once [line:28] INFO valid_loss                    2.3008\n",
            "2023-08-16 21:28:14,737 simple_logger.py log_once [line:28] INFO mean_valid_loss               2.3009\n",
            "2023-08-16 21:28:14,738 simple_logger.py log_once [line:28] INFO std_valid_loss                0.3573\n",
            "2023-08-16 21:28:14,739 fedbase.py run [line:251] INFO Eval Time Cost:               3.2314s\n",
            "2023-08-16 21:28:17,566 fedbase.py run [line:246] INFO --------------Round 12--------------\n",
            "2023-08-16 21:28:17,568 simple_logger.py log_once [line:14] INFO Current_time:12\n",
            "2023-08-16 21:28:21,867 simple_logger.py log_once [line:28] INFO test_accuracy                 0.1000\n",
            "2023-08-16 21:28:21,869 simple_logger.py log_once [line:28] INFO test_loss                     6.9178\n",
            "2023-08-16 21:28:21,872 simple_logger.py log_once [line:28] INFO valid_accuracy                0.0999\n",
            "2023-08-16 21:28:21,875 simple_logger.py log_once [line:28] INFO mean_valid_accuracy           0.0998\n",
            "2023-08-16 21:28:21,878 simple_logger.py log_once [line:28] INFO std_valid_accuracy            0.2995\n",
            "2023-08-16 21:28:21,880 simple_logger.py log_once [line:28] INFO valid_loss                    6.9454\n",
            "2023-08-16 21:28:21,882 simple_logger.py log_once [line:28] INFO mean_valid_loss               6.9469\n",
            "2023-08-16 21:28:21,883 simple_logger.py log_once [line:28] INFO std_valid_loss                3.7979\n",
            "2023-08-16 21:28:21,885 fedbase.py run [line:251] INFO Eval Time Cost:               4.3166s\n",
            "2023-08-16 21:28:24,626 fedbase.py run [line:246] INFO --------------Round 13--------------\n",
            "2023-08-16 21:28:24,627 simple_logger.py log_once [line:14] INFO Current_time:13\n",
            "2023-08-16 21:28:27,781 simple_logger.py log_once [line:28] INFO test_accuracy                 0.1499\n",
            "2023-08-16 21:28:27,782 simple_logger.py log_once [line:28] INFO test_loss                     24.0787\n",
            "2023-08-16 21:28:27,785 simple_logger.py log_once [line:28] INFO valid_accuracy                0.1485\n",
            "2023-08-16 21:28:27,788 simple_logger.py log_once [line:28] INFO mean_valid_accuracy           0.1485\n",
            "2023-08-16 21:28:27,791 simple_logger.py log_once [line:28] INFO std_valid_accuracy            0.3183\n",
            "2023-08-16 21:28:27,796 simple_logger.py log_once [line:28] INFO valid_loss                    24.0720\n",
            "2023-08-16 21:28:27,797 simple_logger.py log_once [line:28] INFO mean_valid_loss               24.0728\n",
            "2023-08-16 21:28:27,800 simple_logger.py log_once [line:28] INFO std_valid_loss                14.9191\n",
            "2023-08-16 21:28:27,801 fedbase.py run [line:251] INFO Eval Time Cost:               3.1741s\n",
            "2023-08-16 21:28:30,735 fedbase.py run [line:246] INFO --------------Round 14--------------\n",
            "2023-08-16 21:28:30,741 simple_logger.py log_once [line:14] INFO Current_time:14\n",
            "2023-08-16 21:28:35,188 simple_logger.py log_once [line:28] INFO test_accuracy                 0.0839\n",
            "2023-08-16 21:28:35,190 simple_logger.py log_once [line:28] INFO test_loss                     15.4928\n",
            "2023-08-16 21:28:35,193 simple_logger.py log_once [line:28] INFO valid_accuracy                0.0808\n",
            "2023-08-16 21:28:35,195 simple_logger.py log_once [line:28] INFO mean_valid_accuracy           0.0808\n",
            "2023-08-16 21:28:35,198 simple_logger.py log_once [line:28] INFO std_valid_accuracy            0.2150\n",
            "2023-08-16 21:28:35,200 simple_logger.py log_once [line:28] INFO valid_loss                    15.4440\n",
            "2023-08-16 21:28:35,201 simple_logger.py log_once [line:28] INFO mean_valid_loss               15.4432\n",
            "2023-08-16 21:28:35,203 simple_logger.py log_once [line:28] INFO std_valid_loss                8.2853\n",
            "2023-08-16 21:28:35,204 fedbase.py run [line:251] INFO Eval Time Cost:               4.4627s\n",
            "2023-08-16 21:28:36,627 fedbase.py run [line:246] INFO --------------Round 15--------------\n",
            "2023-08-16 21:28:36,628 simple_logger.py log_once [line:14] INFO Current_time:15\n",
            "2023-08-16 21:28:40,281 simple_logger.py log_once [line:28] INFO test_accuracy                 0.1000\n",
            "2023-08-16 21:28:40,283 simple_logger.py log_once [line:28] INFO test_loss                     1761.0184\n",
            "2023-08-16 21:28:40,285 simple_logger.py log_once [line:28] INFO valid_accuracy                0.1000\n",
            "2023-08-16 21:28:40,287 simple_logger.py log_once [line:28] INFO mean_valid_accuracy           0.1000\n",
            "2023-08-16 21:28:40,289 simple_logger.py log_once [line:28] INFO std_valid_accuracy            0.3000\n",
            "2023-08-16 21:28:40,291 simple_logger.py log_once [line:28] INFO valid_loss                    1773.1780\n",
            "2023-08-16 21:28:40,293 simple_logger.py log_once [line:28] INFO mean_valid_loss               1773.2251\n",
            "2023-08-16 21:28:40,294 simple_logger.py log_once [line:28] INFO std_valid_loss                991.9505\n",
            "2023-08-16 21:28:40,295 fedbase.py run [line:251] INFO Eval Time Cost:               3.6661s\n",
            "2023-08-16 21:28:43,079 fedbase.py run [line:246] INFO --------------Round 16--------------\n",
            "2023-08-16 21:28:43,081 simple_logger.py log_once [line:14] INFO Current_time:16\n",
            "2023-08-16 21:28:47,544 simple_logger.py log_once [line:28] INFO test_accuracy                 0.1000\n",
            "2023-08-16 21:28:47,546 simple_logger.py log_once [line:28] INFO test_loss                     4916.1231\n",
            "2023-08-16 21:28:47,547 simple_logger.py log_once [line:28] INFO valid_accuracy                0.0998\n",
            "2023-08-16 21:28:47,550 simple_logger.py log_once [line:28] INFO mean_valid_accuracy           0.0998\n",
            "2023-08-16 21:28:47,552 simple_logger.py log_once [line:28] INFO std_valid_accuracy            0.2995\n",
            "2023-08-16 21:28:47,555 simple_logger.py log_once [line:28] INFO valid_loss                    4936.7154\n",
            "2023-08-16 21:28:47,556 simple_logger.py log_once [line:28] INFO mean_valid_loss               4936.4623\n",
            "2023-08-16 21:28:47,558 simple_logger.py log_once [line:28] INFO std_valid_loss                3372.1517\n",
            "2023-08-16 21:28:47,559 fedbase.py run [line:251] INFO Eval Time Cost:               4.4785s\n",
            "2023-08-16 21:28:51,668 fedbase.py run [line:246] INFO --------------Round 17--------------\n",
            "2023-08-16 21:28:51,669 simple_logger.py log_once [line:14] INFO Current_time:17\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-e0d231b2dd2a>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mrunner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mrunner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/content/FLGo/flgo/algorithm/fedbase.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    248\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_if_log\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_round\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval_interval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime_start\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Eval Time Cost'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 250\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_once\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Eval Time Cost'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m                 \u001b[0;31m# check if early stopping\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/FLGo/flgo/experiment/logger/simple_logger.py\u001b[0m in \u001b[0;36mlog_once\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Current_time:{}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'time'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mtest_metric\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoordinator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmet_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmet_val\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtest_metric\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'test_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmet_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmet_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/FLGo/flgo/algorithm/fedbase.py\u001b[0m in \u001b[0;36mtest\u001b[0;34m(self, model, flag)\u001b[0m\n\u001b[1;32m    521\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    522\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 523\u001b[0;31m             return self.calculator.test(model, dataset, batch_size=min(self.option['test_batch_size'], len(dataset)),\n\u001b[0m\u001b[1;32m    524\u001b[0m                                         num_workers=self.option['num_workers'], pin_memory=self.option['pin_memory'])\n\u001b[1;32m    525\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/FLGo/flgo/benchmark/toolkits/cv/classification/__init__.py\u001b[0m in \u001b[0;36mtest\u001b[0;34m(self, model, dataset, batch_size, num_workers, pin_memory)\u001b[0m\n\u001b[1;32m    242\u001b[0m         \u001b[0mtotal_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m         \u001b[0mnum_correct\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 244\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mbatch_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_data\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    245\u001b[0m             \u001b[0mbatch_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    631\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    632\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 633\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    634\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    635\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    675\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    676\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 677\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    678\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    679\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/datasets/mnist.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_transform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, tensor)\u001b[0m\n\u001b[1;32m    275\u001b[0m             \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mNormalized\u001b[0m \u001b[0mTensor\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m         \"\"\"\n\u001b[0;32m--> 277\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py\u001b[0m in \u001b[0;36mnormalize\u001b[0;34m(tensor, mean, std, inplace)\u001b[0m\n\u001b[1;32m    361\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"img should be Tensor Image. Got {type(tensor)}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 363\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mF_t\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "import flgo.algorithm.fedavg as fedprox\n",
        "runner = flgo.init(task, fedprox, option=option, model=model_DC)\n",
        "torch.cuda.empty_cache()\n",
        "runner.model\n",
        "runner.run()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EcOhxeKMNItw",
        "outputId": "ebba208a-5c2e-41d6-d5a5-5fabe59f0695"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-08-15 11:27:33,770 fflow.py init [line:441] INFO Initializing devices: cuda:0 will be used for this running.\n",
            "2023-08-15 11:27:33,813 fflow.py init [line:479] INFO Use `<class 'flgo.simulator.default_simulator.Simulator'>` as the system simulator\n",
            "2023-08-15 11:27:33,816 fflow.py init [line:487] INFO Ready to start.\n",
            "2023-08-15 11:27:33,823 fedbase.py run [line:236] INFO --------------Initial Evaluation--------------\n",
            "2023-08-15 11:27:33,824 simple_logger.py log_once [line:14] INFO Current_time:0\n",
            "2023-08-15 11:27:37,549 simple_logger.py log_once [line:28] INFO test_accuracy                 0.1277\n",
            "2023-08-15 11:27:37,550 simple_logger.py log_once [line:28] INFO test_loss                     2.3034\n",
            "2023-08-15 11:27:37,552 simple_logger.py log_once [line:28] INFO valid_accuracy                0.1256\n",
            "2023-08-15 11:27:37,555 simple_logger.py log_once [line:28] INFO mean_valid_accuracy           0.1271\n",
            "2023-08-15 11:27:37,560 simple_logger.py log_once [line:28] INFO std_valid_accuracy            0.2271\n",
            "2023-08-15 11:27:37,562 simple_logger.py log_once [line:28] INFO valid_loss                    2.3036\n",
            "2023-08-15 11:27:37,563 simple_logger.py log_once [line:28] INFO mean_valid_loss               2.3036\n",
            "2023-08-15 11:27:37,567 simple_logger.py log_once [line:28] INFO std_valid_loss                0.0084\n",
            "2023-08-15 11:27:37,568 fedbase.py run [line:239] INFO Eval Time Cost:               3.7442s\n",
            "2023-08-15 11:27:41,060 fedbase.py run [line:246] INFO --------------Round 1--------------\n",
            "2023-08-15 11:27:41,062 simple_logger.py log_once [line:14] INFO Current_time:1\n",
            "2023-08-15 11:27:46,059 simple_logger.py log_once [line:28] INFO test_accuracy                 0.3118\n",
            "2023-08-15 11:27:46,060 simple_logger.py log_once [line:28] INFO test_loss                     2.2476\n",
            "2023-08-15 11:27:46,064 simple_logger.py log_once [line:28] INFO valid_accuracy                0.3108\n",
            "2023-08-15 11:27:46,068 simple_logger.py log_once [line:28] INFO mean_valid_accuracy           0.3108\n",
            "2023-08-15 11:27:46,070 simple_logger.py log_once [line:28] INFO std_valid_accuracy            0.3057\n",
            "2023-08-15 11:27:46,072 simple_logger.py log_once [line:28] INFO valid_loss                    2.2472\n",
            "2023-08-15 11:27:46,073 simple_logger.py log_once [line:28] INFO mean_valid_loss               2.2516\n",
            "2023-08-15 11:27:46,074 simple_logger.py log_once [line:28] INFO std_valid_loss                0.5880\n",
            "2023-08-15 11:27:46,075 fedbase.py run [line:251] INFO Eval Time Cost:               5.0124s\n",
            "2023-08-15 11:27:49,360 fedbase.py run [line:246] INFO --------------Round 2--------------\n",
            "2023-08-15 11:27:49,361 simple_logger.py log_once [line:14] INFO Current_time:2\n",
            "2023-08-15 11:27:53,087 simple_logger.py log_once [line:28] INFO test_accuracy                 0.3267\n",
            "2023-08-15 11:27:53,088 simple_logger.py log_once [line:28] INFO test_loss                     3.3763\n",
            "2023-08-15 11:27:53,092 simple_logger.py log_once [line:28] INFO valid_accuracy                0.3242\n",
            "2023-08-15 11:27:53,094 simple_logger.py log_once [line:28] INFO mean_valid_accuracy           0.3242\n",
            "2023-08-15 11:27:53,096 simple_logger.py log_once [line:28] INFO std_valid_accuracy            0.3215\n",
            "2023-08-15 11:27:53,098 simple_logger.py log_once [line:28] INFO valid_loss                    3.3499\n",
            "2023-08-15 11:27:53,099 simple_logger.py log_once [line:28] INFO mean_valid_loss               3.3598\n",
            "2023-08-15 11:27:53,100 simple_logger.py log_once [line:28] INFO std_valid_loss                2.0126\n",
            "2023-08-15 11:27:53,101 fedbase.py run [line:251] INFO Eval Time Cost:               3.7398s\n",
            "2023-08-15 11:27:57,101 fedbase.py run [line:246] INFO --------------Round 3--------------\n",
            "2023-08-15 11:27:57,107 simple_logger.py log_once [line:14] INFO Current_time:3\n",
            "2023-08-15 11:28:01,408 simple_logger.py log_once [line:28] INFO test_accuracy                 0.4649\n",
            "2023-08-15 11:28:01,409 simple_logger.py log_once [line:28] INFO test_loss                     2.8496\n",
            "2023-08-15 11:28:01,414 simple_logger.py log_once [line:28] INFO valid_accuracy                0.4738\n",
            "2023-08-15 11:28:01,417 simple_logger.py log_once [line:28] INFO mean_valid_accuracy           0.4713\n",
            "2023-08-15 11:28:01,419 simple_logger.py log_once [line:28] INFO std_valid_accuracy            0.3360\n",
            "2023-08-15 11:28:01,420 simple_logger.py log_once [line:28] INFO valid_loss                    2.8090\n",
            "2023-08-15 11:28:01,423 simple_logger.py log_once [line:28] INFO mean_valid_loss               2.8298\n",
            "2023-08-15 11:28:01,424 simple_logger.py log_once [line:28] INFO std_valid_loss                2.4772\n",
            "2023-08-15 11:28:01,425 fedbase.py run [line:251] INFO Eval Time Cost:               4.3184s\n",
            "2023-08-15 11:28:04,784 fedbase.py run [line:246] INFO --------------Round 4--------------\n",
            "2023-08-15 11:28:04,786 simple_logger.py log_once [line:14] INFO Current_time:4\n",
            "2023-08-15 11:28:08,738 simple_logger.py log_once [line:28] INFO test_accuracy                 0.3288\n",
            "2023-08-15 11:28:08,740 simple_logger.py log_once [line:28] INFO test_loss                     2.5944\n",
            "2023-08-15 11:28:08,742 simple_logger.py log_once [line:28] INFO valid_accuracy                0.3395\n",
            "2023-08-15 11:28:08,744 simple_logger.py log_once [line:28] INFO mean_valid_accuracy           0.3367\n",
            "2023-08-15 11:28:08,746 simple_logger.py log_once [line:28] INFO std_valid_accuracy            0.3380\n",
            "2023-08-15 11:28:08,747 simple_logger.py log_once [line:28] INFO valid_loss                    2.5433\n",
            "2023-08-15 11:28:08,749 simple_logger.py log_once [line:28] INFO mean_valid_loss               2.5629\n",
            "2023-08-15 11:28:08,750 simple_logger.py log_once [line:28] INFO std_valid_loss                1.7886\n",
            "2023-08-15 11:28:08,752 fedbase.py run [line:251] INFO Eval Time Cost:               3.9659s\n",
            "2023-08-15 11:28:13,225 fedbase.py run [line:246] INFO --------------Round 5--------------\n",
            "2023-08-15 11:28:13,226 simple_logger.py log_once [line:14] INFO Current_time:5\n",
            "2023-08-15 11:28:16,911 simple_logger.py log_once [line:28] INFO test_accuracy                 0.4123\n",
            "2023-08-15 11:28:16,912 simple_logger.py log_once [line:28] INFO test_loss                     2.8981\n",
            "2023-08-15 11:28:16,914 simple_logger.py log_once [line:28] INFO valid_accuracy                0.4172\n",
            "2023-08-15 11:28:16,916 simple_logger.py log_once [line:28] INFO mean_valid_accuracy           0.4175\n",
            "2023-08-15 11:28:16,918 simple_logger.py log_once [line:28] INFO std_valid_accuracy            0.3487\n",
            "2023-08-15 11:28:16,923 simple_logger.py log_once [line:28] INFO valid_loss                    2.8330\n",
            "2023-08-15 11:28:16,925 simple_logger.py log_once [line:28] INFO mean_valid_loss               2.8464\n",
            "2023-08-15 11:28:16,931 simple_logger.py log_once [line:28] INFO std_valid_loss                2.2997\n",
            "2023-08-15 11:28:16,932 fedbase.py run [line:251] INFO Eval Time Cost:               3.7059s\n",
            "2023-08-15 11:28:20,016 fedbase.py run [line:246] INFO --------------Round 6--------------\n",
            "2023-08-15 11:28:20,017 simple_logger.py log_once [line:14] INFO Current_time:6\n",
            "2023-08-15 11:28:24,693 simple_logger.py log_once [line:28] INFO test_accuracy                 0.4250\n",
            "2023-08-15 11:28:24,697 simple_logger.py log_once [line:28] INFO test_loss                     1.6577\n",
            "2023-08-15 11:28:24,699 simple_logger.py log_once [line:28] INFO valid_accuracy                0.4270\n",
            "2023-08-15 11:28:24,701 simple_logger.py log_once [line:28] INFO mean_valid_accuracy           0.4292\n",
            "2023-08-15 11:28:24,702 simple_logger.py log_once [line:28] INFO std_valid_accuracy            0.3298\n",
            "2023-08-15 11:28:24,704 simple_logger.py log_once [line:28] INFO valid_loss                    1.6138\n",
            "2023-08-15 11:28:24,705 simple_logger.py log_once [line:28] INFO mean_valid_loss               1.6111\n",
            "2023-08-15 11:28:24,706 simple_logger.py log_once [line:28] INFO std_valid_loss                0.9409\n",
            "2023-08-15 11:28:24,707 fedbase.py run [line:251] INFO Eval Time Cost:               4.6903s\n",
            "2023-08-15 11:28:27,715 fedbase.py run [line:246] INFO --------------Round 7--------------\n",
            "2023-08-15 11:28:27,720 simple_logger.py log_once [line:14] INFO Current_time:7\n",
            "2023-08-15 11:28:32,063 simple_logger.py log_once [line:28] INFO test_accuracy                 0.6290\n",
            "2023-08-15 11:28:32,064 simple_logger.py log_once [line:28] INFO test_loss                     1.5760\n",
            "2023-08-15 11:28:32,067 simple_logger.py log_once [line:28] INFO valid_accuracy                0.6350\n",
            "2023-08-15 11:28:32,070 simple_logger.py log_once [line:28] INFO mean_valid_accuracy           0.6384\n",
            "2023-08-15 11:28:32,072 simple_logger.py log_once [line:28] INFO std_valid_accuracy            0.2418\n",
            "2023-08-15 11:28:32,076 simple_logger.py log_once [line:28] INFO valid_loss                    1.5782\n",
            "2023-08-15 11:28:32,077 simple_logger.py log_once [line:28] INFO mean_valid_loss               1.5541\n",
            "2023-08-15 11:28:32,080 simple_logger.py log_once [line:28] INFO std_valid_loss                1.4032\n",
            "2023-08-15 11:28:32,087 fedbase.py run [line:251] INFO Eval Time Cost:               4.3670s\n",
            "2023-08-15 11:28:35,230 fedbase.py run [line:246] INFO --------------Round 8--------------\n",
            "2023-08-15 11:28:35,231 simple_logger.py log_once [line:14] INFO Current_time:8\n",
            "2023-08-15 11:28:38,941 simple_logger.py log_once [line:28] INFO test_accuracy                 0.6980\n",
            "2023-08-15 11:28:38,943 simple_logger.py log_once [line:28] INFO test_loss                     0.8921\n",
            "2023-08-15 11:28:38,947 simple_logger.py log_once [line:28] INFO valid_accuracy                0.7011\n",
            "2023-08-15 11:28:38,950 simple_logger.py log_once [line:28] INFO mean_valid_accuracy           0.7039\n",
            "2023-08-15 11:28:38,952 simple_logger.py log_once [line:28] INFO std_valid_accuracy            0.1524\n",
            "2023-08-15 11:28:38,954 simple_logger.py log_once [line:28] INFO valid_loss                    0.8825\n",
            "2023-08-15 11:28:38,955 simple_logger.py log_once [line:28] INFO mean_valid_loss               0.8750\n",
            "2023-08-15 11:28:38,957 simple_logger.py log_once [line:28] INFO std_valid_loss                0.4350\n",
            "2023-08-15 11:28:38,958 fedbase.py run [line:251] INFO Eval Time Cost:               3.7267s\n",
            "2023-08-15 11:28:43,636 fedbase.py run [line:246] INFO --------------Round 9--------------\n",
            "2023-08-15 11:28:43,637 simple_logger.py log_once [line:14] INFO Current_time:9\n",
            "2023-08-15 11:28:47,285 simple_logger.py log_once [line:28] INFO test_accuracy                 0.5881\n",
            "2023-08-15 11:28:47,287 simple_logger.py log_once [line:28] INFO test_loss                     1.1951\n",
            "2023-08-15 11:28:47,289 simple_logger.py log_once [line:28] INFO valid_accuracy                0.5846\n",
            "2023-08-15 11:28:47,291 simple_logger.py log_once [line:28] INFO mean_valid_accuracy           0.5818\n",
            "2023-08-15 11:28:47,295 simple_logger.py log_once [line:28] INFO std_valid_accuracy            0.3397\n",
            "2023-08-15 11:28:47,297 simple_logger.py log_once [line:28] INFO valid_loss                    1.1826\n",
            "2023-08-15 11:28:47,299 simple_logger.py log_once [line:28] INFO mean_valid_loss               1.1925\n",
            "2023-08-15 11:28:47,300 simple_logger.py log_once [line:28] INFO std_valid_loss                0.9996\n",
            "2023-08-15 11:28:47,301 fedbase.py run [line:251] INFO Eval Time Cost:               3.6642s\n",
            "2023-08-15 11:28:50,531 fedbase.py run [line:246] INFO --------------Round 10--------------\n",
            "2023-08-15 11:28:50,533 simple_logger.py log_once [line:14] INFO Current_time:10\n",
            "2023-08-15 11:28:54,712 simple_logger.py log_once [line:28] INFO test_accuracy                 0.7034\n",
            "2023-08-15 11:28:54,715 simple_logger.py log_once [line:28] INFO test_loss                     0.8241\n",
            "2023-08-15 11:28:54,716 simple_logger.py log_once [line:28] INFO valid_accuracy                0.7121\n",
            "2023-08-15 11:28:54,718 simple_logger.py log_once [line:28] INFO mean_valid_accuracy           0.7101\n",
            "2023-08-15 11:28:54,720 simple_logger.py log_once [line:28] INFO std_valid_accuracy            0.2334\n",
            "2023-08-15 11:28:54,721 simple_logger.py log_once [line:28] INFO valid_loss                    0.7923\n",
            "2023-08-15 11:28:54,725 simple_logger.py log_once [line:28] INFO mean_valid_loss               0.7977\n",
            "2023-08-15 11:28:54,725 simple_logger.py log_once [line:28] INFO std_valid_loss                0.5827\n",
            "2023-08-15 11:28:54,727 fedbase.py run [line:251] INFO Eval Time Cost:               4.1939s\n",
            "2023-08-15 11:28:58,766 fedbase.py run [line:246] INFO --------------Round 11--------------\n",
            "2023-08-15 11:28:58,767 simple_logger.py log_once [line:14] INFO Current_time:11\n",
            "2023-08-15 11:29:02,477 simple_logger.py log_once [line:28] INFO test_accuracy                 0.7045\n",
            "2023-08-15 11:29:02,478 simple_logger.py log_once [line:28] INFO test_loss                     0.7485\n",
            "2023-08-15 11:29:02,483 simple_logger.py log_once [line:28] INFO valid_accuracy                0.7016\n",
            "2023-08-15 11:29:02,484 simple_logger.py log_once [line:28] INFO mean_valid_accuracy           0.7009\n",
            "2023-08-15 11:29:02,486 simple_logger.py log_once [line:28] INFO std_valid_accuracy            0.2482\n",
            "2023-08-15 11:29:02,489 simple_logger.py log_once [line:28] INFO valid_loss                    0.7326\n",
            "2023-08-15 11:29:02,493 simple_logger.py log_once [line:28] INFO mean_valid_loss               0.7334\n",
            "2023-08-15 11:29:02,496 simple_logger.py log_once [line:28] INFO std_valid_loss                0.4804\n",
            "2023-08-15 11:29:02,497 fedbase.py run [line:251] INFO Eval Time Cost:               3.7299s\n",
            "2023-08-15 11:29:05,671 fedbase.py run [line:246] INFO --------------Round 12--------------\n",
            "2023-08-15 11:29:05,672 simple_logger.py log_once [line:14] INFO Current_time:12\n",
            "2023-08-15 11:29:10,694 simple_logger.py log_once [line:28] INFO test_accuracy                 0.7111\n",
            "2023-08-15 11:29:10,699 simple_logger.py log_once [line:28] INFO test_loss                     0.9666\n",
            "2023-08-15 11:29:10,701 simple_logger.py log_once [line:28] INFO valid_accuracy                0.7044\n",
            "2023-08-15 11:29:10,706 simple_logger.py log_once [line:28] INFO mean_valid_accuracy           0.7050\n",
            "2023-08-15 11:29:10,708 simple_logger.py log_once [line:28] INFO std_valid_accuracy            0.2705\n",
            "2023-08-15 11:29:10,709 simple_logger.py log_once [line:28] INFO valid_loss                    0.9588\n",
            "2023-08-15 11:29:10,713 simple_logger.py log_once [line:28] INFO mean_valid_loss               0.9601\n",
            "2023-08-15 11:29:10,714 simple_logger.py log_once [line:28] INFO std_valid_loss                1.0125\n",
            "2023-08-15 11:29:10,716 fedbase.py run [line:251] INFO Eval Time Cost:               5.0435s\n",
            "2023-08-15 11:29:14,151 fedbase.py run [line:246] INFO --------------Round 13--------------\n",
            "2023-08-15 11:29:14,153 simple_logger.py log_once [line:14] INFO Current_time:13\n",
            "2023-08-15 11:29:17,806 simple_logger.py log_once [line:28] INFO test_accuracy                 0.7130\n",
            "2023-08-15 11:29:17,807 simple_logger.py log_once [line:28] INFO test_loss                     0.9146\n",
            "2023-08-15 11:29:17,813 simple_logger.py log_once [line:28] INFO valid_accuracy                0.7188\n",
            "2023-08-15 11:29:17,814 simple_logger.py log_once [line:28] INFO mean_valid_accuracy           0.7172\n",
            "2023-08-15 11:29:17,818 simple_logger.py log_once [line:28] INFO std_valid_accuracy            0.2543\n",
            "2023-08-15 11:29:17,820 simple_logger.py log_once [line:28] INFO valid_loss                    0.8990\n",
            "2023-08-15 11:29:17,823 simple_logger.py log_once [line:28] INFO mean_valid_loss               0.9055\n",
            "2023-08-15 11:29:17,825 simple_logger.py log_once [line:28] INFO std_valid_loss                0.9422\n",
            "2023-08-15 11:29:17,828 fedbase.py run [line:251] INFO Eval Time Cost:               3.6755s\n",
            "2023-08-15 11:29:20,900 fedbase.py run [line:246] INFO --------------Round 14--------------\n",
            "2023-08-15 11:29:20,901 simple_logger.py log_once [line:14] INFO Current_time:14\n",
            "2023-08-15 11:29:26,046 simple_logger.py log_once [line:28] INFO test_accuracy                 0.6940\n",
            "2023-08-15 11:29:26,048 simple_logger.py log_once [line:28] INFO test_loss                     1.0028\n",
            "2023-08-15 11:29:26,051 simple_logger.py log_once [line:28] INFO valid_accuracy                0.6992\n",
            "2023-08-15 11:29:26,055 simple_logger.py log_once [line:28] INFO mean_valid_accuracy           0.7040\n",
            "2023-08-15 11:29:26,057 simple_logger.py log_once [line:28] INFO std_valid_accuracy            0.2452\n",
            "2023-08-15 11:29:26,059 simple_logger.py log_once [line:28] INFO valid_loss                    0.9816\n",
            "2023-08-15 11:29:26,060 simple_logger.py log_once [line:28] INFO mean_valid_loss               0.9647\n",
            "2023-08-15 11:29:26,061 simple_logger.py log_once [line:28] INFO std_valid_loss                0.8354\n",
            "2023-08-15 11:29:26,063 fedbase.py run [line:251] INFO Eval Time Cost:               5.1615s\n",
            "2023-08-15 11:29:29,324 fedbase.py run [line:246] INFO --------------Round 15--------------\n",
            "2023-08-15 11:29:29,325 simple_logger.py log_once [line:14] INFO Current_time:15\n",
            "2023-08-15 11:29:33,061 simple_logger.py log_once [line:28] INFO test_accuracy                 0.8042\n",
            "2023-08-15 11:29:33,063 simple_logger.py log_once [line:28] INFO test_loss                     0.5281\n",
            "2023-08-15 11:29:33,067 simple_logger.py log_once [line:28] INFO valid_accuracy                0.8072\n",
            "2023-08-15 11:29:33,071 simple_logger.py log_once [line:28] INFO mean_valid_accuracy           0.8071\n",
            "2023-08-15 11:29:33,074 simple_logger.py log_once [line:28] INFO std_valid_accuracy            0.1310\n",
            "2023-08-15 11:29:33,078 simple_logger.py log_once [line:28] INFO valid_loss                    0.5154\n",
            "2023-08-15 11:29:33,080 simple_logger.py log_once [line:28] INFO mean_valid_loss               0.5153\n",
            "2023-08-15 11:29:33,083 simple_logger.py log_once [line:28] INFO std_valid_loss                0.2962\n",
            "2023-08-15 11:29:33,084 fedbase.py run [line:251] INFO Eval Time Cost:               3.7594s\n",
            "2023-08-15 11:29:36,717 fedbase.py run [line:246] INFO --------------Round 16--------------\n",
            "2023-08-15 11:29:36,720 simple_logger.py log_once [line:14] INFO Current_time:16\n",
            "2023-08-15 11:29:41,365 simple_logger.py log_once [line:28] INFO test_accuracy                 0.7442\n",
            "2023-08-15 11:29:41,367 simple_logger.py log_once [line:28] INFO test_loss                     0.8159\n",
            "2023-08-15 11:29:41,372 simple_logger.py log_once [line:28] INFO valid_accuracy                0.7496\n",
            "2023-08-15 11:29:41,373 simple_logger.py log_once [line:28] INFO mean_valid_accuracy           0.7517\n",
            "2023-08-15 11:29:41,376 simple_logger.py log_once [line:28] INFO std_valid_accuracy            0.2521\n",
            "2023-08-15 11:29:41,378 simple_logger.py log_once [line:28] INFO valid_loss                    0.7900\n",
            "2023-08-15 11:29:41,381 simple_logger.py log_once [line:28] INFO mean_valid_loss               0.7827\n",
            "2023-08-15 11:29:41,382 simple_logger.py log_once [line:28] INFO std_valid_loss                0.8185\n",
            "2023-08-15 11:29:41,383 fedbase.py run [line:251] INFO Eval Time Cost:               4.6635s\n",
            "2023-08-15 11:29:44,567 fedbase.py run [line:246] INFO --------------Round 17--------------\n",
            "2023-08-15 11:29:44,568 simple_logger.py log_once [line:14] INFO Current_time:17\n",
            "2023-08-15 11:29:48,189 simple_logger.py log_once [line:28] INFO test_accuracy                 0.8237\n",
            "2023-08-15 11:29:48,191 simple_logger.py log_once [line:28] INFO test_loss                     0.4599\n",
            "2023-08-15 11:29:48,193 simple_logger.py log_once [line:28] INFO valid_accuracy                0.8283\n",
            "2023-08-15 11:29:48,199 simple_logger.py log_once [line:28] INFO mean_valid_accuracy           0.8296\n",
            "2023-08-15 11:29:48,200 simple_logger.py log_once [line:28] INFO std_valid_accuracy            0.1267\n",
            "2023-08-15 11:29:48,202 simple_logger.py log_once [line:28] INFO valid_loss                    0.4493\n",
            "2023-08-15 11:29:48,205 simple_logger.py log_once [line:28] INFO mean_valid_loss               0.4456\n",
            "2023-08-15 11:29:48,206 simple_logger.py log_once [line:28] INFO std_valid_loss                0.2845\n",
            "2023-08-15 11:29:48,207 fedbase.py run [line:251] INFO Eval Time Cost:               3.6391s\n",
            "2023-08-15 11:29:52,560 fedbase.py run [line:246] INFO --------------Round 18--------------\n",
            "2023-08-15 11:29:52,564 simple_logger.py log_once [line:14] INFO Current_time:18\n",
            "2023-08-15 11:29:56,405 simple_logger.py log_once [line:28] INFO test_accuracy                 0.7173\n",
            "2023-08-15 11:29:56,407 simple_logger.py log_once [line:28] INFO test_loss                     0.7980\n",
            "2023-08-15 11:29:56,409 simple_logger.py log_once [line:28] INFO valid_accuracy                0.7168\n",
            "2023-08-15 11:29:56,411 simple_logger.py log_once [line:28] INFO mean_valid_accuracy           0.7170\n",
            "2023-08-15 11:29:56,413 simple_logger.py log_once [line:28] INFO std_valid_accuracy            0.2693\n",
            "2023-08-15 11:29:56,414 simple_logger.py log_once [line:28] INFO valid_loss                    0.7781\n",
            "2023-08-15 11:29:56,416 simple_logger.py log_once [line:28] INFO mean_valid_loss               0.7775\n",
            "2023-08-15 11:29:56,417 simple_logger.py log_once [line:28] INFO std_valid_loss                0.7046\n",
            "2023-08-15 11:29:56,418 fedbase.py run [line:251] INFO Eval Time Cost:               3.8540s\n",
            "2023-08-15 11:29:59,602 fedbase.py run [line:246] INFO --------------Round 19--------------\n",
            "2023-08-15 11:29:59,603 simple_logger.py log_once [line:14] INFO Current_time:19\n",
            "2023-08-15 11:30:03,473 simple_logger.py log_once [line:28] INFO test_accuracy                 0.7510\n",
            "2023-08-15 11:30:03,475 simple_logger.py log_once [line:28] INFO test_loss                     0.7408\n",
            "2023-08-15 11:30:03,477 simple_logger.py log_once [line:28] INFO valid_accuracy                0.7510\n",
            "2023-08-15 11:30:03,481 simple_logger.py log_once [line:28] INFO mean_valid_accuracy           0.7503\n",
            "2023-08-15 11:30:03,484 simple_logger.py log_once [line:28] INFO std_valid_accuracy            0.2476\n",
            "2023-08-15 11:30:03,485 simple_logger.py log_once [line:28] INFO valid_loss                    0.7356\n",
            "2023-08-15 11:30:03,486 simple_logger.py log_once [line:28] INFO mean_valid_loss               0.7383\n",
            "2023-08-15 11:30:03,488 simple_logger.py log_once [line:28] INFO std_valid_loss                0.7362\n",
            "2023-08-15 11:30:03,489 fedbase.py run [line:251] INFO Eval Time Cost:               3.8857s\n",
            "2023-08-15 11:30:05,858 fedbase.py run [line:246] INFO --------------Round 20--------------\n",
            "2023-08-15 11:30:05,863 simple_logger.py log_once [line:14] INFO Current_time:20\n",
            "2023-08-15 11:30:10,026 simple_logger.py log_once [line:28] INFO test_accuracy                 0.5625\n",
            "2023-08-15 11:30:10,028 simple_logger.py log_once [line:28] INFO test_loss                     1.4964\n",
            "2023-08-15 11:30:10,031 simple_logger.py log_once [line:28] INFO valid_accuracy                0.5709\n",
            "2023-08-15 11:30:10,036 simple_logger.py log_once [line:28] INFO mean_valid_accuracy           0.5684\n",
            "2023-08-15 11:30:10,038 simple_logger.py log_once [line:28] INFO std_valid_accuracy            0.3018\n",
            "2023-08-15 11:30:10,040 simple_logger.py log_once [line:28] INFO valid_loss                    1.4535\n",
            "2023-08-15 11:30:10,042 simple_logger.py log_once [line:28] INFO mean_valid_loss               1.4616\n",
            "2023-08-15 11:30:10,051 simple_logger.py log_once [line:28] INFO std_valid_loss                0.9984\n",
            "2023-08-15 11:30:10,052 fedbase.py run [line:251] INFO Eval Time Cost:               4.1899s\n",
            "2023-08-15 11:30:13,327 fedbase.py run [line:246] INFO --------------Round 21--------------\n",
            "2023-08-15 11:30:13,328 simple_logger.py log_once [line:14] INFO Current_time:21\n",
            "2023-08-15 11:30:17,220 simple_logger.py log_once [line:28] INFO test_accuracy                 0.7801\n",
            "2023-08-15 11:30:17,222 simple_logger.py log_once [line:28] INFO test_loss                     0.6873\n",
            "2023-08-15 11:30:17,225 simple_logger.py log_once [line:28] INFO valid_accuracy                0.7868\n",
            "2023-08-15 11:30:17,227 simple_logger.py log_once [line:28] INFO mean_valid_accuracy           0.7888\n",
            "2023-08-15 11:30:17,230 simple_logger.py log_once [line:28] INFO std_valid_accuracy            0.2361\n",
            "2023-08-15 11:30:17,232 simple_logger.py log_once [line:28] INFO valid_loss                    0.6731\n",
            "2023-08-15 11:30:17,234 simple_logger.py log_once [line:28] INFO mean_valid_loss               0.6669\n",
            "2023-08-15 11:30:17,235 simple_logger.py log_once [line:28] INFO std_valid_loss                0.7381\n",
            "2023-08-15 11:30:17,236 fedbase.py run [line:251] INFO Eval Time Cost:               3.9077s\n",
            "2023-08-15 11:30:21,691 fedbase.py run [line:246] INFO --------------Round 22--------------\n",
            "2023-08-15 11:30:21,693 simple_logger.py log_once [line:14] INFO Current_time:22\n",
            "2023-08-15 11:30:25,388 simple_logger.py log_once [line:28] INFO test_accuracy                 0.8476\n",
            "2023-08-15 11:30:25,390 simple_logger.py log_once [line:28] INFO test_loss                     0.4155\n",
            "2023-08-15 11:30:25,394 simple_logger.py log_once [line:28] INFO valid_accuracy                0.8549\n",
            "2023-08-15 11:30:25,396 simple_logger.py log_once [line:28] INFO mean_valid_accuracy           0.8553\n",
            "2023-08-15 11:30:25,398 simple_logger.py log_once [line:28] INFO std_valid_accuracy            0.1444\n",
            "2023-08-15 11:30:25,399 simple_logger.py log_once [line:28] INFO valid_loss                    0.4027\n",
            "2023-08-15 11:30:25,406 simple_logger.py log_once [line:28] INFO mean_valid_loss               0.4012\n",
            "2023-08-15 11:30:25,408 simple_logger.py log_once [line:28] INFO std_valid_loss                0.3691\n",
            "2023-08-15 11:30:25,410 fedbase.py run [line:251] INFO Eval Time Cost:               3.7165s\n",
            "2023-08-15 11:30:28,661 fedbase.py run [line:246] INFO --------------Round 23--------------\n",
            "2023-08-15 11:30:28,664 simple_logger.py log_once [line:14] INFO Current_time:23\n",
            "2023-08-15 11:30:33,141 simple_logger.py log_once [line:28] INFO test_accuracy                 0.7853\n",
            "2023-08-15 11:30:33,148 simple_logger.py log_once [line:28] INFO test_loss                     0.6128\n",
            "2023-08-15 11:30:33,150 simple_logger.py log_once [line:28] INFO valid_accuracy                0.7873\n",
            "2023-08-15 11:30:33,155 simple_logger.py log_once [line:28] INFO mean_valid_accuracy           0.7892\n",
            "2023-08-15 11:30:33,157 simple_logger.py log_once [line:28] INFO std_valid_accuracy            0.2273\n",
            "2023-08-15 11:30:33,158 simple_logger.py log_once [line:28] INFO valid_loss                    0.6149\n",
            "2023-08-15 11:30:33,159 simple_logger.py log_once [line:28] INFO mean_valid_loss               0.6095\n",
            "2023-08-15 11:30:33,161 simple_logger.py log_once [line:28] INFO std_valid_loss                0.6353\n",
            "2023-08-15 11:30:33,169 fedbase.py run [line:251] INFO Eval Time Cost:               4.5056s\n",
            "2023-08-15 11:30:35,400 fedbase.py run [line:246] INFO --------------Round 24--------------\n",
            "2023-08-15 11:30:35,402 simple_logger.py log_once [line:14] INFO Current_time:24\n",
            "2023-08-15 11:30:39,177 simple_logger.py log_once [line:28] INFO test_accuracy                 0.6994\n",
            "2023-08-15 11:30:39,179 simple_logger.py log_once [line:28] INFO test_loss                     1.0952\n",
            "2023-08-15 11:30:39,182 simple_logger.py log_once [line:28] INFO valid_accuracy                0.6969\n",
            "2023-08-15 11:30:39,185 simple_logger.py log_once [line:28] INFO mean_valid_accuracy           0.6987\n",
            "2023-08-15 11:30:39,187 simple_logger.py log_once [line:28] INFO std_valid_accuracy            0.1983\n",
            "2023-08-15 11:30:39,190 simple_logger.py log_once [line:28] INFO valid_loss                    1.1071\n",
            "2023-08-15 11:30:39,191 simple_logger.py log_once [line:28] INFO mean_valid_loss               1.1016\n",
            "2023-08-15 11:30:39,192 simple_logger.py log_once [line:28] INFO std_valid_loss                0.7285\n",
            "2023-08-15 11:30:39,193 fedbase.py run [line:251] INFO Eval Time Cost:               3.7919s\n",
            "2023-08-15 11:30:42,540 fedbase.py run [line:246] INFO --------------Round 25--------------\n",
            "2023-08-15 11:30:42,542 simple_logger.py log_once [line:14] INFO Current_time:25\n",
            "2023-08-15 11:30:47,018 simple_logger.py log_once [line:28] INFO test_accuracy                 0.6901\n",
            "2023-08-15 11:30:47,024 simple_logger.py log_once [line:28] INFO test_loss                     1.0718\n",
            "2023-08-15 11:30:47,026 simple_logger.py log_once [line:28] INFO valid_accuracy                0.6822\n",
            "2023-08-15 11:30:47,030 simple_logger.py log_once [line:28] INFO mean_valid_accuracy           0.6826\n",
            "2023-08-15 11:30:47,031 simple_logger.py log_once [line:28] INFO std_valid_accuracy            0.2602\n",
            "2023-08-15 11:30:47,036 simple_logger.py log_once [line:28] INFO valid_loss                    1.0526\n",
            "2023-08-15 11:30:47,038 simple_logger.py log_once [line:28] INFO mean_valid_loss               1.0531\n",
            "2023-08-15 11:30:47,039 simple_logger.py log_once [line:28] INFO std_valid_loss                0.8768\n",
            "2023-08-15 11:30:47,040 fedbase.py run [line:251] INFO Eval Time Cost:               4.4983s\n",
            "2023-08-15 11:30:51,012 fedbase.py run [line:246] INFO --------------Round 26--------------\n",
            "2023-08-15 11:30:51,013 simple_logger.py log_once [line:14] INFO Current_time:26\n",
            "2023-08-15 11:30:54,817 simple_logger.py log_once [line:28] INFO test_accuracy                 0.8164\n",
            "2023-08-15 11:30:54,819 simple_logger.py log_once [line:28] INFO test_loss                     0.5044\n",
            "2023-08-15 11:30:54,823 simple_logger.py log_once [line:28] INFO valid_accuracy                0.8175\n",
            "2023-08-15 11:30:54,826 simple_logger.py log_once [line:28] INFO mean_valid_accuracy           0.8169\n",
            "2023-08-15 11:30:54,830 simple_logger.py log_once [line:28] INFO std_valid_accuracy            0.1584\n",
            "2023-08-15 11:30:54,832 simple_logger.py log_once [line:28] INFO valid_loss                    0.4940\n",
            "2023-08-15 11:30:54,833 simple_logger.py log_once [line:28] INFO mean_valid_loss               0.4954\n",
            "2023-08-15 11:30:54,840 simple_logger.py log_once [line:28] INFO std_valid_loss                0.3761\n",
            "2023-08-15 11:30:54,841 fedbase.py run [line:251] INFO Eval Time Cost:               3.8271s\n",
            "2023-08-15 11:30:58,058 fedbase.py run [line:246] INFO --------------Round 27--------------\n",
            "2023-08-15 11:30:58,060 simple_logger.py log_once [line:14] INFO Current_time:27\n",
            "2023-08-15 11:31:03,288 simple_logger.py log_once [line:28] INFO test_accuracy                 0.8375\n",
            "2023-08-15 11:31:03,290 simple_logger.py log_once [line:28] INFO test_loss                     0.4875\n",
            "2023-08-15 11:31:03,292 simple_logger.py log_once [line:28] INFO valid_accuracy                0.8372\n",
            "2023-08-15 11:31:03,295 simple_logger.py log_once [line:28] INFO mean_valid_accuracy           0.8372\n",
            "2023-08-15 11:31:03,297 simple_logger.py log_once [line:28] INFO std_valid_accuracy            0.0836\n",
            "2023-08-15 11:31:03,298 simple_logger.py log_once [line:28] INFO valid_loss                    0.4758\n",
            "2023-08-15 11:31:03,305 simple_logger.py log_once [line:28] INFO mean_valid_loss               0.4758\n",
            "2023-08-15 11:31:03,306 simple_logger.py log_once [line:28] INFO std_valid_loss                0.2306\n",
            "2023-08-15 11:31:03,307 fedbase.py run [line:251] INFO Eval Time Cost:               5.2477s\n",
            "2023-08-15 11:31:06,549 fedbase.py run [line:246] INFO --------------Round 28--------------\n",
            "2023-08-15 11:31:06,551 simple_logger.py log_once [line:14] INFO Current_time:28\n",
            "2023-08-15 11:31:10,396 simple_logger.py log_once [line:28] INFO test_accuracy                 0.8350\n",
            "2023-08-15 11:31:10,398 simple_logger.py log_once [line:28] INFO test_loss                     0.4920\n",
            "2023-08-15 11:31:10,400 simple_logger.py log_once [line:28] INFO valid_accuracy                0.8270\n",
            "2023-08-15 11:31:10,402 simple_logger.py log_once [line:28] INFO mean_valid_accuracy           0.8283\n",
            "2023-08-15 11:31:10,407 simple_logger.py log_once [line:28] INFO std_valid_accuracy            0.1168\n",
            "2023-08-15 11:31:10,409 simple_logger.py log_once [line:28] INFO valid_loss                    0.4927\n",
            "2023-08-15 11:31:10,412 simple_logger.py log_once [line:28] INFO mean_valid_loss               0.4894\n",
            "2023-08-15 11:31:10,413 simple_logger.py log_once [line:28] INFO std_valid_loss                0.2901\n",
            "2023-08-15 11:31:10,415 fedbase.py run [line:251] INFO Eval Time Cost:               3.8644s\n",
            "2023-08-15 11:31:13,987 fedbase.py run [line:246] INFO --------------Round 29--------------\n",
            "2023-08-15 11:31:13,993 simple_logger.py log_once [line:14] INFO Current_time:29\n",
            "2023-08-15 11:31:18,775 simple_logger.py log_once [line:28] INFO test_accuracy                 0.8526\n",
            "2023-08-15 11:31:18,776 simple_logger.py log_once [line:28] INFO test_loss                     0.3838\n",
            "2023-08-15 11:31:18,780 simple_logger.py log_once [line:28] INFO valid_accuracy                0.8557\n",
            "2023-08-15 11:31:18,783 simple_logger.py log_once [line:28] INFO mean_valid_accuracy           0.8561\n",
            "2023-08-15 11:31:18,789 simple_logger.py log_once [line:28] INFO std_valid_accuracy            0.1258\n",
            "2023-08-15 11:31:18,790 simple_logger.py log_once [line:28] INFO valid_loss                    0.3729\n",
            "2023-08-15 11:31:18,793 simple_logger.py log_once [line:28] INFO mean_valid_loss               0.3713\n",
            "2023-08-15 11:31:18,795 simple_logger.py log_once [line:28] INFO std_valid_loss                0.2694\n",
            "2023-08-15 11:31:18,798 fedbase.py run [line:251] INFO Eval Time Cost:               4.8045s\n",
            "2023-08-15 11:31:21,976 fedbase.py run [line:246] INFO --------------Round 30--------------\n",
            "2023-08-15 11:31:21,977 simple_logger.py log_once [line:14] INFO Current_time:30\n",
            "2023-08-15 11:31:25,660 simple_logger.py log_once [line:28] INFO test_accuracy                 0.8634\n",
            "2023-08-15 11:31:25,661 simple_logger.py log_once [line:28] INFO test_loss                     0.4085\n",
            "2023-08-15 11:31:25,665 simple_logger.py log_once [line:28] INFO valid_accuracy                0.8635\n",
            "2023-08-15 11:31:25,671 simple_logger.py log_once [line:28] INFO mean_valid_accuracy           0.8638\n",
            "2023-08-15 11:31:25,672 simple_logger.py log_once [line:28] INFO std_valid_accuracy            0.0723\n",
            "2023-08-15 11:31:25,676 simple_logger.py log_once [line:28] INFO valid_loss                    0.3993\n",
            "2023-08-15 11:31:25,679 simple_logger.py log_once [line:28] INFO mean_valid_loss               0.3989\n",
            "2023-08-15 11:31:25,680 simple_logger.py log_once [line:28] INFO std_valid_loss                0.1952\n",
            "2023-08-15 11:31:25,682 fedbase.py run [line:251] INFO Eval Time Cost:               3.7053s\n",
            "2023-08-15 11:31:29,882 fedbase.py run [line:246] INFO --------------Round 31--------------\n",
            "2023-08-15 11:31:29,886 simple_logger.py log_once [line:14] INFO Current_time:31\n",
            "2023-08-15 11:31:33,983 simple_logger.py log_once [line:28] INFO test_accuracy                 0.7198\n",
            "2023-08-15 11:31:33,984 simple_logger.py log_once [line:28] INFO test_loss                     0.9036\n",
            "2023-08-15 11:31:33,991 simple_logger.py log_once [line:28] INFO valid_accuracy                0.7189\n",
            "2023-08-15 11:31:33,993 simple_logger.py log_once [line:28] INFO mean_valid_accuracy           0.7189\n",
            "2023-08-15 11:31:33,995 simple_logger.py log_once [line:28] INFO std_valid_accuracy            0.2580\n",
            "2023-08-15 11:31:33,998 simple_logger.py log_once [line:28] INFO valid_loss                    0.8859\n",
            "2023-08-15 11:31:33,999 simple_logger.py log_once [line:28] INFO mean_valid_loss               0.8871\n",
            "2023-08-15 11:31:34,001 simple_logger.py log_once [line:28] INFO std_valid_loss                0.8352\n",
            "2023-08-15 11:31:34,002 fedbase.py run [line:251] INFO Eval Time Cost:               4.1157s\n",
            "2023-08-15 11:31:37,180 fedbase.py run [line:246] INFO --------------Round 32--------------\n",
            "2023-08-15 11:31:37,181 simple_logger.py log_once [line:14] INFO Current_time:32\n",
            "2023-08-15 11:31:41,010 simple_logger.py log_once [line:28] INFO test_accuracy                 0.8072\n",
            "2023-08-15 11:31:41,012 simple_logger.py log_once [line:28] INFO test_loss                     0.6190\n",
            "2023-08-15 11:31:41,014 simple_logger.py log_once [line:28] INFO valid_accuracy                0.8095\n",
            "2023-08-15 11:31:41,016 simple_logger.py log_once [line:28] INFO mean_valid_accuracy           0.8086\n",
            "2023-08-15 11:31:41,018 simple_logger.py log_once [line:28] INFO std_valid_accuracy            0.2571\n",
            "2023-08-15 11:31:41,019 simple_logger.py log_once [line:28] INFO valid_loss                    0.6085\n",
            "2023-08-15 11:31:41,024 simple_logger.py log_once [line:28] INFO mean_valid_loss               0.6121\n",
            "2023-08-15 11:31:41,025 simple_logger.py log_once [line:28] INFO std_valid_loss                0.9279\n",
            "2023-08-15 11:31:41,029 fedbase.py run [line:251] INFO Eval Time Cost:               3.8477s\n",
            "2023-08-15 11:31:45,839 fedbase.py run [line:246] INFO --------------Round 33--------------\n",
            "2023-08-15 11:31:45,841 simple_logger.py log_once [line:14] INFO Current_time:33\n",
            "2023-08-15 11:31:50,715 simple_logger.py log_once [line:28] INFO test_accuracy                 0.8419\n",
            "2023-08-15 11:31:50,716 simple_logger.py log_once [line:28] INFO test_loss                     0.4903\n",
            "2023-08-15 11:31:50,722 simple_logger.py log_once [line:28] INFO valid_accuracy                0.8397\n",
            "2023-08-15 11:31:50,725 simple_logger.py log_once [line:28] INFO mean_valid_accuracy           0.8403\n",
            "2023-08-15 11:31:50,729 simple_logger.py log_once [line:28] INFO std_valid_accuracy            0.1119\n",
            "2023-08-15 11:31:50,731 simple_logger.py log_once [line:28] INFO valid_loss                    0.4890\n",
            "2023-08-15 11:31:50,733 simple_logger.py log_once [line:28] INFO mean_valid_loss               0.4870\n",
            "2023-08-15 11:31:50,735 simple_logger.py log_once [line:28] INFO std_valid_loss                0.3422\n",
            "2023-08-15 11:31:50,739 fedbase.py run [line:251] INFO Eval Time Cost:               4.8977s\n",
            "2023-08-15 11:31:53,907 fedbase.py run [line:246] INFO --------------Round 34--------------\n",
            "2023-08-15 11:31:53,909 simple_logger.py log_once [line:14] INFO Current_time:34\n",
            "2023-08-15 11:31:58,953 simple_logger.py log_once [line:28] INFO test_accuracy                 0.8328\n",
            "2023-08-15 11:31:58,954 simple_logger.py log_once [line:28] INFO test_loss                     0.4810\n",
            "2023-08-15 11:31:58,958 simple_logger.py log_once [line:28] INFO valid_accuracy                0.8374\n",
            "2023-08-15 11:31:58,960 simple_logger.py log_once [line:28] INFO mean_valid_accuracy           0.8368\n",
            "2023-08-15 11:31:58,962 simple_logger.py log_once [line:28] INFO std_valid_accuracy            0.1637\n",
            "2023-08-15 11:31:58,964 simple_logger.py log_once [line:28] INFO valid_loss                    0.4632\n",
            "2023-08-15 11:31:58,966 simple_logger.py log_once [line:28] INFO mean_valid_loss               0.4650\n",
            "2023-08-15 11:31:58,968 simple_logger.py log_once [line:28] INFO std_valid_loss                0.4597\n",
            "2023-08-15 11:31:58,970 fedbase.py run [line:251] INFO Eval Time Cost:               5.0612s\n",
            "2023-08-15 11:32:02,164 fedbase.py run [line:246] INFO --------------Round 35--------------\n",
            "2023-08-15 11:32:02,165 simple_logger.py log_once [line:14] INFO Current_time:35\n",
            "2023-08-15 11:32:05,812 simple_logger.py log_once [line:28] INFO test_accuracy                 0.7531\n",
            "2023-08-15 11:32:05,816 simple_logger.py log_once [line:28] INFO test_loss                     0.8393\n",
            "2023-08-15 11:32:05,820 simple_logger.py log_once [line:28] INFO valid_accuracy                0.7583\n",
            "2023-08-15 11:32:05,822 simple_logger.py log_once [line:28] INFO mean_valid_accuracy           0.7581\n",
            "2023-08-15 11:32:05,824 simple_logger.py log_once [line:28] INFO std_valid_accuracy            0.2276\n",
            "2023-08-15 11:32:05,826 simple_logger.py log_once [line:28] INFO valid_loss                    0.8136\n",
            "2023-08-15 11:32:05,828 simple_logger.py log_once [line:28] INFO mean_valid_loss               0.8152\n",
            "2023-08-15 11:32:05,829 simple_logger.py log_once [line:28] INFO std_valid_loss                0.8502\n",
            "2023-08-15 11:32:05,830 fedbase.py run [line:251] INFO Eval Time Cost:               3.6644s\n",
            "2023-08-15 11:32:07,381 fedbase.py run [line:246] INFO --------------Round 36--------------\n",
            "2023-08-15 11:32:07,382 simple_logger.py log_once [line:14] INFO Current_time:36\n",
            "2023-08-15 11:32:12,330 simple_logger.py log_once [line:28] INFO test_accuracy                 0.7660\n",
            "2023-08-15 11:32:12,332 simple_logger.py log_once [line:28] INFO test_loss                     0.7346\n",
            "2023-08-15 11:32:12,335 simple_logger.py log_once [line:28] INFO valid_accuracy                0.7642\n",
            "2023-08-15 11:32:12,338 simple_logger.py log_once [line:28] INFO mean_valid_accuracy           0.7677\n",
            "2023-08-15 11:32:12,340 simple_logger.py log_once [line:28] INFO std_valid_accuracy            0.1813\n",
            "2023-08-15 11:32:12,341 simple_logger.py log_once [line:28] INFO valid_loss                    0.7427\n",
            "2023-08-15 11:32:12,343 simple_logger.py log_once [line:28] INFO mean_valid_loss               0.7316\n",
            "2023-08-15 11:32:12,344 simple_logger.py log_once [line:28] INFO std_valid_loss                0.5902\n",
            "2023-08-15 11:32:12,345 fedbase.py run [line:251] INFO Eval Time Cost:               4.9630s\n",
            "2023-08-15 11:32:15,853 fedbase.py run [line:246] INFO --------------Round 37--------------\n",
            "2023-08-15 11:32:15,855 simple_logger.py log_once [line:14] INFO Current_time:37\n",
            "2023-08-15 11:32:19,531 simple_logger.py log_once [line:28] INFO test_accuracy                 0.8486\n",
            "2023-08-15 11:32:19,533 simple_logger.py log_once [line:28] INFO test_loss                     0.4854\n",
            "2023-08-15 11:32:19,536 simple_logger.py log_once [line:28] INFO valid_accuracy                0.8524\n",
            "2023-08-15 11:32:19,539 simple_logger.py log_once [line:28] INFO mean_valid_accuracy           0.8530\n",
            "2023-08-15 11:32:19,541 simple_logger.py log_once [line:28] INFO std_valid_accuracy            0.0818\n",
            "2023-08-15 11:32:19,542 simple_logger.py log_once [line:28] INFO valid_loss                    0.4704\n",
            "2023-08-15 11:32:19,544 simple_logger.py log_once [line:28] INFO mean_valid_loss               0.4694\n",
            "2023-08-15 11:32:19,546 simple_logger.py log_once [line:28] INFO std_valid_loss                0.2455\n",
            "2023-08-15 11:32:19,547 fedbase.py run [line:251] INFO Eval Time Cost:               3.6916s\n",
            "2023-08-15 11:32:22,798 fedbase.py run [line:246] INFO --------------Round 38--------------\n",
            "2023-08-15 11:32:22,799 simple_logger.py log_once [line:14] INFO Current_time:38\n",
            "2023-08-15 11:32:27,884 simple_logger.py log_once [line:28] INFO test_accuracy                 0.8608\n",
            "2023-08-15 11:32:27,886 simple_logger.py log_once [line:28] INFO test_loss                     0.3961\n",
            "2023-08-15 11:32:27,890 simple_logger.py log_once [line:28] INFO valid_accuracy                0.8687\n",
            "2023-08-15 11:32:27,892 simple_logger.py log_once [line:28] INFO mean_valid_accuracy           0.8686\n",
            "2023-08-15 11:32:27,895 simple_logger.py log_once [line:28] INFO std_valid_accuracy            0.0941\n",
            "2023-08-15 11:32:27,896 simple_logger.py log_once [line:28] INFO valid_loss                    0.3684\n",
            "2023-08-15 11:32:27,903 simple_logger.py log_once [line:28] INFO mean_valid_loss               0.3689\n",
            "2023-08-15 11:32:27,906 simple_logger.py log_once [line:28] INFO std_valid_loss                0.2582\n",
            "2023-08-15 11:32:27,909 fedbase.py run [line:251] INFO Eval Time Cost:               5.1101s\n",
            "2023-08-15 11:32:31,005 fedbase.py run [line:246] INFO --------------Round 39--------------\n",
            "2023-08-15 11:32:31,007 simple_logger.py log_once [line:14] INFO Current_time:39\n",
            "2023-08-15 11:32:34,633 simple_logger.py log_once [line:28] INFO test_accuracy                 0.8645\n",
            "2023-08-15 11:32:34,635 simple_logger.py log_once [line:28] INFO test_loss                     0.3821\n",
            "2023-08-15 11:32:34,637 simple_logger.py log_once [line:28] INFO valid_accuracy                0.8666\n",
            "2023-08-15 11:32:34,640 simple_logger.py log_once [line:28] INFO mean_valid_accuracy           0.8667\n",
            "2023-08-15 11:32:34,644 simple_logger.py log_once [line:28] INFO std_valid_accuracy            0.1355\n",
            "2023-08-15 11:32:34,646 simple_logger.py log_once [line:28] INFO valid_loss                    0.3640\n",
            "2023-08-15 11:32:34,648 simple_logger.py log_once [line:28] INFO mean_valid_loss               0.3633\n",
            "2023-08-15 11:32:34,649 simple_logger.py log_once [line:28] INFO std_valid_loss                0.3356\n",
            "2023-08-15 11:32:34,650 fedbase.py run [line:251] INFO Eval Time Cost:               3.6435s\n",
            "2023-08-15 11:32:38,356 fedbase.py run [line:246] INFO --------------Round 40--------------\n",
            "2023-08-15 11:32:38,361 simple_logger.py log_once [line:14] INFO Current_time:40\n",
            "2023-08-15 11:32:42,932 simple_logger.py log_once [line:28] INFO test_accuracy                 0.8638\n",
            "2023-08-15 11:32:42,933 simple_logger.py log_once [line:28] INFO test_loss                     0.3902\n",
            "2023-08-15 11:32:42,935 simple_logger.py log_once [line:28] INFO valid_accuracy                0.8602\n",
            "2023-08-15 11:32:42,938 simple_logger.py log_once [line:28] INFO mean_valid_accuracy           0.8612\n",
            "2023-08-15 11:32:42,939 simple_logger.py log_once [line:28] INFO std_valid_accuracy            0.0974\n",
            "2023-08-15 11:32:42,941 simple_logger.py log_once [line:28] INFO valid_loss                    0.3965\n",
            "2023-08-15 11:32:42,942 simple_logger.py log_once [line:28] INFO mean_valid_loss               0.3936\n",
            "2023-08-15 11:32:42,943 simple_logger.py log_once [line:28] INFO std_valid_loss                0.2716\n",
            "2023-08-15 11:32:42,944 fedbase.py run [line:251] INFO Eval Time Cost:               4.5859s\n",
            "2023-08-15 11:32:46,059 fedbase.py run [line:246] INFO --------------Round 41--------------\n",
            "2023-08-15 11:32:46,060 simple_logger.py log_once [line:14] INFO Current_time:41\n",
            "2023-08-15 11:32:49,706 simple_logger.py log_once [line:28] INFO test_accuracy                 0.8074\n",
            "2023-08-15 11:32:49,708 simple_logger.py log_once [line:28] INFO test_loss                     0.6603\n",
            "2023-08-15 11:32:49,714 simple_logger.py log_once [line:28] INFO valid_accuracy                0.8061\n",
            "2023-08-15 11:32:49,716 simple_logger.py log_once [line:28] INFO mean_valid_accuracy           0.8084\n",
            "2023-08-15 11:32:49,719 simple_logger.py log_once [line:28] INFO std_valid_accuracy            0.1496\n",
            "2023-08-15 11:32:49,720 simple_logger.py log_once [line:28] INFO valid_loss                    0.6713\n",
            "2023-08-15 11:32:49,722 simple_logger.py log_once [line:28] INFO mean_valid_loss               0.6634\n",
            "2023-08-15 11:32:49,723 simple_logger.py log_once [line:28] INFO std_valid_loss                0.5355\n",
            "2023-08-15 11:32:49,724 fedbase.py run [line:251] INFO Eval Time Cost:               3.6639s\n",
            "2023-08-15 11:32:51,749 fedbase.py run [line:246] INFO --------------Round 42--------------\n",
            "2023-08-15 11:32:51,751 simple_logger.py log_once [line:14] INFO Current_time:42\n",
            "2023-08-15 11:32:56,500 simple_logger.py log_once [line:28] INFO test_accuracy                 0.7389\n",
            "2023-08-15 11:32:56,501 simple_logger.py log_once [line:28] INFO test_loss                     0.9931\n",
            "2023-08-15 11:32:56,504 simple_logger.py log_once [line:28] INFO valid_accuracy                0.7479\n",
            "2023-08-15 11:32:56,509 simple_logger.py log_once [line:28] INFO mean_valid_accuracy           0.7488\n",
            "2023-08-15 11:32:56,514 simple_logger.py log_once [line:28] INFO std_valid_accuracy            0.2340\n",
            "2023-08-15 11:32:56,515 simple_logger.py log_once [line:28] INFO valid_loss                    0.9632\n",
            "2023-08-15 11:32:56,517 simple_logger.py log_once [line:28] INFO mean_valid_loss               0.9595\n",
            "2023-08-15 11:32:56,518 simple_logger.py log_once [line:28] INFO std_valid_loss                0.9503\n",
            "2023-08-15 11:32:56,519 fedbase.py run [line:251] INFO Eval Time Cost:               4.7672s\n",
            "2023-08-15 11:32:58,075 fedbase.py run [line:246] INFO --------------Round 43--------------\n",
            "2023-08-15 11:32:58,076 simple_logger.py log_once [line:14] INFO Current_time:43\n",
            "2023-08-15 11:33:01,736 simple_logger.py log_once [line:28] INFO test_accuracy                 0.6146\n",
            "2023-08-15 11:33:01,737 simple_logger.py log_once [line:28] INFO test_loss                     1.4592\n",
            "2023-08-15 11:33:01,740 simple_logger.py log_once [line:28] INFO valid_accuracy                0.6236\n",
            "2023-08-15 11:33:01,742 simple_logger.py log_once [line:28] INFO mean_valid_accuracy           0.6284\n",
            "2023-08-15 11:33:01,748 simple_logger.py log_once [line:28] INFO std_valid_accuracy            0.2691\n",
            "2023-08-15 11:33:01,750 simple_logger.py log_once [line:28] INFO valid_loss                    1.4175\n",
            "2023-08-15 11:33:01,752 simple_logger.py log_once [line:28] INFO mean_valid_loss               1.3968\n",
            "2023-08-15 11:33:01,753 simple_logger.py log_once [line:28] INFO std_valid_loss                1.1786\n",
            "2023-08-15 11:33:01,755 fedbase.py run [line:251] INFO Eval Time Cost:               3.6783s\n",
            "2023-08-15 11:33:03,309 fedbase.py run [line:246] INFO --------------Round 44--------------\n",
            "2023-08-15 11:33:03,310 simple_logger.py log_once [line:14] INFO Current_time:44\n",
            "2023-08-15 11:33:08,364 simple_logger.py log_once [line:28] INFO test_accuracy                 0.6942\n",
            "2023-08-15 11:33:08,366 simple_logger.py log_once [line:28] INFO test_loss                     1.0880\n",
            "2023-08-15 11:33:08,370 simple_logger.py log_once [line:28] INFO valid_accuracy                0.7008\n",
            "2023-08-15 11:33:08,373 simple_logger.py log_once [line:28] INFO mean_valid_accuracy           0.7056\n",
            "2023-08-15 11:33:08,375 simple_logger.py log_once [line:28] INFO std_valid_accuracy            0.2499\n",
            "2023-08-15 11:33:08,377 simple_logger.py log_once [line:28] INFO valid_loss                    1.0589\n",
            "2023-08-15 11:33:08,382 simple_logger.py log_once [line:28] INFO mean_valid_loss               1.0409\n",
            "2023-08-15 11:33:08,383 simple_logger.py log_once [line:28] INFO std_valid_loss                0.9610\n",
            "2023-08-15 11:33:08,384 fedbase.py run [line:251] INFO Eval Time Cost:               5.0737s\n",
            "2023-08-15 11:33:11,848 fedbase.py run [line:246] INFO --------------Round 45--------------\n",
            "2023-08-15 11:33:11,849 simple_logger.py log_once [line:14] INFO Current_time:45\n",
            "2023-08-15 11:33:15,620 simple_logger.py log_once [line:28] INFO test_accuracy                 0.8252\n",
            "2023-08-15 11:33:15,622 simple_logger.py log_once [line:28] INFO test_loss                     0.4937\n",
            "2023-08-15 11:33:15,625 simple_logger.py log_once [line:28] INFO valid_accuracy                0.8257\n",
            "2023-08-15 11:33:15,627 simple_logger.py log_once [line:28] INFO mean_valid_accuracy           0.8251\n",
            "2023-08-15 11:33:15,629 simple_logger.py log_once [line:28] INFO std_valid_accuracy            0.1699\n",
            "2023-08-15 11:33:15,630 simple_logger.py log_once [line:28] INFO valid_loss                    0.4971\n",
            "2023-08-15 11:33:15,632 simple_logger.py log_once [line:28] INFO mean_valid_loss               0.4985\n",
            "2023-08-15 11:33:15,633 simple_logger.py log_once [line:28] INFO std_valid_loss                0.4791\n",
            "2023-08-15 11:33:15,634 fedbase.py run [line:251] INFO Eval Time Cost:               3.7848s\n",
            "2023-08-15 11:33:19,053 fedbase.py run [line:246] INFO --------------Round 46--------------\n",
            "2023-08-15 11:33:19,058 simple_logger.py log_once [line:14] INFO Current_time:46\n",
            "2023-08-15 11:33:23,923 simple_logger.py log_once [line:28] INFO test_accuracy                 0.7849\n",
            "2023-08-15 11:33:23,925 simple_logger.py log_once [line:28] INFO test_loss                     0.7427\n",
            "2023-08-15 11:33:23,927 simple_logger.py log_once [line:28] INFO valid_accuracy                0.7822\n",
            "2023-08-15 11:33:23,931 simple_logger.py log_once [line:28] INFO mean_valid_accuracy           0.7821\n",
            "2023-08-15 11:33:23,933 simple_logger.py log_once [line:28] INFO std_valid_accuracy            0.2334\n",
            "2023-08-15 11:33:23,935 simple_logger.py log_once [line:28] INFO valid_loss                    0.7403\n",
            "2023-08-15 11:33:23,937 simple_logger.py log_once [line:28] INFO mean_valid_loss               0.7420\n",
            "2023-08-15 11:33:23,938 simple_logger.py log_once [line:28] INFO std_valid_loss                0.9177\n",
            "2023-08-15 11:33:23,939 fedbase.py run [line:251] INFO Eval Time Cost:               4.8808s\n",
            "2023-08-15 11:33:27,080 fedbase.py run [line:246] INFO --------------Round 47--------------\n",
            "2023-08-15 11:33:27,081 simple_logger.py log_once [line:14] INFO Current_time:47\n",
            "2023-08-15 11:33:30,773 simple_logger.py log_once [line:28] INFO test_accuracy                 0.7178\n",
            "2023-08-15 11:33:30,774 simple_logger.py log_once [line:28] INFO test_loss                     1.2270\n",
            "2023-08-15 11:33:30,778 simple_logger.py log_once [line:28] INFO valid_accuracy                0.7266\n",
            "2023-08-15 11:33:30,780 simple_logger.py log_once [line:28] INFO mean_valid_accuracy           0.7274\n",
            "2023-08-15 11:33:30,782 simple_logger.py log_once [line:28] INFO std_valid_accuracy            0.2497\n",
            "2023-08-15 11:33:30,784 simple_logger.py log_once [line:28] INFO valid_loss                    1.1769\n",
            "2023-08-15 11:33:30,786 simple_logger.py log_once [line:28] INFO mean_valid_loss               1.1716\n",
            "2023-08-15 11:33:30,787 simple_logger.py log_once [line:28] INFO std_valid_loss                1.1824\n",
            "2023-08-15 11:33:30,788 fedbase.py run [line:251] INFO Eval Time Cost:               3.7073s\n",
            "2023-08-15 11:33:34,687 fedbase.py run [line:246] INFO --------------Round 48--------------\n",
            "2023-08-15 11:33:34,690 simple_logger.py log_once [line:14] INFO Current_time:48\n",
            "2023-08-15 11:33:38,950 simple_logger.py log_once [line:28] INFO test_accuracy                 0.8175\n",
            "2023-08-15 11:33:38,951 simple_logger.py log_once [line:28] INFO test_loss                     0.4939\n",
            "2023-08-15 11:33:38,955 simple_logger.py log_once [line:28] INFO valid_accuracy                0.8256\n",
            "2023-08-15 11:33:38,956 simple_logger.py log_once [line:28] INFO mean_valid_accuracy           0.8246\n",
            "2023-08-15 11:33:38,958 simple_logger.py log_once [line:28] INFO std_valid_accuracy            0.1797\n",
            "2023-08-15 11:33:38,960 simple_logger.py log_once [line:28] INFO valid_loss                    0.4706\n",
            "2023-08-15 11:33:38,961 simple_logger.py log_once [line:28] INFO mean_valid_loss               0.4732\n",
            "2023-08-15 11:33:38,964 simple_logger.py log_once [line:28] INFO std_valid_loss                0.4592\n",
            "2023-08-15 11:33:38,965 fedbase.py run [line:251] INFO Eval Time Cost:               4.2753s\n",
            "2023-08-15 11:33:42,132 fedbase.py run [line:246] INFO --------------Round 49--------------\n",
            "2023-08-15 11:33:42,133 simple_logger.py log_once [line:14] INFO Current_time:49\n",
            "2023-08-15 11:33:45,761 simple_logger.py log_once [line:28] INFO test_accuracy                 0.7097\n",
            "2023-08-15 11:33:45,762 simple_logger.py log_once [line:28] INFO test_loss                     0.9860\n",
            "2023-08-15 11:33:45,766 simple_logger.py log_once [line:28] INFO valid_accuracy                0.7163\n",
            "2023-08-15 11:33:45,772 simple_logger.py log_once [line:28] INFO mean_valid_accuracy           0.7155\n",
            "2023-08-15 11:33:45,775 simple_logger.py log_once [line:28] INFO std_valid_accuracy            0.2800\n",
            "2023-08-15 11:33:45,779 simple_logger.py log_once [line:28] INFO valid_loss                    0.9409\n",
            "2023-08-15 11:33:45,780 simple_logger.py log_once [line:28] INFO mean_valid_loss               0.9457\n",
            "2023-08-15 11:33:45,781 simple_logger.py log_once [line:28] INFO std_valid_loss                1.0791\n",
            "2023-08-15 11:33:45,782 fedbase.py run [line:251] INFO Eval Time Cost:               3.6488s\n",
            "2023-08-15 11:33:50,206 fedbase.py run [line:246] INFO --------------Round 50--------------\n",
            "2023-08-15 11:33:50,207 simple_logger.py log_once [line:14] INFO Current_time:50\n",
            "2023-08-15 11:33:53,883 simple_logger.py log_once [line:28] INFO test_accuracy                 0.8379\n",
            "2023-08-15 11:33:53,884 simple_logger.py log_once [line:28] INFO test_loss                     0.4840\n",
            "2023-08-15 11:33:53,886 simple_logger.py log_once [line:28] INFO valid_accuracy                0.8447\n",
            "2023-08-15 11:33:53,890 simple_logger.py log_once [line:28] INFO mean_valid_accuracy           0.8468\n",
            "2023-08-15 11:33:53,893 simple_logger.py log_once [line:28] INFO std_valid_accuracy            0.1585\n",
            "2023-08-15 11:33:53,896 simple_logger.py log_once [line:28] INFO valid_loss                    0.4671\n",
            "2023-08-15 11:33:53,898 simple_logger.py log_once [line:28] INFO mean_valid_loss               0.4606\n",
            "2023-08-15 11:33:53,899 simple_logger.py log_once [line:28] INFO std_valid_loss                0.4719\n",
            "2023-08-15 11:33:53,901 fedbase.py run [line:251] INFO Eval Time Cost:               3.6933s\n",
            "2023-08-15 11:33:53,904 fedbase.py run [line:257] INFO =================End==================\n",
            "2023-08-15 11:33:53,904 fedbase.py run [line:258] INFO Total Time Cost:              380.0818s\n"
          ]
        }
      ],
      "source": [
        "import flgo.algorithm.fedavg as fedprox\n",
        "runner = flgo.init(task, fedavg, option=option, model=model_DC)\n",
        "torch.cuda.empty_cache()\n",
        "runner.model\n",
        "runner.run()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a4HbKr-PWIR3",
        "outputId": "c0628dcf-e476-4aee-c988-3b319fb1c3cc"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-71-22740df4d839>:1: UserWarning: torch.range is deprecated and will be removed in a future release because its behavior is inconsistent with Python's range builtin. Instead, use torch.arange, which produces values in [start, end).\n",
            "  torch.range(0,10,dtype=torch.int64)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10])"
            ]
          },
          "execution_count": 71,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.range(0,10,dtype=torch.int64)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kt74viro8V_g",
        "outputId": "4a80d429-1b05-42da-91af-cb6dd5870f32"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "当前分配给Tensor存储的GPU内存量: 9.89 GB\n",
            "当前在GPU上缓存的内存量: 10.53 GB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/cuda/memory.py:416: FutureWarning: torch.cuda.memory_cached has been renamed to torch.cuda.memory_reserved\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "runner=1\n",
        "del runner\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "# 查看当前分配给Tensor存储的GPU内存量\n",
        "allocated_memory = torch.cuda.memory_allocated()\n",
        "print(f\"当前分配给Tensor存储的GPU内存量: {allocated_memory / (1024**3):.2f} GB\")\n",
        "\n",
        "# 查看当前在GPU上缓存的内存量\n",
        "cached_memory = torch.cuda.memory_cached()\n",
        "print(f\"当前在GPU上缓存的内存量: {cached_memory / (1024**3):.2f} GB\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zuIhGJpk34Oe",
        "outputId": "1cdbc220-45d4-4e4d-bfed-7a1d1bd974c6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import cv2 as cv\n",
        "img=torch.rand(10,10).cpu().detach().numpy()\n",
        "new_img = cv.resize(img,None,fx=10,fy=10)\n",
        "cv.imwrite('1.png',new_img)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 503
        },
        "id": "rT5sOUpigQiL",
        "outputId": "570c7528-4d66-49d1-d181-498b897523ff"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(10, 10, 28, 28)\n",
            "(100, 28, 28, 1)\n",
            "torch.Size([10, 10, 10])\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7b15f41bb3d0>"
            ]
          },
          "execution_count": 105,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "samples=runner.clients[9].samples\n",
        "print(samples.shape)\n",
        "B,C,shape,_=samples.shape\n",
        "print(samples.reshape(-1,shape,shape,1).shape)\n",
        "syn = runner.clients[9].gan.D(torch.tensor(samples.reshape(-1,1,shape,shape)).float().cuda())\n",
        "syn = syn.reshape([B,C,-1])\n",
        "print(syn.shape)\n",
        "plt.imshow(syn.mean(0).cpu().detach().numpy())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eosw-N7ggprw",
        "outputId": "766b264f-bb6b-4267-d784-ff4928476423"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-07-12 19:59:35,975 fflow.py init [line:441] INFO Initializing devices: cuda:0 will be used for this running.\n",
            "2023-07-12 19:59:36,412 fflow.py init [line:479] INFO Use `<class 'flgo.simulator.default_simulator.Simulator'>` as the system simulator\n",
            "2023-07-12 19:59:36,414 fflow.py init [line:487] INFO Ready to start.\n",
            "2023-07-12 19:59:36,417 fedbase.py run [line:236] INFO --------------Initial Evaluation--------------\n",
            "2023-07-12 19:59:36,419 simple_logger.py log_once [line:14] INFO Current_time:0\n",
            "2023-07-12 19:59:41,457 simple_logger.py log_once [line:28] INFO test_accuracy                 0.1091\n",
            "2023-07-12 19:59:41,458 simple_logger.py log_once [line:28] INFO test_loss                     2.3020\n",
            "2023-07-12 19:59:41,464 simple_logger.py log_once [line:28] INFO valid_accuracy                0.1076\n",
            "2023-07-12 19:59:41,465 simple_logger.py log_once [line:28] INFO mean_valid_accuracy           0.1070\n",
            "2023-07-12 19:59:41,469 simple_logger.py log_once [line:28] INFO std_valid_accuracy            0.1139\n",
            "2023-07-12 19:59:41,471 simple_logger.py log_once [line:28] INFO valid_loss                    2.3026\n",
            "2023-07-12 19:59:41,473 simple_logger.py log_once [line:28] INFO mean_valid_loss               2.3027\n",
            "2023-07-12 19:59:41,474 simple_logger.py log_once [line:28] INFO std_valid_loss                0.0115\n",
            "2023-07-12 19:59:41,475 fedbase.py run [line:239] INFO Eval Time Cost:               5.0562s\n",
            "2023-07-12 19:59:44,558 fedbase.py run [line:246] INFO --------------Round 1--------------\n",
            "2023-07-12 19:59:44,559 simple_logger.py log_once [line:14] INFO Current_time:1\n",
            "2023-07-12 19:59:48,291 simple_logger.py log_once [line:28] INFO test_accuracy                 0.6188\n",
            "2023-07-12 19:59:48,292 simple_logger.py log_once [line:28] INFO test_loss                     1.3831\n",
            "2023-07-12 19:59:48,295 simple_logger.py log_once [line:28] INFO valid_accuracy                0.6126\n",
            "2023-07-12 19:59:48,296 simple_logger.py log_once [line:28] INFO mean_valid_accuracy           0.6147\n",
            "2023-07-12 19:59:48,302 simple_logger.py log_once [line:28] INFO std_valid_accuracy            0.2765\n",
            "2023-07-12 19:59:48,303 simple_logger.py log_once [line:28] INFO valid_loss                    1.3944\n",
            "2023-07-12 19:59:48,305 simple_logger.py log_once [line:28] INFO mean_valid_loss               1.3880\n",
            "2023-07-12 19:59:48,307 simple_logger.py log_once [line:28] INFO std_valid_loss                1.1210\n",
            "2023-07-12 19:59:48,308 fedbase.py run [line:251] INFO Eval Time Cost:               3.7483s\n",
            "2023-07-12 19:59:51,476 fedbase.py run [line:246] INFO --------------Round 2--------------\n",
            "2023-07-12 19:59:51,479 simple_logger.py log_once [line:14] INFO Current_time:2\n",
            "2023-07-12 19:59:56,439 simple_logger.py log_once [line:28] INFO test_accuracy                 0.6753\n",
            "2023-07-12 19:59:56,441 simple_logger.py log_once [line:28] INFO test_loss                     1.0675\n",
            "2023-07-12 19:59:56,443 simple_logger.py log_once [line:28] INFO valid_accuracy                0.6668\n",
            "2023-07-12 19:59:56,446 simple_logger.py log_once [line:28] INFO mean_valid_accuracy           0.6680\n",
            "2023-07-12 19:59:56,448 simple_logger.py log_once [line:28] INFO std_valid_accuracy            0.2576\n",
            "2023-07-12 19:59:56,449 simple_logger.py log_once [line:28] INFO valid_loss                    1.0895\n",
            "2023-07-12 19:59:56,451 simple_logger.py log_once [line:28] INFO mean_valid_loss               1.0823\n",
            "2023-07-12 19:59:56,452 simple_logger.py log_once [line:28] INFO std_valid_loss                0.9187\n",
            "2023-07-12 19:59:56,453 fedbase.py run [line:251] INFO Eval Time Cost:               4.9748s\n",
            "2023-07-12 19:59:59,966 fedbase.py run [line:246] INFO --------------Round 3--------------\n",
            "2023-07-12 19:59:59,967 simple_logger.py log_once [line:14] INFO Current_time:3\n",
            "2023-07-12 20:00:03,788 simple_logger.py log_once [line:28] INFO test_accuracy                 0.7261\n",
            "2023-07-12 20:00:03,789 simple_logger.py log_once [line:28] INFO test_loss                     0.9822\n",
            "2023-07-12 20:00:03,790 simple_logger.py log_once [line:28] INFO valid_accuracy                0.7255\n",
            "2023-07-12 20:00:03,793 simple_logger.py log_once [line:28] INFO mean_valid_accuracy           0.7270\n",
            "2023-07-12 20:00:03,795 simple_logger.py log_once [line:28] INFO std_valid_accuracy            0.2849\n",
            "2023-07-12 20:00:03,796 simple_logger.py log_once [line:28] INFO valid_loss                    0.9913\n",
            "2023-07-12 20:00:03,798 simple_logger.py log_once [line:28] INFO mean_valid_loss               0.9843\n",
            "2023-07-12 20:00:03,799 simple_logger.py log_once [line:28] INFO std_valid_loss                1.0343\n",
            "2023-07-12 20:00:03,800 fedbase.py run [line:251] INFO Eval Time Cost:               3.8328s\n",
            "2023-07-12 20:00:08,047 fedbase.py run [line:246] INFO --------------Round 4--------------\n",
            "2023-07-12 20:00:08,049 simple_logger.py log_once [line:14] INFO Current_time:4\n",
            "2023-07-12 20:00:11,843 simple_logger.py log_once [line:28] INFO test_accuracy                 0.5688\n",
            "2023-07-12 20:00:11,844 simple_logger.py log_once [line:28] INFO test_loss                     1.1686\n",
            "2023-07-12 20:00:11,848 simple_logger.py log_once [line:28] INFO valid_accuracy                0.5606\n",
            "2023-07-12 20:00:11,850 simple_logger.py log_once [line:28] INFO mean_valid_accuracy           0.5594\n",
            "2023-07-12 20:00:11,853 simple_logger.py log_once [line:28] INFO std_valid_accuracy            0.2674\n",
            "2023-07-12 20:00:11,858 simple_logger.py log_once [line:28] INFO valid_loss                    1.1840\n",
            "2023-07-12 20:00:11,859 simple_logger.py log_once [line:28] INFO mean_valid_loss               1.1873\n",
            "2023-07-12 20:00:11,862 simple_logger.py log_once [line:28] INFO std_valid_loss                0.9221\n",
            "2023-07-12 20:00:11,862 fedbase.py run [line:251] INFO Eval Time Cost:               3.8136s\n",
            "2023-07-12 20:00:14,934 fedbase.py run [line:246] INFO --------------Round 5--------------\n",
            "2023-07-12 20:00:14,935 simple_logger.py log_once [line:14] INFO Current_time:5\n",
            "2023-07-12 20:00:19,087 simple_logger.py log_once [line:28] INFO test_accuracy                 0.7597\n",
            "2023-07-12 20:00:19,092 simple_logger.py log_once [line:28] INFO test_loss                     0.6662\n",
            "2023-07-12 20:00:19,094 simple_logger.py log_once [line:28] INFO valid_accuracy                0.7551\n",
            "2023-07-12 20:00:19,096 simple_logger.py log_once [line:28] INFO mean_valid_accuracy           0.7553\n",
            "2023-07-12 20:00:19,098 simple_logger.py log_once [line:28] INFO std_valid_accuracy            0.1543\n",
            "2023-07-12 20:00:19,099 simple_logger.py log_once [line:28] INFO valid_loss                    0.6851\n",
            "2023-07-12 20:00:19,100 simple_logger.py log_once [line:28] INFO mean_valid_loss               0.6845\n",
            "2023-07-12 20:00:19,103 simple_logger.py log_once [line:28] INFO std_valid_loss                0.3898\n",
            "2023-07-12 20:00:19,104 fedbase.py run [line:251] INFO Eval Time Cost:               4.1691s\n",
            "2023-07-12 20:00:22,997 fedbase.py run [line:246] INFO --------------Round 6--------------\n",
            "2023-07-12 20:00:22,999 simple_logger.py log_once [line:14] INFO Current_time:6\n",
            "2023-07-12 20:00:27,100 simple_logger.py log_once [line:28] INFO test_accuracy                 0.6683\n",
            "2023-07-12 20:00:27,101 simple_logger.py log_once [line:28] INFO test_loss                     1.2485\n",
            "2023-07-12 20:00:27,103 simple_logger.py log_once [line:28] INFO valid_accuracy                0.6606\n",
            "2023-07-12 20:00:27,106 simple_logger.py log_once [line:28] INFO mean_valid_accuracy           0.6602\n",
            "2023-07-12 20:00:27,110 simple_logger.py log_once [line:28] INFO std_valid_accuracy            0.2917\n",
            "2023-07-12 20:00:27,113 simple_logger.py log_once [line:28] INFO valid_loss                    1.2901\n",
            "2023-07-12 20:00:27,115 simple_logger.py log_once [line:28] INFO mean_valid_loss               1.2885\n",
            "2023-07-12 20:00:27,116 simple_logger.py log_once [line:28] INFO std_valid_loss                1.3479\n",
            "2023-07-12 20:00:27,117 fedbase.py run [line:251] INFO Eval Time Cost:               4.1179s\n",
            "2023-07-12 20:00:28,732 fedbase.py run [line:246] INFO --------------Round 7--------------\n",
            "2023-07-12 20:00:28,734 simple_logger.py log_once [line:14] INFO Current_time:7\n",
            "2023-07-12 20:00:33,111 simple_logger.py log_once [line:28] INFO test_accuracy                 0.6994\n",
            "2023-07-12 20:00:33,114 simple_logger.py log_once [line:28] INFO test_loss                     1.6615\n",
            "2023-07-12 20:00:33,118 simple_logger.py log_once [line:28] INFO valid_accuracy                0.6970\n",
            "2023-07-12 20:00:33,120 simple_logger.py log_once [line:28] INFO mean_valid_accuracy           0.6975\n",
            "2023-07-12 20:00:33,122 simple_logger.py log_once [line:28] INFO std_valid_accuracy            0.2955\n",
            "2023-07-12 20:00:33,125 simple_logger.py log_once [line:28] INFO valid_loss                    1.7303\n",
            "2023-07-12 20:00:33,126 simple_logger.py log_once [line:28] INFO mean_valid_loss               1.7244\n",
            "2023-07-12 20:00:33,127 simple_logger.py log_once [line:28] INFO std_valid_loss                2.2310\n",
            "2023-07-12 20:00:33,128 fedbase.py run [line:251] INFO Eval Time Cost:               4.3940s\n",
            "2023-07-12 20:00:36,841 fedbase.py run [line:246] INFO --------------Round 8--------------\n",
            "2023-07-12 20:00:36,843 simple_logger.py log_once [line:14] INFO Current_time:8\n",
            "2023-07-12 20:00:40,637 simple_logger.py log_once [line:28] INFO test_accuracy                 0.7561\n",
            "2023-07-12 20:00:40,639 simple_logger.py log_once [line:28] INFO test_loss                     0.6838\n",
            "2023-07-12 20:00:40,642 simple_logger.py log_once [line:28] INFO valid_accuracy                0.7474\n",
            "2023-07-12 20:00:40,644 simple_logger.py log_once [line:28] INFO mean_valid_accuracy           0.7469\n",
            "2023-07-12 20:00:40,648 simple_logger.py log_once [line:28] INFO std_valid_accuracy            0.1962\n",
            "2023-07-12 20:00:40,649 simple_logger.py log_once [line:28] INFO valid_loss                    0.7137\n",
            "2023-07-12 20:00:40,651 simple_logger.py log_once [line:28] INFO mean_valid_loss               0.7152\n",
            "2023-07-12 20:00:40,652 simple_logger.py log_once [line:28] INFO std_valid_loss                0.5272\n",
            "2023-07-12 20:00:40,653 fedbase.py run [line:251] INFO Eval Time Cost:               3.8097s\n",
            "2023-07-12 20:00:43,686 fedbase.py run [line:246] INFO --------------Round 9--------------\n",
            "2023-07-12 20:00:43,688 simple_logger.py log_once [line:14] INFO Current_time:9\n",
            "2023-07-12 20:00:48,609 simple_logger.py log_once [line:28] INFO test_accuracy                 0.8493\n",
            "2023-07-12 20:00:48,611 simple_logger.py log_once [line:28] INFO test_loss                     0.4298\n",
            "2023-07-12 20:00:48,616 simple_logger.py log_once [line:28] INFO valid_accuracy                0.8559\n",
            "2023-07-12 20:00:48,619 simple_logger.py log_once [line:28] INFO mean_valid_accuracy           0.8569\n",
            "2023-07-12 20:00:48,620 simple_logger.py log_once [line:28] INFO std_valid_accuracy            0.1037\n",
            "2023-07-12 20:00:48,625 simple_logger.py log_once [line:28] INFO valid_loss                    0.4287\n",
            "2023-07-12 20:00:48,627 simple_logger.py log_once [line:28] INFO mean_valid_loss               0.4255\n",
            "2023-07-12 20:00:48,630 simple_logger.py log_once [line:28] INFO std_valid_loss                0.3071\n",
            "2023-07-12 20:00:48,631 fedbase.py run [line:251] INFO Eval Time Cost:               4.9429s\n",
            "2023-07-12 20:00:52,579 fedbase.py run [line:246] INFO --------------Round 10--------------\n",
            "2023-07-12 20:00:52,580 simple_logger.py log_once [line:14] INFO Current_time:10\n",
            "2023-07-12 20:00:56,407 simple_logger.py log_once [line:28] INFO test_accuracy                 0.8250\n",
            "2023-07-12 20:00:56,408 simple_logger.py log_once [line:28] INFO test_loss                     0.4788\n",
            "2023-07-12 20:00:56,412 simple_logger.py log_once [line:28] INFO valid_accuracy                0.8195\n",
            "2023-07-12 20:00:56,415 simple_logger.py log_once [line:28] INFO mean_valid_accuracy           0.8201\n",
            "2023-07-12 20:00:56,417 simple_logger.py log_once [line:28] INFO std_valid_accuracy            0.1414\n",
            "2023-07-12 20:00:56,419 simple_logger.py log_once [line:28] INFO valid_loss                    0.5003\n",
            "2023-07-12 20:00:56,420 simple_logger.py log_once [line:28] INFO mean_valid_loss               0.4989\n",
            "2023-07-12 20:00:56,421 simple_logger.py log_once [line:28] INFO std_valid_loss                0.3808\n",
            "2023-07-12 20:00:56,422 fedbase.py run [line:251] INFO Eval Time Cost:               3.8421s\n",
            "2023-07-12 20:01:00,130 fedbase.py run [line:246] INFO --------------Round 11--------------\n",
            "2023-07-12 20:01:00,134 simple_logger.py log_once [line:14] INFO Current_time:11\n",
            "2023-07-12 20:01:04,518 simple_logger.py log_once [line:28] INFO test_accuracy                 0.9293\n",
            "2023-07-12 20:01:04,519 simple_logger.py log_once [line:28] INFO test_loss                     0.2150\n",
            "2023-07-12 20:01:04,520 simple_logger.py log_once [line:28] INFO valid_accuracy                0.9264\n",
            "2023-07-12 20:01:04,523 simple_logger.py log_once [line:28] INFO mean_valid_accuracy           0.9268\n",
            "2023-07-12 20:01:04,525 simple_logger.py log_once [line:28] INFO std_valid_accuracy            0.0630\n",
            "2023-07-12 20:01:04,530 simple_logger.py log_once [line:28] INFO valid_loss                    0.2365\n",
            "2023-07-12 20:01:04,532 simple_logger.py log_once [line:28] INFO mean_valid_loss               0.2352\n",
            "2023-07-12 20:01:04,533 simple_logger.py log_once [line:28] INFO std_valid_loss                0.1888\n",
            "2023-07-12 20:01:04,534 fedbase.py run [line:251] INFO Eval Time Cost:               4.4005s\n",
            "2023-07-12 20:01:07,563 fedbase.py run [line:246] INFO --------------Round 12--------------\n",
            "2023-07-12 20:01:07,565 simple_logger.py log_once [line:14] INFO Current_time:12\n",
            "2023-07-12 20:01:11,678 simple_logger.py log_once [line:28] INFO test_accuracy                 0.9307\n",
            "2023-07-12 20:01:11,683 simple_logger.py log_once [line:28] INFO test_loss                     0.2128\n",
            "2023-07-12 20:01:11,685 simple_logger.py log_once [line:28] INFO valid_accuracy                0.9229\n",
            "2023-07-12 20:01:11,686 simple_logger.py log_once [line:28] INFO mean_valid_accuracy           0.9230\n",
            "2023-07-12 20:01:11,688 simple_logger.py log_once [line:28] INFO std_valid_accuracy            0.0623\n",
            "2023-07-12 20:01:11,693 simple_logger.py log_once [line:28] INFO valid_loss                    0.2394\n",
            "2023-07-12 20:01:11,694 simple_logger.py log_once [line:28] INFO mean_valid_loss               0.2389\n",
            "2023-07-12 20:01:11,695 simple_logger.py log_once [line:28] INFO std_valid_loss                0.1833\n",
            "2023-07-12 20:01:11,696 fedbase.py run [line:251] INFO Eval Time Cost:               4.1315s\n",
            "2023-07-12 20:01:15,700 fedbase.py run [line:246] INFO --------------Round 13--------------\n",
            "2023-07-12 20:01:15,701 simple_logger.py log_once [line:14] INFO Current_time:13\n",
            "2023-07-12 20:01:19,541 simple_logger.py log_once [line:28] INFO test_accuracy                 0.8883\n",
            "2023-07-12 20:01:19,543 simple_logger.py log_once [line:28] INFO test_loss                     0.3205\n",
            "2023-07-12 20:01:19,547 simple_logger.py log_once [line:28] INFO valid_accuracy                0.8887\n",
            "2023-07-12 20:01:19,552 simple_logger.py log_once [line:28] INFO mean_valid_accuracy           0.8895\n",
            "2023-07-12 20:01:19,555 simple_logger.py log_once [line:28] INFO std_valid_accuracy            0.0857\n",
            "2023-07-12 20:01:19,559 simple_logger.py log_once [line:28] INFO valid_loss                    0.3202\n",
            "2023-07-12 20:01:19,560 simple_logger.py log_once [line:28] INFO mean_valid_loss               0.3181\n",
            "2023-07-12 20:01:19,561 simple_logger.py log_once [line:28] INFO std_valid_loss                0.2426\n",
            "2023-07-12 20:01:19,562 fedbase.py run [line:251] INFO Eval Time Cost:               3.8611s\n",
            "2023-07-12 20:01:22,632 fedbase.py run [line:246] INFO --------------Round 14--------------\n",
            "2023-07-12 20:01:22,633 simple_logger.py log_once [line:14] INFO Current_time:14\n",
            "2023-07-12 20:01:27,253 simple_logger.py log_once [line:28] INFO test_accuracy                 0.8831\n",
            "2023-07-12 20:01:27,257 simple_logger.py log_once [line:28] INFO test_loss                     0.3520\n",
            "2023-07-12 20:01:27,259 simple_logger.py log_once [line:28] INFO valid_accuracy                0.8792\n",
            "2023-07-12 20:01:27,263 simple_logger.py log_once [line:28] INFO mean_valid_accuracy           0.8803\n",
            "2023-07-12 20:01:27,265 simple_logger.py log_once [line:28] INFO std_valid_accuracy            0.1631\n",
            "2023-07-12 20:01:27,266 simple_logger.py log_once [line:28] INFO valid_loss                    0.3655\n",
            "2023-07-12 20:01:27,268 simple_logger.py log_once [line:28] INFO mean_valid_loss               0.3623\n",
            "2023-07-12 20:01:27,269 simple_logger.py log_once [line:28] INFO std_valid_loss                0.4705\n",
            "2023-07-12 20:01:27,270 fedbase.py run [line:251] INFO Eval Time Cost:               4.6369s\n",
            "2023-07-12 20:01:30,538 fedbase.py run [line:246] INFO --------------Round 15--------------\n",
            "2023-07-12 20:01:30,540 simple_logger.py log_once [line:14] INFO Current_time:15\n",
            "2023-07-12 20:01:34,367 simple_logger.py log_once [line:28] INFO test_accuracy                 0.8630\n",
            "2023-07-12 20:01:34,368 simple_logger.py log_once [line:28] INFO test_loss                     0.3610\n",
            "2023-07-12 20:01:34,370 simple_logger.py log_once [line:28] INFO valid_accuracy                0.8590\n",
            "2023-07-12 20:01:34,374 simple_logger.py log_once [line:28] INFO mean_valid_accuracy           0.8594\n",
            "2023-07-12 20:01:34,376 simple_logger.py log_once [line:28] INFO std_valid_accuracy            0.1286\n",
            "2023-07-12 20:01:34,377 simple_logger.py log_once [line:28] INFO valid_loss                    0.3822\n",
            "2023-07-12 20:01:34,379 simple_logger.py log_once [line:28] INFO mean_valid_loss               0.3811\n",
            "2023-07-12 20:01:34,381 simple_logger.py log_once [line:28] INFO std_valid_loss                0.3393\n",
            "2023-07-12 20:01:34,382 fedbase.py run [line:251] INFO Eval Time Cost:               3.8427s\n",
            "2023-07-12 20:01:37,481 fedbase.py run [line:246] INFO --------------Round 16--------------\n",
            "2023-07-12 20:01:37,482 simple_logger.py log_once [line:14] INFO Current_time:16\n",
            "2023-07-12 20:01:42,480 simple_logger.py log_once [line:28] INFO test_accuracy                 0.8980\n",
            "2023-07-12 20:01:42,482 simple_logger.py log_once [line:28] INFO test_loss                     0.2952\n",
            "2023-07-12 20:01:42,484 simple_logger.py log_once [line:28] INFO valid_accuracy                0.8935\n",
            "2023-07-12 20:01:42,487 simple_logger.py log_once [line:28] INFO mean_valid_accuracy           0.8930\n",
            "2023-07-12 20:01:42,489 simple_logger.py log_once [line:28] INFO std_valid_accuracy            0.0977\n",
            "2023-07-12 20:01:42,490 simple_logger.py log_once [line:28] INFO valid_loss                    0.3192\n",
            "2023-07-12 20:01:42,493 simple_logger.py log_once [line:28] INFO mean_valid_loss               0.3206\n",
            "2023-07-12 20:01:42,494 simple_logger.py log_once [line:28] INFO std_valid_loss                0.2504\n",
            "2023-07-12 20:01:42,495 fedbase.py run [line:251] INFO Eval Time Cost:               5.0125s\n",
            "2023-07-12 20:01:45,602 fedbase.py run [line:246] INFO --------------Round 17--------------\n",
            "2023-07-12 20:01:45,604 simple_logger.py log_once [line:14] INFO Current_time:17\n",
            "2023-07-12 20:01:49,467 simple_logger.py log_once [line:28] INFO test_accuracy                 0.9056\n",
            "2023-07-12 20:01:49,469 simple_logger.py log_once [line:28] INFO test_loss                     0.2677\n",
            "2023-07-12 20:01:49,471 simple_logger.py log_once [line:28] INFO valid_accuracy                0.9069\n",
            "2023-07-12 20:01:49,475 simple_logger.py log_once [line:28] INFO mean_valid_accuracy           0.9081\n",
            "2023-07-12 20:01:49,482 simple_logger.py log_once [line:28] INFO std_valid_accuracy            0.0888\n",
            "2023-07-12 20:01:49,484 simple_logger.py log_once [line:28] INFO valid_loss                    0.2763\n",
            "2023-07-12 20:01:49,487 simple_logger.py log_once [line:28] INFO mean_valid_loss               0.2730\n",
            "2023-07-12 20:01:49,488 simple_logger.py log_once [line:28] INFO std_valid_loss                0.2581\n",
            "2023-07-12 20:01:49,489 fedbase.py run [line:251] INFO Eval Time Cost:               3.8854s\n",
            "2023-07-12 20:01:53,382 fedbase.py run [line:246] INFO --------------Round 18--------------\n",
            "2023-07-12 20:01:53,384 simple_logger.py log_once [line:14] INFO Current_time:18\n",
            "2023-07-12 20:01:57,703 simple_logger.py log_once [line:28] INFO test_accuracy                 0.9522\n",
            "2023-07-12 20:01:57,705 simple_logger.py log_once [line:28] INFO test_loss                     0.1616\n",
            "2023-07-12 20:01:57,709 simple_logger.py log_once [line:28] INFO valid_accuracy                0.9438\n",
            "2023-07-12 20:01:57,712 simple_logger.py log_once [line:28] INFO mean_valid_accuracy           0.9438\n",
            "2023-07-12 20:01:57,714 simple_logger.py log_once [line:28] INFO std_valid_accuracy            0.0359\n",
            "2023-07-12 20:01:57,716 simple_logger.py log_once [line:28] INFO valid_loss                    0.1836\n",
            "2023-07-12 20:01:57,718 simple_logger.py log_once [line:28] INFO mean_valid_loss               0.1834\n",
            "2023-07-12 20:01:57,719 simple_logger.py log_once [line:28] INFO std_valid_loss                0.1173\n",
            "2023-07-12 20:01:57,720 fedbase.py run [line:251] INFO Eval Time Cost:               4.3358s\n",
            "2023-07-12 20:02:00,812 fedbase.py run [line:246] INFO --------------Round 19--------------\n",
            "2023-07-12 20:02:00,813 simple_logger.py log_once [line:14] INFO Current_time:19\n",
            "2023-07-12 20:02:04,674 simple_logger.py log_once [line:28] INFO test_accuracy                 0.9403\n",
            "2023-07-12 20:02:04,679 simple_logger.py log_once [line:28] INFO test_loss                     0.1914\n",
            "2023-07-12 20:02:04,682 simple_logger.py log_once [line:28] INFO valid_accuracy                0.9333\n",
            "2023-07-12 20:02:04,683 simple_logger.py log_once [line:28] INFO mean_valid_accuracy           0.9332\n",
            "2023-07-12 20:02:04,685 simple_logger.py log_once [line:28] INFO std_valid_accuracy            0.0737\n",
            "2023-07-12 20:02:04,686 simple_logger.py log_once [line:28] INFO valid_loss                    0.2153\n",
            "2023-07-12 20:02:04,688 simple_logger.py log_once [line:28] INFO mean_valid_loss               0.2156\n",
            "2023-07-12 20:02:04,690 simple_logger.py log_once [line:28] INFO std_valid_loss                0.2201\n",
            "2023-07-12 20:02:04,694 fedbase.py run [line:251] INFO Eval Time Cost:               3.8807s\n",
            "2023-07-12 20:02:07,087 fedbase.py run [line:246] INFO --------------Round 20--------------\n",
            "2023-07-12 20:02:07,090 simple_logger.py log_once [line:14] INFO Current_time:20\n",
            "2023-07-12 20:02:11,168 simple_logger.py log_once [line:28] INFO test_accuracy                 0.7240\n",
            "2023-07-12 20:02:11,169 simple_logger.py log_once [line:28] INFO test_loss                     0.7044\n",
            "2023-07-12 20:02:11,173 simple_logger.py log_once [line:28] INFO valid_accuracy                0.7222\n",
            "2023-07-12 20:02:11,176 simple_logger.py log_once [line:28] INFO mean_valid_accuracy           0.7220\n",
            "2023-07-12 20:02:11,178 simple_logger.py log_once [line:28] INFO std_valid_accuracy            0.1538\n",
            "2023-07-12 20:02:11,180 simple_logger.py log_once [line:28] INFO valid_loss                    0.7245\n",
            "2023-07-12 20:02:11,182 simple_logger.py log_once [line:28] INFO mean_valid_loss               0.7247\n",
            "2023-07-12 20:02:11,183 simple_logger.py log_once [line:28] INFO std_valid_loss                0.4065\n",
            "2023-07-12 20:02:11,184 fedbase.py run [line:251] INFO Eval Time Cost:               4.0941s\n",
            "2023-07-12 20:02:14,240 fedbase.py run [line:246] INFO --------------Round 21--------------\n",
            "2023-07-12 20:02:14,241 simple_logger.py log_once [line:14] INFO Current_time:21\n",
            "2023-07-12 20:02:18,166 simple_logger.py log_once [line:28] INFO test_accuracy                 0.8763\n",
            "2023-07-12 20:02:18,168 simple_logger.py log_once [line:28] INFO test_loss                     0.3601\n",
            "2023-07-12 20:02:18,170 simple_logger.py log_once [line:28] INFO valid_accuracy                0.8647\n",
            "2023-07-12 20:02:18,172 simple_logger.py log_once [line:28] INFO mean_valid_accuracy           0.8638\n",
            "2023-07-12 20:02:18,174 simple_logger.py log_once [line:28] INFO std_valid_accuracy            0.1033\n",
            "2023-07-12 20:02:18,176 simple_logger.py log_once [line:28] INFO valid_loss                    0.3977\n",
            "2023-07-12 20:02:18,177 simple_logger.py log_once [line:28] INFO mean_valid_loss               0.4003\n",
            "2023-07-12 20:02:18,178 simple_logger.py log_once [line:28] INFO std_valid_loss                0.2911\n",
            "2023-07-12 20:02:18,179 fedbase.py run [line:251] INFO Eval Time Cost:               3.9379s\n",
            "2023-07-12 20:02:22,307 fedbase.py run [line:246] INFO --------------Round 22--------------\n",
            "2023-07-12 20:02:22,308 simple_logger.py log_once [line:14] INFO Current_time:22\n",
            "2023-07-12 20:02:26,159 simple_logger.py log_once [line:28] INFO test_accuracy                 0.9060\n",
            "2023-07-12 20:02:26,161 simple_logger.py log_once [line:28] INFO test_loss                     0.2784\n",
            "2023-07-12 20:02:26,163 simple_logger.py log_once [line:28] INFO valid_accuracy                0.8989\n",
            "2023-07-12 20:02:26,168 simple_logger.py log_once [line:28] INFO mean_valid_accuracy           0.8986\n",
            "2023-07-12 20:02:26,170 simple_logger.py log_once [line:28] INFO std_valid_accuracy            0.0986\n",
            "2023-07-12 20:02:26,171 simple_logger.py log_once [line:28] INFO valid_loss                    0.3015\n",
            "2023-07-12 20:02:26,172 simple_logger.py log_once [line:28] INFO mean_valid_loss               0.3023\n",
            "2023-07-12 20:02:26,173 simple_logger.py log_once [line:28] INFO std_valid_loss                0.2812\n",
            "2023-07-12 20:02:26,175 fedbase.py run [line:251] INFO Eval Time Cost:               3.8666s\n",
            "2023-07-12 20:02:29,272 fedbase.py run [line:246] INFO --------------Round 23--------------\n",
            "2023-07-12 20:02:29,274 simple_logger.py log_once [line:14] INFO Current_time:23\n",
            "2023-07-12 20:02:34,266 simple_logger.py log_once [line:28] INFO test_accuracy                 0.9120\n",
            "2023-07-12 20:02:34,269 simple_logger.py log_once [line:28] INFO test_loss                     0.2459\n",
            "2023-07-12 20:02:34,270 simple_logger.py log_once [line:28] INFO valid_accuracy                0.9029\n",
            "2023-07-12 20:02:34,272 simple_logger.py log_once [line:28] INFO mean_valid_accuracy           0.9024\n",
            "2023-07-12 20:02:34,274 simple_logger.py log_once [line:28] INFO std_valid_accuracy            0.0771\n",
            "2023-07-12 20:02:34,276 simple_logger.py log_once [line:28] INFO valid_loss                    0.2769\n",
            "2023-07-12 20:02:34,277 simple_logger.py log_once [line:28] INFO mean_valid_loss               0.2784\n",
            "2023-07-12 20:02:34,278 simple_logger.py log_once [line:28] INFO std_valid_loss                0.2207\n",
            "2023-07-12 20:02:34,279 fedbase.py run [line:251] INFO Eval Time Cost:               5.0052s\n",
            "2023-07-12 20:02:36,094 fedbase.py run [line:246] INFO --------------Round 24--------------\n",
            "2023-07-12 20:02:36,096 simple_logger.py log_once [line:14] INFO Current_time:24\n",
            "2023-07-12 20:02:39,965 simple_logger.py log_once [line:28] INFO test_accuracy                 0.8131\n",
            "2023-07-12 20:02:39,966 simple_logger.py log_once [line:28] INFO test_loss                     0.5358\n",
            "2023-07-12 20:02:39,967 simple_logger.py log_once [line:28] INFO valid_accuracy                0.8034\n",
            "2023-07-12 20:02:39,969 simple_logger.py log_once [line:28] INFO mean_valid_accuracy           0.8024\n",
            "2023-07-12 20:02:39,974 simple_logger.py log_once [line:28] INFO std_valid_accuracy            0.1439\n",
            "2023-07-12 20:02:39,976 simple_logger.py log_once [line:28] INFO valid_loss                    0.5860\n",
            "2023-07-12 20:02:39,978 simple_logger.py log_once [line:28] INFO mean_valid_loss               0.5891\n",
            "2023-07-12 20:02:39,979 simple_logger.py log_once [line:28] INFO std_valid_loss                0.4641\n",
            "2023-07-12 20:02:39,979 fedbase.py run [line:251] INFO Eval Time Cost:               3.8838s\n",
            "2023-07-12 20:02:43,049 fedbase.py run [line:246] INFO --------------Round 25--------------\n",
            "2023-07-12 20:02:43,051 simple_logger.py log_once [line:14] INFO Current_time:25\n",
            "2023-07-12 20:02:47,939 simple_logger.py log_once [line:28] INFO test_accuracy                 0.9336\n",
            "2023-07-12 20:02:47,940 simple_logger.py log_once [line:28] INFO test_loss                     0.2080\n",
            "2023-07-12 20:02:47,943 simple_logger.py log_once [line:28] INFO valid_accuracy                0.9239\n",
            "2023-07-12 20:02:47,945 simple_logger.py log_once [line:28] INFO mean_valid_accuracy           0.9239\n",
            "2023-07-12 20:02:47,948 simple_logger.py log_once [line:28] INFO std_valid_accuracy            0.0593\n",
            "2023-07-12 20:02:47,949 simple_logger.py log_once [line:28] INFO valid_loss                    0.2395\n",
            "2023-07-12 20:02:47,951 simple_logger.py log_once [line:28] INFO mean_valid_loss               0.2395\n",
            "2023-07-12 20:02:47,952 simple_logger.py log_once [line:28] INFO std_valid_loss                0.1750\n",
            "2023-07-12 20:02:47,953 fedbase.py run [line:251] INFO Eval Time Cost:               4.9023s\n",
            "2023-07-12 20:02:50,994 fedbase.py run [line:246] INFO --------------Round 26--------------\n",
            "2023-07-12 20:02:50,996 simple_logger.py log_once [line:14] INFO Current_time:26\n",
            "2023-07-12 20:02:54,743 simple_logger.py log_once [line:28] INFO test_accuracy                 0.9459\n",
            "2023-07-12 20:02:54,744 simple_logger.py log_once [line:28] INFO test_loss                     0.1743\n",
            "2023-07-12 20:02:54,749 simple_logger.py log_once [line:28] INFO valid_accuracy                0.9396\n",
            "2023-07-12 20:02:54,751 simple_logger.py log_once [line:28] INFO mean_valid_accuracy           0.9394\n",
            "2023-07-12 20:02:54,757 simple_logger.py log_once [line:28] INFO std_valid_accuracy            0.0435\n",
            "2023-07-12 20:02:54,758 simple_logger.py log_once [line:28] INFO valid_loss                    0.1944\n",
            "2023-07-12 20:02:54,759 simple_logger.py log_once [line:28] INFO mean_valid_loss               0.1952\n",
            "2023-07-12 20:02:54,760 simple_logger.py log_once [line:28] INFO std_valid_loss                0.1321\n",
            "2023-07-12 20:02:54,761 fedbase.py run [line:251] INFO Eval Time Cost:               3.7658s\n",
            "2023-07-12 20:02:57,875 fedbase.py run [line:246] INFO --------------Round 27--------------\n",
            "2023-07-12 20:02:57,877 simple_logger.py log_once [line:14] INFO Current_time:27\n",
            "2023-07-12 20:03:02,803 simple_logger.py log_once [line:28] INFO test_accuracy                 0.9260\n",
            "2023-07-12 20:03:02,804 simple_logger.py log_once [line:28] INFO test_loss                     0.2309\n",
            "2023-07-12 20:03:02,808 simple_logger.py log_once [line:28] INFO valid_accuracy                0.9151\n",
            "2023-07-12 20:03:02,810 simple_logger.py log_once [line:28] INFO mean_valid_accuracy           0.9146\n",
            "2023-07-12 20:03:02,813 simple_logger.py log_once [line:28] INFO std_valid_accuracy            0.1090\n",
            "2023-07-12 20:03:02,817 simple_logger.py log_once [line:28] INFO valid_loss                    0.2678\n",
            "2023-07-12 20:03:02,818 simple_logger.py log_once [line:28] INFO mean_valid_loss               0.2693\n",
            "2023-07-12 20:03:02,820 simple_logger.py log_once [line:28] INFO std_valid_loss                0.3461\n",
            "2023-07-12 20:03:02,821 fedbase.py run [line:251] INFO Eval Time Cost:               4.9439s\n",
            "2023-07-12 20:03:05,849 fedbase.py run [line:246] INFO --------------Round 28--------------\n",
            "2023-07-12 20:03:05,851 simple_logger.py log_once [line:14] INFO Current_time:28\n",
            "2023-07-12 20:03:09,606 simple_logger.py log_once [line:28] INFO test_accuracy                 0.9195\n",
            "2023-07-12 20:03:09,607 simple_logger.py log_once [line:28] INFO test_loss                     0.2401\n",
            "2023-07-12 20:03:09,615 simple_logger.py log_once [line:28] INFO valid_accuracy                0.9126\n",
            "2023-07-12 20:03:09,616 simple_logger.py log_once [line:28] INFO mean_valid_accuracy           0.9124\n",
            "2023-07-12 20:03:09,619 simple_logger.py log_once [line:28] INFO std_valid_accuracy            0.0713\n",
            "2023-07-12 20:03:09,625 simple_logger.py log_once [line:28] INFO valid_loss                    0.2638\n",
            "2023-07-12 20:03:09,626 simple_logger.py log_once [line:28] INFO mean_valid_loss               0.2645\n",
            "2023-07-12 20:03:09,629 simple_logger.py log_once [line:28] INFO std_valid_loss                0.1954\n",
            "2023-07-12 20:03:09,632 fedbase.py run [line:251] INFO Eval Time Cost:               3.7812s\n",
            "2023-07-12 20:03:13,337 fedbase.py run [line:246] INFO --------------Round 29--------------\n",
            "2023-07-12 20:03:13,342 simple_logger.py log_once [line:14] INFO Current_time:29\n",
            "2023-07-12 20:03:17,727 simple_logger.py log_once [line:28] INFO test_accuracy                 0.9537\n",
            "2023-07-12 20:03:17,728 simple_logger.py log_once [line:28] INFO test_loss                     0.1374\n",
            "2023-07-12 20:03:17,732 simple_logger.py log_once [line:28] INFO valid_accuracy                0.9540\n",
            "2023-07-12 20:03:17,734 simple_logger.py log_once [line:28] INFO mean_valid_accuracy           0.9544\n",
            "2023-07-12 20:03:17,736 simple_logger.py log_once [line:28] INFO std_valid_accuracy            0.0384\n",
            "2023-07-12 20:03:17,738 simple_logger.py log_once [line:28] INFO valid_loss                    0.1421\n",
            "2023-07-12 20:03:17,743 simple_logger.py log_once [line:28] INFO mean_valid_loss               0.1407\n",
            "2023-07-12 20:03:17,744 simple_logger.py log_once [line:28] INFO std_valid_loss                0.1116\n",
            "2023-07-12 20:03:17,747 fedbase.py run [line:251] INFO Eval Time Cost:               4.4047s\n",
            "2023-07-12 20:03:20,824 fedbase.py run [line:246] INFO --------------Round 30--------------\n",
            "2023-07-12 20:03:20,825 simple_logger.py log_once [line:14] INFO Current_time:30\n",
            "2023-07-12 20:03:24,782 simple_logger.py log_once [line:28] INFO test_accuracy                 0.9489\n",
            "2023-07-12 20:03:24,789 simple_logger.py log_once [line:28] INFO test_loss                     0.1599\n",
            "2023-07-12 20:03:24,791 simple_logger.py log_once [line:28] INFO valid_accuracy                0.9399\n",
            "2023-07-12 20:03:24,792 simple_logger.py log_once [line:28] INFO mean_valid_accuracy           0.9396\n",
            "2023-07-12 20:03:24,794 simple_logger.py log_once [line:28] INFO std_valid_accuracy            0.0521\n",
            "2023-07-12 20:03:24,795 simple_logger.py log_once [line:28] INFO valid_loss                    0.1841\n",
            "2023-07-12 20:03:24,799 simple_logger.py log_once [line:28] INFO mean_valid_loss               0.1850\n",
            "2023-07-12 20:03:24,800 simple_logger.py log_once [line:28] INFO std_valid_loss                0.1461\n",
            "2023-07-12 20:03:24,801 fedbase.py run [line:251] INFO Eval Time Cost:               3.9756s\n",
            "2023-07-12 20:03:24,802 fedbase.py run [line:257] INFO =================End==================\n",
            "2023-07-12 20:03:24,802 fedbase.py run [line:258] INFO Total Time Cost:              228.3859s\n"
          ]
        }
      ],
      "source": [
        "import flgo.algorithm.fedavg as fedavg\n",
        "runner = flgo.init(task, fedavg, option=option, model=model_DC)\n",
        "runner.model\n",
        "runner.run()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q0l4wOC-AF06",
        "outputId": "3567dc67-d5f5-464d-8214-e5ba2ead667f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1 2\n",
            "0\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<__main__.C at 0x7f476d4c5240>"
            ]
          },
          "execution_count": 117,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "class B():#\n",
        "  def __init__(self, a, b):\n",
        "      print(a,b)\n",
        "class C(B):\n",
        "  def __init__(self, c, *args, **kwargs):\n",
        "    B.__init__(self, *args, **kwargs)\n",
        "    print(c)\n",
        "C(0,1,2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VkkuYnmU25UG",
        "outputId": "22869452-806e-4e5c-bb5f-1a2f624d189e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0.60653066, 1.        , 7.3890561 ])"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "np.exp([-0.5,0,2])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gZejqGYEanME",
        "outputId": "c0584f36-35de-43f9-a7a9-d7e8984217a0"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-07-10 19:31:41,505 fflow.py init [line:441] INFO Initializing devices: cuda:0 will be used for this running.\n",
            "2023-07-10 19:31:41,606 fflow.py init [line:479] INFO Use `<class 'flgo.simulator.default_simulator.Simulator'>` as the system simulator\n",
            "2023-07-10 19:31:41,609 fflow.py init [line:487] INFO Ready to start.\n",
            "2023-07-10 19:31:41,610 fedbase.py run [line:236] INFO --------------Initial Evaluation--------------\n",
            "2023-07-10 19:31:41,611 simple_logger.py log_once [line:14] INFO Current_time:0\n",
            "2023-07-10 19:31:46,088 simple_logger.py log_once [line:28] INFO test_accuracy                 0.0721\n",
            "2023-07-10 19:31:46,090 simple_logger.py log_once [line:28] INFO test_loss                     2.3057\n",
            "2023-07-10 19:31:46,093 simple_logger.py log_once [line:28] INFO valid_accuracy                0.0729\n",
            "2023-07-10 19:31:46,095 simple_logger.py log_once [line:28] INFO mean_valid_accuracy           0.0729\n",
            "2023-07-10 19:31:46,098 simple_logger.py log_once [line:28] INFO std_valid_accuracy            0.0526\n",
            "2023-07-10 19:31:46,101 simple_logger.py log_once [line:28] INFO valid_loss                    2.3050\n",
            "2023-07-10 19:31:46,104 simple_logger.py log_once [line:28] INFO mean_valid_loss               2.3050\n",
            "2023-07-10 19:31:46,107 simple_logger.py log_once [line:28] INFO std_valid_loss                0.0066\n",
            "2023-07-10 19:31:46,113 fedbase.py run [line:239] INFO Eval Time Cost:               4.5018s\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "选择： [3, 9]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-07-10 19:31:49,600 fedbase.py run [line:246] INFO --------------Round 1--------------\n",
            "2023-07-10 19:31:49,601 simple_logger.py log_once [line:14] INFO Current_time:1\n",
            "2023-07-10 19:31:55,149 simple_logger.py log_once [line:28] INFO test_accuracy                 0.4437\n",
            "2023-07-10 19:31:55,150 simple_logger.py log_once [line:28] INFO test_loss                     1.7366\n",
            "2023-07-10 19:31:55,153 simple_logger.py log_once [line:28] INFO valid_accuracy                0.4387\n",
            "2023-07-10 19:31:55,155 simple_logger.py log_once [line:28] INFO mean_valid_accuracy           0.4373\n",
            "2023-07-10 19:31:55,158 simple_logger.py log_once [line:28] INFO std_valid_accuracy            0.2748\n",
            "2023-07-10 19:31:55,160 simple_logger.py log_once [line:28] INFO valid_loss                    1.7434\n",
            "2023-07-10 19:31:55,162 simple_logger.py log_once [line:28] INFO mean_valid_loss               1.7453\n",
            "2023-07-10 19:31:55,163 simple_logger.py log_once [line:28] INFO std_valid_loss                0.8699\n",
            "2023-07-10 19:31:55,164 fedbase.py run [line:251] INFO Eval Time Cost:               5.5630s\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "选择： [7, 6]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-07-10 19:31:58,686 fedbase.py run [line:246] INFO --------------Round 2--------------\n",
            "2023-07-10 19:31:58,687 simple_logger.py log_once [line:14] INFO Current_time:2\n",
            "2023-07-10 19:32:03,020 simple_logger.py log_once [line:28] INFO test_accuracy                 0.6193\n",
            "2023-07-10 19:32:03,021 simple_logger.py log_once [line:28] INFO test_loss                     1.0472\n",
            "2023-07-10 19:32:03,024 simple_logger.py log_once [line:28] INFO valid_accuracy                0.6254\n",
            "2023-07-10 19:32:03,029 simple_logger.py log_once [line:28] INFO mean_valid_accuracy           0.6267\n",
            "2023-07-10 19:32:03,031 simple_logger.py log_once [line:28] INFO std_valid_accuracy            0.2409\n",
            "2023-07-10 19:32:03,035 simple_logger.py log_once [line:28] INFO valid_loss                    1.0509\n",
            "2023-07-10 19:32:03,037 simple_logger.py log_once [line:28] INFO mean_valid_loss               1.0477\n",
            "2023-07-10 19:32:03,038 simple_logger.py log_once [line:28] INFO std_valid_loss                0.5920\n",
            "2023-07-10 19:32:03,040 fedbase.py run [line:251] INFO Eval Time Cost:               4.3522s\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "选择： [1, 1]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-07-10 19:32:04,813 fedbase.py run [line:246] INFO --------------Round 3--------------\n",
            "2023-07-10 19:32:04,814 simple_logger.py log_once [line:14] INFO Current_time:3\n",
            "2023-07-10 19:32:10,897 simple_logger.py log_once [line:28] INFO test_accuracy                 0.6084\n",
            "2023-07-10 19:32:10,899 simple_logger.py log_once [line:28] INFO test_loss                     1.6367\n",
            "2023-07-10 19:32:10,904 simple_logger.py log_once [line:28] INFO valid_accuracy                0.6039\n",
            "2023-07-10 19:32:10,907 simple_logger.py log_once [line:28] INFO mean_valid_accuracy           0.6035\n",
            "2023-07-10 19:32:10,911 simple_logger.py log_once [line:28] INFO std_valid_accuracy            0.2839\n",
            "2023-07-10 19:32:10,912 simple_logger.py log_once [line:28] INFO valid_loss                    1.6691\n",
            "2023-07-10 19:32:10,914 simple_logger.py log_once [line:28] INFO mean_valid_loss               1.6662\n",
            "2023-07-10 19:32:10,915 simple_logger.py log_once [line:28] INFO std_valid_loss                1.6602\n",
            "2023-07-10 19:32:10,916 fedbase.py run [line:251] INFO Eval Time Cost:               6.1017s\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "选择： [0, 8]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-07-10 19:32:14,384 fedbase.py run [line:246] INFO --------------Round 4--------------\n",
            "2023-07-10 19:32:14,386 simple_logger.py log_once [line:14] INFO Current_time:4\n",
            "2023-07-10 19:32:18,946 simple_logger.py log_once [line:28] INFO test_accuracy                 0.6966\n",
            "2023-07-10 19:32:18,947 simple_logger.py log_once [line:28] INFO test_loss                     1.3276\n",
            "2023-07-10 19:32:18,950 simple_logger.py log_once [line:28] INFO valid_accuracy                0.6927\n",
            "2023-07-10 19:32:18,953 simple_logger.py log_once [line:28] INFO mean_valid_accuracy           0.6927\n",
            "2023-07-10 19:32:18,956 simple_logger.py log_once [line:28] INFO std_valid_accuracy            0.3119\n",
            "2023-07-10 19:32:18,957 simple_logger.py log_once [line:28] INFO valid_loss                    1.3546\n",
            "2023-07-10 19:32:18,958 simple_logger.py log_once [line:28] INFO mean_valid_loss               1.3531\n",
            "2023-07-10 19:32:18,960 simple_logger.py log_once [line:28] INFO std_valid_loss                1.5871\n",
            "2023-07-10 19:32:18,961 fedbase.py run [line:251] INFO Eval Time Cost:               4.5747s\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "选择： [6, 7]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-07-10 19:32:24,271 fedbase.py run [line:246] INFO --------------Round 5--------------\n",
            "2023-07-10 19:32:24,274 simple_logger.py log_once [line:14] INFO Current_time:5\n",
            "2023-07-10 19:32:29,174 simple_logger.py log_once [line:28] INFO test_accuracy                 0.8414\n",
            "2023-07-10 19:32:29,175 simple_logger.py log_once [line:28] INFO test_loss                     0.4627\n",
            "2023-07-10 19:32:29,179 simple_logger.py log_once [line:28] INFO valid_accuracy                0.8343\n",
            "2023-07-10 19:32:29,182 simple_logger.py log_once [line:28] INFO mean_valid_accuracy           0.8351\n",
            "2023-07-10 19:32:29,185 simple_logger.py log_once [line:28] INFO std_valid_accuracy            0.1621\n",
            "2023-07-10 19:32:29,191 simple_logger.py log_once [line:28] INFO valid_loss                    0.4747\n",
            "2023-07-10 19:32:29,192 simple_logger.py log_once [line:28] INFO mean_valid_loss               0.4727\n",
            "2023-07-10 19:32:29,195 simple_logger.py log_once [line:28] INFO std_valid_loss                0.3792\n",
            "2023-07-10 19:32:29,197 fedbase.py run [line:251] INFO Eval Time Cost:               4.9232s\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "选择： [0, 9]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-07-10 19:32:32,796 fedbase.py run [line:246] INFO --------------Round 6--------------\n",
            "2023-07-10 19:32:32,797 simple_logger.py log_once [line:14] INFO Current_time:6\n",
            "2023-07-10 19:32:38,626 simple_logger.py log_once [line:28] INFO test_accuracy                 0.8161\n",
            "2023-07-10 19:32:38,627 simple_logger.py log_once [line:28] INFO test_loss                     0.5394\n",
            "2023-07-10 19:32:38,631 simple_logger.py log_once [line:28] INFO valid_accuracy                0.8120\n",
            "2023-07-10 19:32:38,635 simple_logger.py log_once [line:28] INFO mean_valid_accuracy           0.8136\n",
            "2023-07-10 19:32:38,637 simple_logger.py log_once [line:28] INFO std_valid_accuracy            0.1946\n",
            "2023-07-10 19:32:38,638 simple_logger.py log_once [line:28] INFO valid_loss                    0.5577\n",
            "2023-07-10 19:32:38,640 simple_logger.py log_once [line:28] INFO mean_valid_loss               0.5537\n",
            "2023-07-10 19:32:38,641 simple_logger.py log_once [line:28] INFO std_valid_loss                0.5575\n",
            "2023-07-10 19:32:38,643 fedbase.py run [line:251] INFO Eval Time Cost:               5.8456s\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "选择： [8, 2]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-07-10 19:32:42,095 fedbase.py run [line:246] INFO --------------Round 7--------------\n",
            "2023-07-10 19:32:42,097 simple_logger.py log_once [line:14] INFO Current_time:7\n",
            "2023-07-10 19:32:46,585 simple_logger.py log_once [line:28] INFO test_accuracy                 0.9023\n",
            "2023-07-10 19:32:46,586 simple_logger.py log_once [line:28] INFO test_loss                     0.2964\n",
            "2023-07-10 19:32:46,591 simple_logger.py log_once [line:28] INFO valid_accuracy                0.8884\n",
            "2023-07-10 19:32:46,594 simple_logger.py log_once [line:28] INFO mean_valid_accuracy           0.8885\n",
            "2023-07-10 19:32:46,598 simple_logger.py log_once [line:28] INFO std_valid_accuracy            0.0917\n",
            "2023-07-10 19:32:46,601 simple_logger.py log_once [line:28] INFO valid_loss                    0.3150\n",
            "2023-07-10 19:32:46,603 simple_logger.py log_once [line:28] INFO mean_valid_loss               0.3145\n",
            "2023-07-10 19:32:46,606 simple_logger.py log_once [line:28] INFO std_valid_loss                0.2389\n",
            "2023-07-10 19:32:46,609 fedbase.py run [line:251] INFO Eval Time Cost:               4.5122s\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "选择： [1, 1]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-07-10 19:32:48,958 fedbase.py run [line:246] INFO --------------Round 8--------------\n",
            "2023-07-10 19:32:48,962 simple_logger.py log_once [line:14] INFO Current_time:8\n",
            "2023-07-10 19:32:54,233 simple_logger.py log_once [line:28] INFO test_accuracy                 0.6956\n",
            "2023-07-10 19:32:54,235 simple_logger.py log_once [line:28] INFO test_loss                     1.1857\n",
            "2023-07-10 19:32:54,240 simple_logger.py log_once [line:28] INFO valid_accuracy                0.6965\n",
            "2023-07-10 19:32:54,243 simple_logger.py log_once [line:28] INFO mean_valid_accuracy           0.6969\n",
            "2023-07-10 19:32:54,245 simple_logger.py log_once [line:28] INFO std_valid_accuracy            0.2813\n",
            "2023-07-10 19:32:54,247 simple_logger.py log_once [line:28] INFO valid_loss                    1.2026\n",
            "2023-07-10 19:32:54,248 simple_logger.py log_once [line:28] INFO mean_valid_loss               1.1999\n",
            "2023-07-10 19:32:54,249 simple_logger.py log_once [line:28] INFO std_valid_loss                1.3177\n",
            "2023-07-10 19:32:54,251 fedbase.py run [line:251] INFO Eval Time Cost:               5.2884s\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "选择： [3, 5]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-07-10 19:32:57,746 fedbase.py run [line:246] INFO --------------Round 9--------------\n",
            "2023-07-10 19:32:57,747 simple_logger.py log_once [line:14] INFO Current_time:9\n",
            "2023-07-10 19:33:03,044 simple_logger.py log_once [line:28] INFO test_accuracy                 0.9263\n",
            "2023-07-10 19:33:03,051 simple_logger.py log_once [line:28] INFO test_loss                     0.2447\n",
            "2023-07-10 19:33:03,055 simple_logger.py log_once [line:28] INFO valid_accuracy                0.9233\n",
            "2023-07-10 19:33:03,057 simple_logger.py log_once [line:28] INFO mean_valid_accuracy           0.9236\n",
            "2023-07-10 19:33:03,058 simple_logger.py log_once [line:28] INFO std_valid_accuracy            0.0499\n",
            "2023-07-10 19:33:03,061 simple_logger.py log_once [line:28] INFO valid_loss                    0.2542\n",
            "2023-07-10 19:33:03,062 simple_logger.py log_once [line:28] INFO mean_valid_loss               0.2536\n",
            "2023-07-10 19:33:03,064 simple_logger.py log_once [line:28] INFO std_valid_loss                0.1292\n",
            "2023-07-10 19:33:03,065 fedbase.py run [line:251] INFO Eval Time Cost:               5.3177s\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "选择： [4, 2]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-07-10 19:33:07,294 fedbase.py run [line:246] INFO --------------Round 10--------------\n",
            "2023-07-10 19:33:07,296 simple_logger.py log_once [line:14] INFO Current_time:10\n",
            "2023-07-10 19:33:11,725 simple_logger.py log_once [line:28] INFO test_accuracy                 0.9402\n",
            "2023-07-10 19:33:11,727 simple_logger.py log_once [line:28] INFO test_loss                     0.2038\n",
            "2023-07-10 19:33:11,728 simple_logger.py log_once [line:28] INFO valid_accuracy                0.9359\n",
            "2023-07-10 19:33:11,733 simple_logger.py log_once [line:28] INFO mean_valid_accuracy           0.9363\n",
            "2023-07-10 19:33:11,743 simple_logger.py log_once [line:28] INFO std_valid_accuracy            0.0557\n",
            "2023-07-10 19:33:11,744 simple_logger.py log_once [line:28] INFO valid_loss                    0.2157\n",
            "2023-07-10 19:33:11,745 simple_logger.py log_once [line:28] INFO mean_valid_loss               0.2146\n",
            "2023-07-10 19:33:11,747 simple_logger.py log_once [line:28] INFO std_valid_loss                0.1731\n",
            "2023-07-10 19:33:11,748 fedbase.py run [line:251] INFO Eval Time Cost:               4.4519s\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "选择： [6, 1]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-07-10 19:33:15,699 fedbase.py run [line:246] INFO --------------Round 11--------------\n",
            "2023-07-10 19:33:15,702 simple_logger.py log_once [line:14] INFO Current_time:11\n",
            "2023-07-10 19:33:21,229 simple_logger.py log_once [line:28] INFO test_accuracy                 0.7559\n",
            "2023-07-10 19:33:21,231 simple_logger.py log_once [line:28] INFO test_loss                     0.8381\n",
            "2023-07-10 19:33:21,234 simple_logger.py log_once [line:28] INFO valid_accuracy                0.7476\n",
            "2023-07-10 19:33:21,236 simple_logger.py log_once [line:28] INFO mean_valid_accuracy           0.7479\n",
            "2023-07-10 19:33:21,239 simple_logger.py log_once [line:28] INFO std_valid_accuracy            0.2190\n",
            "2023-07-10 19:33:21,241 simple_logger.py log_once [line:28] INFO valid_loss                    0.8501\n",
            "2023-07-10 19:33:21,245 simple_logger.py log_once [line:28] INFO mean_valid_loss               0.8476\n",
            "2023-07-10 19:33:21,247 simple_logger.py log_once [line:28] INFO std_valid_loss                0.8974\n",
            "2023-07-10 19:33:21,250 fedbase.py run [line:251] INFO Eval Time Cost:               5.5478s\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "选择： [2, 3]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-07-10 19:33:24,692 fedbase.py run [line:246] INFO --------------Round 12--------------\n",
            "2023-07-10 19:33:24,694 simple_logger.py log_once [line:14] INFO Current_time:12\n",
            "2023-07-10 19:33:29,213 simple_logger.py log_once [line:28] INFO test_accuracy                 0.7872\n",
            "2023-07-10 19:33:29,218 simple_logger.py log_once [line:28] INFO test_loss                     0.5630\n",
            "2023-07-10 19:33:29,220 simple_logger.py log_once [line:28] INFO valid_accuracy                0.7868\n",
            "2023-07-10 19:33:29,226 simple_logger.py log_once [line:28] INFO mean_valid_accuracy           0.7868\n",
            "2023-07-10 19:33:29,228 simple_logger.py log_once [line:28] INFO std_valid_accuracy            0.2349\n",
            "2023-07-10 19:33:29,229 simple_logger.py log_once [line:28] INFO valid_loss                    0.5781\n",
            "2023-07-10 19:33:29,230 simple_logger.py log_once [line:28] INFO mean_valid_loss               0.5781\n",
            "2023-07-10 19:33:29,231 simple_logger.py log_once [line:28] INFO std_valid_loss                0.6364\n",
            "2023-07-10 19:33:29,235 fedbase.py run [line:251] INFO Eval Time Cost:               4.5417s\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "选择： [4, 7]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-07-10 19:33:33,857 fedbase.py run [line:246] INFO --------------Round 13--------------\n",
            "2023-07-10 19:33:33,858 simple_logger.py log_once [line:14] INFO Current_time:13\n",
            "2023-07-10 19:33:38,322 simple_logger.py log_once [line:28] INFO test_accuracy                 0.9463\n",
            "2023-07-10 19:33:38,323 simple_logger.py log_once [line:28] INFO test_loss                     0.1662\n",
            "2023-07-10 19:33:38,326 simple_logger.py log_once [line:28] INFO valid_accuracy                0.9404\n",
            "2023-07-10 19:33:38,331 simple_logger.py log_once [line:28] INFO mean_valid_accuracy           0.9408\n",
            "2023-07-10 19:33:38,334 simple_logger.py log_once [line:28] INFO std_valid_accuracy            0.0469\n",
            "2023-07-10 19:33:38,336 simple_logger.py log_once [line:28] INFO valid_loss                    0.1857\n",
            "2023-07-10 19:33:38,338 simple_logger.py log_once [line:28] INFO mean_valid_loss               0.1845\n",
            "2023-07-10 19:33:38,339 simple_logger.py log_once [line:28] INFO std_valid_loss                0.1451\n",
            "2023-07-10 19:33:38,343 fedbase.py run [line:251] INFO Eval Time Cost:               4.4850s\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "选择： [2, 5]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-07-10 19:33:41,790 fedbase.py run [line:246] INFO --------------Round 14--------------\n",
            "2023-07-10 19:33:41,791 simple_logger.py log_once [line:14] INFO Current_time:14\n",
            "2023-07-10 19:33:47,443 simple_logger.py log_once [line:28] INFO test_accuracy                 0.8979\n",
            "2023-07-10 19:33:47,445 simple_logger.py log_once [line:28] INFO test_loss                     0.2893\n",
            "2023-07-10 19:33:47,449 simple_logger.py log_once [line:28] INFO valid_accuracy                0.8999\n",
            "2023-07-10 19:33:47,451 simple_logger.py log_once [line:28] INFO mean_valid_accuracy           0.9011\n",
            "2023-07-10 19:33:47,453 simple_logger.py log_once [line:28] INFO std_valid_accuracy            0.0921\n",
            "2023-07-10 19:33:47,458 simple_logger.py log_once [line:28] INFO valid_loss                    0.2872\n",
            "2023-07-10 19:33:47,459 simple_logger.py log_once [line:28] INFO mean_valid_loss               0.2838\n",
            "2023-07-10 19:33:47,460 simple_logger.py log_once [line:28] INFO std_valid_loss                0.2651\n",
            "2023-07-10 19:33:47,462 fedbase.py run [line:251] INFO Eval Time Cost:               5.6703s\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "选择： [5, 0]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-07-10 19:33:50,905 fedbase.py run [line:246] INFO --------------Round 15--------------\n",
            "2023-07-10 19:33:50,906 simple_logger.py log_once [line:14] INFO Current_time:15\n",
            "2023-07-10 19:33:55,199 simple_logger.py log_once [line:28] INFO test_accuracy                 0.8436\n",
            "2023-07-10 19:33:55,200 simple_logger.py log_once [line:28] INFO test_loss                     0.4652\n",
            "2023-07-10 19:33:55,203 simple_logger.py log_once [line:28] INFO valid_accuracy                0.8417\n",
            "2023-07-10 19:33:55,204 simple_logger.py log_once [line:28] INFO mean_valid_accuracy           0.8431\n",
            "2023-07-10 19:33:55,206 simple_logger.py log_once [line:28] INFO std_valid_accuracy            0.1702\n",
            "2023-07-10 19:33:55,208 simple_logger.py log_once [line:28] INFO valid_loss                    0.4922\n",
            "2023-07-10 19:33:55,211 simple_logger.py log_once [line:28] INFO mean_valid_loss               0.4878\n",
            "2023-07-10 19:33:55,212 simple_logger.py log_once [line:28] INFO std_valid_loss                0.5277\n",
            "2023-07-10 19:33:55,213 fedbase.py run [line:251] INFO Eval Time Cost:               4.3065s\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "选择： [6, 1]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-07-10 19:33:59,869 fedbase.py run [line:246] INFO --------------Round 16--------------\n",
            "2023-07-10 19:33:59,872 simple_logger.py log_once [line:14] INFO Current_time:16\n",
            "2023-07-10 19:34:04,495 simple_logger.py log_once [line:28] INFO test_accuracy                 0.8301\n",
            "2023-07-10 19:34:04,498 simple_logger.py log_once [line:28] INFO test_loss                     0.4788\n",
            "2023-07-10 19:34:04,501 simple_logger.py log_once [line:28] INFO valid_accuracy                0.8176\n",
            "2023-07-10 19:34:04,502 simple_logger.py log_once [line:28] INFO mean_valid_accuracy           0.8178\n",
            "2023-07-10 19:34:04,504 simple_logger.py log_once [line:28] INFO std_valid_accuracy            0.1626\n",
            "2023-07-10 19:34:04,509 simple_logger.py log_once [line:28] INFO valid_loss                    0.5027\n",
            "2023-07-10 19:34:04,510 simple_logger.py log_once [line:28] INFO mean_valid_loss               0.5022\n",
            "2023-07-10 19:34:04,511 simple_logger.py log_once [line:28] INFO std_valid_loss                0.4434\n",
            "2023-07-10 19:34:04,512 fedbase.py run [line:251] INFO Eval Time Cost:               4.6400s\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "选择： [0, 9]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-07-10 19:34:07,994 fedbase.py run [line:246] INFO --------------Round 17--------------\n",
            "2023-07-10 19:34:07,996 simple_logger.py log_once [line:14] INFO Current_time:17\n",
            "2023-07-10 19:34:13,288 simple_logger.py log_once [line:28] INFO test_accuracy                 0.8946\n",
            "2023-07-10 19:34:13,290 simple_logger.py log_once [line:28] INFO test_loss                     0.3145\n",
            "2023-07-10 19:34:13,296 simple_logger.py log_once [line:28] INFO valid_accuracy                0.8889\n",
            "2023-07-10 19:34:13,298 simple_logger.py log_once [line:28] INFO mean_valid_accuracy           0.8897\n",
            "2023-07-10 19:34:13,303 simple_logger.py log_once [line:28] INFO std_valid_accuracy            0.1086\n",
            "2023-07-10 19:34:13,305 simple_logger.py log_once [line:28] INFO valid_loss                    0.3297\n",
            "2023-07-10 19:34:13,306 simple_logger.py log_once [line:28] INFO mean_valid_loss               0.3273\n",
            "2023-07-10 19:34:13,308 simple_logger.py log_once [line:28] INFO std_valid_loss                0.3099\n",
            "2023-07-10 19:34:13,309 fedbase.py run [line:251] INFO Eval Time Cost:               5.3127s\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "选择： [9, 8]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-07-10 19:34:17,001 fedbase.py run [line:246] INFO --------------Round 18--------------\n",
            "2023-07-10 19:34:17,003 simple_logger.py log_once [line:14] INFO Current_time:18\n",
            "2023-07-10 19:34:21,395 simple_logger.py log_once [line:28] INFO test_accuracy                 0.9427\n",
            "2023-07-10 19:34:21,397 simple_logger.py log_once [line:28] INFO test_loss                     0.1894\n",
            "2023-07-10 19:34:21,403 simple_logger.py log_once [line:28] INFO valid_accuracy                0.9416\n",
            "2023-07-10 19:34:21,406 simple_logger.py log_once [line:28] INFO mean_valid_accuracy           0.9417\n",
            "2023-07-10 19:34:21,410 simple_logger.py log_once [line:28] INFO std_valid_accuracy            0.0404\n",
            "2023-07-10 19:34:21,413 simple_logger.py log_once [line:28] INFO valid_loss                    0.1863\n",
            "2023-07-10 19:34:21,416 simple_logger.py log_once [line:28] INFO mean_valid_loss               0.1859\n",
            "2023-07-10 19:34:21,419 simple_logger.py log_once [line:28] INFO std_valid_loss                0.1225\n",
            "2023-07-10 19:34:21,421 fedbase.py run [line:251] INFO Eval Time Cost:               4.4188s\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "选择： [3, 0]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-07-10 19:34:25,188 fedbase.py run [line:246] INFO --------------Round 19--------------\n",
            "2023-07-10 19:34:25,191 simple_logger.py log_once [line:14] INFO Current_time:19\n",
            "2023-07-10 19:34:30,704 simple_logger.py log_once [line:28] INFO test_accuracy                 0.8815\n",
            "2023-07-10 19:34:30,705 simple_logger.py log_once [line:28] INFO test_loss                     0.3718\n",
            "2023-07-10 19:34:30,708 simple_logger.py log_once [line:28] INFO valid_accuracy                0.8783\n",
            "2023-07-10 19:34:30,712 simple_logger.py log_once [line:28] INFO mean_valid_accuracy           0.8777\n",
            "2023-07-10 19:34:30,714 simple_logger.py log_once [line:28] INFO std_valid_accuracy            0.2126\n",
            "2023-07-10 19:34:30,716 simple_logger.py log_once [line:28] INFO valid_loss                    0.3985\n",
            "2023-07-10 19:34:30,720 simple_logger.py log_once [line:28] INFO mean_valid_loss               0.4007\n",
            "2023-07-10 19:34:30,721 simple_logger.py log_once [line:28] INFO std_valid_loss                0.6694\n",
            "2023-07-10 19:34:30,722 fedbase.py run [line:251] INFO Eval Time Cost:               5.5309s\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "选择： [6, 4]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-07-10 19:34:34,246 fedbase.py run [line:246] INFO --------------Round 20--------------\n",
            "2023-07-10 19:34:34,247 simple_logger.py log_once [line:14] INFO Current_time:20\n",
            "2023-07-10 19:34:38,846 simple_logger.py log_once [line:28] INFO test_accuracy                 0.9183\n",
            "2023-07-10 19:34:38,849 simple_logger.py log_once [line:28] INFO test_loss                     0.2430\n",
            "2023-07-10 19:34:38,851 simple_logger.py log_once [line:28] INFO valid_accuracy                0.9123\n",
            "2023-07-10 19:34:38,853 simple_logger.py log_once [line:28] INFO mean_valid_accuracy           0.9120\n",
            "2023-07-10 19:34:38,854 simple_logger.py log_once [line:28] INFO std_valid_accuracy            0.0732\n",
            "2023-07-10 19:34:38,860 simple_logger.py log_once [line:28] INFO valid_loss                    0.2667\n",
            "2023-07-10 19:34:38,861 simple_logger.py log_once [line:28] INFO mean_valid_loss               0.2676\n",
            "2023-07-10 19:34:38,862 simple_logger.py log_once [line:28] INFO std_valid_loss                0.1899\n",
            "2023-07-10 19:34:38,863 fedbase.py run [line:251] INFO Eval Time Cost:               4.6161s\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "选择： [1, 4]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-07-10 19:34:43,363 fedbase.py run [line:246] INFO --------------Round 21--------------\n",
            "2023-07-10 19:34:43,365 simple_logger.py log_once [line:14] INFO Current_time:21\n",
            "2023-07-10 19:34:47,912 simple_logger.py log_once [line:28] INFO test_accuracy                 0.9162\n",
            "2023-07-10 19:34:47,913 simple_logger.py log_once [line:28] INFO test_loss                     0.2670\n",
            "2023-07-10 19:34:47,916 simple_logger.py log_once [line:28] INFO valid_accuracy                0.9104\n",
            "2023-07-10 19:34:47,921 simple_logger.py log_once [line:28] INFO mean_valid_accuracy           0.9103\n",
            "2023-07-10 19:34:47,924 simple_logger.py log_once [line:28] INFO std_valid_accuracy            0.0753\n",
            "2023-07-10 19:34:47,926 simple_logger.py log_once [line:28] INFO valid_loss                    0.2856\n",
            "2023-07-10 19:34:47,930 simple_logger.py log_once [line:28] INFO mean_valid_loss               0.2862\n",
            "2023-07-10 19:34:47,931 simple_logger.py log_once [line:28] INFO std_valid_loss                0.1975\n",
            "2023-07-10 19:34:47,932 fedbase.py run [line:251] INFO Eval Time Cost:               4.5671s\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "选择： [0, 9]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-07-10 19:34:51,534 fedbase.py run [line:246] INFO --------------Round 22--------------\n",
            "2023-07-10 19:34:51,535 simple_logger.py log_once [line:14] INFO Current_time:22\n",
            "2023-07-10 19:34:58,779 simple_logger.py log_once [line:28] INFO test_accuracy                 0.9498\n",
            "2023-07-10 19:34:58,781 simple_logger.py log_once [line:28] INFO test_loss                     0.1596\n",
            "2023-07-10 19:34:58,783 simple_logger.py log_once [line:28] INFO valid_accuracy                0.9448\n",
            "2023-07-10 19:34:58,785 simple_logger.py log_once [line:28] INFO mean_valid_accuracy           0.9451\n",
            "2023-07-10 19:34:58,787 simple_logger.py log_once [line:28] INFO std_valid_accuracy            0.0440\n",
            "2023-07-10 19:34:58,788 simple_logger.py log_once [line:28] INFO valid_loss                    0.1716\n",
            "2023-07-10 19:34:58,789 simple_logger.py log_once [line:28] INFO mean_valid_loss               0.1706\n",
            "2023-07-10 19:34:58,790 simple_logger.py log_once [line:28] INFO std_valid_loss                0.1214\n",
            "2023-07-10 19:34:58,796 fedbase.py run [line:251] INFO Eval Time Cost:               7.2603s\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "选择： [2, 6]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-07-10 19:35:02,401 fedbase.py run [line:246] INFO --------------Round 23--------------\n",
            "2023-07-10 19:35:02,402 simple_logger.py log_once [line:14] INFO Current_time:23\n",
            "2023-07-10 19:35:06,765 simple_logger.py log_once [line:28] INFO test_accuracy                 0.9369\n",
            "2023-07-10 19:35:06,768 simple_logger.py log_once [line:28] INFO test_loss                     0.1919\n",
            "2023-07-10 19:35:06,770 simple_logger.py log_once [line:28] INFO valid_accuracy                0.9341\n",
            "2023-07-10 19:35:06,772 simple_logger.py log_once [line:28] INFO mean_valid_accuracy           0.9342\n",
            "2023-07-10 19:35:06,774 simple_logger.py log_once [line:28] INFO std_valid_accuracy            0.0638\n",
            "2023-07-10 19:35:06,776 simple_logger.py log_once [line:28] INFO valid_loss                    0.2102\n",
            "2023-07-10 19:35:06,777 simple_logger.py log_once [line:28] INFO mean_valid_loss               0.2101\n",
            "2023-07-10 19:35:06,778 simple_logger.py log_once [line:28] INFO std_valid_loss                0.1951\n",
            "2023-07-10 19:35:06,779 fedbase.py run [line:251] INFO Eval Time Cost:               4.3764s\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "选择： [3, 5]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-07-10 19:35:11,522 fedbase.py run [line:246] INFO --------------Round 24--------------\n",
            "2023-07-10 19:35:11,523 simple_logger.py log_once [line:14] INFO Current_time:24\n",
            "2023-07-10 19:35:15,800 simple_logger.py log_once [line:28] INFO test_accuracy                 0.9619\n",
            "2023-07-10 19:35:15,801 simple_logger.py log_once [line:28] INFO test_loss                     0.1267\n",
            "2023-07-10 19:35:15,804 simple_logger.py log_once [line:28] INFO valid_accuracy                0.9613\n",
            "2023-07-10 19:35:15,806 simple_logger.py log_once [line:28] INFO mean_valid_accuracy           0.9614\n",
            "2023-07-10 19:35:15,809 simple_logger.py log_once [line:28] INFO std_valid_accuracy            0.0256\n",
            "2023-07-10 19:35:15,813 simple_logger.py log_once [line:28] INFO valid_loss                    0.1352\n",
            "2023-07-10 19:35:15,815 simple_logger.py log_once [line:28] INFO mean_valid_loss               0.1349\n",
            "2023-07-10 19:35:15,820 simple_logger.py log_once [line:28] INFO std_valid_loss                0.0759\n",
            "2023-07-10 19:35:15,820 fedbase.py run [line:251] INFO Eval Time Cost:               4.2973s\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "选择： [5, 1]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-07-10 19:35:19,270 fedbase.py run [line:246] INFO --------------Round 25--------------\n",
            "2023-07-10 19:35:19,272 simple_logger.py log_once [line:14] INFO Current_time:25\n",
            "2023-07-10 19:35:25,107 simple_logger.py log_once [line:28] INFO test_accuracy                 0.9023\n",
            "2023-07-10 19:35:25,108 simple_logger.py log_once [line:28] INFO test_loss                     0.2642\n",
            "2023-07-10 19:35:25,114 simple_logger.py log_once [line:28] INFO valid_accuracy                0.8954\n",
            "2023-07-10 19:35:25,118 simple_logger.py log_once [line:28] INFO mean_valid_accuracy           0.8963\n",
            "2023-07-10 19:35:25,120 simple_logger.py log_once [line:28] INFO std_valid_accuracy            0.1457\n",
            "2023-07-10 19:35:25,122 simple_logger.py log_once [line:28] INFO valid_loss                    0.2812\n",
            "2023-07-10 19:35:25,126 simple_logger.py log_once [line:28] INFO mean_valid_loss               0.2790\n",
            "2023-07-10 19:35:25,127 simple_logger.py log_once [line:28] INFO std_valid_loss                0.3572\n",
            "2023-07-10 19:35:25,130 fedbase.py run [line:251] INFO Eval Time Cost:               5.8580s\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "选择： [9, 7]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-07-10 19:35:28,579 fedbase.py run [line:246] INFO --------------Round 26--------------\n",
            "2023-07-10 19:35:28,581 simple_logger.py log_once [line:14] INFO Current_time:26\n",
            "2023-07-10 19:35:33,016 simple_logger.py log_once [line:28] INFO test_accuracy                 0.9110\n",
            "2023-07-10 19:35:33,018 simple_logger.py log_once [line:28] INFO test_loss                     0.2694\n",
            "2023-07-10 19:35:33,022 simple_logger.py log_once [line:28] INFO valid_accuracy                0.9056\n",
            "2023-07-10 19:35:33,024 simple_logger.py log_once [line:28] INFO mean_valid_accuracy           0.9065\n",
            "2023-07-10 19:35:33,026 simple_logger.py log_once [line:28] INFO std_valid_accuracy            0.0767\n",
            "2023-07-10 19:35:33,028 simple_logger.py log_once [line:28] INFO valid_loss                    0.2732\n",
            "2023-07-10 19:35:33,030 simple_logger.py log_once [line:28] INFO mean_valid_loss               0.2708\n",
            "2023-07-10 19:35:33,031 simple_logger.py log_once [line:28] INFO std_valid_loss                0.2065\n",
            "2023-07-10 19:35:33,032 fedbase.py run [line:251] INFO Eval Time Cost:               4.4511s\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "选择： [9, 8]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-07-10 19:35:37,746 fedbase.py run [line:246] INFO --------------Round 27--------------\n",
            "2023-07-10 19:35:37,749 simple_logger.py log_once [line:14] INFO Current_time:27\n",
            "2023-07-10 19:35:42,461 simple_logger.py log_once [line:28] INFO test_accuracy                 0.9565\n",
            "2023-07-10 19:35:42,462 simple_logger.py log_once [line:28] INFO test_loss                     0.1487\n",
            "2023-07-10 19:35:42,469 simple_logger.py log_once [line:28] INFO valid_accuracy                0.9523\n",
            "2023-07-10 19:35:42,470 simple_logger.py log_once [line:28] INFO mean_valid_accuracy           0.9524\n",
            "2023-07-10 19:35:42,475 simple_logger.py log_once [line:28] INFO std_valid_accuracy            0.0298\n",
            "2023-07-10 19:35:42,477 simple_logger.py log_once [line:28] INFO valid_loss                    0.1514\n",
            "2023-07-10 19:35:42,479 simple_logger.py log_once [line:28] INFO mean_valid_loss               0.1510\n",
            "2023-07-10 19:35:42,482 simple_logger.py log_once [line:28] INFO std_valid_loss                0.0946\n",
            "2023-07-10 19:35:42,485 fedbase.py run [line:251] INFO Eval Time Cost:               4.7360s\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "选择： [5, 9]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-07-10 19:35:45,845 fedbase.py run [line:246] INFO --------------Round 28--------------\n",
            "2023-07-10 19:35:45,847 simple_logger.py log_once [line:14] INFO Current_time:28\n",
            "2023-07-10 19:35:51,184 simple_logger.py log_once [line:28] INFO test_accuracy                 0.8533\n",
            "2023-07-10 19:35:51,187 simple_logger.py log_once [line:28] INFO test_loss                     0.4455\n",
            "2023-07-10 19:35:51,189 simple_logger.py log_once [line:28] INFO valid_accuracy                0.8443\n",
            "2023-07-10 19:35:51,192 simple_logger.py log_once [line:28] INFO mean_valid_accuracy           0.8451\n",
            "2023-07-10 19:35:51,195 simple_logger.py log_once [line:28] INFO std_valid_accuracy            0.1274\n",
            "2023-07-10 19:35:51,198 simple_logger.py log_once [line:28] INFO valid_loss                    0.4542\n",
            "2023-07-10 19:35:51,201 simple_logger.py log_once [line:28] INFO mean_valid_loss               0.4518\n",
            "2023-07-10 19:35:51,202 simple_logger.py log_once [line:28] INFO std_valid_loss                0.3898\n",
            "2023-07-10 19:35:51,205 fedbase.py run [line:251] INFO Eval Time Cost:               5.3578s\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "选择： [0, 1]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-07-10 19:35:54,919 fedbase.py run [line:246] INFO --------------Round 29--------------\n",
            "2023-07-10 19:35:54,920 simple_logger.py log_once [line:14] INFO Current_time:29\n",
            "2023-07-10 19:35:59,314 simple_logger.py log_once [line:28] INFO test_accuracy                 0.8722\n",
            "2023-07-10 19:35:59,316 simple_logger.py log_once [line:28] INFO test_loss                     0.3669\n",
            "2023-07-10 19:35:59,320 simple_logger.py log_once [line:28] INFO valid_accuracy                0.8685\n",
            "2023-07-10 19:35:59,324 simple_logger.py log_once [line:28] INFO mean_valid_accuracy           0.8690\n",
            "2023-07-10 19:35:59,325 simple_logger.py log_once [line:28] INFO std_valid_accuracy            0.1524\n",
            "2023-07-10 19:35:59,327 simple_logger.py log_once [line:28] INFO valid_loss                    0.3808\n",
            "2023-07-10 19:35:59,328 simple_logger.py log_once [line:28] INFO mean_valid_loss               0.3793\n",
            "2023-07-10 19:35:59,329 simple_logger.py log_once [line:28] INFO std_valid_loss                0.4118\n",
            "2023-07-10 19:35:59,330 fedbase.py run [line:251] INFO Eval Time Cost:               4.4101s\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "选择： [0, 3]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-07-10 19:36:03,039 fedbase.py run [line:246] INFO --------------Round 30--------------\n",
            "2023-07-10 19:36:03,044 simple_logger.py log_once [line:14] INFO Current_time:30\n",
            "2023-07-10 19:36:08,415 simple_logger.py log_once [line:28] INFO test_accuracy                 0.9075\n",
            "2023-07-10 19:36:08,416 simple_logger.py log_once [line:28] INFO test_loss                     0.2887\n",
            "2023-07-10 19:36:08,419 simple_logger.py log_once [line:28] INFO valid_accuracy                0.9014\n",
            "2023-07-10 19:36:08,421 simple_logger.py log_once [line:28] INFO mean_valid_accuracy           0.9008\n",
            "2023-07-10 19:36:08,423 simple_logger.py log_once [line:28] INFO std_valid_accuracy            0.1656\n",
            "2023-07-10 19:36:08,425 simple_logger.py log_once [line:28] INFO valid_loss                    0.3182\n",
            "2023-07-10 19:36:08,428 simple_logger.py log_once [line:28] INFO mean_valid_loss               0.3199\n",
            "2023-07-10 19:36:08,429 simple_logger.py log_once [line:28] INFO std_valid_loss                0.5288\n",
            "2023-07-10 19:36:08,430 fedbase.py run [line:251] INFO Eval Time Cost:               5.3854s\n",
            "2023-07-10 19:36:08,431 fedbase.py run [line:257] INFO =================End==================\n",
            "2023-07-10 19:36:08,432 fedbase.py run [line:258] INFO Total Time Cost:              266.8216s\n"
          ]
        }
      ],
      "source": [
        "import flgo\n",
        "import torch\n",
        "import flgo.algorithm.fedprox as fedprox\n",
        "import flgo.algorithm.fedavg as fedavg\n",
        "task = './mnist_dir10'\n",
        "config_dir10 = {'benchmark':{'name':'flgo.benchmark.mnist_classification'},'partitioner':{'name': 'DirichletPartitioner','para':{'num_clients':10, 'alpha':1.0}}}\n",
        "if not os.path.exists(task): flgo.gen_task(config_dir10, task_path = task)\n",
        "option = {'num_rounds':30, 'num_epochs':1, 'batch_size':64, 'learning_rate':0.1, 'gpu':0 if torch.cuda.is_available() else ''}\n",
        "runner = flgo.init(task, test2, option=option, model= model_DC)\n",
        "runner.model\n",
        "runner.run()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 314
        },
        "id": "9sIQuO_DBODI",
        "outputId": "96bc999d-6ffc-4408-cba9-76193ba4d944"
      },
      "outputs": [
        {
          "ename": "PicklingError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mPicklingError\u001b[0m                             Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-07ead7c38433>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrunner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'0.pth'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization)\u001b[0m\n\u001b[1;32m    439\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_use_new_zipfile_serialization\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0m_open_zipfile_writer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_zipfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 441\u001b[0;31m             \u001b[0m_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopened_zipfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_protocol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    442\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_save\u001b[0;34m(obj, zip_file, pickle_module, pickle_protocol)\u001b[0m\n\u001b[1;32m    651\u001b[0m     \u001b[0mpickler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPickler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpickle_protocol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    652\u001b[0m     \u001b[0mpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpersistent_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpersistent_id\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 653\u001b[0;31m     \u001b[0mpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    654\u001b[0m     \u001b[0mdata_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_buf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    655\u001b[0m     \u001b[0mzip_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite_record\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data.pkl'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mPicklingError\u001b[0m: args[0] from __newobj__ args has the wrong class"
          ]
        }
      ],
      "source": [
        "torch.save(runner.model.state_dict(),'0.pth')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cRXRm2A7uu2t"
      },
      "source": [
        "## 保存不同阶段的联邦分类模型"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IfNEIXpwu9C4",
        "outputId": "140d986b-0ffc-4e2b-82a9-b27a9e9a9a78"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "参数： Namespace(gan_type='GAN', dataset='mnist', split='', epoch=50, batch_size=64, input_size=28, save_dir='models', result_dir='results', log_dir='logs', lrG=0.0002, lrD=0.0002, beta1=0.5, beta2=0.999, gpu_mode=True, benchmark_mode=True)\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to /content/FLGo/flgo/benchmark/RAW_DATA/MNIST/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 9912422/9912422 [00:00<00:00, 76461500.01it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting /content/FLGo/flgo/benchmark/RAW_DATA/MNIST/MNIST/raw/train-images-idx3-ubyte.gz to /content/FLGo/flgo/benchmark/RAW_DATA/MNIST/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to /content/FLGo/flgo/benchmark/RAW_DATA/MNIST/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 28881/28881 [00:00<00:00, 83947119.77it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting /content/FLGo/flgo/benchmark/RAW_DATA/MNIST/MNIST/raw/train-labels-idx1-ubyte.gz to /content/FLGo/flgo/benchmark/RAW_DATA/MNIST/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to /content/FLGo/flgo/benchmark/RAW_DATA/MNIST/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1648877/1648877 [00:00<00:00, 26104007.75it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting /content/FLGo/flgo/benchmark/RAW_DATA/MNIST/MNIST/raw/t10k-images-idx3-ubyte.gz to /content/FLGo/flgo/benchmark/RAW_DATA/MNIST/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to /content/FLGo/flgo/benchmark/RAW_DATA/MNIST/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4542/4542 [00:00<00:00, 5089641.67it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting /content/FLGo/flgo/benchmark/RAW_DATA/MNIST/MNIST/raw/t10k-labels-idx1-ubyte.gz to /content/FLGo/flgo/benchmark/RAW_DATA/MNIST/MNIST/raw\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error: 0.02401501\n",
            "Error: 0.01364348\n",
            "Error: 0.00603127\n",
            "Error: 0.00467864\n",
            "Error: 0.00319496\n",
            "Error: 0.00162526\n",
            "Error: 0.00103384\n",
            "Error: 0.00090822\n",
            "Error: 0.00071784\n",
            "Error: 0.00068880\n",
            "Error: 0.00058186\n",
            "Error: 0.00051637\n",
            "Error: 0.00038528\n",
            "Error: 0.00028419\n",
            "Error: 0.00012981\n",
            "Error: 0.00007049\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-07-04 14:29:03,147 fflow.py init [line:441] INFO Initializing devices: cuda:0 will be used for this running.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Task ./mnist_dir10 has been successfully generated.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
            "  warnings.warn(warning.format(ret))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "---------- Networks architecture -------------\n",
            "generator(\n",
            "  (fc): Sequential(\n",
            "    (0): Linear(in_features=74, out_features=1024, bias=True)\n",
            "    (1): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU()\n",
            "    (3): Linear(in_features=1024, out_features=6272, bias=True)\n",
            "    (4): BatchNorm1d(6272, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU()\n",
            "  )\n",
            "  (deconv): Sequential(\n",
            "    (0): ConvTranspose2d(128, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU()\n",
            "    (3): ConvTranspose2d(64, 1, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
            "    (4): Tanh()\n",
            "  )\n",
            ")\n",
            "Total number of parameters: 6652481\n",
            "discriminator_pro(\n",
            "  (conv): Sequential(\n",
            "    (0): Conv2d(1, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
            "    (1): LeakyReLU(negative_slope=0.2)\n",
            "    (2): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
            "    (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (4): LeakyReLU(negative_slope=0.2)\n",
            "  )\n",
            "  (fc): Sequential(\n",
            "    (0): Linear(in_features=6272, out_features=1024, bias=True)\n",
            "    (1): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): LeakyReLU(negative_slope=0.2)\n",
            "    (3): Linear(in_features=1024, out_features=13, bias=True)\n",
            "  )\n",
            ")\n",
            "Total number of parameters: 6571469\n",
            "-----------------------------------------------\n",
            "client 0 总样本数： 5389  各类： [   0  352 2210    6   19  203   49    0    0 2550]\n",
            "---------- Networks architecture -------------\n",
            "generator(\n",
            "  (fc): Sequential(\n",
            "    (0): Linear(in_features=74, out_features=1024, bias=True)\n",
            "    (1): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU()\n",
            "    (3): Linear(in_features=1024, out_features=6272, bias=True)\n",
            "    (4): BatchNorm1d(6272, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU()\n",
            "  )\n",
            "  (deconv): Sequential(\n",
            "    (0): ConvTranspose2d(128, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU()\n",
            "    (3): ConvTranspose2d(64, 1, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
            "    (4): Tanh()\n",
            "  )\n",
            ")\n",
            "Total number of parameters: 6652481\n",
            "discriminator_pro(\n",
            "  (conv): Sequential(\n",
            "    (0): Conv2d(1, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
            "    (1): LeakyReLU(negative_slope=0.2)\n",
            "    (2): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
            "    (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (4): LeakyReLU(negative_slope=0.2)\n",
            "  )\n",
            "  (fc): Sequential(\n",
            "    (0): Linear(in_features=6272, out_features=1024, bias=True)\n",
            "    (1): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): LeakyReLU(negative_slope=0.2)\n",
            "    (3): Linear(in_features=1024, out_features=13, bias=True)\n",
            "  )\n",
            ")\n",
            "Total number of parameters: 6571469\n",
            "-----------------------------------------------\n",
            "client 1 总样本数： 5291  各类： [   0    1   89   59 4208  111  157    0   42  624]\n",
            "---------- Networks architecture -------------\n",
            "generator(\n",
            "  (fc): Sequential(\n",
            "    (0): Linear(in_features=74, out_features=1024, bias=True)\n",
            "    (1): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU()\n",
            "    (3): Linear(in_features=1024, out_features=6272, bias=True)\n",
            "    (4): BatchNorm1d(6272, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU()\n",
            "  )\n",
            "  (deconv): Sequential(\n",
            "    (0): ConvTranspose2d(128, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU()\n",
            "    (3): ConvTranspose2d(64, 1, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
            "    (4): Tanh()\n",
            "  )\n",
            ")\n",
            "Total number of parameters: 6652481\n",
            "discriminator_pro(\n",
            "  (conv): Sequential(\n",
            "    (0): Conv2d(1, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
            "    (1): LeakyReLU(negative_slope=0.2)\n",
            "    (2): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
            "    (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (4): LeakyReLU(negative_slope=0.2)\n",
            "  )\n",
            "  (fc): Sequential(\n",
            "    (0): Linear(in_features=6272, out_features=1024, bias=True)\n",
            "    (1): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): LeakyReLU(negative_slope=0.2)\n",
            "    (3): Linear(in_features=1024, out_features=13, bias=True)\n",
            "  )\n",
            ")\n",
            "Total number of parameters: 6571469\n",
            "-----------------------------------------------\n",
            "client 2 总样本数： 5342  各类： [   0 1889    0  342  402    1 2152  552    3    1]\n",
            "---------- Networks architecture -------------\n",
            "generator(\n",
            "  (fc): Sequential(\n",
            "    (0): Linear(in_features=74, out_features=1024, bias=True)\n",
            "    (1): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU()\n",
            "    (3): Linear(in_features=1024, out_features=6272, bias=True)\n",
            "    (4): BatchNorm1d(6272, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU()\n",
            "  )\n",
            "  (deconv): Sequential(\n",
            "    (0): ConvTranspose2d(128, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU()\n",
            "    (3): ConvTranspose2d(64, 1, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
            "    (4): Tanh()\n",
            "  )\n",
            ")\n",
            "Total number of parameters: 6652481\n",
            "discriminator_pro(\n",
            "  (conv): Sequential(\n",
            "    (0): Conv2d(1, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
            "    (1): LeakyReLU(negative_slope=0.2)\n",
            "    (2): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
            "    (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (4): LeakyReLU(negative_slope=0.2)\n",
            "  )\n",
            "  (fc): Sequential(\n",
            "    (0): Linear(in_features=6272, out_features=1024, bias=True)\n",
            "    (1): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): LeakyReLU(negative_slope=0.2)\n",
            "    (3): Linear(in_features=1024, out_features=13, bias=True)\n",
            "  )\n",
            ")\n",
            "Total number of parameters: 6571469\n",
            "-----------------------------------------------\n",
            "client 3 总样本数： 5470  各类： [   0    0  501  158    1    0   26 4518  266    0]\n",
            "---------- Networks architecture -------------\n",
            "generator(\n",
            "  (fc): Sequential(\n",
            "    (0): Linear(in_features=74, out_features=1024, bias=True)\n",
            "    (1): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU()\n",
            "    (3): Linear(in_features=1024, out_features=6272, bias=True)\n",
            "    (4): BatchNorm1d(6272, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU()\n",
            "  )\n",
            "  (deconv): Sequential(\n",
            "    (0): ConvTranspose2d(128, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU()\n",
            "    (3): ConvTranspose2d(64, 1, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
            "    (4): Tanh()\n",
            "  )\n",
            ")\n",
            "Total number of parameters: 6652481\n",
            "discriminator_pro(\n",
            "  (conv): Sequential(\n",
            "    (0): Conv2d(1, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
            "    (1): LeakyReLU(negative_slope=0.2)\n",
            "    (2): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
            "    (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (4): LeakyReLU(negative_slope=0.2)\n",
            "  )\n",
            "  (fc): Sequential(\n",
            "    (0): Linear(in_features=6272, out_features=1024, bias=True)\n",
            "    (1): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): LeakyReLU(negative_slope=0.2)\n",
            "    (3): Linear(in_features=1024, out_features=13, bias=True)\n",
            "  )\n",
            ")\n",
            "Total number of parameters: 6571469\n",
            "-----------------------------------------------\n",
            "client 4 总样本数： 5474  各类： [  27    0 2198    0   94 1443    0  469    0 1243]\n",
            "---------- Networks architecture -------------\n",
            "generator(\n",
            "  (fc): Sequential(\n",
            "    (0): Linear(in_features=74, out_features=1024, bias=True)\n",
            "    (1): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU()\n",
            "    (3): Linear(in_features=1024, out_features=6272, bias=True)\n",
            "    (4): BatchNorm1d(6272, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU()\n",
            "  )\n",
            "  (deconv): Sequential(\n",
            "    (0): ConvTranspose2d(128, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU()\n",
            "    (3): ConvTranspose2d(64, 1, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
            "    (4): Tanh()\n",
            "  )\n",
            ")\n",
            "Total number of parameters: 6652481\n",
            "discriminator_pro(\n",
            "  (conv): Sequential(\n",
            "    (0): Conv2d(1, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
            "    (1): LeakyReLU(negative_slope=0.2)\n",
            "    (2): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
            "    (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (4): LeakyReLU(negative_slope=0.2)\n",
            "  )\n",
            "  (fc): Sequential(\n",
            "    (0): Linear(in_features=6272, out_features=1024, bias=True)\n",
            "    (1): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): LeakyReLU(negative_slope=0.2)\n",
            "    (3): Linear(in_features=1024, out_features=13, bias=True)\n",
            "  )\n",
            ")\n",
            "Total number of parameters: 6571469\n",
            "-----------------------------------------------\n",
            "client 5 总样本数： 5355  各类： [4917    0    0   76    0    3    0    0    0  359]\n",
            "---------- Networks architecture -------------\n",
            "generator(\n",
            "  (fc): Sequential(\n",
            "    (0): Linear(in_features=74, out_features=1024, bias=True)\n",
            "    (1): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU()\n",
            "    (3): Linear(in_features=1024, out_features=6272, bias=True)\n",
            "    (4): BatchNorm1d(6272, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU()\n",
            "  )\n",
            "  (deconv): Sequential(\n",
            "    (0): ConvTranspose2d(128, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU()\n",
            "    (3): ConvTranspose2d(64, 1, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
            "    (4): Tanh()\n",
            "  )\n",
            ")\n",
            "Total number of parameters: 6652481\n",
            "discriminator_pro(\n",
            "  (conv): Sequential(\n",
            "    (0): Conv2d(1, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
            "    (1): LeakyReLU(negative_slope=0.2)\n",
            "    (2): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
            "    (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (4): LeakyReLU(negative_slope=0.2)\n",
            "  )\n",
            "  (fc): Sequential(\n",
            "    (0): Linear(in_features=6272, out_features=1024, bias=True)\n",
            "    (1): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): LeakyReLU(negative_slope=0.2)\n",
            "    (3): Linear(in_features=1024, out_features=13, bias=True)\n",
            "  )\n",
            ")\n",
            "Total number of parameters: 6571469\n",
            "-----------------------------------------------\n",
            "client 6 总样本数： 5526  各类： [   2    0    0    0  498    9  760    0 3683  574]\n",
            "---------- Networks architecture -------------\n",
            "generator(\n",
            "  (fc): Sequential(\n",
            "    (0): Linear(in_features=74, out_features=1024, bias=True)\n",
            "    (1): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU()\n",
            "    (3): Linear(in_features=1024, out_features=6272, bias=True)\n",
            "    (4): BatchNorm1d(6272, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU()\n",
            "  )\n",
            "  (deconv): Sequential(\n",
            "    (0): ConvTranspose2d(128, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU()\n",
            "    (3): ConvTranspose2d(64, 1, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
            "    (4): Tanh()\n",
            "  )\n",
            ")\n",
            "Total number of parameters: 6652481\n",
            "discriminator_pro(\n",
            "  (conv): Sequential(\n",
            "    (0): Conv2d(1, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
            "    (1): LeakyReLU(negative_slope=0.2)\n",
            "    (2): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
            "    (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (4): LeakyReLU(negative_slope=0.2)\n",
            "  )\n",
            "  (fc): Sequential(\n",
            "    (0): Linear(in_features=6272, out_features=1024, bias=True)\n",
            "    (1): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): LeakyReLU(negative_slope=0.2)\n",
            "    (3): Linear(in_features=1024, out_features=13, bias=True)\n",
            "  )\n",
            ")\n",
            "Total number of parameters: 6571469\n",
            "-----------------------------------------------\n",
            "client 7 总样本数： 5309  各类： [  28 2880    0  169    7   11 2154   60    0    0]\n",
            "---------- Networks architecture -------------\n",
            "generator(\n",
            "  (fc): Sequential(\n",
            "    (0): Linear(in_features=74, out_features=1024, bias=True)\n",
            "    (1): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU()\n",
            "    (3): Linear(in_features=1024, out_features=6272, bias=True)\n",
            "    (4): BatchNorm1d(6272, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU()\n",
            "  )\n",
            "  (deconv): Sequential(\n",
            "    (0): ConvTranspose2d(128, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU()\n",
            "    (3): ConvTranspose2d(64, 1, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
            "    (4): Tanh()\n",
            "  )\n",
            ")\n",
            "Total number of parameters: 6652481\n",
            "discriminator_pro(\n",
            "  (conv): Sequential(\n",
            "    (0): Conv2d(1, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
            "    (1): LeakyReLU(negative_slope=0.2)\n",
            "    (2): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
            "    (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (4): LeakyReLU(negative_slope=0.2)\n",
            "  )\n",
            "  (fc): Sequential(\n",
            "    (0): Linear(in_features=6272, out_features=1024, bias=True)\n",
            "    (1): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): LeakyReLU(negative_slope=0.2)\n",
            "    (3): Linear(in_features=1024, out_features=13, bias=True)\n",
            "  )\n",
            ")\n",
            "Total number of parameters: 6571469\n",
            "-----------------------------------------------\n",
            "client 8 总样本数： 5493  各类： [   0  902  242   42    2 3102    0    0 1203    0]\n",
            "---------- Networks architecture -------------\n",
            "generator(\n",
            "  (fc): Sequential(\n",
            "    (0): Linear(in_features=74, out_features=1024, bias=True)\n",
            "    (1): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU()\n",
            "    (3): Linear(in_features=1024, out_features=6272, bias=True)\n",
            "    (4): BatchNorm1d(6272, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU()\n",
            "  )\n",
            "  (deconv): Sequential(\n",
            "    (0): ConvTranspose2d(128, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU()\n",
            "    (3): ConvTranspose2d(64, 1, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
            "    (4): Tanh()\n",
            "  )\n",
            ")\n",
            "Total number of parameters: 6652481\n",
            "discriminator_pro(\n",
            "  (conv): Sequential(\n",
            "    (0): Conv2d(1, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
            "    (1): LeakyReLU(negative_slope=0.2)\n",
            "    (2): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
            "    (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (4): LeakyReLU(negative_slope=0.2)\n",
            "  )\n",
            "  (fc): Sequential(\n",
            "    (0): Linear(in_features=6272, out_features=1024, bias=True)\n",
            "    (1): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): LeakyReLU(negative_slope=0.2)\n",
            "    (3): Linear(in_features=1024, out_features=13, bias=True)\n",
            "  )\n",
            ")\n",
            "Total number of parameters: 6571469\n",
            "-----------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-07-04 14:29:27,737 fflow.py init [line:479] INFO Use `<class 'flgo.simulator.default_simulator.Simulator'>` as the system simulator\n",
            "2023-07-04 14:29:27,738 fflow.py init [line:487] INFO Ready to start.\n",
            "2023-07-04 14:29:27,745 fedbase.py run [line:236] INFO --------------Initial Evaluation--------------\n",
            "2023-07-04 14:29:27,748 simple_logger.py log_once [line:14] INFO Current_time:0\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "client 9 总样本数： 5357  各类： [ 366   24  126 4658   24    1   13   41   75   29]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-07-04 14:29:40,571 simple_logger.py log_once [line:28] INFO test_accuracy                 0.0697\n",
            "2023-07-04 14:29:40,572 simple_logger.py log_once [line:28] INFO test_loss                     2.3036\n",
            "2023-07-04 14:29:40,580 simple_logger.py log_once [line:28] INFO valid_accuracy                0.0686\n",
            "2023-07-04 14:29:40,581 simple_logger.py log_once [line:28] INFO mean_valid_accuracy           0.0684\n",
            "2023-07-04 14:29:40,583 simple_logger.py log_once [line:28] INFO std_valid_accuracy            0.0400\n",
            "2023-07-04 14:29:40,587 simple_logger.py log_once [line:28] INFO valid_loss                    2.3037\n",
            "2023-07-04 14:29:40,588 simple_logger.py log_once [line:28] INFO mean_valid_loss               2.3037\n",
            "2023-07-04 14:29:40,590 simple_logger.py log_once [line:28] INFO std_valid_loss                0.0061\n",
            "2023-07-04 14:29:40,592 fedbase.py run [line:239] INFO Eval Time Cost:               12.8442s\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "round: 1 Online: [0, 1, 3, 4, 5, 6, 7, 8, 9]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-07-04 14:30:13,678 fedbase.py run [line:246] INFO --------------Round 1--------------\n",
            "2023-07-04 14:30:13,680 simple_logger.py log_once [line:14] INFO Current_time:1\n",
            "2023-07-04 14:30:19,510 simple_logger.py log_once [line:28] INFO test_accuracy                 0.2144\n",
            "2023-07-04 14:30:19,511 simple_logger.py log_once [line:28] INFO test_loss                     2.2356\n",
            "2023-07-04 14:30:19,514 simple_logger.py log_once [line:28] INFO valid_accuracy                0.2133\n",
            "2023-07-04 14:30:19,516 simple_logger.py log_once [line:28] INFO mean_valid_accuracy           0.2118\n",
            "2023-07-04 14:30:19,518 simple_logger.py log_once [line:28] INFO std_valid_accuracy            0.2251\n",
            "2023-07-04 14:30:19,520 simple_logger.py log_once [line:28] INFO valid_loss                    2.2369\n",
            "2023-07-04 14:30:19,522 simple_logger.py log_once [line:28] INFO mean_valid_loss               2.2376\n",
            "2023-07-04 14:30:19,523 simple_logger.py log_once [line:28] INFO std_valid_loss                0.0984\n",
            "2023-07-04 14:30:19,524 fedbase.py run [line:251] INFO Eval Time Cost:               5.8440s\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "round: 2 Online: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "save: 2\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-07-04 14:30:56,404 fedbase.py run [line:246] INFO --------------Round 2--------------\n",
            "2023-07-04 14:30:56,407 simple_logger.py log_once [line:14] INFO Current_time:2\n",
            "2023-07-04 14:31:02,274 simple_logger.py log_once [line:28] INFO test_accuracy                 0.5227\n",
            "2023-07-04 14:31:02,276 simple_logger.py log_once [line:28] INFO test_loss                     1.5346\n",
            "2023-07-04 14:31:02,281 simple_logger.py log_once [line:28] INFO valid_accuracy                0.5238\n",
            "2023-07-04 14:31:02,286 simple_logger.py log_once [line:28] INFO mean_valid_accuracy           0.5234\n",
            "2023-07-04 14:31:02,290 simple_logger.py log_once [line:28] INFO std_valid_accuracy            0.1969\n",
            "2023-07-04 14:31:02,295 simple_logger.py log_once [line:28] INFO valid_loss                    1.5456\n",
            "2023-07-04 14:31:02,298 simple_logger.py log_once [line:28] INFO mean_valid_loss               1.5462\n",
            "2023-07-04 14:31:02,301 simple_logger.py log_once [line:28] INFO std_valid_loss                0.2270\n",
            "2023-07-04 14:31:02,305 fedbase.py run [line:251] INFO Eval Time Cost:               5.8980s\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "round: 3 Online: [0, 1, 3, 4, 5, 6, 7, 8, 9]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-07-04 14:31:33,043 fedbase.py run [line:246] INFO --------------Round 3--------------\n",
            "2023-07-04 14:31:33,044 simple_logger.py log_once [line:14] INFO Current_time:3\n",
            "2023-07-04 14:31:37,615 simple_logger.py log_once [line:28] INFO test_accuracy                 0.7261\n",
            "2023-07-04 14:31:37,617 simple_logger.py log_once [line:28] INFO test_loss                     0.8777\n",
            "2023-07-04 14:31:37,621 simple_logger.py log_once [line:28] INFO valid_accuracy                0.7164\n",
            "2023-07-04 14:31:37,622 simple_logger.py log_once [line:28] INFO mean_valid_accuracy           0.7166\n",
            "2023-07-04 14:31:37,628 simple_logger.py log_once [line:28] INFO std_valid_accuracy            0.1354\n",
            "2023-07-04 14:31:37,630 simple_logger.py log_once [line:28] INFO valid_loss                    0.8990\n",
            "2023-07-04 14:31:37,631 simple_logger.py log_once [line:28] INFO mean_valid_loss               0.8982\n",
            "2023-07-04 14:31:37,633 simple_logger.py log_once [line:28] INFO std_valid_loss                0.2525\n",
            "2023-07-04 14:31:37,634 fedbase.py run [line:251] INFO Eval Time Cost:               4.5901s\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "round: 4 Online: [0, 1, 3, 4, 5, 6, 7, 8, 9]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-07-04 14:32:10,416 fedbase.py run [line:246] INFO --------------Round 4--------------\n",
            "2023-07-04 14:32:10,418 simple_logger.py log_once [line:14] INFO Current_time:4\n",
            "2023-07-04 14:32:14,885 simple_logger.py log_once [line:28] INFO test_accuracy                 0.7709\n",
            "2023-07-04 14:32:14,887 simple_logger.py log_once [line:28] INFO test_loss                     0.5996\n",
            "2023-07-04 14:32:14,891 simple_logger.py log_once [line:28] INFO valid_accuracy                0.7631\n",
            "2023-07-04 14:32:14,895 simple_logger.py log_once [line:28] INFO mean_valid_accuracy           0.7633\n",
            "2023-07-04 14:32:14,899 simple_logger.py log_once [line:28] INFO std_valid_accuracy            0.1347\n",
            "2023-07-04 14:32:14,901 simple_logger.py log_once [line:28] INFO valid_loss                    0.6283\n",
            "2023-07-04 14:32:14,904 simple_logger.py log_once [line:28] INFO mean_valid_loss               0.6279\n",
            "2023-07-04 14:32:14,905 simple_logger.py log_once [line:28] INFO std_valid_loss                0.2775\n",
            "2023-07-04 14:32:14,906 fedbase.py run [line:251] INFO Eval Time Cost:               4.4877s\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "round: 5 Online: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "save: 2\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-07-04 14:32:48,838 fedbase.py run [line:246] INFO --------------Round 5--------------\n",
            "2023-07-04 14:32:48,840 simple_logger.py log_once [line:14] INFO Current_time:5\n",
            "2023-07-04 14:32:54,352 simple_logger.py log_once [line:28] INFO test_accuracy                 0.8632\n",
            "2023-07-04 14:32:54,354 simple_logger.py log_once [line:28] INFO test_loss                     0.4013\n",
            "2023-07-04 14:32:54,358 simple_logger.py log_once [line:28] INFO valid_accuracy                0.8542\n",
            "2023-07-04 14:32:54,362 simple_logger.py log_once [line:28] INFO mean_valid_accuracy           0.8545\n",
            "2023-07-04 14:32:54,365 simple_logger.py log_once [line:28] INFO std_valid_accuracy            0.0748\n",
            "2023-07-04 14:32:54,368 simple_logger.py log_once [line:28] INFO valid_loss                    0.4330\n",
            "2023-07-04 14:32:54,370 simple_logger.py log_once [line:28] INFO mean_valid_loss               0.4324\n",
            "2023-07-04 14:32:54,371 simple_logger.py log_once [line:28] INFO std_valid_loss                0.1713\n",
            "2023-07-04 14:32:54,373 fedbase.py run [line:251] INFO Eval Time Cost:               5.5330s\n",
            "2023-07-04 14:32:54,374 fedbase.py run [line:257] INFO =================End==================\n",
            "2023-07-04 14:32:54,376 fedbase.py run [line:258] INFO Total Time Cost:              206.6305s\n"
          ]
        }
      ],
      "source": [
        "from flgo.algorithm.fedbase import BasicServer, BasicClient\n",
        "os.chdir('/content/GAN')\n",
        "#from infoGAN import infoGAN\n",
        "os.chdir(BASEPATH)\n",
        "import copy\n",
        "from flgo.utils import fmodule\n",
        "import flgo\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "D=3\n",
        "\n",
        "class Server(BasicServer):\n",
        "  def sample(self):\n",
        "    available_clients = [cid for cid in range(self.num_clients) if (self.current_round+1)%self.clients[cid].delay==0]\n",
        "    print('round:',self.current_round,'Online:',available_clients)\n",
        "    return available_clients\n",
        "class Client(BasicClient):\n",
        "  def initialize(self, *args, **kwargs):\n",
        "    self.train_data=new_normalize(self.train_data,mean=0.5,std=0.5)\n",
        "    if self.id==2:\n",
        "      self.delay=D #慢客户端\n",
        "    else:\n",
        "      self.delay=1 #快客户端\n",
        "\n",
        "    current_steps = self.current_steps\n",
        "    data_shape = self.get_batch_data()[0].shape[1]\n",
        "    self.current_steps = current_steps\n",
        "\n",
        "    print(data_shape)\n",
        "    print(self.ba)\n",
        "\n",
        "    gan_args.task = self.option['task'].replace('/','').replace('.','')\n",
        "    self.gan = my_ACGAN(gan_args,data_shape,name='client '+str(self.id))\n",
        "    self.I=1\n",
        "    self.C=self.get_loc_data()\n",
        "  def reply(self, svr_pkg):\n",
        "    model = self.unpack(svr_pkg) #svr_pkg (dict): the package received from the server\n",
        "    if self.delay==D:\n",
        "      print(\"save:\",self.id)\n",
        "      torch.save(model.state_dict(),task+'/'+str(self.I)+'.pth')\n",
        "      self.I+=1\n",
        "    self.train(model)\n",
        "    cpkg = self.pack(model)\n",
        "    return cpkg #client_pkg (dict): the package to be send to the server\n",
        "  def get_loc_data(self):\n",
        "    date_num=len(self.train_data.indices)\n",
        "    data_loader = self.calculator.get_dataloader(self.train_data, batch_size=date_num)\n",
        "    y_ = data_loader.__iter__().__next__()[1]\n",
        "    y_vec_ = torch.zeros((y_.shape[0], 10)).scatter_(1, y_.type(torch.LongTensor).unsqueeze(1), 1)\n",
        "    c = y_vec_.sum(0)\n",
        "    print(\"client\",self.id,\"总样本数：\",date_num,\" 各类：\", c.int().numpy())\n",
        "    return c\n",
        "class test:\n",
        "    Server=Server\n",
        "    Client=Client\n",
        "\n",
        "\n",
        "gan_args=parse_args()\n",
        "gan_args.gpu_mode=torch.cuda.is_available()\n",
        "gan_args.epoch=50\n",
        "#gan_args.lrD=0.0003\n",
        "#gan_args.lrG=0.0004\n",
        "#gan_args.batch_size=10\n",
        "print('参数：',gan_args)\n",
        "\n",
        "\n",
        "#task = './mnist_iid'\n",
        "#config_iid = {'benchmark':{'name':'flgo.benchmark.mnist_classification'},'partitioner':{'name': 'IIDPartitioner','para':{'num_clients':10}}}\n",
        "#task = './mnist_dir01'\n",
        "#config_dir01 = {'benchmark':{'name':'flgo.benchmark.mnist_classification'},'partitioner':{'name': 'DirichletPartitioner','para':{'num_clients':10, 'alpha':0.1}}}\n",
        "task = './mnist_dir10'\n",
        "config_dir10 = {'benchmark':{'name':'flgo.benchmark.mnist_classification'},'partitioner':{'name': 'DirichletPartitioner','para':{'num_clients':10, 'alpha':1.0}}}\n",
        "\n",
        "if not os.path.exists(task): flgo.gen_task(config_dir10, task_path = task)\n",
        "option = {'num_rounds':D*2-1, 'num_epochs':1, 'batch_size':8, 'learning_rate':0.1, 'gpu':0 if torch.cuda.is_available() else ''}\n",
        "runner = flgo.init(task, test, option=option, model=model_DC)\n",
        "runner.run()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ugIISxvdvj5i",
        "outputId": "dd1518cc-e1d1-4c56-a5d9-154f897a006c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "results/mnist_dir10/client 2/round0\n",
            "client 2 : training start!!\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-32-ea84f3a57de6>:298: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  global_loss.append((F.softmax(global_model(x_))*y_vec_).sum(-1).mean().item())\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: [ 1] [  83/  83]     D1: -1.38|-0.74|0.10|-0.05     0.94\n",
            "C_logic2    [0.99995625 0.         0.9992508  0.9999873  0.9999537  0.99978244\n",
            " 0.         0.9998814  0.99923164 0.99934226]\n",
            "C_logic    [0.95560795 0.         0.99696416 0.9995505  0.9964721  0.98184764\n",
            " 0.         0.9062098  0.95585895 0.98747075]\n",
            "C_pre_loss  [0.04704363 0.         0.0030573  0.00044958 0.00353474 0.01944183\n",
            " 0.         0.10371181 0.04655043 0.01267479]\n",
            "alpha     [0.03681285 0.         0.02       0.02       0.02       0.02893191\n",
            " 0.         0.08798362 0.03597229 0.02      ]\n",
            "=================================================================   \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: [ 2] [  83/  83]     D1: -1.34|-0.73|0.13|-0.08     0.94\n",
            "C_logic2    [0.9984988  0.9986975  0.99992007 0.9999698  0.99517095 0.9999966\n",
            " 0.         0.         0.99964696 0.999654  ]\n",
            "C_logic    [0.9682259  0.98718715 0.9929202  0.99901813 0.99763715 0.99746644\n",
            " 0.         0.         0.9685783  0.9795578 ]\n",
            "C_pre_loss  [0.03265549 0.01289564 0.00722339 0.00098251 0.00236833 0.00253818\n",
            " 0.         0.         0.0323401  0.02094574]\n",
            "alpha     [0.0243475  0.02       0.02       0.02       0.02       0.02\n",
            " 0.         0.         0.02483059 0.02186259]\n",
            "=================================================================   \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: [ 3] [  83/  83]     D1: -1.41|-0.74|0.07|-0.06     0.94\n",
            "C_logic2    [0.9991507  0.         0.9998783  0.9999995  0.99983686 0.9999275\n",
            " 0.         0.         0.9998991  0.9999326 ]\n",
            "C_logic    [0.9709723  0.         0.9955534  0.99976796 0.9967184  0.9963391\n",
            " 0.         0.         0.9750059  0.97441214]\n",
            "C_pre_loss  [0.03018328 0.         0.00448131 0.00023207 0.00329557 0.00367102\n",
            " 0.         0.         0.02570111 0.02621746]\n",
            "alpha     [0.02749518 0.         0.02       0.02       0.02       0.02\n",
            " 0.         0.         0.02390497 0.02124926]\n",
            "=================================================================   \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: [ 4] [  83/  83]     D1: -1.40|-0.75|0.09|-0.05     0.94\n",
            "C_logic2    [0.99962157 0.         0.9999139  0.9988145  0.99999315 0.99995804\n",
            " 0.         0.         0.99992347 0.9997389 ]\n",
            "C_logic    [0.9646901  0.         0.9926875  0.996893   0.99968356 0.99764377\n",
            " 0.         0.         0.9654826  0.9777174 ]\n",
            "C_pre_loss  [0.03636886 0.         0.00740418 0.00311618 0.00031648 0.00235964\n",
            " 0.         0.         0.036135   0.02278402]\n",
            "alpha     [0.02537082 0.         0.02       0.02       0.02       0.02\n",
            " 0.         0.         0.03037034 0.02156058]\n",
            "=================================================================   \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: [ 5] [  83/  83]     D1: -1.39|-0.74|0.10|-0.08     0.94\n",
            "C_logic2    [0.9997887  0.99730396 0.9999902  0.9999992  0.9993683  0.99952143\n",
            " 0.         0.9997363  0.9997974  0.9996336 ]\n",
            "C_logic    [0.9896889  0.9844005  0.99561614 0.99966854 0.9951643  0.99061346\n",
            " 0.         0.96279347 0.98037267 0.97344065]\n",
            "C_pre_loss  [0.01038707 0.01574565 0.0044437  0.00033157 0.00485901 0.00945734\n",
            " 0.         0.0380935  0.01989047 0.02789031]\n",
            "alpha     [0.02       0.02       0.02       0.02       0.02       0.02\n",
            " 0.         0.02       0.02       0.03015338]\n",
            "=================================================================   \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: [ 6] [  83/  83]     D1: -1.30|-0.70|0.10|-0.14     0.94\n",
            "C_logic2    [0.99914056 0.         0.99980575 0.         0.9999989  0.99689543\n",
            " 0.         0.99778163 0.9999954  0.99998295]\n",
            "C_logic    [0.97805685 0.         0.99630946 0.         0.9996069  0.98335594\n",
            " 0.         0.9965575  0.9891165  0.9897713 ]\n",
            "C_pre_loss  [0.02249448 0.         0.00371228 0.         0.00039319 0.01699125\n",
            " 0.         0.00344883 0.0109971  0.01037748]\n",
            "alpha     [0.02164683 0.         0.02       0.         0.02       0.02103447\n",
            " 0.         0.02       0.02       0.02      ]\n",
            "=================================================================   \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: [ 7] [  83/  83]     D1: -1.38|-0.74|0.11|-0.06     0.94\n",
            "C_logic2    [0.99992925 0.         0.9999644  1.         0.99999994 0.99975836\n",
            " 0.99662966 0.         0.99951714 0.99985343]\n",
            "C_logic    [0.97906744 0.         0.99917686 0.9998771  0.9997906  0.9816665\n",
            " 0.9987204  0.         0.97635263 0.97077143]\n",
            "C_pre_loss  [0.02127337 0.         0.000824   0.0001229  0.00020942 0.01876218\n",
            " 0.00128044 0.         0.02405314 0.03032753]\n",
            "alpha     [0.02       0.         0.02       0.02       0.02       0.02202942\n",
            " 0.02       0.         0.02060445 0.02719492]\n",
            "=================================================================   \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: [ 8] [  83/  83]     D1: -1.26|-0.74|0.20|-0.09     0.94\n",
            "C_logic2    [0.99998075 0.         0.9995644  0.9997089  0.9970062  0.99846995\n",
            " 0.99967086 0.         0.99947375 0.99998385]\n",
            "C_logic    [0.9829173  0.         0.99543417 0.98731494 0.9733912  0.9911361\n",
            " 0.9990717  0.         0.98203385 0.9934783 ]\n",
            "C_pre_loss  [0.0173063  0.         0.00459032 0.01279642 0.02753958 0.00893841\n",
            " 0.00092869 0.         0.01838169 0.00656393]\n",
            "alpha     [0.02       0.         0.02       0.02       0.02611348 0.02\n",
            " 0.02       0.         0.02254793 0.02      ]\n",
            "=================================================================   \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: [ 9] [  83/  83]     D1: -1.45|-0.76|0.07|-0.04     0.94\n",
            "C_logic2    [0.9998507  0.         0.9996856  0.99999994 0.9998944  0.99976426\n",
            " 0.99817395 0.         0.9999713  0.9987194 ]\n",
            "C_logic    [0.97240996 0.         0.997097   0.9998676  0.9947102  0.9860869\n",
            " 0.9996805  0.         0.9837056  0.97813404]\n",
            "C_pre_loss  [0.02839831 0.         0.00291308 0.00013237 0.00530384 0.01411248\n",
            " 0.00031955 0.         0.01652151 0.02260032]\n",
            "alpha     [0.02422801 0.         0.02       0.02       0.02       0.02\n",
            " 0.02       0.         0.02       0.02503813]\n",
            "=================================================================   \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: [10] [  83/  83]     D1: -1.45|-0.77|0.08|-0.04     0.94\n",
            "C_logic2    [0.9999645  0.9973272  0.99990183 0.9999847  0.99993885 0.99936235\n",
            " 0.         0.99999917 0.99997383 0.99988467]\n",
            "C_logic    [0.9874115  0.98837984 0.9964997  0.99772334 0.9540515  0.988449\n",
            " 0.         0.9979937  0.9865386  0.97990555]\n",
            "C_pre_loss  [0.01272443 0.0116882  0.00352076 0.00228166 0.04817598 0.01189762\n",
            " 0.         0.00200833 0.01365467 0.02111928]\n",
            "alpha     [0.02       0.02       0.02       0.02       0.03767743 0.02260088\n",
            " 0.         0.02       0.02       0.02680898]\n",
            "=================================================================   \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: [11] [  83/  83]     D1: -1.40|-0.74|0.08|-0.02     0.94\n",
            "C_logic2    [0.99986786 0.         0.9999858  0.         0.9994849  0.9996441\n",
            " 0.         0.98259616 0.999983   0.9995246 ]\n",
            "C_logic    [0.97547626 0.         0.9935646  0.         0.99815726 0.97955024\n",
            " 0.         0.9940328  0.98115563 0.9849643 ]\n",
            "C_pre_loss  [0.02522254 0.         0.00652082 0.         0.00184761 0.02088791\n",
            " 0.         0.00599828 0.01915628 0.01520941]\n",
            "alpha     [0.02328197 0.         0.02       0.         0.02       0.02064785\n",
            " 0.         0.02       0.02       0.02      ]\n",
            "=================================================================   \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: [12] [  83/  83]     D1: -1.19|-0.73|0.27|-0.08     0.94\n",
            "C_logic2    [0.9998182  0.99518245 0.99999005 0.9999764  0.99999976 0.99993736\n",
            " 0.         0.9999942  0.9999026  0.99994177]\n",
            "C_logic    [0.9832669  0.97577786 0.99893314 0.99977416 0.9997789  0.98755825\n",
            " 0.         0.9970848  0.9803556  0.9807936 ]\n",
            "C_pre_loss  [0.01695451 0.024556   0.00106826 0.00022588 0.00022111 0.01257645\n",
            " 0.         0.00291955 0.01992501 0.01957005]\n",
            "alpha     [0.02 0.02 0.02 0.02 0.02 0.02 0.   0.02 0.02 0.02]\n",
            "=================================================================   \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: [13] [  83/  83]     D1: -1.43|-0.75|0.07|-0.01     0.94\n",
            "C_logic2    [0.99995774 0.         0.9999418  0.99954814 0.99999964 0.99914116\n",
            " 0.         0.9999727  0.9999682  0.9998525 ]\n",
            "C_logic    [0.97882247 0.         0.9961262  0.9990645  0.99987745 0.96776694\n",
            " 0.         0.9953537  0.98987436 0.984478  ]\n",
            "C_pre_loss  [0.02176565 0.         0.00390154 0.00093641 0.00012254 0.03363866\n",
            " 0.         0.00465714 0.01019254 0.01593487]\n",
            "alpha     [0.02253612 0.         0.02       0.02       0.02       0.02875283\n",
            " 0.         0.02       0.02       0.02257027]\n",
            "=================================================================   \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: [14] [  83/  83]     D1: -1.41|-0.73|0.06|-0.07     0.94\n",
            "C_logic2    [0.9999477  0.         0.99993825 0.99219275 0.         0.9999977\n",
            " 0.997113   1.         0.999741   0.99950546]\n",
            "C_logic    [0.9882733  0.         0.99809194 0.99867475 0.         0.99234897\n",
            " 0.98731846 0.9967091  0.97870934 0.98686236]\n",
            "C_pre_loss  [0.01181682 0.         0.0019118  0.0013269  0.         0.00769053\n",
            " 0.01276265 0.0032963  0.02166406 0.01332967]\n",
            "alpha     [0.02       0.         0.02       0.02       0.         0.02\n",
            " 0.02       0.02       0.02052826 0.02      ]\n",
            "=================================================================   \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: [15] [  83/  83]     D1: -1.38|-0.73|0.08|-0.05     0.94\n",
            "C_logic2    [0.9999952  0.         0.99985254 1.         0.         0.9998788\n",
            " 0.         0.         0.99959147 0.9999747 ]\n",
            "C_logic    [0.99440795 0.         0.99773777 0.9997979  0.         0.9956901\n",
            " 0.         0.         0.9548135  0.9884434 ]\n",
            "C_pre_loss  [0.00560999 0.         0.00226901 0.00020216 0.         0.00432187\n",
            " 0.         0.         0.05848479 0.01166244]\n",
            "alpha     [0.02       0.         0.02       0.02       0.         0.02\n",
            " 0.         0.         0.05042161 0.02      ]\n",
            "=================================================================   \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: [16] [  83/  83]     D1: -1.46|-0.76|0.06|-0.04     0.94\n",
            "C_logic2    [0.99962944 0.9918424  0.999713   0.99999994 0.9999988  0.99994415\n",
            " 0.         0.99965256 0.9999663  0.9998923 ]\n",
            "C_logic    [0.98599976 0.982957   0.99669075 0.99939966 0.9995925  0.98664904\n",
            " 0.         0.99220955 0.98999286 0.9929541 ]\n",
            "C_pre_loss  [0.01414193 0.01718992 0.00331687 0.00060068 0.00040761 0.01355021\n",
            " 0.         0.00783427 0.01008917 0.00711396]\n",
            "alpha     [0.02 0.02 0.02 0.02 0.02 0.02 0.   0.02 0.02 0.02]\n",
            "=================================================================   \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: [17] [  83/  83]     D1: -1.41|-0.76|0.11|-0.02     0.94\n",
            "C_logic2    [0.9999632  0.         0.9999837  1.         0.         0.99995065\n",
            " 0.         0.         0.9997974  0.99975383]\n",
            "C_logic    [0.9840046  0.         0.9976035  0.9996338  0.         0.99084306\n",
            " 0.         0.         0.9864429  0.9907099 ]\n",
            "C_pre_loss  [0.01618713 0.         0.00240552 0.00036626 0.         0.0092264\n",
            " 0.         0.         0.01374465 0.00939324]\n",
            "alpha     [0.02 0.   0.02 0.02 0.   0.02 0.   0.   0.02 0.02]\n",
            "=================================================================   \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: [18] [  83/  83]     D1: -1.43|-0.73|0.04|-0.02     0.94\n",
            "C_logic2    [0.99923664 0.9949791  0.9999754  1.         0.9999989  0.99991405\n",
            " 0.         0.99982995 0.99991244 0.99996245]\n",
            "C_logic    [0.9733693  0.9907766  0.99609125 0.99981046 0.9996785  0.9833427\n",
            " 0.         0.97641957 0.9858209  0.98559386]\n",
            "C_pre_loss  [0.02762135 0.00926623 0.00392153 0.00018957 0.00032157 0.0170741\n",
            " 0.         0.02394263 0.01437978 0.01459226]\n",
            "alpha     [0.02524915 0.02       0.02       0.02       0.02       0.02188779\n",
            " 0.         0.02       0.02       0.02      ]\n",
            "=================================================================   \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: [19] [  83/  83]     D1: -1.32|-0.73|0.15|-0.07     0.94\n",
            "C_logic2    [0.99990547 0.         0.9999646  0.9999917  0.         0.9999023\n",
            " 0.         0.         0.9997705  0.9999453 ]\n",
            "C_logic    [0.970572   0.         0.99248326 0.9994996  0.         0.9872603\n",
            " 0.         0.         0.9585694  0.99726075]\n",
            "C_pre_loss  [0.03082655 0.         0.00770515 0.00050056 0.         0.01288485\n",
            " 0.         0.         0.04336955 0.00274595]\n",
            "alpha     [0.02874301 0.         0.02       0.02       0.         0.02\n",
            " 0.         0.         0.03162441 0.02      ]\n",
            "=================================================================   \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: [20] [  83/  83]     D1: -1.49|-0.76|0.02|-0.01     0.94\n",
            "C_logic2    [0.9999548  0.99975234 0.9996527  0.         0.         0.9999904\n",
            " 0.97827464 0.9999846  0.99991155 0.9990813 ]\n",
            "C_logic    [0.9899957  0.97643375 0.99379796 0.         0.         0.99264747\n",
            " 0.99884343 0.99834526 0.983225   0.99266493]\n",
            "C_pre_loss  [0.01008563 0.02384835 0.00639381 0.         0.         0.00739774\n",
            " 0.00115721 0.00165611 0.01736748 0.00741048]\n",
            "alpha     [0.02       0.02       0.02070214 0.         0.         0.02\n",
            " 0.02       0.02       0.02432584 0.02      ]\n",
            "=================================================================   \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: [21] [  83/  83]     D1: -1.38|-0.71|0.03|-0.05     0.94\n",
            "C_logic2    [0.9999493  0.         0.9999282  0.9999999  0.99997586 0.9996979\n",
            " 0.         0.         0.9999857  0.9999906 ]\n",
            "C_logic    [0.98974115 0.         0.99432164 0.9997806  0.9997039  0.9918929\n",
            " 0.         0.         0.99375737 0.9946763 ]\n",
            "C_pre_loss  [0.01032702 0.         0.00577096 0.00021944 0.00029618 0.0081572\n",
            " 0.         0.         0.00626786 0.00536112]\n",
            "alpha     [0.02 0.   0.02 0.02 0.02 0.02 0.   0.   0.02 0.02]\n",
            "=================================================================   \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: [22] [  83/  83]     D1: -1.38|-0.76|0.15|-0.03     0.94\n",
            "C_logic2    [0.9960086  0.         0.9999097  0.99999976 1.         0.99995804\n",
            " 0.         0.9988574  0.9999554  1.        ]\n",
            "C_logic    [0.94910496 0.         0.98729783 0.99848557 0.9926489  0.97978085\n",
            " 0.         0.99333996 0.98438644 0.9941995 ]\n",
            "C_pre_loss  [0.05539483 0.         0.01305575 0.00151635 0.00737823 0.02055949\n",
            " 0.         0.00668231 0.01595526 0.00582271]\n",
            "alpha     [0.04442475 0.         0.02241291 0.02       0.02       0.02093785\n",
            " 0.         0.02       0.02074925 0.02      ]\n",
            "=================================================================   \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: [23] [  83/  83]     D1: -1.38|-0.71|0.04|-0.09     0.94\n",
            "C_logic2    [0.9999898  0.99702674 0.99983144 0.99989986 0.99866503 0.9999971\n",
            " 0.         0.         0.9997429  0.9999223 ]\n",
            "C_logic    [0.98641884 0.9825355  0.99699974 0.9991205  0.9665995  0.98882127\n",
            " 0.         0.         0.99226105 0.9901315 ]\n",
            "C_pre_loss  [0.01372834 0.01761881 0.00301625 0.00088002 0.03434675 0.01127003\n",
            " 0.         0.         0.00779963 0.00999477]\n",
            "alpha     [0.02       0.02       0.02       0.02       0.02282387 0.02\n",
            " 0.         0.         0.02       0.02      ]\n",
            "=================================================================   \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: [24] [  83/  83]     D1: -1.34|-0.75|0.15|-0.10     0.94\n",
            "C_logic2    [0.9999187  0.98364484 0.99929005 0.9999997  0.9999975  0.9997156\n",
            " 0.9999224  0.9999984  0.99988043 0.99992937]\n",
            "C_logic    [0.98613197 0.92055225 0.9896367  0.9999073  0.9933077  0.9824535\n",
            " 0.999411   0.9976703  0.98841965 0.9901928 ]\n",
            "C_pre_loss  [1.4137891e-02 8.2781501e-02 1.0560955e-02 9.2659226e-05 6.7147571e-03\n",
            " 1.7883619e-02 5.8919709e-04 2.3329945e-03 1.1703698e-02 9.8934118e-03]\n",
            "alpha     [0.0212643  0.04261698 0.02       0.02       0.02       0.02132028\n",
            " 0.02       0.02       0.02       0.02      ]\n",
            "=================================================================   \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: [25] [  83/  83]     D1: -1.49|-0.77|0.04|-0.02     0.94\n",
            "C_logic2    [0.9999771  0.         0.99995035 0.999995   0.9999884  0.9999884\n",
            " 0.9998299  0.9933653  0.99995196 0.99997026]\n",
            "C_logic    [0.9917794  0.         0.9909691  0.9998229  0.9997075  0.9928143\n",
            " 0.99491346 0.934478   0.9898472  0.9858822 ]\n",
            "C_pre_loss  [0.0082657  0.         0.00921618 0.00017713 0.00029253 0.00722419\n",
            " 0.0050995  0.07006747 0.01025885 0.01442663]\n",
            "alpha     [0.02       0.         0.02       0.02       0.02       0.02\n",
            " 0.02       0.05752505 0.02       0.0208085 ]\n",
            "=================================================================   \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: [26] [  83/  83]     D1: -1.47|-0.75|0.03|-0.03     0.94\n",
            "C_logic2    [0.99997544 0.         0.999989   0.99999124 0.         0.9999939\n",
            " 0.         0.         0.99982643 0.9999264 ]\n",
            "C_logic    [0.9917645  0.         0.9980793  0.99821013 0.         0.9879563\n",
            " 0.         0.         0.9843953  0.9888232 ]\n",
            "C_pre_loss  [0.00829504 0.         0.00192399 0.00179396 0.         0.01215588\n",
            " 0.         0.         0.01586902 0.01131325]\n",
            "alpha     [0.02       0.         0.02       0.02       0.         0.02\n",
            " 0.         0.         0.02030414 0.02      ]\n",
            "=================================================================   \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: [27] [  83/  83]     D1: -1.52|-0.77|0.02|-0.01     0.94\n",
            "C_logic2    [0.99998623 0.         0.9999981  0.9999918  0.         0.9998346\n",
            " 0.999608   0.99999523 0.99979067 0.99993515]\n",
            "C_logic    [0.9856712  0.         0.99817336 0.9985832  0.         0.9878418\n",
            " 0.9997868  0.9403064  0.97991765 0.99117595]\n",
            "C_pre_loss  [0.0145802  0.         0.00183296 0.00141838 0.         0.01229999\n",
            " 0.00021324 0.06154948 0.02066009 0.00892985]\n",
            "alpha     [0.02060928 0.         0.02       0.02       0.         0.02\n",
            " 0.02       0.0216433  0.02343473 0.02      ]\n",
            "=================================================================   \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: [28] [  83/  83]     D1: -1.48|-0.76|0.03|-0.04     0.94\n",
            "C_logic2    [0.99996054 0.         0.9999624  0.9999452  0.99997586 0.99910724\n",
            " 0.         0.9999341  0.9999903  0.9999468 ]\n",
            "C_logic    [0.98974335 0.         0.99427825 0.9991843  0.98973125 0.9918024\n",
            " 0.         0.98897994 0.9925057  0.9898322 ]\n",
            "C_pre_loss  [0.01033647 0.         0.00579251 0.00081626 0.01042243 0.00825105\n",
            " 0.         0.01108123 0.00752851 0.01029784]\n",
            "alpha     [0.02 0.   0.02 0.02 0.02 0.02 0.   0.02 0.02 0.02]\n",
            "=================================================================   \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: [29] [  83/  83]     D1: -1.48|-0.77|0.06|-0.02     0.94\n",
            "C_logic2    [0.9999895  0.         0.9999801  0.9990073  0.9991879  0.9999586\n",
            " 0.9994486  0.99999416 0.9999864  0.99972147]\n",
            "C_logic    [0.99110204 0.         0.9970104  0.95239925 0.9918127  0.9837053\n",
            " 0.9995034  0.987458   0.98985344 0.9872589 ]\n",
            "C_pre_loss  [0.00897969 0.         0.00299933 0.05251804 0.008221   0.01662721\n",
            " 0.0004968  0.01266802 0.01025185 0.01288786]\n",
            "alpha     [0.02       0.         0.02       0.05377658 0.02       0.02184449\n",
            " 0.02       0.02       0.02       0.02      ]\n",
            "=================================================================   \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: [30] [  83/  83]     D1: -1.48|-0.77|0.06|-0.01     0.94\n",
            "C_logic2    [0.9999985  0.         0.9995249  0.9999997  0.99931496 0.9999892\n",
            " 0.         0.         0.999646   0.99919915]\n",
            "C_logic    [0.9955463  0.         0.99745005 0.9997308  0.9959974  0.9835611\n",
            " 0.         0.         0.98765886 0.97974056]\n",
            "C_pre_loss  [0.00446611 0.         0.00257316 0.0002692  0.00401241 0.01712066\n",
            " 0.         0.         0.01256565 0.02077346]\n",
            "alpha     [0.02       0.         0.02       0.02       0.02       0.0256097\n",
            " 0.         0.         0.02021324 0.02261182]\n",
            "=================================================================   \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: [31] [  83/  83]     D1: -1.50|-0.77|0.05|-0.01     0.94\n",
            "C_logic2    [0.99999976 0.9998254  0.9999336  0.9999547  0.9999925  0.9999785\n",
            " 0.99993896 0.         0.99896425 0.99834985]\n",
            "C_logic    [0.9917479  0.9862346  0.98385537 0.99687856 0.9996911  0.9883779\n",
            " 0.99867755 0.         0.9830968  0.9892667 ]\n",
            "C_pre_loss  [0.00828913 0.01386099 0.01732335 0.00312707 0.00030894 0.01172458\n",
            " 0.0013233  0.         0.01712214 0.0109764 ]\n",
            "alpha     [0.02       0.02       0.0281986  0.02       0.02       0.02\n",
            " 0.02       0.         0.02       0.02119857]\n",
            "=================================================================   \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: [32] [  83/  83]     D1: -1.52|-0.77|0.03|-0.01     0.94\n",
            "C_logic2    [0.9996894 0.        0.9999845 0.9999992 0.9999929 0.9991694 0.9996049\n",
            " 0.        0.99991   0.9999582]\n",
            "C_logic    [0.99117166 0.         0.9973236  0.9985021  0.99981153 0.9791465\n",
            " 0.9993529  0.         0.9922247  0.98788327]\n",
            "C_pre_loss  [0.00890086 0.         0.00268516 0.00150043 0.00018851 0.02153034\n",
            " 0.00064734 0.         0.00783077 0.01225185]\n",
            "alpha     [0.02       0.         0.02       0.02       0.02       0.02472662\n",
            " 0.02       0.         0.02       0.02      ]\n",
            "=================================================================   \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: [33] [  83/  83]     D1: -1.47|-0.76|0.06|-0.04     0.94\n",
            "C_logic2    [0.9999967  0.         0.9999597  0.9999966  0.9999988  0.9999949\n",
            " 0.         0.         0.9999158  0.99996185]\n",
            "C_logic    [0.9907499  0.         0.9980541  0.9994271  0.9997731  0.99143255\n",
            " 0.         0.         0.980174   0.9933581 ]\n",
            "C_pre_loss  [0.00930895 0.         0.00195065 0.00057315 0.00022695 0.00861154\n",
            " 0.         0.         0.02028693 0.00668198]\n",
            "alpha     [0.02      0.        0.02      0.02      0.02      0.02      0.\n",
            " 0.        0.0213962 0.02     ]\n",
            "=================================================================   \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: [34] [  83/  83]     D1: -1.49|-0.77|0.06|-0.00     0.94\n",
            "C_logic2    [0.99999076 0.         0.99997985 0.9999709  0.99998623 0.99999046\n",
            " 0.         0.         0.99995613 0.99984604]\n",
            "C_logic    [0.99219733 0.         0.99708986 0.9994664  0.9989176  0.990317\n",
            " 0.         0.         0.9893694  0.98180044]\n",
            "C_pre_loss  [0.00784386 0.         0.00292093 0.00053375 0.00108327 0.00978405\n",
            " 0.         0.         0.01072455 0.01872673]\n",
            "alpha     [0.02       0.         0.02       0.02       0.02       0.02\n",
            " 0.         0.         0.02       0.02378627]\n",
            "=================================================================   \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: [35] [  83/  83]     D1: -1.52|-0.77|0.01|-0.01     0.94\n",
            "C_logic2    [0.9997431  0.         0.9999957  0.9999469  0.9995998  0.9997358\n",
            " 0.         0.99724376 0.9999869  0.99991405]\n",
            "C_logic    [0.9932009  0.         0.9973408  0.9994159  0.99898934 0.9903648\n",
            " 0.         0.9934001  0.9908782  0.98834777]\n",
            "C_pre_loss  [0.00682833 0.         0.00266685 0.00058444 0.0010116  0.00975199\n",
            " 0.         0.0066218  0.00920855 0.01184869]\n",
            "alpha     [0.02 0.   0.02 0.02 0.02 0.02 0.   0.02 0.02 0.02]\n",
            "=================================================================   \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: [36] [  83/  83]     D1: -1.43|-0.75|0.07|-0.06     0.94\n",
            "C_logic2    [0.99974006 0.         0.99999976 0.9999731  0.         0.9999698\n",
            " 0.         1.         0.999992   0.9998785 ]\n",
            "C_logic    [0.97641957 0.         0.9974057  0.9965434  0.         0.9807924\n",
            " 0.         0.9992167  0.9926939  0.9816573 ]\n",
            "C_pre_loss  [0.02435051 0.         0.00260404 0.00346579 0.         0.02036232\n",
            " 0.         0.00078361 0.00734517 0.01870872]\n",
            "alpha     [0.02536234 0.         0.02       0.02       0.         0.02799665\n",
            " 0.         0.02       0.02       0.02057655]\n",
            "=================================================================   \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: [37] [  83/  83]     D1: -1.45|-0.77|0.09|-0.02     0.94\n",
            "C_logic2    [0.99999374 0.         0.99999064 1.         0.99999523 0.99998754\n",
            " 0.         0.9999401  0.9963323  0.9999858 ]\n",
            "C_logic    [0.98705846 0.         0.99884003 0.99954814 0.99899054 0.9877335\n",
            " 0.         0.9855445  0.9615424  0.9906145 ]\n",
            "C_pre_loss  [0.01307015 0.         0.00116145 0.00045194 0.00101048 0.01240265\n",
            " 0.         0.01466325 0.04107931 0.00950135]\n",
            "alpha     [0.02       0.         0.02       0.02       0.02       0.02\n",
            " 0.         0.02       0.03266022 0.02      ]\n",
            "=================================================================   \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: [38] [  83/  83]     D1: -1.48|-0.76|0.04|-0.00     0.94\n",
            "C_logic2    [0.9999783  0.999413   0.99999267 1.         0.99997634 0.99997497\n",
            " 0.         0.9999993  0.9999429  0.99980843]\n",
            "C_logic    [0.9820986  0.9799257  0.99856746 0.9766404  0.9995093  0.98953766\n",
            " 0.         0.9979765  0.9876188  0.9940981 ]\n",
            "C_pre_loss  [0.01828785 0.02027852 0.00143425 0.02411585 0.00049091 0.01064141\n",
            " 0.         0.00202558 0.01254447 0.00593564]\n",
            "alpha     [0.02160899 0.02       0.02       0.02269206 0.02       0.02\n",
            " 0.         0.02       0.02       0.02      ]\n",
            "=================================================================   \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: [39] [  83/  83]     D1: -1.47|-0.76|0.05|-0.01     0.94\n",
            "C_logic2    [0.99998486 0.         0.999998   0.9999995  0.9999964  0.99999213\n",
            " 0.         0.99993676 0.9999366  0.9999972 ]\n",
            "C_logic    [0.9814516  0.         0.9972913  0.9997781  0.99959904 0.9837739\n",
            " 0.         0.99745387 0.98772174 0.99587345]\n",
            "C_pre_loss  [0.01890018 0.         0.00271649 0.00022194 0.00040106 0.0164791\n",
            " 0.         0.00255051 0.01243901 0.00414144]\n",
            "alpha     [0.02013021 0.         0.02       0.02       0.02       0.02\n",
            " 0.         0.02       0.02       0.02      ]\n",
            "=================================================================   \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: [40] [  83/  83]     D1: -1.51|-0.76|0.02|-0.02     0.94\n",
            "C_logic2    [0.99972177 0.         0.99998564 0.         0.         0.99997884\n",
            " 0.         0.9999995  0.9999943  0.9999847 ]\n",
            "C_logic    [0.9784415  0.         0.99753714 0.         0.         0.99287736\n",
            " 0.         0.9992887  0.9899111  0.99642503]\n",
            "C_pre_loss  [0.02210004 0.         0.0024686  0.         0.         0.00715654\n",
            " 0.         0.00071155 0.01018859 0.00358502]\n",
            "alpha     [0.02311887 0.         0.02       0.         0.         0.02\n",
            " 0.         0.02       0.02       0.02      ]\n",
            "=================================================================   \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: [41] [  83/  83]     D1: -1.54|-0.77|0.01|-0.00     0.94\n",
            "C_logic2    [0.99999523 0.         0.9999936  0.99999446 0.9999999  0.9998335\n",
            " 0.         0.99999845 0.9999873  0.9994269 ]\n",
            "C_logic    [0.9853557  0.         0.9983263  0.99798656 0.9949687  0.9882978\n",
            " 0.         0.9967642  0.9910912  0.9954328 ]\n",
            "C_pre_loss  [0.01488949 0.         0.00167556 0.0020193  0.005044   0.01181801\n",
            " 0.         0.00324105 0.00897885 0.00458215]\n",
            "alpha     [0.02 0.   0.02 0.02 0.02 0.02 0.   0.02 0.02 0.02]\n",
            "=================================================================   \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: [42] [  83/  83]     D1: -1.49|-0.78|0.07|-0.02     0.94\n",
            "C_logic2    [0.9997964  0.99995303 0.9999999  1.         0.9999997  0.9998045\n",
            " 0.         0.99999964 0.9999959  0.99993366]\n",
            "C_logic    [0.9859157  0.9930559  0.9986102  0.99954104 0.99762785 0.9858335\n",
            " 0.         0.9986308  0.99564445 0.9900595 ]\n",
            "C_pre_loss  [0.01429849 0.00696836 0.00139156 0.00045912 0.00237726 0.01459763\n",
            " 0.         0.00137009 0.0043666  0.01003454]\n",
            "alpha     [0.02       0.02       0.02       0.02       0.02       0.02280143\n",
            " 0.         0.02       0.02       0.02      ]\n",
            "=================================================================   \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: [43] [  83/  83]     D1: -1.39|-0.74|0.09|-0.05     0.94\n",
            "C_logic2    [0.99989986 0.         0.9999973  0.99999994 0.99886733 0.9999965\n",
            " 0.         0.         0.9999935  0.9996155 ]\n",
            "C_logic    [0.97032154 0.         0.99859047 0.9995832  0.9959777  0.99143666\n",
            " 0.         0.         0.98987293 0.9782192 ]\n",
            "C_pre_loss  [0.03043742 0.         0.00141104 0.0004169  0.00403833 0.00867612\n",
            " 0.         0.         0.01020243 0.02311261]\n",
            "alpha     [0.02365405 0.         0.02       0.02       0.02       0.02\n",
            " 0.         0.         0.02       0.02855827]\n",
            "=================================================================   \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: [44] [  83/  83]     D1: -1.51|-0.77|0.04|-0.01     0.94\n",
            "C_logic2    [0.9999854  0.         0.9999941  0.99999994 0.9999933  0.9999644\n",
            " 0.9995771  0.         0.99996865 0.9999954 ]\n",
            "C_logic    [0.98793465 0.         0.99875    0.99983644 0.9998851  0.99422777\n",
            " 0.99981004 0.         0.991436   0.9952549 ]\n",
            "C_pre_loss  [0.01218882 0.         0.00125205 0.00016359 0.00011491 0.00581132\n",
            " 0.00019    0.         0.00861818 0.00476449]\n",
            "alpha     [0.02 0.   0.02 0.02 0.02 0.02 0.02 0.   0.02 0.02]\n",
            "=================================================================   \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: [45] [  83/  83]     D1: -1.52|-0.76|0.00|-0.00     0.94\n",
            "C_logic2    [0.9999863  0.99979    0.99997646 1.         0.9998007  0.9995817\n",
            " 0.         0.         0.99999094 0.999126  ]\n",
            "C_logic    [0.9848202  0.9829811  0.99934006 0.99977785 0.99985945 0.9948804\n",
            " 0.         0.         0.98981714 0.9926496 ]\n",
            "C_pre_loss  [0.01546237 0.01716543 0.00066058 0.00022218 0.00014059 0.00514307\n",
            " 0.         0.         0.01025054 0.0074559 ]\n",
            "alpha     [0.02021573 0.02       0.02       0.02       0.02       0.02\n",
            " 0.         0.         0.02       0.02      ]\n",
            "=================================================================   \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
            "WARNING:imageio:Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: [46] [  83/  83]     D1: -1.38|-0.77|0.16|-0.08     0.94\n",
            "C_logic2    [0.9999871  0.         0.9999353  1.         0.9999894  0.9999819\n",
            " 0.         0.99999017 0.9999204  0.9988947 ]\n",
            "C_logic    [0.9876933  0.         0.9926889  0.99855024 0.9980215  0.99529713\n",
            " 0.         0.9920133  0.9928697  0.9927546 ]\n",
            "C_pre_loss  [0.01245257 0.         0.00746514 0.0014508  0.00198049 0.00471761\n",
            " 0.         0.00804609 0.00716278 0.00731333]\n",
            "alpha     [0.02 0.   0.02 0.02 0.02 0.02 0.   0.02 0.02 0.02]\n",
            "=================================================================   \n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-42-590cb7966d35>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'/'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'.pth'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mgan\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mgan_args\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mglobal_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-32-ea84f3a57de6>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, train_data, gan_epoch, global_model, optimizer, round)\u001b[0m\n\u001b[1;32m    299\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglobal_loss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mglobal_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m                 \u001b[0mprint_head\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Epoch: [%2d] [%4d/%4d]\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0miter\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_loader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 301\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_vec_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_distribution\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglobal_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprint_head\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    302\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_hist\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'per_epoch_time'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mepoch_start_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-32-ea84f3a57de6>\u001b[0m in \u001b[0;36mtrain_step\u001b[0;34m(self, x_, y_vec_, iter, y_distribution, global_model, optimizer, print_head)\u001b[0m\n\u001b[1;32m    218\u001b[0m         \u001b[0mG_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mD_loss_G\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mC_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 220\u001b[0;31m         \u001b[0mG_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    221\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mG_optimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    485\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m             )\n\u001b[0;32m--> 487\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    488\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    198\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    201\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "model2=torch.load(task+'/'+str(2)+'.pth')\n",
        "gan.train(client.train_data,gan_args.epoch,global_model=model2,optimizer=optimizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kk-0cMyiwlL9",
        "outputId": "3755f20d-7117-4125-82df-22444158c1d2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([0.0000e+00, 1.8890e+03, 0.0000e+00, 3.4200e+02, 4.0200e+02, 1.0000e+00,\n",
            "        2.1520e+03, 5.5200e+02, 3.0000e+00, 1.0000e+00])\n",
            "6    2400\n",
            "1    2094\n",
            "7     614\n",
            "4     442\n",
            "3     380\n",
            "8       3\n",
            "5       1\n",
            "9       1\n",
            "Name: label, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "from typing import Callable\n",
        "\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.utils.data\n",
        "import torchvision\n",
        "\n",
        "\n",
        "class BalancedSampler(torch.utils.data.sampler.Sampler):\n",
        "    def __init__(\n",
        "        self,\n",
        "        dataset,\n",
        "        label_to_count,\n",
        "        labels: list = None,\n",
        "        indices: list = None,\n",
        "        num_samples: int = None,\n",
        "        callback_get_label: Callable = None,\n",
        "    ):\n",
        "    # if indices is not provided, all elements in the dataset will be considered\n",
        "        self.indices = list(range(len(dataset))) if indices is None else indices\n",
        "\n",
        "        # define custom callback\n",
        "        self.callback_get_label = callback_get_label\n",
        "\n",
        "        # if num_samples is not provided, draw `len(indices)` samples in each iteration\n",
        "        self.num_samples = len(self.indices) if num_samples is None else num_samples\n",
        "\n",
        "        # distribution of classes in the dataset\n",
        "        df = pd.DataFrame()\n",
        "        df[\"label\"] = self._get_labels(dataset) if labels is None else labels\n",
        "        df.index = self.indices\n",
        "        df = df.sort_index()\n",
        "\n",
        "        label_to_count = df[\"label\"].value_counts()\n",
        "        print(label_to_count)\n",
        "        weights = 1.0 / label_to_count[df[\"label\"]]\n",
        "\n",
        "        self.weights = torch.DoubleTensor(weights.to_list())\n",
        "    def _get_labels(self, dataset):\n",
        "        return [dataset[i][1] for i in self.indices ]\n",
        "\n",
        "    def __iter__(self):\n",
        "        return (self.indices[i] for i in torch.multinomial(self.weights, self.num_samples, replacement=True))\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.num_samples\n",
        "\n",
        "print(client.C)\n",
        "train_data=client.train_data.dataset\n",
        "data_loader = DataLoader(new_normalize(train_data,mean=0.5,std=0.5), \\\n",
        "                                 sampler=BalancedSampler(train_data,client.C),\\\n",
        "                                 batch_size=20)\n",
        "#for x,y in data_loader:\n",
        "  #print(y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xeJy7TE24w76"
      },
      "source": [
        "## 查看数据分布"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NbmXYe9G4E7j",
        "outputId": "8dbd4440-6401-4a75-a9cb-b3880e60eae8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "client 0 总样本数： 5389  各类： [   0  352 2210    6   19  203   49    0    0 2550]\n",
            "client 1 总样本数： 5291  各类： [   0    1   89   59 4208  111  157    0   42  624]\n",
            "client 2 总样本数： 5342  各类： [   0 1889    0  342  402    1 2152  552    3    1]\n",
            "client 3 总样本数： 5470  各类： [   0    0  501  158    1    0   26 4518  266    0]\n",
            "client 4 总样本数： 5474  各类： [  27    0 2198    0   94 1443    0  469    0 1243]\n",
            "client 5 总样本数： 5355  各类： [4917    0    0   76    0    3    0    0    0  359]\n",
            "client 6 总样本数： 5526  各类： [   2    0    0    0  498    9  760    0 3683  574]\n",
            "client 7 总样本数： 5309  各类： [  28 2880    0  169    7   11 2154   60    0    0]\n",
            "client 8 总样本数： 5493  各类： [   0  902  242   42    2 3102    0    0 1203    0]\n",
            "client 9 总样本数： 5357  各类： [ 366   24  126 4658   24    1   13   41   75   29]\n"
          ]
        }
      ],
      "source": [
        "def show_loc_data(client):\n",
        "  date_num=len(client.train_data.indices)\n",
        "  data_loader = client.calculator.get_dataloader(client.train_data, batch_size=date_num)\n",
        "  y_ = data_loader.__iter__().__next__()[1]\n",
        "  y_vec_ = torch.zeros((y_.shape[0], 10)).scatter_(1, y_.type(torch.LongTensor).unsqueeze(1), 1)\n",
        "  print(\"client\",client.id,\"总样本数：\",date_num,\" 各类：\",y_vec_.sum(0).int().numpy())\n",
        "\n",
        "for client in runner.clients:\n",
        "  show_loc_data(client)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UaevHs-Ty77Z",
        "outputId": "42b4ad4a-8fb1-4f50-ebcf-73d012b68d5f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([0.0000, 0.8204, 0.9858, 0.5460, 0.6127, 0.7764, 0.6735, 0.0000, 0.0000,\n",
              "        1.0000])"
            ]
          },
          "execution_count": 48,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_distribution=torch.tensor([0, 352, 2210, 6, 19, 203, 49, 0, 0, 2550])\n",
        "(y_distribution/y_distribution.max())**0.1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GzXzdVWcsTdU",
        "outputId": "3cbff356-624e-4420-c59b-479aa2258149"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-05-25 12:18:42,233 fflow.py init [line:441] INFO Initializing devices: cuda:0 will be used for this running.\n",
            "2023-05-25 12:18:42,271 fflow.py init [line:479] INFO Use `<class 'flgo.simulator.default_simulator.Simulator'>` as the system simulator\n",
            "2023-05-25 12:18:42,273 fflow.py init [line:487] INFO Ready to start.\n",
            "2023-05-25 12:18:42,276 fedbase.py run [line:236] INFO --------------Initial Evaluation--------------\n",
            "2023-05-25 12:18:42,278 simple_logger.py log_once [line:14] INFO Current_time:0\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "客户端 0\n",
            "数据量 5400\n",
            "客户端 1\n",
            "数据量 5400\n",
            "客户端 2\n",
            "数据量 5400\n",
            "客户端 3\n",
            "数据量 5400\n",
            "客户端 4\n",
            "数据量 5400\n",
            "客户端 5\n",
            "数据量 5400\n",
            "客户端 6\n",
            "数据量 5400\n",
            "客户端 7\n",
            "数据量 5400\n",
            "客户端 8\n",
            "数据量 5400\n",
            "客户端 9\n",
            "数据量 5400\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-05-25 12:18:46,557 simple_logger.py log_once [line:28] INFO test_accuracy                 0.1142\n",
            "2023-05-25 12:18:46,561 simple_logger.py log_once [line:28] INFO test_loss                     2.3023\n",
            "2023-05-25 12:18:46,565 simple_logger.py log_once [line:28] INFO valid_accuracy                0.1133\n",
            "2023-05-25 12:18:46,567 simple_logger.py log_once [line:28] INFO mean_valid_accuracy           0.1133\n",
            "2023-05-25 12:18:46,573 simple_logger.py log_once [line:28] INFO std_valid_accuracy            0.0165\n",
            "2023-05-25 12:18:46,577 simple_logger.py log_once [line:28] INFO valid_loss                    2.3035\n",
            "2023-05-25 12:18:46,579 simple_logger.py log_once [line:28] INFO mean_valid_loss               2.3035\n",
            "2023-05-25 12:18:46,580 simple_logger.py log_once [line:28] INFO std_valid_loss                0.0037\n",
            "2023-05-25 12:18:46,582 fedbase.py run [line:239] INFO Eval Time Cost:               4.3036s\n",
            "2023-05-25 12:18:46,584 fedbase.py run [line:257] INFO =================End==================\n",
            "2023-05-25 12:18:46,585 fedbase.py run [line:258] INFO Total Time Cost:              4.3094s\n"
          ]
        }
      ],
      "source": [
        "#查看一下数据\n",
        "class Client(BasicClient):\n",
        "  def initialize(self, *args, **kwargs):\n",
        "    print(\"客户端\",self.id)\n",
        "    print(\"数据量\",len(self.train_data))\n",
        "    if self._train_loader is None:\n",
        "      self._train_loader = self.calculator.get_dataloader(self.train_data, batch_size=self.batch_size,\n",
        "                                  num_workers=self.loader_num_workers,\n",
        "                                  pin_memory=self.option['pin_memory'])\n",
        "    #for iter, (x_, y_) in enumerate(self._train_loader):\n",
        "      #print(y_)\n",
        "  def train(self, model):\n",
        "    pass\n",
        "class view_data:\n",
        "  Server=BasicServer\n",
        "  Client=Client\n",
        "option = {'num_rounds':0, 'num_epochs':0, 'batch_size':8, 'learning_rate':0.1, 'gpu':0 if torch.cuda.is_available() else ''}\n",
        "runner = flgo.init(task, view_data, option=option)\n",
        "runner.run()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iujPKS6KkVI_",
        "outputId": "44103099-74fd-4d75-f575-be665b20d843"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-05-25 11:25:40,425 fflow.py init [line:441] INFO Initializing devices: cuda:0 will be used for this running.\n",
            "2023-05-25 11:25:40,460 fflow.py init [line:479] INFO Use `<class 'flgo.simulator.default_simulator.Simulator'>` as the system simulator\n",
            "2023-05-25 11:25:40,461 fflow.py init [line:487] INFO Ready to start.\n",
            "2023-05-25 11:25:40,464 fedbase.py run [line:236] INFO --------------Initial Evaluation--------------\n",
            "2023-05-25 11:25:40,466 simple_logger.py log_once [line:14] INFO Current_time:0\n",
            "2023-05-25 11:25:45,878 simple_logger.py log_once [line:28] INFO test_accuracy                 0.1142\n",
            "2023-05-25 11:25:45,883 simple_logger.py log_once [line:28] INFO test_loss                     2.3023\n",
            "2023-05-25 11:25:45,889 simple_logger.py log_once [line:28] INFO valid_accuracy                0.1133\n",
            "2023-05-25 11:25:45,890 simple_logger.py log_once [line:28] INFO mean_valid_accuracy           0.1133\n",
            "2023-05-25 11:25:45,893 simple_logger.py log_once [line:28] INFO std_valid_accuracy            0.0165\n",
            "2023-05-25 11:25:45,895 simple_logger.py log_once [line:28] INFO valid_loss                    2.3035\n",
            "2023-05-25 11:25:45,896 simple_logger.py log_once [line:28] INFO mean_valid_loss               2.3035\n",
            "2023-05-25 11:25:45,901 simple_logger.py log_once [line:28] INFO std_valid_loss                0.0037\n",
            "2023-05-25 11:25:45,902 fedbase.py run [line:239] INFO Eval Time Cost:               5.4358s\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0, 1]\n",
            "train: 0\n",
            "train: 1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-05-25 11:25:51,621 fedbase.py run [line:246] INFO --------------Round 1--------------\n",
            "2023-05-25 11:25:51,623 simple_logger.py log_once [line:14] INFO Current_time:1\n",
            "2023-05-25 11:25:55,625 simple_logger.py log_once [line:28] INFO test_accuracy                 0.9680\n",
            "2023-05-25 11:25:55,626 simple_logger.py log_once [line:28] INFO test_loss                     0.1485\n",
            "2023-05-25 11:25:55,628 simple_logger.py log_once [line:28] INFO valid_accuracy                0.9608\n",
            "2023-05-25 11:25:55,633 simple_logger.py log_once [line:28] INFO mean_valid_accuracy           0.9608\n",
            "2023-05-25 11:25:55,635 simple_logger.py log_once [line:28] INFO std_valid_accuracy            0.0093\n",
            "2023-05-25 11:25:55,643 simple_logger.py log_once [line:28] INFO valid_loss                    0.1668\n",
            "2023-05-25 11:25:55,644 simple_logger.py log_once [line:28] INFO mean_valid_loss               0.1668\n",
            "2023-05-25 11:25:55,645 simple_logger.py log_once [line:28] INFO std_valid_loss                0.0189\n",
            "2023-05-25 11:25:55,646 fedbase.py run [line:251] INFO Eval Time Cost:               4.0235s\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0, 1]\n",
            "train: 0\n",
            "train: 1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-05-25 11:26:02,456 fedbase.py run [line:246] INFO --------------Round 2--------------\n",
            "2023-05-25 11:26:02,458 simple_logger.py log_once [line:14] INFO Current_time:2\n",
            "2023-05-25 11:26:06,519 simple_logger.py log_once [line:28] INFO test_accuracy                 0.9761\n",
            "2023-05-25 11:26:06,521 simple_logger.py log_once [line:28] INFO test_loss                     0.0705\n",
            "2023-05-25 11:26:06,525 simple_logger.py log_once [line:28] INFO valid_accuracy                0.9753\n",
            "2023-05-25 11:26:06,528 simple_logger.py log_once [line:28] INFO mean_valid_accuracy           0.9753\n",
            "2023-05-25 11:26:06,530 simple_logger.py log_once [line:28] INFO std_valid_accuracy            0.0063\n",
            "2023-05-25 11:26:06,532 simple_logger.py log_once [line:28] INFO valid_loss                    0.0802\n",
            "2023-05-25 11:26:06,535 simple_logger.py log_once [line:28] INFO mean_valid_loss               0.0802\n",
            "2023-05-25 11:26:06,539 simple_logger.py log_once [line:28] INFO std_valid_loss                0.0140\n",
            "2023-05-25 11:26:06,540 fedbase.py run [line:251] INFO Eval Time Cost:               4.0823s\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0, 1]\n",
            "train: 0\n",
            "train: 1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-05-25 11:26:11,920 fedbase.py run [line:246] INFO --------------Round 3--------------\n",
            "2023-05-25 11:26:11,922 simple_logger.py log_once [line:14] INFO Current_time:3\n",
            "2023-05-25 11:26:17,614 simple_logger.py log_once [line:28] INFO test_accuracy                 0.9819\n",
            "2023-05-25 11:26:17,616 simple_logger.py log_once [line:28] INFO test_loss                     0.0559\n",
            "2023-05-25 11:26:17,620 simple_logger.py log_once [line:28] INFO valid_accuracy                0.9772\n",
            "2023-05-25 11:26:17,623 simple_logger.py log_once [line:28] INFO mean_valid_accuracy           0.9772\n",
            "2023-05-25 11:26:17,625 simple_logger.py log_once [line:28] INFO std_valid_accuracy            0.0077\n",
            "2023-05-25 11:26:17,631 simple_logger.py log_once [line:28] INFO valid_loss                    0.0720\n",
            "2023-05-25 11:26:17,632 simple_logger.py log_once [line:28] INFO mean_valid_loss               0.0720\n",
            "2023-05-25 11:26:17,635 simple_logger.py log_once [line:28] INFO std_valid_loss                0.0198\n",
            "2023-05-25 11:26:17,638 fedbase.py run [line:251] INFO Eval Time Cost:               5.7157s\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0, 1]\n",
            "train: 0\n",
            "train: 1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-05-25 11:26:23,074 fedbase.py run [line:246] INFO --------------Round 4--------------\n",
            "2023-05-25 11:26:23,075 simple_logger.py log_once [line:14] INFO Current_time:4\n",
            "2023-05-25 11:26:27,474 simple_logger.py log_once [line:28] INFO test_accuracy                 0.9809\n",
            "2023-05-25 11:26:27,481 simple_logger.py log_once [line:28] INFO test_loss                     0.0608\n",
            "2023-05-25 11:26:27,484 simple_logger.py log_once [line:28] INFO valid_accuracy                0.9780\n",
            "2023-05-25 11:26:27,487 simple_logger.py log_once [line:28] INFO mean_valid_accuracy           0.9780\n",
            "2023-05-25 11:26:27,489 simple_logger.py log_once [line:28] INFO std_valid_accuracy            0.0071\n",
            "2023-05-25 11:26:27,493 simple_logger.py log_once [line:28] INFO valid_loss                    0.0746\n",
            "2023-05-25 11:26:27,494 simple_logger.py log_once [line:28] INFO mean_valid_loss               0.0746\n",
            "2023-05-25 11:26:27,496 simple_logger.py log_once [line:28] INFO std_valid_loss                0.0241\n",
            "2023-05-25 11:26:27,497 fedbase.py run [line:251] INFO Eval Time Cost:               4.4216s\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0, 1]\n",
            "train: 0\n",
            "train: 1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-05-25 11:26:34,195 fedbase.py run [line:246] INFO --------------Round 5--------------\n",
            "2023-05-25 11:26:34,196 simple_logger.py log_once [line:14] INFO Current_time:5\n",
            "2023-05-25 11:26:38,263 simple_logger.py log_once [line:28] INFO test_accuracy                 0.9840\n",
            "2023-05-25 11:26:38,264 simple_logger.py log_once [line:28] INFO test_loss                     0.0522\n",
            "2023-05-25 11:26:38,268 simple_logger.py log_once [line:28] INFO valid_accuracy                0.9813\n",
            "2023-05-25 11:26:38,270 simple_logger.py log_once [line:28] INFO mean_valid_accuracy           0.9813\n",
            "2023-05-25 11:26:38,278 simple_logger.py log_once [line:28] INFO std_valid_accuracy            0.0041\n",
            "2023-05-25 11:26:38,279 simple_logger.py log_once [line:28] INFO valid_loss                    0.0672\n",
            "2023-05-25 11:26:38,282 simple_logger.py log_once [line:28] INFO mean_valid_loss               0.0672\n",
            "2023-05-25 11:26:38,284 simple_logger.py log_once [line:28] INFO std_valid_loss                0.0169\n",
            "2023-05-25 11:26:38,285 fedbase.py run [line:251] INFO Eval Time Cost:               4.0893s\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0, 1]\n",
            "train: 0\n",
            "train: 1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-05-25 11:26:44,234 fedbase.py run [line:246] INFO --------------Round 6--------------\n",
            "2023-05-25 11:26:44,240 simple_logger.py log_once [line:14] INFO Current_time:6\n",
            "2023-05-25 11:26:50,296 simple_logger.py log_once [line:28] INFO test_accuracy                 0.9834\n",
            "2023-05-25 11:26:50,298 simple_logger.py log_once [line:28] INFO test_loss                     0.0514\n",
            "2023-05-25 11:26:50,302 simple_logger.py log_once [line:28] INFO valid_accuracy                0.9775\n",
            "2023-05-25 11:26:50,305 simple_logger.py log_once [line:28] INFO mean_valid_accuracy           0.9775\n",
            "2023-05-25 11:26:50,307 simple_logger.py log_once [line:28] INFO std_valid_accuracy            0.0097\n",
            "2023-05-25 11:26:50,309 simple_logger.py log_once [line:28] INFO valid_loss                    0.0702\n",
            "2023-05-25 11:26:50,310 simple_logger.py log_once [line:28] INFO mean_valid_loss               0.0702\n",
            "2023-05-25 11:26:50,311 simple_logger.py log_once [line:28] INFO std_valid_loss                0.0239\n",
            "2023-05-25 11:26:50,312 fedbase.py run [line:251] INFO Eval Time Cost:               6.0725s\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0, 1]\n",
            "train: 0\n",
            "train: 1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-05-25 11:26:55,754 fedbase.py run [line:246] INFO --------------Round 7--------------\n",
            "2023-05-25 11:26:55,755 simple_logger.py log_once [line:14] INFO Current_time:7\n",
            "2023-05-25 11:27:00,860 simple_logger.py log_once [line:28] INFO test_accuracy                 0.9859\n",
            "2023-05-25 11:27:00,866 simple_logger.py log_once [line:28] INFO test_loss                     0.0508\n",
            "2023-05-25 11:27:00,871 simple_logger.py log_once [line:28] INFO valid_accuracy                0.9808\n",
            "2023-05-25 11:27:00,873 simple_logger.py log_once [line:28] INFO mean_valid_accuracy           0.9808\n",
            "2023-05-25 11:27:00,875 simple_logger.py log_once [line:28] INFO std_valid_accuracy            0.0066\n",
            "2023-05-25 11:27:00,880 simple_logger.py log_once [line:28] INFO valid_loss                    0.0718\n",
            "2023-05-25 11:27:00,881 simple_logger.py log_once [line:28] INFO mean_valid_loss               0.0718\n",
            "2023-05-25 11:27:00,882 simple_logger.py log_once [line:28] INFO std_valid_loss                0.0245\n",
            "2023-05-25 11:27:00,883 fedbase.py run [line:251] INFO Eval Time Cost:               5.1279s\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0, 1]\n",
            "train: 0\n",
            "train: 1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-05-25 11:27:06,822 fedbase.py run [line:246] INFO --------------Round 8--------------\n",
            "2023-05-25 11:27:06,824 simple_logger.py log_once [line:14] INFO Current_time:8\n",
            "2023-05-25 11:27:10,875 simple_logger.py log_once [line:28] INFO test_accuracy                 0.9870\n",
            "2023-05-25 11:27:10,876 simple_logger.py log_once [line:28] INFO test_loss                     0.0505\n",
            "2023-05-25 11:27:10,879 simple_logger.py log_once [line:28] INFO valid_accuracy                0.9852\n",
            "2023-05-25 11:27:10,886 simple_logger.py log_once [line:28] INFO mean_valid_accuracy           0.9852\n",
            "2023-05-25 11:27:10,887 simple_logger.py log_once [line:28] INFO std_valid_accuracy            0.0049\n",
            "2023-05-25 11:27:10,889 simple_logger.py log_once [line:28] INFO valid_loss                    0.0701\n",
            "2023-05-25 11:27:10,894 simple_logger.py log_once [line:28] INFO mean_valid_loss               0.0701\n",
            "2023-05-25 11:27:10,897 simple_logger.py log_once [line:28] INFO std_valid_loss                0.0239\n",
            "2023-05-25 11:27:10,903 fedbase.py run [line:251] INFO Eval Time Cost:               4.0796s\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0, 1]\n",
            "train: 0\n",
            "train: 1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-05-25 11:27:17,780 fedbase.py run [line:246] INFO --------------Round 9--------------\n",
            "2023-05-25 11:27:17,781 simple_logger.py log_once [line:14] INFO Current_time:9\n",
            "2023-05-25 11:27:21,971 simple_logger.py log_once [line:28] INFO test_accuracy                 0.9866\n",
            "2023-05-25 11:27:21,972 simple_logger.py log_once [line:28] INFO test_loss                     0.0535\n",
            "2023-05-25 11:27:21,976 simple_logger.py log_once [line:28] INFO valid_accuracy                0.9853\n",
            "2023-05-25 11:27:21,979 simple_logger.py log_once [line:28] INFO mean_valid_accuracy           0.9853\n",
            "2023-05-25 11:27:21,981 simple_logger.py log_once [line:28] INFO std_valid_accuracy            0.0038\n",
            "2023-05-25 11:27:21,988 simple_logger.py log_once [line:28] INFO valid_loss                    0.0675\n",
            "2023-05-25 11:27:21,989 simple_logger.py log_once [line:28] INFO mean_valid_loss               0.0675\n",
            "2023-05-25 11:27:21,993 simple_logger.py log_once [line:28] INFO std_valid_loss                0.0280\n",
            "2023-05-25 11:27:21,994 fedbase.py run [line:251] INFO Eval Time Cost:               4.2129s\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0, 1]\n",
            "train: 0\n",
            "train: 1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-05-25 11:27:27,618 fedbase.py run [line:246] INFO --------------Round 10--------------\n",
            "2023-05-25 11:27:27,620 simple_logger.py log_once [line:14] INFO Current_time:10\n",
            "2023-05-25 11:27:33,401 simple_logger.py log_once [line:28] INFO test_accuracy                 0.9867\n",
            "2023-05-25 11:27:33,403 simple_logger.py log_once [line:28] INFO test_loss                     0.0599\n",
            "2023-05-25 11:27:33,406 simple_logger.py log_once [line:28] INFO valid_accuracy                0.9827\n",
            "2023-05-25 11:27:33,409 simple_logger.py log_once [line:28] INFO mean_valid_accuracy           0.9827\n",
            "2023-05-25 11:27:33,411 simple_logger.py log_once [line:28] INFO std_valid_accuracy            0.0070\n",
            "2023-05-25 11:27:33,413 simple_logger.py log_once [line:28] INFO valid_loss                    0.0777\n",
            "2023-05-25 11:27:33,421 simple_logger.py log_once [line:28] INFO mean_valid_loss               0.0777\n",
            "2023-05-25 11:27:33,423 simple_logger.py log_once [line:28] INFO std_valid_loss                0.0308\n",
            "2023-05-25 11:27:33,425 fedbase.py run [line:251] INFO Eval Time Cost:               5.8055s\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0, 1]\n",
            "train: 0\n",
            "train: 1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-05-25 11:27:38,893 fedbase.py run [line:246] INFO --------------Round 11--------------\n",
            "2023-05-25 11:27:38,894 simple_logger.py log_once [line:14] INFO Current_time:11\n",
            "2023-05-25 11:27:43,106 simple_logger.py log_once [line:28] INFO test_accuracy                 0.9881\n",
            "2023-05-25 11:27:43,112 simple_logger.py log_once [line:28] INFO test_loss                     0.0560\n",
            "2023-05-25 11:27:43,115 simple_logger.py log_once [line:28] INFO valid_accuracy                0.9862\n",
            "2023-05-25 11:27:43,118 simple_logger.py log_once [line:28] INFO mean_valid_accuracy           0.9862\n",
            "2023-05-25 11:27:43,123 simple_logger.py log_once [line:28] INFO std_valid_accuracy            0.0043\n",
            "2023-05-25 11:27:43,124 simple_logger.py log_once [line:28] INFO valid_loss                    0.0696\n",
            "2023-05-25 11:27:43,125 simple_logger.py log_once [line:28] INFO mean_valid_loss               0.0696\n",
            "2023-05-25 11:27:43,126 simple_logger.py log_once [line:28] INFO std_valid_loss                0.0312\n",
            "2023-05-25 11:27:43,127 fedbase.py run [line:251] INFO Eval Time Cost:               4.2331s\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0, 1]\n",
            "train: 0\n",
            "train: 1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-05-25 11:27:49,767 fedbase.py run [line:246] INFO --------------Round 12--------------\n",
            "2023-05-25 11:27:49,768 simple_logger.py log_once [line:14] INFO Current_time:12\n",
            "2023-05-25 11:27:53,905 simple_logger.py log_once [line:28] INFO test_accuracy                 0.9881\n",
            "2023-05-25 11:27:53,906 simple_logger.py log_once [line:28] INFO test_loss                     0.0527\n",
            "2023-05-25 11:27:53,913 simple_logger.py log_once [line:28] INFO valid_accuracy                0.9860\n",
            "2023-05-25 11:27:53,917 simple_logger.py log_once [line:28] INFO mean_valid_accuracy           0.9860\n",
            "2023-05-25 11:27:53,920 simple_logger.py log_once [line:28] INFO std_valid_accuracy            0.0052\n",
            "2023-05-25 11:27:53,922 simple_logger.py log_once [line:28] INFO valid_loss                    0.0674\n",
            "2023-05-25 11:27:53,923 simple_logger.py log_once [line:28] INFO mean_valid_loss               0.0674\n",
            "2023-05-25 11:27:53,924 simple_logger.py log_once [line:28] INFO std_valid_loss                0.0272\n",
            "2023-05-25 11:27:53,926 fedbase.py run [line:251] INFO Eval Time Cost:               4.1574s\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0, 1]\n",
            "train: 0\n",
            "train: 1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-05-25 11:27:59,882 fedbase.py run [line:246] INFO --------------Round 13--------------\n",
            "2023-05-25 11:27:59,886 simple_logger.py log_once [line:14] INFO Current_time:13\n",
            "2023-05-25 11:28:04,860 simple_logger.py log_once [line:28] INFO test_accuracy                 0.9880\n",
            "2023-05-25 11:28:04,861 simple_logger.py log_once [line:28] INFO test_loss                     0.0539\n",
            "2023-05-25 11:28:04,863 simple_logger.py log_once [line:28] INFO valid_accuracy                0.9860\n",
            "2023-05-25 11:28:04,865 simple_logger.py log_once [line:28] INFO mean_valid_accuracy           0.9860\n",
            "2023-05-25 11:28:04,869 simple_logger.py log_once [line:28] INFO std_valid_accuracy            0.0052\n",
            "2023-05-25 11:28:04,871 simple_logger.py log_once [line:28] INFO valid_loss                    0.0690\n",
            "2023-05-25 11:28:04,873 simple_logger.py log_once [line:28] INFO mean_valid_loss               0.0690\n",
            "2023-05-25 11:28:04,879 simple_logger.py log_once [line:28] INFO std_valid_loss                0.0281\n",
            "2023-05-25 11:28:04,880 fedbase.py run [line:251] INFO Eval Time Cost:               4.9936s\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0, 1]\n",
            "train: 0\n",
            "train: 1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-05-25 11:28:10,341 fedbase.py run [line:246] INFO --------------Round 14--------------\n",
            "2023-05-25 11:28:10,342 simple_logger.py log_once [line:14] INFO Current_time:14\n",
            "2023-05-25 11:28:15,503 simple_logger.py log_once [line:28] INFO test_accuracy                 0.9879\n",
            "2023-05-25 11:28:15,505 simple_logger.py log_once [line:28] INFO test_loss                     0.0549\n",
            "2023-05-25 11:28:15,512 simple_logger.py log_once [line:28] INFO valid_accuracy                0.9858\n",
            "2023-05-25 11:28:15,514 simple_logger.py log_once [line:28] INFO mean_valid_accuracy           0.9858\n",
            "2023-05-25 11:28:15,516 simple_logger.py log_once [line:28] INFO std_valid_accuracy            0.0052\n",
            "2023-05-25 11:28:15,519 simple_logger.py log_once [line:28] INFO valid_loss                    0.0703\n",
            "2023-05-25 11:28:15,521 simple_logger.py log_once [line:28] INFO mean_valid_loss               0.0703\n",
            "2023-05-25 11:28:15,523 simple_logger.py log_once [line:28] INFO std_valid_loss                0.0286\n",
            "2023-05-25 11:28:15,526 fedbase.py run [line:251] INFO Eval Time Cost:               5.1839s\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0, 1]\n",
            "train: 0\n",
            "train: 1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-05-25 11:28:21,299 fedbase.py run [line:246] INFO --------------Round 15--------------\n",
            "2023-05-25 11:28:21,300 simple_logger.py log_once [line:14] INFO Current_time:15\n",
            "2023-05-25 11:28:25,576 simple_logger.py log_once [line:28] INFO test_accuracy                 0.9880\n",
            "2023-05-25 11:28:25,578 simple_logger.py log_once [line:28] INFO test_loss                     0.0558\n",
            "2023-05-25 11:28:25,584 simple_logger.py log_once [line:28] INFO valid_accuracy                0.9863\n",
            "2023-05-25 11:28:25,588 simple_logger.py log_once [line:28] INFO mean_valid_accuracy           0.9863\n",
            "2023-05-25 11:28:25,590 simple_logger.py log_once [line:28] INFO std_valid_accuracy            0.0056\n",
            "2023-05-25 11:28:25,593 simple_logger.py log_once [line:28] INFO valid_loss                    0.0715\n",
            "2023-05-25 11:28:25,601 simple_logger.py log_once [line:28] INFO mean_valid_loss               0.0715\n",
            "2023-05-25 11:28:25,602 simple_logger.py log_once [line:28] INFO std_valid_loss                0.0291\n",
            "2023-05-25 11:28:25,603 fedbase.py run [line:251] INFO Eval Time Cost:               4.3030s\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0, 1]\n",
            "train: 0\n",
            "train: 1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-05-25 11:28:32,187 fedbase.py run [line:246] INFO --------------Round 16--------------\n",
            "2023-05-25 11:28:32,189 simple_logger.py log_once [line:14] INFO Current_time:16\n",
            "2023-05-25 11:28:36,226 simple_logger.py log_once [line:28] INFO test_accuracy                 0.9880\n",
            "2023-05-25 11:28:36,227 simple_logger.py log_once [line:28] INFO test_loss                     0.0565\n",
            "2023-05-25 11:28:36,232 simple_logger.py log_once [line:28] INFO valid_accuracy                0.9863\n",
            "2023-05-25 11:28:36,236 simple_logger.py log_once [line:28] INFO mean_valid_accuracy           0.9863\n",
            "2023-05-25 11:28:36,238 simple_logger.py log_once [line:28] INFO std_valid_accuracy            0.0056\n",
            "2023-05-25 11:28:36,240 simple_logger.py log_once [line:28] INFO valid_loss                    0.0725\n",
            "2023-05-25 11:28:36,243 simple_logger.py log_once [line:28] INFO mean_valid_loss               0.0725\n",
            "2023-05-25 11:28:36,245 simple_logger.py log_once [line:28] INFO std_valid_loss                0.0296\n",
            "2023-05-25 11:28:36,250 fedbase.py run [line:251] INFO Eval Time Cost:               4.0611s\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0, 1]\n",
            "train: 0\n",
            "train: 1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-05-25 11:28:42,063 fedbase.py run [line:246] INFO --------------Round 17--------------\n",
            "2023-05-25 11:28:42,066 simple_logger.py log_once [line:14] INFO Current_time:17\n",
            "2023-05-25 11:28:47,162 simple_logger.py log_once [line:28] INFO test_accuracy                 0.9880\n",
            "2023-05-25 11:28:47,164 simple_logger.py log_once [line:28] INFO test_loss                     0.0572\n",
            "2023-05-25 11:28:47,166 simple_logger.py log_once [line:28] INFO valid_accuracy                0.9863\n",
            "2023-05-25 11:28:47,170 simple_logger.py log_once [line:28] INFO mean_valid_accuracy           0.9863\n",
            "2023-05-25 11:28:47,172 simple_logger.py log_once [line:28] INFO std_valid_accuracy            0.0056\n",
            "2023-05-25 11:28:47,175 simple_logger.py log_once [line:28] INFO valid_loss                    0.0733\n",
            "2023-05-25 11:28:47,176 simple_logger.py log_once [line:28] INFO mean_valid_loss               0.0733\n",
            "2023-05-25 11:28:47,177 simple_logger.py log_once [line:28] INFO std_valid_loss                0.0300\n",
            "2023-05-25 11:28:47,178 fedbase.py run [line:251] INFO Eval Time Cost:               5.1127s\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0, 1]\n",
            "train: 0\n",
            "train: 1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-05-25 11:28:52,544 fedbase.py run [line:246] INFO --------------Round 18--------------\n",
            "2023-05-25 11:28:52,545 simple_logger.py log_once [line:14] INFO Current_time:18\n",
            "2023-05-25 11:28:57,455 simple_logger.py log_once [line:28] INFO test_accuracy                 0.9880\n",
            "2023-05-25 11:28:57,459 simple_logger.py log_once [line:28] INFO test_loss                     0.0578\n",
            "2023-05-25 11:28:57,464 simple_logger.py log_once [line:28] INFO valid_accuracy                0.9862\n",
            "2023-05-25 11:28:57,466 simple_logger.py log_once [line:28] INFO mean_valid_accuracy           0.9862\n",
            "2023-05-25 11:28:57,472 simple_logger.py log_once [line:28] INFO std_valid_accuracy            0.0055\n",
            "2023-05-25 11:28:57,473 simple_logger.py log_once [line:28] INFO valid_loss                    0.0741\n",
            "2023-05-25 11:28:57,474 simple_logger.py log_once [line:28] INFO mean_valid_loss               0.0741\n",
            "2023-05-25 11:28:57,475 simple_logger.py log_once [line:28] INFO std_valid_loss                0.0303\n",
            "2023-05-25 11:28:57,477 fedbase.py run [line:251] INFO Eval Time Cost:               4.9316s\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0, 1]\n",
            "train: 0\n",
            "train: 1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-05-25 11:29:03,394 fedbase.py run [line:246] INFO --------------Round 19--------------\n",
            "2023-05-25 11:29:03,395 simple_logger.py log_once [line:14] INFO Current_time:19\n",
            "2023-05-25 11:29:07,421 simple_logger.py log_once [line:28] INFO test_accuracy                 0.9880\n",
            "2023-05-25 11:29:07,423 simple_logger.py log_once [line:28] INFO test_loss                     0.0583\n",
            "2023-05-25 11:29:07,424 simple_logger.py log_once [line:28] INFO valid_accuracy                0.9865\n",
            "2023-05-25 11:29:07,426 simple_logger.py log_once [line:28] INFO mean_valid_accuracy           0.9865\n",
            "2023-05-25 11:29:07,436 simple_logger.py log_once [line:28] INFO std_valid_accuracy            0.0052\n",
            "2023-05-25 11:29:07,441 simple_logger.py log_once [line:28] INFO valid_loss                    0.0748\n",
            "2023-05-25 11:29:07,443 simple_logger.py log_once [line:28] INFO mean_valid_loss               0.0748\n",
            "2023-05-25 11:29:07,444 simple_logger.py log_once [line:28] INFO std_valid_loss                0.0307\n",
            "2023-05-25 11:29:07,447 fedbase.py run [line:251] INFO Eval Time Cost:               4.0519s\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0, 1]\n",
            "train: 0\n",
            "train: 1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-05-25 11:29:14,012 fedbase.py run [line:246] INFO --------------Round 20--------------\n",
            "2023-05-25 11:29:14,014 simple_logger.py log_once [line:14] INFO Current_time:20\n",
            "2023-05-25 11:29:18,107 simple_logger.py log_once [line:28] INFO test_accuracy                 0.9880\n",
            "2023-05-25 11:29:18,109 simple_logger.py log_once [line:28] INFO test_loss                     0.0588\n",
            "2023-05-25 11:29:18,110 simple_logger.py log_once [line:28] INFO valid_accuracy                0.9865\n",
            "2023-05-25 11:29:18,119 simple_logger.py log_once [line:28] INFO mean_valid_accuracy           0.9865\n",
            "2023-05-25 11:29:18,122 simple_logger.py log_once [line:28] INFO std_valid_accuracy            0.0052\n",
            "2023-05-25 11:29:18,124 simple_logger.py log_once [line:28] INFO valid_loss                    0.0754\n",
            "2023-05-25 11:29:18,128 simple_logger.py log_once [line:28] INFO mean_valid_loss               0.0754\n",
            "2023-05-25 11:29:18,131 simple_logger.py log_once [line:28] INFO std_valid_loss                0.0310\n",
            "2023-05-25 11:29:18,135 fedbase.py run [line:251] INFO Eval Time Cost:               4.1209s\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0, 1]\n",
            "train: 0\n",
            "train: 1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-05-25 11:29:23,625 fedbase.py run [line:246] INFO --------------Round 21--------------\n",
            "2023-05-25 11:29:23,627 simple_logger.py log_once [line:14] INFO Current_time:21\n",
            "2023-05-25 11:29:29,116 simple_logger.py log_once [line:28] INFO test_accuracy                 0.9880\n",
            "2023-05-25 11:29:29,118 simple_logger.py log_once [line:28] INFO test_loss                     0.0592\n",
            "2023-05-25 11:29:29,124 simple_logger.py log_once [line:28] INFO valid_accuracy                0.9865\n",
            "2023-05-25 11:29:29,126 simple_logger.py log_once [line:28] INFO mean_valid_accuracy           0.9865\n",
            "2023-05-25 11:29:29,129 simple_logger.py log_once [line:28] INFO std_valid_accuracy            0.0052\n",
            "2023-05-25 11:29:29,130 simple_logger.py log_once [line:28] INFO valid_loss                    0.0759\n",
            "2023-05-25 11:29:29,134 simple_logger.py log_once [line:28] INFO mean_valid_loss               0.0759\n",
            "2023-05-25 11:29:29,134 simple_logger.py log_once [line:28] INFO std_valid_loss                0.0312\n",
            "2023-05-25 11:29:29,136 fedbase.py run [line:251] INFO Eval Time Cost:               5.5084s\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0, 1]\n",
            "train: 0\n",
            "train: 1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-05-25 11:29:34,552 fedbase.py run [line:246] INFO --------------Round 22--------------\n",
            "2023-05-25 11:29:34,553 simple_logger.py log_once [line:14] INFO Current_time:22\n",
            "2023-05-25 11:29:39,091 simple_logger.py log_once [line:28] INFO test_accuracy                 0.9880\n",
            "2023-05-25 11:29:39,094 simple_logger.py log_once [line:28] INFO test_loss                     0.0597\n",
            "2023-05-25 11:29:39,096 simple_logger.py log_once [line:28] INFO valid_accuracy                0.9865\n",
            "2023-05-25 11:29:39,098 simple_logger.py log_once [line:28] INFO mean_valid_accuracy           0.9865\n",
            "2023-05-25 11:29:39,100 simple_logger.py log_once [line:28] INFO std_valid_accuracy            0.0052\n",
            "2023-05-25 11:29:39,102 simple_logger.py log_once [line:28] INFO valid_loss                    0.0765\n",
            "2023-05-25 11:29:39,107 simple_logger.py log_once [line:28] INFO mean_valid_loss               0.0765\n",
            "2023-05-25 11:29:39,108 simple_logger.py log_once [line:28] INFO std_valid_loss                0.0315\n",
            "2023-05-25 11:29:39,109 fedbase.py run [line:251] INFO Eval Time Cost:               4.5562s\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0, 1]\n",
            "train: 0\n",
            "train: 1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-05-25 11:29:45,390 fedbase.py run [line:246] INFO --------------Round 23--------------\n",
            "2023-05-25 11:29:45,392 simple_logger.py log_once [line:14] INFO Current_time:23\n",
            "2023-05-25 11:29:49,418 simple_logger.py log_once [line:28] INFO test_accuracy                 0.9880\n",
            "2023-05-25 11:29:49,419 simple_logger.py log_once [line:28] INFO test_loss                     0.0600\n",
            "2023-05-25 11:29:49,420 simple_logger.py log_once [line:28] INFO valid_accuracy                0.9865\n",
            "2023-05-25 11:29:49,426 simple_logger.py log_once [line:28] INFO mean_valid_accuracy           0.9865\n",
            "2023-05-25 11:29:49,430 simple_logger.py log_once [line:28] INFO std_valid_accuracy            0.0052\n",
            "2023-05-25 11:29:49,432 simple_logger.py log_once [line:28] INFO valid_loss                    0.0770\n",
            "2023-05-25 11:29:49,436 simple_logger.py log_once [line:28] INFO mean_valid_loss               0.0770\n",
            "2023-05-25 11:29:49,437 simple_logger.py log_once [line:28] INFO std_valid_loss                0.0317\n",
            "2023-05-25 11:29:49,438 fedbase.py run [line:251] INFO Eval Time Cost:               4.0464s\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0, 1]\n",
            "train: 0\n",
            "train: 1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-05-25 11:29:55,921 fedbase.py run [line:246] INFO --------------Round 24--------------\n",
            "2023-05-25 11:29:55,927 simple_logger.py log_once [line:14] INFO Current_time:24\n",
            "2023-05-25 11:30:00,129 simple_logger.py log_once [line:28] INFO test_accuracy                 0.9881\n",
            "2023-05-25 11:30:00,130 simple_logger.py log_once [line:28] INFO test_loss                     0.0604\n",
            "2023-05-25 11:30:00,135 simple_logger.py log_once [line:28] INFO valid_accuracy                0.9865\n",
            "2023-05-25 11:30:00,136 simple_logger.py log_once [line:28] INFO mean_valid_accuracy           0.9865\n",
            "2023-05-25 11:30:00,139 simple_logger.py log_once [line:28] INFO std_valid_accuracy            0.0052\n",
            "2023-05-25 11:30:00,144 simple_logger.py log_once [line:28] INFO valid_loss                    0.0775\n",
            "2023-05-25 11:30:00,145 simple_logger.py log_once [line:28] INFO mean_valid_loss               0.0775\n",
            "2023-05-25 11:30:00,146 simple_logger.py log_once [line:28] INFO std_valid_loss                0.0320\n",
            "2023-05-25 11:30:00,147 fedbase.py run [line:251] INFO Eval Time Cost:               4.2198s\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0, 1]\n",
            "train: 0\n",
            "train: 1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-05-25 11:30:05,624 fedbase.py run [line:246] INFO --------------Round 25--------------\n",
            "2023-05-25 11:30:05,625 simple_logger.py log_once [line:14] INFO Current_time:25\n",
            "2023-05-25 11:30:11,087 simple_logger.py log_once [line:28] INFO test_accuracy                 0.9881\n",
            "2023-05-25 11:30:11,088 simple_logger.py log_once [line:28] INFO test_loss                     0.0607\n",
            "2023-05-25 11:30:11,090 simple_logger.py log_once [line:28] INFO valid_accuracy                0.9865\n",
            "2023-05-25 11:30:11,096 simple_logger.py log_once [line:28] INFO mean_valid_accuracy           0.9865\n",
            "2023-05-25 11:30:11,098 simple_logger.py log_once [line:28] INFO std_valid_accuracy            0.0052\n",
            "2023-05-25 11:30:11,099 simple_logger.py log_once [line:28] INFO valid_loss                    0.0779\n",
            "2023-05-25 11:30:11,101 simple_logger.py log_once [line:28] INFO mean_valid_loss               0.0779\n",
            "2023-05-25 11:30:11,102 simple_logger.py log_once [line:28] INFO std_valid_loss                0.0322\n",
            "2023-05-25 11:30:11,103 fedbase.py run [line:251] INFO Eval Time Cost:               5.4783s\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0, 1]\n",
            "train: 0\n",
            "train: 1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-05-25 11:30:16,498 fedbase.py run [line:246] INFO --------------Round 26--------------\n",
            "2023-05-25 11:30:16,500 simple_logger.py log_once [line:14] INFO Current_time:26\n",
            "2023-05-25 11:30:20,642 simple_logger.py log_once [line:28] INFO test_accuracy                 0.9881\n",
            "2023-05-25 11:30:20,649 simple_logger.py log_once [line:28] INFO test_loss                     0.0610\n",
            "2023-05-25 11:30:20,651 simple_logger.py log_once [line:28] INFO valid_accuracy                0.9865\n",
            "2023-05-25 11:30:20,653 simple_logger.py log_once [line:28] INFO mean_valid_accuracy           0.9865\n",
            "2023-05-25 11:30:20,659 simple_logger.py log_once [line:28] INFO std_valid_accuracy            0.0052\n",
            "2023-05-25 11:30:20,660 simple_logger.py log_once [line:28] INFO valid_loss                    0.0783\n",
            "2023-05-25 11:30:20,662 simple_logger.py log_once [line:28] INFO mean_valid_loss               0.0783\n",
            "2023-05-25 11:30:20,663 simple_logger.py log_once [line:28] INFO std_valid_loss                0.0324\n",
            "2023-05-25 11:30:20,664 fedbase.py run [line:251] INFO Eval Time Cost:               4.1641s\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0, 1]\n",
            "train: 0\n",
            "train: 1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-05-25 11:30:27,165 fedbase.py run [line:246] INFO --------------Round 27--------------\n",
            "2023-05-25 11:30:27,166 simple_logger.py log_once [line:14] INFO Current_time:27\n",
            "2023-05-25 11:30:31,334 simple_logger.py log_once [line:28] INFO test_accuracy                 0.9881\n",
            "2023-05-25 11:30:31,336 simple_logger.py log_once [line:28] INFO test_loss                     0.0613\n",
            "2023-05-25 11:30:31,338 simple_logger.py log_once [line:28] INFO valid_accuracy                0.9865\n",
            "2023-05-25 11:30:31,342 simple_logger.py log_once [line:28] INFO mean_valid_accuracy           0.9865\n",
            "2023-05-25 11:30:31,344 simple_logger.py log_once [line:28] INFO std_valid_accuracy            0.0052\n",
            "2023-05-25 11:30:31,346 simple_logger.py log_once [line:28] INFO valid_loss                    0.0787\n",
            "2023-05-25 11:30:31,347 simple_logger.py log_once [line:28] INFO mean_valid_loss               0.0787\n",
            "2023-05-25 11:30:31,348 simple_logger.py log_once [line:28] INFO std_valid_loss                0.0325\n",
            "2023-05-25 11:30:31,349 fedbase.py run [line:251] INFO Eval Time Cost:               4.1832s\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0, 1]\n",
            "train: 0\n",
            "train: 1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-05-25 11:30:37,405 fedbase.py run [line:246] INFO --------------Round 28--------------\n",
            "2023-05-25 11:30:37,412 simple_logger.py log_once [line:14] INFO Current_time:28\n",
            "2023-05-25 11:30:42,116 simple_logger.py log_once [line:28] INFO test_accuracy                 0.9881\n",
            "2023-05-25 11:30:42,117 simple_logger.py log_once [line:28] INFO test_loss                     0.0616\n",
            "2023-05-25 11:30:42,121 simple_logger.py log_once [line:28] INFO valid_accuracy                0.9865\n",
            "2023-05-25 11:30:42,123 simple_logger.py log_once [line:28] INFO mean_valid_accuracy           0.9865\n",
            "2023-05-25 11:30:42,125 simple_logger.py log_once [line:28] INFO std_valid_accuracy            0.0052\n",
            "2023-05-25 11:30:42,127 simple_logger.py log_once [line:28] INFO valid_loss                    0.0791\n",
            "2023-05-25 11:30:42,128 simple_logger.py log_once [line:28] INFO mean_valid_loss               0.0791\n",
            "2023-05-25 11:30:42,129 simple_logger.py log_once [line:28] INFO std_valid_loss                0.0327\n",
            "2023-05-25 11:30:42,131 fedbase.py run [line:251] INFO Eval Time Cost:               4.7189s\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0, 1]\n",
            "train: 0\n",
            "train: 1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-05-25 11:30:47,518 fedbase.py run [line:246] INFO --------------Round 29--------------\n",
            "2023-05-25 11:30:47,519 simple_logger.py log_once [line:14] INFO Current_time:29\n",
            "2023-05-25 11:30:52,839 simple_logger.py log_once [line:28] INFO test_accuracy                 0.9881\n",
            "2023-05-25 11:30:52,843 simple_logger.py log_once [line:28] INFO test_loss                     0.0619\n",
            "2023-05-25 11:30:52,845 simple_logger.py log_once [line:28] INFO valid_accuracy                0.9867\n",
            "2023-05-25 11:30:52,848 simple_logger.py log_once [line:28] INFO mean_valid_accuracy           0.9867\n",
            "2023-05-25 11:30:52,849 simple_logger.py log_once [line:28] INFO std_valid_accuracy            0.0053\n",
            "2023-05-25 11:30:52,852 simple_logger.py log_once [line:28] INFO valid_loss                    0.0795\n",
            "2023-05-25 11:30:52,855 simple_logger.py log_once [line:28] INFO mean_valid_loss               0.0795\n",
            "2023-05-25 11:30:52,857 simple_logger.py log_once [line:28] INFO std_valid_loss                0.0329\n",
            "2023-05-25 11:30:52,858 fedbase.py run [line:251] INFO Eval Time Cost:               5.3395s\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0, 1]\n",
            "train: 0\n",
            "train: 1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-05-25 11:30:58,339 fedbase.py run [line:246] INFO --------------Round 30--------------\n",
            "2023-05-25 11:30:58,341 simple_logger.py log_once [line:14] INFO Current_time:30\n",
            "2023-05-25 11:31:02,367 simple_logger.py log_once [line:28] INFO test_accuracy                 0.9881\n",
            "2023-05-25 11:31:02,368 simple_logger.py log_once [line:28] INFO test_loss                     0.0621\n",
            "2023-05-25 11:31:02,372 simple_logger.py log_once [line:28] INFO valid_accuracy                0.9867\n",
            "2023-05-25 11:31:02,374 simple_logger.py log_once [line:28] INFO mean_valid_accuracy           0.9867\n",
            "2023-05-25 11:31:02,375 simple_logger.py log_once [line:28] INFO std_valid_accuracy            0.0053\n",
            "2023-05-25 11:31:02,377 simple_logger.py log_once [line:28] INFO valid_loss                    0.0798\n",
            "2023-05-25 11:31:02,379 simple_logger.py log_once [line:28] INFO mean_valid_loss               0.0798\n",
            "2023-05-25 11:31:02,380 simple_logger.py log_once [line:28] INFO std_valid_loss                0.0330\n",
            "2023-05-25 11:31:02,381 fedbase.py run [line:251] INFO Eval Time Cost:               4.0400s\n",
            "2023-05-25 11:31:02,382 fedbase.py run [line:257] INFO =================End==================\n",
            "2023-05-25 11:31:02,383 fedbase.py run [line:258] INFO Total Time Cost:              321.9190s\n"
          ]
        }
      ],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B79JdhjStVO7"
      },
      "source": [
        "# 代码修改"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A1_2r44gc7N0",
        "outputId": "74b4c194-e5c7-4620-8aee-9bd3aa0c1893"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-06-27 08:34:39,239 fflow.py init [line:441] INFO Initializing devices: cpu will be used for this running.\n",
            "2023-06-27 08:34:39,316 fflow.py init [line:479] INFO Use `<class 'flgo.simulator.default_simulator.Simulator'>` as the system simulator\n",
            "2023-06-27 08:34:39,325 fflow.py init [line:487] INFO Ready to start.\n"
          ]
        }
      ],
      "source": [
        "# 定义一个任务\n",
        "import flgo\n",
        "import torch\n",
        "import flgo.algorithm.fedprox as fedprox\n",
        "import flgo.algorithm.fedavg as fedavg\n",
        "task = './mnist_dir10'\n",
        "config_dir10 = {'benchmark':{'name':'flgo.benchmark.mnist_classification'},'partitioner':{'name': 'DirichletPartitioner','para':{'num_clients':10, 'alpha':1.0}}}\n",
        "if not os.path.exists(task): flgo.gen_task(config_dir10, task_path = task)\n",
        "option = {'num_rounds':10, 'num_epochs':1, 'batch_size':8, 'learning_rate':0.1, 'gpu':0 if torch.cuda.is_available() else ''}\n",
        "runner = flgo.init(task, fedavg, option=option)\n",
        "#runner.run()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g7SgfxA-YhsQ",
        "outputId": "7814a087-4013-4d52-eace-f4fc01326bf7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'benchmark': 'flgo.benchmark.mnist_classification',\n",
              " 'scene': 'unknown',\n",
              " 'num_clients': 10}"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import importlib\n",
        "import json\n",
        "task= './mnist_dir10'\n",
        "with open(os.path.join(task, 'info'), 'r') as inf:\n",
        "    task_info = json.load(inf)\n",
        "\n",
        "task_info"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9YfBwTrDWvsa",
        "outputId": "0bb7951d-95bd-4987-e33e-ec6c9008f9d4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<module 'flgo.benchmark.mnist_classification.model.cnn' from '/content/FLGo/flgo/benchmark/mnist_classification/model/cnn.py'>\n"
          ]
        }
      ],
      "source": [
        "bmk_module = importlib.import_module(task_info['benchmark'])\n",
        "model = getattr(bmk_module, 'default_model')\n",
        "model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CLHZN0pv3Pn9"
      },
      "source": [
        "## 访问client0查看它的成员 [BasicClient](https://github.com/WwZzz/easyFL/blob/4b05d3d982bb32eb43efd08b3f104e0f8ce1fd5b/flgo/algorithm/fedbase.py#L608)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BH2NxJlY3Oou",
        "outputId": "d0d893b2-a5a4-46a7-e271-f40c7ed6800e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "optimizer_name:\t SGD\n",
            "[task]:    \t ./mnist_dir10\n",
            "discriminator(\n",
            "  (conv): Sequential(\n",
            "    (0): Conv2d(1, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
            "    (1): LeakyReLU(negative_slope=0.2)\n",
            "    (2): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
            "    (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (4): LeakyReLU(negative_slope=0.2)\n",
            "  )\n",
            "  (fc): Sequential(\n",
            "    (0): Linear(in_features=6272, out_features=1024, bias=True)\n",
            "    (1): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): LeakyReLU(negative_slope=0.2)\n",
            "    (3): Linear(in_features=1024, out_features=13, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "client=runner.clients[0] #runner本身是surver\n",
        "#print(get_Normalize_mean_std(client.train_data.dataset.dataset.transform))\n",
        "print(\"optimizer_name:\\t\",client.optimizer_name)\n",
        "print(\"[task]:    \\t\",client.option['task'])\n",
        "print(client.gan.D)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nBzZ1hD5-v1Z"
      },
      "source": [
        "## 访问surver查看它的成员 [code](https://github.com/WwZzz/easyFL/blob/4b05d3d982bb32eb43efd08b3f104e0f8ce1fd5b/flgo/algorithm/fedbase.py#L196)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RO1lVpzv_ANR",
        "outputId": "cc5f583e-95f4-44bf-e40a-627bbde126d3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "task:  ./mnist_dir01\n"
          ]
        }
      ],
      "source": [
        "print(\"task: \",runner.task)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dyust92r_wuQ",
        "outputId": "c56d4429-99d4-4818-c608-9007a60313f1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model(\n",
            "  (conv1): Conv2d(1, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
            "  (conv2): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
            "  (fc1): Linear(in_features=3136, out_features=512, bias=True)\n",
            "  (fc2): Linear(in_features=512, out_features=10, bias=True)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "print(runner.model) #默认的model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HvR3NaJ4a31p"
      },
      "source": [
        "## test,测试代码在这里\n",
        "https://github.com/WwZzz/easyFL/blob/FLGo/flgo/benchmark/toolkits/cv/classification/__init__.py#L202\n",
        "- 调用.test()的时候输入dataset\n",
        "- 客户端本地进行test？：https://github.com/WwZzz/easyFL/blob/FLGo/flgo/algorithm/fedbase.py#L487\n",
        "- `from flgo.benchmark.toolkits.cv.classification import GeneralCalculator, FromDatasetPipe, FromDatasetGenerator`\n",
        "https://github.com/WwZzz/easyFL/blob/4b05d3d982bb32eb43efd08b3f104e0f8ce1fd5b/flgo/benchmark/toolkits/cv/classification/__init__.py#L228"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5qxgRVVma3DL",
        "outputId": "729dcd8a-f5fc-4144-cc68-6cca2282192e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0 : {'accuracy': 0.01839464882943144, 'loss': 2.207299742012917}\n",
            "1 : {'accuracy': 0.017035775127768313, 'loss': 2.306316253070734}\n",
            "2 : {'accuracy': 0.07588532883642496, 'loss': 2.3723134475855963}\n",
            "3 : {'accuracy': 0.10378912685337727, 'loss': 2.104594892882044}\n",
            "4 : {'accuracy': 0.029605263157894735, 'loss': 2.1388067697223865}\n",
            "5 : {'accuracy': 0.008417508417508417, 'loss': 2.2206497850642863}\n",
            "6 : {'accuracy': 0.052202283849918436, 'loss': 2.128586469622265}\n",
            "7 : {'accuracy': 0.03225806451612903, 'loss': 2.4884150424918414}\n",
            "8 : {'accuracy': 0.04918032786885246, 'loss': 2.1802161974985093}\n",
            "9 : {'accuracy': 0.880672268907563, 'loss': 1.8864630470756723}\n",
            "G: {'accuracy': 0.1239, 'loss': 2.1986347305297853}\n"
          ]
        }
      ],
      "source": [
        "model=load(task+'/'+str(1)+'.pth',data_shape[1],data_shape[2]).to(runner.device)\n",
        "for i in range(10):\n",
        "  print(i,':',runner.clients[i].test(model)) #本地测试数据\n",
        "print('G:',runner.test(model)) #全局测试数据"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PxbiaOVWsAfJ"
      },
      "source": [
        "# 修改client"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JQo3H7GqsDfU"
      },
      "outputs": [],
      "source": [
        "class Client(BasicClient):\n",
        "  def reply(self, svr_pkg):#它调用了train\n",
        "      model = self.unpack(svr_pkg)\n",
        "      self.train(model)\n",
        "      cpkg = self.pack(model)\n",
        "      return cpkg"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pBnGAPVztX0t"
      },
      "source": [
        "## 添加一个参数\n",
        "直接在config这里添加，没有的就是None\n",
        "![image.png](data:image/png;base64,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)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "in1-W4svwYuo"
      },
      "source": [
        "option有默认值default_option = read_option_from_command() 【fflow.py】\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fSOfSwVAF9lI"
      },
      "source": [
        "# 删除文件夹"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rwDjAnx7F_1f"
      },
      "outputs": [],
      "source": [
        "!rm -r /content/FLGo/mnist_dir01"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z-EsUs8Dk4mW"
      },
      "source": [
        "# 将google云盘的代码上传到github"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IbgZW5g1crhL"
      },
      "source": [
        "## FLGo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iJ6aZaz0k6hn",
        "outputId": "5c4313b3-64b7-4b8b-ad98-92e3bdfecf7b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Reinitialized existing Git repository in /content/FLGo/.git/\n",
            "Cloning into 'FLGo'...\n",
            "remote: Enumerating objects: 5341, done.\u001b[K\n",
            "remote: Counting objects: 100% (1436/1436), done.\u001b[K\n",
            "remote: Compressing objects: 100% (552/552), done.\u001b[K\n",
            "remote: Total 5341 (delta 873), reused 1345 (delta 825), pack-reused 3905\u001b[K\n",
            "Receiving objects: 100% (5341/5341), 9.57 MiB | 5.67 MiB/s, done.\n",
            "Resolving deltas: 100% (3121/3121), done.\n"
          ]
        }
      ],
      "source": [
        "!git init\n",
        "!git config remote.origin.url 'https://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@github.com/hermittt/FLGo.git'\n",
        "#!git config remote.origin.url 'https://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@github.com/hermittt/FLGo.git'\n",
        "!git clone https://github.com/hermittt/FLGo.git\n",
        "!git config --global user.email \"499655727@qq.com\"\n",
        "!git config --global user.name \"hermittt\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n90yGwzn4uaM"
      },
      "outputs": [],
      "source": [
        "!git remote set-url origin 'https://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@github.com/hermittt/FLGo.git'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AcQEEKdP6Hbe"
      },
      "outputs": [],
      "source": [
        "!rm /content/FLGo/task/mnist_dir10_clients10 -r"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "edizMFkHlJVD",
        "outputId": "ef91170c-5b57-4cd3-f414-1a2b33fab694"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[my dd6b538] task\n",
            " 2 files changed, 2 insertions(+)\n",
            " create mode 100644 task/svhn_dir10/data.json\n",
            " create mode 100644 task/svhn_dir10/info\n",
            "From https://github.com/hermittt/FLGo\n",
            " * branch            my         -> FETCH_HEAD\n",
            "Already up to date.\n",
            "Enumerating objects: 8, done.\n",
            "Counting objects: 100% (8/8), done.\n",
            "Delta compression using up to 2 threads\n",
            "Compressing objects: 100% (6/6), done.\n",
            "Writing objects: 100% (6/6), 197.38 KiB | 2.63 MiB/s, done.\n",
            "Total 6 (delta 2), reused 0 (delta 0), pack-reused 0\n",
            "remote: Resolving deltas: 100% (2/2), completed with 2 local objects.\u001b[K\n",
            "To https://github.com/hermittt/FLGo.git\n",
            "   ac9c6b5..dd6b538  my -> my\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "CODEPATH=\"/content/FLGo\"\n",
        "os.chdir(CODEPATH)\n",
        "!git add /content/FLGo/task\n",
        "#!git add /content/FLGo/flgo/benchmark/fashion_classification/__init__.py\n",
        "!git commit -m \"task\"\n",
        "!git pull origin my\n",
        "!git push origin my"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bCwZgxfG4W6J",
        "outputId": "369f46d1-5b87-4ea8-909f-0c8bf3220040"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enumerating objects: 7, done.\n",
            "Counting objects:  14% (1/7)\rCounting objects:  28% (2/7)\rCounting objects:  42% (3/7)\rCounting objects:  57% (4/7)\rCounting objects:  71% (5/7)\rCounting objects:  85% (6/7)\rCounting objects: 100% (7/7)\rCounting objects: 100% (7/7), done.\n",
            "Delta compression using up to 2 threads\n",
            "Compressing objects:  20% (1/5)\rCompressing objects:  40% (2/5)\rCompressing objects:  60% (3/5)\rCompressing objects:  80% (4/5)\rCompressing objects: 100% (5/5)\rCompressing objects: 100% (5/5), done.\n",
            "Writing objects:  16% (1/6)\rWriting objects:  33% (2/6)\rWriting objects:  50% (3/6)\rWriting objects:  66% (4/6)\rWriting objects:  83% (5/6)\rWriting objects: 100% (6/6)\rWriting objects: 100% (6/6), 160.24 KiB | 3.73 MiB/s, done.\n",
            "Total 6 (delta 1), reused 0 (delta 0), pack-reused 0\n",
            "remote: Resolving deltas:   0% (0/1)\u001b[K\rremote: Resolving deltas: 100% (1/1)\u001b[K\rremote: Resolving deltas: 100% (1/1), completed with 1 local object.\u001b[K\n",
            "To https://github.com/hermittt/FLGo.git\n",
            "   9652dfa..8667377  my -> my\n"
          ]
        }
      ],
      "source": [
        "!git push origin my"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sSCqxE3EcxUZ"
      },
      "source": [
        "## GAN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p4VGFoZncqUW",
        "outputId": "932ad001-e2d2-4903-f314-6f4e21ec1ad1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Reinitialized existing Git repository in /content/GAN/.git/\n",
            "fatal: destination path 'pytorch-generative-model-collections' already exists and is not an empty directory.\n"
          ]
        }
      ],
      "source": [
        "!git init\n",
        "!git config remote.origin.url 'https://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@github.com/hermittt/pytorch-generative-model-collections.git'\n",
        "!git clone https://github.com/hermittt/pytorch-generative-model-collections.git\n",
        "!git config --global user.email \"499655727@qq.com\"\n",
        "!git config --global user.name \"hermittt\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H_9TY8RVdE_j",
        "outputId": "86f0b2cc-f126-4690-cd6d-f3d5ba62c7cb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "On branch my\n",
            "Your branch and 'origin/my' have diverged,\n",
            "and have 92 and 775 different commits each, respectively.\n",
            "  (use \"git pull\" to merge the remote branch into yours)\n",
            "\n",
            "Untracked files:\n",
            "  (use \"git add <file>...\" to include in what will be committed)\n",
            "\t\u001b[31mFLGo/\u001b[m\n",
            "\t\u001b[31m__pycache__/\u001b[m\n",
            "\t\u001b[31mdata/\u001b[m\n",
            "\t\u001b[31mpytorch-generative-model-collections/\u001b[m\n",
            "\n",
            "nothing added to commit but untracked files present (use \"git add\" to track)\n",
            "From https://github.com/hermittt/pytorch-generative-model-collections\n",
            " * branch            my         -> FETCH_HEAD\n",
            " + 26fe0a3...5e6400d my         -> origin/my  (forced update)\n",
            "Already up to date.\n",
            "Enumerating objects: 5, done.\n",
            "Counting objects: 100% (5/5), done.\n",
            "Delta compression using up to 2 threads\n",
            "Compressing objects: 100% (3/3), done.\n",
            "Writing objects: 100% (3/3), 288 bytes | 288.00 KiB/s, done.\n",
            "Total 3 (delta 2), reused 0 (delta 0), pack-reused 0\n",
            "remote: Resolving deltas: 100% (2/2), completed with 2 local objects.\u001b[K\n",
            "To https://github.com/hermittt/pytorch-generative-model-collections.git\n",
            "   5e6400d..9f4b072  my -> my\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "CODEPATH=\"/content/GAN\"\n",
        "os.chdir(CODEPATH)\n",
        "!git add /content/GAN/dataloader.py\n",
        "!git commit -m \"form colab\"\n",
        "!git pull origin my\n",
        "!git push origin my"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GPK-sNkcoV0k"
      },
      "outputs": [],
      "source": [
        "!git add /content/drive/MyDrive/Colab/easyFL/flgo/benchmark/toolkits/visualization.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6RADRnw4om_M",
        "outputId": "caf1d25d-d60c-4d3c-d1a6-543afbabc7bd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "M\tflgo/utils/fflow.py\n",
            "Switched to branch 'my'\n"
          ]
        }
      ],
      "source": [
        "!git branch my\n",
        "!git checkout my"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IU0ytmfqoYRv",
        "outputId": "7c285088-f47b-4ce0-ea64-bbcf3c898562"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enumerating objects: 11, done.\n",
            "Counting objects:   9% (1/11)\rCounting objects:  18% (2/11)\rCounting objects:  27% (3/11)\rCounting objects:  36% (4/11)\rCounting objects:  45% (5/11)\rCounting objects:  54% (6/11)\rCounting objects:  63% (7/11)\rCounting objects:  72% (8/11)\rCounting objects:  81% (9/11)\rCounting objects:  90% (10/11)\rCounting objects: 100% (11/11)\rCounting objects: 100% (11/11), done.\n",
            "Delta compression using up to 2 threads\n",
            "Compressing objects:  16% (1/6)\rCompressing objects:  33% (2/6)\rCompressing objects:  50% (3/6)\rCompressing objects:  66% (4/6)\rCompressing objects:  83% (5/6)\rCompressing objects: 100% (6/6)\rCompressing objects: 100% (6/6), done.\n",
            "Writing objects:  16% (1/6)\rWriting objects:  33% (2/6)\rWriting objects:  50% (3/6)\rWriting objects:  66% (4/6)\rWriting objects:  83% (5/6)\rWriting objects: 100% (6/6)\rWriting objects: 100% (6/6), 505 bytes | 126.00 KiB/s, done.\n",
            "Total 6 (delta 5), reused 0 (delta 0)\n",
            "remote: Resolving deltas:   0% (0/5)\u001b[K\rremote: Resolving deltas:  20% (1/5)\u001b[K\rremote: Resolving deltas:  40% (2/5)\u001b[K\rremote: Resolving deltas:  60% (3/5)\u001b[K\rremote: Resolving deltas:  80% (4/5)\u001b[K\rremote: Resolving deltas: 100% (5/5)\u001b[K\rremote: Resolving deltas: 100% (5/5), completed with 5 local objects.\u001b[K\n",
            "To https://github.com/hermittt/FLGo.git\n",
            "   4b05d3d..a7dce11  my -> my\n"
          ]
        }
      ],
      "source": [
        "!git push origin my"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 732
        },
        "id": "MZhVX8RdfcR7",
        "outputId": "fc464a38-e4f3-47b6-f374-1864bff3a47f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error: 0.00164234\n",
            "Error: 0.00129964\n",
            "Error: 0.00115567\n",
            "Error: 0.00089481\n",
            "Error: 0.00079232\n",
            "Error: 0.00049996\n",
            "Error: 0.00043670\n",
            "Error: 0.00042448\n",
            "Error: 0.00027098\n",
            "Error: 0.00024495\n",
            "Error: 0.00009273\n",
            "Error: 0.00002686\n",
            "Error: 0.00002152\n",
            "Error: 0.00000983\n",
            "Error: 0.00000690\n",
            "Error: 0.00000517\n",
            "Error: 0.00000309\n",
            "Error: 0.00000164\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-1ead97f14fde>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'./test_mnist'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'benchmark'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'name'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m'flgo.benchmark.mnist_classification'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'partitioner'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'name'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'DirichletPartitioner'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'para'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'num_clients'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mflgo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen_task\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtask_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/content/easyFL/flgo/utils/fflow.py\u001b[0m in \u001b[0;36mgen_task\u001b[0;34m(config, task_path, rawdata_path, seed)\u001b[0m\n\u001b[1;32m    336\u001b[0m             \u001b[0mpartitioner\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    337\u001b[0m     \u001b[0;31m# generate federated task\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 338\u001b[0;31m     \u001b[0mtask_generator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    339\u001b[0m     \u001b[0;31m# save the generated federated benchmark\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m     \u001b[0;31m# initialize task pipe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/easyFL/flgo/benchmark/base.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, *args, **kwarg)\u001b[0m\n\u001b[1;32m    409\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwarg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    410\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare_data_for_partition\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 411\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpartition\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    412\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpartition\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/easyFL/flgo/benchmark/base.py\u001b[0m in \u001b[0;36mpartition\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    412\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpartition\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 414\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlocal_datas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpartitioner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    415\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_clients\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlocal_datas\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/easyFL/flgo/benchmark/toolkits/partition.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    194\u001b[0m                     \u001b[0malter_prop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdel_prop\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msamples_per_client\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mexcid\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0msup_prop\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcid\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m                     \u001b[0malter_prop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0malter_prop\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0malter_prop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m                     \u001b[0merror_alter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malter_prop\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m                     \u001b[0malter_norms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_alter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malter_norms\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0merror_norm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/numpy/core/_methods.py\u001b[0m in \u001b[0;36m_sum\u001b[0;34m(a, axis, dtype, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m     46\u001b[0m def _sum(a, axis=None, dtype=None, out=None, keepdims=False,\n\u001b[1;32m     47\u001b[0m          initial=_NoValue, where=True):\n\u001b[0;32m---> 48\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mumr_sum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwhere\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m def _prod(a, axis=None, dtype=None, out=None, keepdims=False,\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "import flgo\n",
        "import flgo.benchmark.mnist_classification as mnist\n",
        "task = './test_mnist'\n",
        "config = {'benchmark':{'name':'flgo.benchmark.mnist_classification'},'partitioner':{'name': 'DirichletPartitioner','para':{'num_clients':100}}}\n",
        "flgo.gen_task(config, task_path = task)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YeajotfSf3pe"
      },
      "outputs": [],
      "source": [
        "task = './test_mnist'\n",
        "config = {'benchmark':{'name':'flgo.benchmark.mnist_classification'},'partitioner':{'name': 'IIDPartitioner','para':{'num_clients':100}}}\n",
        "if not os.path.exists(task): flgo.gen_task(config, task_path = task)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C0WbZTDRZDt6"
      },
      "source": [
        "# 生成联邦任务 \\ Generate Federated Task\n",
        "生成mnist的IID划分，人数为100人，代码如下："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 841
        },
        "id": "WNQlN_U7ZCWg",
        "outputId": "874ea49b-31f9-4f90-a1b6-303f52d8a144"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to /usr/local/lib/python3.10/dist-packages/flgo/benchmark/RAW_DATA/MNIST/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 9912422/9912422 [00:00<00:00, 280556793.60it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting /usr/local/lib/python3.10/dist-packages/flgo/benchmark/RAW_DATA/MNIST/MNIST/raw/train-images-idx3-ubyte.gz to /usr/local/lib/python3.10/dist-packages/flgo/benchmark/RAW_DATA/MNIST/MNIST/raw\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to /usr/local/lib/python3.10/dist-packages/flgo/benchmark/RAW_DATA/MNIST/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 28881/28881 [00:00<00:00, 41385614.56it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting /usr/local/lib/python3.10/dist-packages/flgo/benchmark/RAW_DATA/MNIST/MNIST/raw/train-labels-idx1-ubyte.gz to /usr/local/lib/python3.10/dist-packages/flgo/benchmark/RAW_DATA/MNIST/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to /usr/local/lib/python3.10/dist-packages/flgo/benchmark/RAW_DATA/MNIST/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1648877/1648877 [00:00<00:00, 192573480.26it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting /usr/local/lib/python3.10/dist-packages/flgo/benchmark/RAW_DATA/MNIST/MNIST/raw/t10k-images-idx3-ubyte.gz to /usr/local/lib/python3.10/dist-packages/flgo/benchmark/RAW_DATA/MNIST/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to /usr/local/lib/python3.10/dist-packages/flgo/benchmark/RAW_DATA/MNIST/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4542/4542 [00:00<00:00, 5293283.90it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting /usr/local/lib/python3.10/dist-packages/flgo/benchmark/RAW_DATA/MNIST/MNIST/raw/t10k-labels-idx1-ubyte.gz to /usr/local/lib/python3.10/dist-packages/flgo/benchmark/RAW_DATA/MNIST/MNIST/raw\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Task ./test_mnist has been successfully generated.\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "task = './test_mnist'\n",
        "config = {'benchmark':{'name':'flgo.benchmark.mnist_classification'},'partitioner':{'name': 'IIDPartitioner','para':{'num_clients':100}}}\n",
        "if not os.path.exists(task): flgo.gen_task(config, task_path = task)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "higxwB92WkZK"
      },
      "outputs": [],
      "source": [
        "import flgo.benchmark.mnist_classification as bmk_module\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 841
        },
        "id": "-ijLy8emd-ci",
        "outputId": "04b2cc0e-4532-416c-bee5-4657360d30a3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to /usr/local/lib/python3.10/dist-packages/flgo/benchmark/RAW_DATA/MNIST/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 9912422/9912422 [00:00<00:00, 94688452.98it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting /usr/local/lib/python3.10/dist-packages/flgo/benchmark/RAW_DATA/MNIST/MNIST/raw/train-images-idx3-ubyte.gz to /usr/local/lib/python3.10/dist-packages/flgo/benchmark/RAW_DATA/MNIST/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to /usr/local/lib/python3.10/dist-packages/flgo/benchmark/RAW_DATA/MNIST/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 28881/28881 [00:00<00:00, 55951821.63it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting /usr/local/lib/python3.10/dist-packages/flgo/benchmark/RAW_DATA/MNIST/MNIST/raw/train-labels-idx1-ubyte.gz to /usr/local/lib/python3.10/dist-packages/flgo/benchmark/RAW_DATA/MNIST/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to /usr/local/lib/python3.10/dist-packages/flgo/benchmark/RAW_DATA/MNIST/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1648877/1648877 [00:00<00:00, 23216103.14it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting /usr/local/lib/python3.10/dist-packages/flgo/benchmark/RAW_DATA/MNIST/MNIST/raw/t10k-images-idx3-ubyte.gz to /usr/local/lib/python3.10/dist-packages/flgo/benchmark/RAW_DATA/MNIST/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to /usr/local/lib/python3.10/dist-packages/flgo/benchmark/RAW_DATA/MNIST/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4542/4542 [00:00<00:00, 22760488.37it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting /usr/local/lib/python3.10/dist-packages/flgo/benchmark/RAW_DATA/MNIST/MNIST/raw/t10k-labels-idx1-ubyte.gz to /usr/local/lib/python3.10/dist-packages/flgo/benchmark/RAW_DATA/MNIST/MNIST/raw\n",
            "\n",
            "Task ./test_mnist has been successfully generated.\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# task为任务路径，可以自行定义，该目录将被视作一个联邦任务\n",
        "task = './test_mnist'\n",
        "# benchmark关键字指定的是数据集，partitioner关键字指定的是联邦学习数据集划分器\n",
        "config = {'benchmark':{'name':'flgo.benchmark.mnist_classification'},'partitioner':{'name': 'IIDPartitioner','para':{'num_clients':100}}}\n",
        "# 如果同名任务不存在，则生成该任务\n",
        "if not os.path.exists(task): flgo.gen_task(config, task_path = task)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CHkotQl2gOMk",
        "outputId": "66df873b-b411-41b1-e1f6-5da90ef34049"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-05-14 13:44:35,924 fflow.py init [line:442] INFO Initializing devices: cpu will be used for this running.\n",
            "2023-05-14 13:44:36,321 fflow.py init [line:480] INFO Use `<class 'flgo.simulator.default_simulator.Simulator'>` as the system simulator\n",
            "2023-05-14 13:44:36,329 fflow.py init [line:488] INFO Ready to start.\n",
            "2023-05-14 13:44:36,334 fedbase.py run [line:236] INFO --------------Initial Evaluation--------------\n",
            "2023-05-14 13:44:36,337 simple_logger.py log_once [line:14] INFO Current_time:0\n",
            "2023-05-14 13:45:04,570 simple_logger.py log_once [line:28] INFO test_accuracy                 0.0845\n",
            "2023-05-14 13:45:04,572 simple_logger.py log_once [line:28] INFO test_loss                     2.3038\n",
            "2023-05-14 13:45:04,576 simple_logger.py log_once [line:28] INFO valid_accuracy                0.0772\n",
            "2023-05-14 13:45:04,579 simple_logger.py log_once [line:28] INFO mean_valid_accuracy           0.0772\n",
            "2023-05-14 13:45:04,581 simple_logger.py log_once [line:28] INFO std_valid_accuracy            0.0365\n",
            "2023-05-14 13:45:04,583 simple_logger.py log_once [line:28] INFO valid_loss                    2.3038\n",
            "2023-05-14 13:45:04,586 simple_logger.py log_once [line:28] INFO mean_valid_loss               2.3038\n",
            "2023-05-14 13:45:04,587 simple_logger.py log_once [line:28] INFO std_valid_loss                0.0076\n",
            "2023-05-14 13:45:04,588 fedbase.py run [line:239] INFO Eval Time Cost:               28.2510s\n",
            "2023-05-14 13:45:25,202 fedbase.py run [line:246] INFO --------------Round 1--------------\n",
            "2023-05-14 13:45:25,204 simple_logger.py log_once [line:14] INFO Current_time:1\n",
            "2023-05-14 13:45:41,344 simple_logger.py log_once [line:28] INFO test_accuracy                 0.6480\n",
            "2023-05-14 13:45:41,351 simple_logger.py log_once [line:28] INFO test_loss                     1.5871\n",
            "2023-05-14 13:45:41,356 simple_logger.py log_once [line:28] INFO valid_accuracy                0.6348\n",
            "2023-05-14 13:45:41,359 simple_logger.py log_once [line:28] INFO mean_valid_accuracy           0.6348\n",
            "2023-05-14 13:45:41,361 simple_logger.py log_once [line:28] INFO std_valid_accuracy            0.0616\n",
            "2023-05-14 13:45:41,362 simple_logger.py log_once [line:28] INFO valid_loss                    1.6084\n",
            "2023-05-14 13:45:41,364 simple_logger.py log_once [line:28] INFO mean_valid_loss               1.6084\n",
            "2023-05-14 13:45:41,365 simple_logger.py log_once [line:28] INFO std_valid_loss                0.0485\n",
            "2023-05-14 13:45:41,366 fedbase.py run [line:251] INFO Eval Time Cost:               16.1625s\n",
            "2023-05-14 13:46:06,728 fedbase.py run [line:246] INFO --------------Round 2--------------\n",
            "2023-05-14 13:46:06,729 simple_logger.py log_once [line:14] INFO Current_time:2\n",
            "2023-05-14 13:46:23,497 simple_logger.py log_once [line:28] INFO test_accuracy                 0.7504\n",
            "2023-05-14 13:46:23,500 simple_logger.py log_once [line:28] INFO test_loss                     1.3000\n",
            "2023-05-14 13:46:23,503 simple_logger.py log_once [line:28] INFO valid_accuracy                0.7248\n",
            "2023-05-14 13:46:23,506 simple_logger.py log_once [line:28] INFO mean_valid_accuracy           0.7248\n",
            "2023-05-14 13:46:23,508 simple_logger.py log_once [line:28] INFO std_valid_accuracy            0.0542\n",
            "2023-05-14 13:46:23,510 simple_logger.py log_once [line:28] INFO valid_loss                    1.3321\n",
            "2023-05-14 13:46:23,511 simple_logger.py log_once [line:28] INFO mean_valid_loss               1.3321\n",
            "2023-05-14 13:46:23,512 simple_logger.py log_once [line:28] INFO std_valid_loss                0.0693\n",
            "2023-05-14 13:46:23,513 fedbase.py run [line:251] INFO Eval Time Cost:               16.7843s\n",
            "2023-05-14 13:46:44,925 fedbase.py run [line:246] INFO --------------Round 3--------------\n",
            "2023-05-14 13:46:44,927 simple_logger.py log_once [line:14] INFO Current_time:3\n",
            "2023-05-14 13:47:01,089 simple_logger.py log_once [line:28] INFO test_accuracy                 0.7946\n",
            "2023-05-14 13:47:01,092 simple_logger.py log_once [line:28] INFO test_loss                     0.6330\n",
            "2023-05-14 13:47:01,096 simple_logger.py log_once [line:28] INFO valid_accuracy                0.7770\n",
            "2023-05-14 13:47:01,099 simple_logger.py log_once [line:28] INFO mean_valid_accuracy           0.7770\n",
            "2023-05-14 13:47:01,101 simple_logger.py log_once [line:28] INFO std_valid_accuracy            0.0557\n",
            "2023-05-14 13:47:01,103 simple_logger.py log_once [line:28] INFO valid_loss                    0.6593\n",
            "2023-05-14 13:47:01,105 simple_logger.py log_once [line:28] INFO mean_valid_loss               0.6593\n",
            "2023-05-14 13:47:01,106 simple_logger.py log_once [line:28] INFO std_valid_loss                0.0967\n",
            "2023-05-14 13:47:01,107 fedbase.py run [line:251] INFO Eval Time Cost:               16.1799s\n",
            "2023-05-14 13:47:23,286 fedbase.py run [line:246] INFO --------------Round 4--------------\n",
            "2023-05-14 13:47:23,289 simple_logger.py log_once [line:14] INFO Current_time:4\n",
            "2023-05-14 13:47:38,900 simple_logger.py log_once [line:28] INFO test_accuracy                 0.8516\n",
            "2023-05-14 13:47:38,902 simple_logger.py log_once [line:28] INFO test_loss                     0.4854\n",
            "2023-05-14 13:47:38,906 simple_logger.py log_once [line:28] INFO valid_accuracy                0.8372\n",
            "2023-05-14 13:47:38,910 simple_logger.py log_once [line:28] INFO mean_valid_accuracy           0.8372\n",
            "2023-05-14 13:47:38,914 simple_logger.py log_once [line:28] INFO std_valid_accuracy            0.0484\n",
            "2023-05-14 13:47:38,917 simple_logger.py log_once [line:28] INFO valid_loss                    0.5127\n",
            "2023-05-14 13:47:38,920 simple_logger.py log_once [line:28] INFO mean_valid_loss               0.5127\n",
            "2023-05-14 13:47:38,921 simple_logger.py log_once [line:28] INFO std_valid_loss                0.0939\n",
            "2023-05-14 13:47:38,923 fedbase.py run [line:251] INFO Eval Time Cost:               15.6340s\n",
            "2023-05-14 13:48:02,602 fedbase.py run [line:246] INFO --------------Round 5--------------\n",
            "2023-05-14 13:48:02,603 simple_logger.py log_once [line:14] INFO Current_time:5\n",
            "2023-05-14 13:48:18,322 simple_logger.py log_once [line:28] INFO test_accuracy                 0.9166\n",
            "2023-05-14 13:48:18,324 simple_logger.py log_once [line:28] INFO test_loss                     0.3060\n",
            "2023-05-14 13:48:18,328 simple_logger.py log_once [line:28] INFO valid_accuracy                0.9033\n",
            "2023-05-14 13:48:18,331 simple_logger.py log_once [line:28] INFO mean_valid_accuracy           0.9033\n",
            "2023-05-14 13:48:18,333 simple_logger.py log_once [line:28] INFO std_valid_accuracy            0.0414\n",
            "2023-05-14 13:48:18,335 simple_logger.py log_once [line:28] INFO valid_loss                    0.3309\n",
            "2023-05-14 13:48:18,337 simple_logger.py log_once [line:28] INFO mean_valid_loss               0.3309\n",
            "2023-05-14 13:48:18,338 simple_logger.py log_once [line:28] INFO std_valid_loss                0.0892\n",
            "2023-05-14 13:48:18,338 fedbase.py run [line:251] INFO Eval Time Cost:               15.7349s\n",
            "2023-05-14 13:48:18,347 fedbase.py run [line:257] INFO =================End==================\n",
            "2023-05-14 13:48:18,348 fedbase.py run [line:258] INFO Total Time Cost:              222.0143s\n"
          ]
        }
      ],
      "source": [
        "fedavg_runner = flgo.init(task=task, algorithm=fedavg, option={'num_rounds':5, 'num_epochs':1})\n",
        "#fedavg_runner = flgo.init(task=task, algorithm=fedavg, option={'num_rounds':5, 'num_epochs':1, 'gpu':0})\n",
        "fedavg_runner.run()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 887
        },
        "id": "RKiYAn2InbcS",
        "outputId": "ca9262ba-26f6-4df2-9b6f-c673287e8cc3"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import flgo.experiment.analyzer\n",
        "analysis_plan = {\n",
        "    'Selector':{\n",
        "        'task': task,\n",
        "        'header':['fedavg']\n",
        "    },\n",
        "    'Painter':{\n",
        "        'Curve':[\n",
        "            {'args':{'x': 'communication_round', 'y':'valid_loss'}, 'fig_option':{'title':'valid loss on MNIST'}},\n",
        "            {'args':{'x': 'communication_round', 'y':'valid_accuracy'},  'fig_option':{'title':'valid accuracy on MNIST'}},\n",
        "        ]\n",
        "    }\n",
        "}\n",
        "flgo.experiment.analyzer.show(analysis_plan)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A4SdFXL_PfpQ",
        "outputId": "156b1def-fdba-4a35-8a04-59f0904857f6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (2.27.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests) (3.4)\n",
            "Total projects: 68\n",
            "https://github.com/EasyFL-AI/EasyFL\n",
            "https://github.com/WilliamXu96/ABP-MicroService\n",
            "https://github.com/JDEasyFlow/jd-easyflow\n",
            "https://github.com/MagerValp/u4remastered\n",
            "https://github.com/azzhu/EasyFlyTracker\n",
            "https://github.com/YashMakan/easy-flask-swagger\n",
            "https://github.com/EasyFL-AI/EasyFL\n",
            "https://github.com/Joey61Liuyi/FedAA\n",
            "https://github.com/azzhu/EasyFlyTracker\n",
            "https://github.com/EasyFL-AI/EasyFL\n",
            "https://github.com/fernandonieuwveldt/easyflow\n",
            "https://github.com/WilliamXu96/ABP-MicroService\n",
            "https://github.com/EasyFL-AI/EasyFL\n",
            "https://github.com/Joey61Liuyi/FedAA\n",
            "https://github.com/SkiingIsFun123/EasyFlash\n",
            "https://github.com/peterkrull/EIT5-B2-209-Autonomous-Drone\n",
            "https://github.com/zypp-io/easyflex\n",
            "https://github.com/YashMakan/easy-flask-swagger\n",
            "https://github.com/EasyFL-AI/EasyFL\n",
            "https://github.com/azzhu/EasyFlyTracker\n",
            "https://github.com/zypp-io/easyflex\n",
            "https://github.com/fernandonieuwveldt/easyflow\n",
            "https://github.com/EasyFL-AI/EasyFL\n",
            "https://github.com/peterkrull/EIT5-B2-209-Autonomous-Drone\n",
            "https://github.com/EasyFL-AI/EasyFL\n",
            "https://github.com/EasyFL-AI/EasyFL\n",
            "https://github.com/EasyFL-AI/EasyFL\n",
            "https://github.com/fernandonieuwveldt/easyflow\n",
            "https://github.com/EasyFL-AI/EasyFL\n",
            "https://github.com/EasyFL-AI/EasyFL\n"
          ]
        }
      ],
      "source": [
        "!pip install requests\n",
        "import requests\n",
        "\n",
        "# 设置 GitHub Personal Access Token\n",
        "access_token = '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'\n",
        "\n",
        "# 设置搜索关键字\n",
        "search_query = '\"import easyfl\"'\n",
        "\n",
        "# 发送搜索请求\n",
        "search_url = f'https://api.github.com/search/code?q={search_query}'\n",
        "headers = {'Authorization': f'token {access_token}'}\n",
        "response = requests.get(search_url, headers=headers)\n",
        "response_json = response.json()\n",
        "\n",
        "# 提取项目总数\n",
        "total_count = response_json['total_count']\n",
        "print(f'Total projects: {total_count}')\n",
        "\n",
        "# 获取所有项目的 URL\n",
        "project_urls = [item['repository']['html_url'] for item in response_json['items']]\n",
        "\n",
        "# 打印项目 URL\n",
        "for url in project_urls:\n",
        "    print(url)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f1SNOjxrRo_2",
        "outputId": "96dd844d-77cd-4f40-c754-74900a0b2e91"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total projects: 0\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "import base64\n",
        "\n",
        "# 设置 GitHub Personal Access Token\n",
        "access_token = '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'\n",
        "\n",
        "# 设置搜索关键字\n",
        "search_query = 'import easyfl'\n",
        "\n",
        "# 发送搜索请求\n",
        "search_url = f'https://api.github.com/search/code?q={search_query}'\n",
        "headers = {'Authorization': f'token {access_token}'}\n",
        "response = requests.get(search_url, headers=headers)\n",
        "response_json = response.json()\n",
        "\n",
        "# 过滤出精确匹配的 import 语句\n",
        "exact_matches = []\n",
        "for item in response_json['items']:\n",
        "    download_url = item['repository']['contents_url'].replace('{+path}', item['path'])\n",
        "    file_content = requests.get(download_url, headers=headers).json()\n",
        "    if file_content and file_content.get('content'):\n",
        "        content = file_content['content']\n",
        "        decoded_content = base64.b64decode(content).decode('utf-8')\n",
        "        if f'\"{search_query}\"' in decoded_content or f\"'{search_query}'\" in decoded_content:\n",
        "            exact_matches.append(item['repository']['html_url'])\n",
        "\n",
        "# 提取项目总数\n",
        "total_count = len(exact_matches)\n",
        "print(f'Total projects: {total_count}')\n",
        "\n",
        "# 打印项目 URL\n",
        "for url in exact_matches:\n",
        "    print(url)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aE_UOkVgRLdJ"
      },
      "source": [
        "# 反向传播\n",
        "https://zhang-yang.medium.com/the-gradient-argument-in-pytorchs-backward-function-explained-by-examples-68f266950c29"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B5GeNT0cRNmE"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "from torch import tensor\n",
        "from numpy import array"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FUIHOWfJRX68"
      },
      "source": [
        "## 输入是标量，输出是标量\n",
        "首先，一个简单的例子，其中 $x=1$ 和 $y = x^2$ 都是标量。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zyDyPi-ORQ3h",
        "outputId": "602fef9b-6b64-4028-f528-87b3f3ead81a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "x: tensor(1., requires_grad=True)\n",
            "y: tensor(1., grad_fn=<PowBackward0>)\n",
            "x.grad: tensor(2.)\n"
          ]
        }
      ],
      "source": [
        "x = tensor(1., requires_grad=True)\n",
        "print('x:', x)\n",
        "y = x**2\n",
        "print('y:', y)\n",
        "y.backward() # this is the same as y.backward(tensor(1.))\n",
        "print('x.grad:', x.grad)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GUMT50OeRno8"
      },
      "source": [
        "现在手动计算 Jacobian J（雅可比）。在这种情况下，x 和 y 都是标量（每个分别只有一个分量 $x_1$ 和 $y_1$）。我们有\n",
        "![image.png](data:image/png;base64,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)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1d_RxZrKRkhH",
        "outputId": "eedff2b6-05ca-47b1-8274-eba4585dc347"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "J: [[2.]]\n"
          ]
        }
      ],
      "source": [
        "x = x.detach().numpy()\n",
        "J = array([[2*x]])\n",
        "print('J:', J)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CX3YKi_USnFE",
        "outputId": "fab67775-1407-40e1-d531-022b31329a9f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "x: tensor(-1., requires_grad=True)\n",
            "y: tensor(4., grad_fn=<PowBackward0>)\n",
            "x.grad: tensor(-4.)\n"
          ]
        }
      ],
      "source": [
        "x = tensor(-1., requires_grad=True)\n",
        "print('x:', x)\n",
        "y = (x-1)**2\n",
        "print('y:', y)\n",
        "y.backward() # this is the same as y.backward(tensor(1.))\n",
        "print('x.grad:', x.grad)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GoqeSEelyV5i",
        "outputId": "6caa2513-065e-4a08-9aba-524795780d3a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "x: tensor(-1., requires_grad=True)\n",
            "y: tensor(2., grad_fn=<AbsBackward0>)\n",
            "x.grad: tensor(-1.)\n"
          ]
        }
      ],
      "source": [
        "x = tensor(-1., requires_grad=True)\n",
        "print('x:', x)\n",
        "y = (x-1).abs()\n",
        "print('y:', y)\n",
        "y.backward() # this is the same as y.backward(tensor(1.))\n",
        "print('x.grad:', x.grad)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "08a7c7d8fef14323a13b43aa7a1dddb9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "VBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_cebaa5c272a143c5bcd266f519fc9ac0",
              "IPY_MODEL_527272c4dbd24880a7481b26bb93d339"
            ],
            "layout": "IPY_MODEL_216b149c52f443569b098cd8e9ab78f0"
          }
        },
        "1dfb66d8c1d34eba9e2d40481fa2f88a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "216b149c52f443569b098cd8e9ab78f0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "527272c4dbd24880a7481b26bb93d339": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_770859fd9af14213aeb55400247f1d79",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_61416b9acadf44e9a8e4a175665513a0",
            "value": 0.12110409452026889
          }
        },
        "61416b9acadf44e9a8e4a175665513a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "770859fd9af14213aeb55400247f1d79": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7e03033100384238a6546b96366c624c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cebaa5c272a143c5bcd266f519fc9ac0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "LabelModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1dfb66d8c1d34eba9e2d40481fa2f88a",
            "placeholder": "​",
            "style": "IPY_MODEL_7e03033100384238a6546b96366c624c",
            "value": "0.001 MB of 0.009 MB uploaded (0.000 MB deduped)\r"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}